\def\stat{shestakov}

\def\tit{О СТАТИСТИЧЕСКИХ СВОЙСТВАХ ОЦЕНКИ РИСКА
В~ЗАДАЧЕ ОБРАЩЕНИЯ ПРЕОБРАЗОВАНИЯ РАДОНА
ПРИ~СЛУЧАЙНОМ ОБЪЕМЕ ПРОЕКЦИОННЫХ ДАННЫХ$^*$}

\def\titkol{О статистических свойствах оценки риска
в~задаче обращения преобразования Радона
при~случайном объеме} % проекционных данных}

\def\aut{О.\,В.~Шестаков$^1$}

\def\autkol{О.\,В.~Шестаков}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Шестаков О.\,В.}
\index{Shestakov O.\,V.}
 

{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Работа выполнена при финансовой поддержке РФФИ (проект 19-07-00352)
и в соответствии с программой Московского цент\-ра 
фундаментальной и~прикладной математики.}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский государственный университет им.\ М.\,В.~Ломоносова, 
кафедра математической статистики факультета вычислительной математики 
и~кибернетики; Институт проб\-лем информатики Федерального исследовательского 
центра <<Информатика и~управ\-ле\-ние>> Российской академии наук, 
\mbox{oshestakov@cs.msu.su}}

\vspace*{-12pt}



\Abst{При реконструкции томографических изображений необходимо решать
 задачу подавления шума, возникающего при регистрации проекционных данных. 
 Методы решения этой задачи, основанные на вейв\-лет-ал\-го\-рит\-мах 
 и~процедурах пороговой обработки, обладают рядом преимуществ, включая 
 вычислительную эффективность и~возможность адаптации к~локальным особенностям 
 изображений. Анализ погрешностей этих методов представляет собой важную 
 практическую задачу, поскольку дает возможность оценить качество как 
 самих методов, так и~используемого оборудования. При использовании методов 
 пороговой обработки обычно предполагается, что число коэффициентов 
 разложения фиксировано, а~распределение шума гауссово. Эта модель 
 хорошо изучена в~литературе, и~для разных классов функций вычислены 
 оптимальные значения порогов. Однако в~некоторых ситуациях объем выборки 
 заранее не фиксирован и~его приходится моделировать некоторой случайной 
 величиной.
   В~данной работе рассматривается модель со случайным числом 
 наблюдений и~исследуются асимптотические свойства оценки среднеквадратичного 
 риска. Доказывается, что предельное распределение этой оценки принадлежит 
 классу сдвиг-масш\-таб\-ных смесей нормальных законов.}

\KW{пороговая обработка; случайный объем выборки; преобразование
 Радона; оценка среднеквадратичного риска}
 
\DOI{10.14357/19922264200306} 
 
\vspace*{-6pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}


\section{Введение}

Задачи реконструкции изображений по проекциям возникают во многих 
прикладных областях, включая медицину, биологию, астрономию, 
физику плазмы и~многие другие. Большинство математических методов 
реконструкции основано на обращении так называемого преобразования 
Радона, которое описывает проекционные данные.

 Преобразование 
Радона является линейным и~однородным, и~поэтому для его обращения 
оказываются применимыми методы вейв\-лет-ана\-ли\-за и~пороговой обработки, 
позволяющие эффективно подавлять шум, возникающий при регистрации проекционных 
данных. Эти методы получили развитие в~работах~\cite{D94, Kol94, Lee97}, 
в~которых оценивается порядок среднеквадратичного риска и~описываются 
алгоритмы вычисления оптимальных параметров пороговой обработки. 
%
Также изучены статистические свойства оценки среднеквадратичного риска,
 позволяющей судить о~качестве реконструкции на основе только наблюдаемых 
 данных. Показано, что при определенных условиях она является сильно 
 состоятельной и~асимптотически нормальной~\cite{SH16-1}.

В некоторых случаях объем данных, доступных для анализа, заранее 
не известен. Такие ситуации могут возникать, например, в~случае пропуска 
данных или недостатке информации о~характеристиках используемого оборудования. 
В~таком случае предполагается, что объем выборки данных представляет собой 
случайную величину с~некоторым заданным распределением.

 В~данной работе рассматривается модель со случайным числом <<загрязненных>> 
 белым гауссовым шумом коэффициентов разложения функции, описывающей 
 проекционные данные томографического изображения. Показано, что 
 предельное распределение оценки среднеквадратичного риска уже не 
 обязано быть нормальным.
 
 \vspace*{-6pt}

\section{Обращение преобразования Радона 
с~помощью метода вейвлет--вейглет-разложения}

Математическая модель задачи реконструкции\linebreak томографических 
изображений основана на так\linebreak называемом преобразовании Радона. 
Обозначим через $\mathrm{Lip}(\gamma,L)$ класс равномерно регулярных 
по Липшицу функций, где $\gamma$~--- показатель, а~$L$~--- 
константа Липшица~\cite{Mall99}. Пусть изображение описывается
 функцией $f(x,y)\hm\in\mathrm{Lip}(\gamma,L)$ с~компактным носителем 
 (без ограничения общности будем считать, что это круг единичного 
 радиуса с~центром в~начале координат) и~некоторым показателем $\gamma\hm>0$. 
 Преобразованием Радона функции~$f$ называется преобразование вида:
\begin{equation*}
\mathrm{Rf}\left(s,\theta\right) = \int\limits_{L_{s,\theta}} f(x,y)\, dl\,,
\end{equation*}
где
\begin{equation*}
L_{s,\theta} = \left\{(x,y)\colon x\cos\theta + y\sin\theta - s = 0 \right\}.
\end{equation*}

Одним из возможных методов обращения преобразования~$\mathrm{Rf}$ служит метод 
вейв\-лет--вейг\-лет-раз\-ло\-же\-ния~\cite{D94}.

Пусть заданы $\phi(x)$ и~$\psi(x)$~--- отцовская и~материнская вейв\-лет-функ\-ции.
Определим
\begin{equation}
\left.
\begin{array}{rl}
\psi_{j,k_1,k_2}^{[1]} (x,y) &= 2^j \phi\left(2^j x - k_1\right) \psi\left(2^j y - k_2\right);\\[6pt]
\psi_{j,k_1,k_2}^{[2]} (x,y) &= 2^j \psi\left(2^j x - k_1\right) \phi\left(2^j y - k_2\right);\\[6pt]
\psi_{j,k_1,k_2}^{[3]} (x,y) &= 2^j \psi\left(2^j x - k_1\right) \psi\left(2^j y - k_2\right).
\end{array}
\right\}
\label{vaguelette_2d}
\end{equation}
Семейство $\{\psi^{[\lambda]}_{j,k_1,k_2}\}$
образует ортонормированный базис в~$L^2(\mathbb{R}^2)$. Индекс~$j$ 
в~(\ref{vaguelette_2d}) называется масштабом, а~индексы $k_1$ и~$k_2$~---
сдвигами. В~данной работе предполагается, что используются вейвлеты 
Мейера~\cite{Mall99}, имеющие~$M$ непрерывных производных ($M\hm\geqslant\gamma$).

Вейвлет-разложение функции $f$ имеет вид:
\begin{equation*}                                                                   
%\label{waveletdecomp}
f = \sum\limits_{\lambda,j,k_1,k_2}\left \langle 
f,\psi^{[\lambda]}_{j,k_1,k_2}\right\rangle \psi^{[\lambda]}_{j,k_1,k_2}.
\end{equation*}


Определим функции $\xi_{j,k_1,k_2}^{[\lambda]}(s,\theta)$:
\begin{equation*}
\xi_{j,k_1,k_2}^{[\lambda]}(s,\theta) = 
\fr{2^{-j/2}}{4\pi} I^{-1}\left[R\psi_{j,k_1,k_2}^{[\lambda]}
\right](s,\theta),
\end{equation*}
где $I^{\alpha}$~--- потенциал Рисса, определяемый в~пространстве 
Фурье по формуле $\widehat{I^{\alpha} g}(\omega) \hm= 
|w|^{-\alpha} \widehat{g}(\omega)$.
Эти функции называются <<вейглетами>>~\cite{D94}. 
Для них справедливо соотношение
\begin{equation*}
\left\langle f,\psi_{j,k_1,k_2}^{[\lambda]}\right\rangle=
2^{j/2}\left\langle \mathrm{Rf}, \xi_{j,k_1,k_2}^{[\lambda]}\right\rangle.
\end{equation*}
Последовательность $\{\xi_{j,k_1,k_2}^{[\lambda]}\}$ 
образует устойчивый базис~\cite{Lee97}, и~вейв\-лет-вейг\-лет--раз\-ло\-же\-ние~$f$ 
имеет вид:
\begin{equation}                                                                   
\label{WVD}
f = \sum\limits_{\lambda,j,k_1,k_2} 2^{j/2}\left\langle \mathrm{Rf}, 
\xi_{j,k_1,k_2}^{[\lambda]}\right\rangle \psi^{[\lambda]}_{j,k_1,k_2}.
\end{equation}
В разложении~\eqref{WVD} используются только проекционные данные, 
и~оно служит основой метода реконструкции.

\vspace*{-6pt}

\section{Метод подавления шума, основанный на~пороговой обработке}

В практических задачах изображение описывается дискретными
 отсчетами некоторой функции. При этом, поскольку носителем 
 функции выступает единичный круг, $(s,\theta)\hm\in [-1,1]\times[0,\pi]$ 
 и~модель зашумленных проекционных данных, рас\-смат\-ри\-ва\-емая в~данной работе, 
 выглядит следующим об\-разом:
 
 \noindent
\begin{multline*}
Y_{i,j} = \mathrm{Rf}\left(-1+\fr{2i}{N},\fr{j\pi}{N}\right) + e_{i,j}, \\
i = 1, \dots, N, \enskip j = 1, \dots, N,
\end{multline*}
где $N=2^J$ для некоторого $J\hm>0$. Предполагается, что~$e_{i,j}$ 
независимы и~имеют нормальное распределение с~нулевым 
средним и~дисперсией~$\sigma^2$.
Тогда в~дискретном аналоге вейв\-лет--вейг\-лет-раз\-ло\-же\-ния 
коэффициенты описываются моделью~\cite{ESH14}:
\begin{equation}
X_{j,k_1,k_2}^{[\lambda]} = \mu_{j,k_1,k_2}^{[\lambda]} + 
 e_{j,k_1,k_2}^{[\lambda]},
\label{WVD_model}
\end{equation}
где 

\noindent
$$
\mu_{j,k_1,k_2}^{[\lambda]} =  2^J\left\langle \mathrm{Rf}, 
\xi_{j,k_1,k_2}^{[\lambda]}\right\rangle;
$$
$e^{[\lambda]}_{j,k_1,k_2}$ 
имеют нормальное распределение с~нулевым средним 
и~дисперсией~$\sigma^2_\lambda$ ($\lambda\hm=1,2,3$). Эти коэффициенты 
уже не являются независимыми. Значение~$\sigma^2_\lambda$ зависит от 
выбранного вейв\-лет-ба\-зи\-са и~$\lambda$, но не зависит 
от~$k_1$, $k_2$ и~$j$.

Для подавления шума и~построения оценок 
коэффициентов~$\mu_{j,k_1,k_2}^{[\lambda]}$, как правило, используется 
пороговая обработка зашумленных коэффициентов модели~\eqref{WVD_model}. 
Смысл этой обработки заключается в~удалении достаточно маленьких 
коэффициентов, которые считаются шумом. Оценки~$\mu_{j,k_1,k_2}^{[\lambda]}$ 
вы\-чис\-ля\-ют\-ся с~по\-мощью функции пороговой обработки~$\rho(x,T_{\lambda})$ 
с~некоторым порогом~$T_{\lambda}$: 

\noindent
$$
\widehat{\mu}_{j,k_1,k_2}^{[\lambda]}
=\rho\left(X_{j,k_1,k_2}^{[\lambda]},T_{\lambda}\right)\,.
$$
 
В~данной работе предполагается, что используется функция жесткой 
пороговой обработки $\rho_{H}(x,T_{\lambda})\hm=x\mathbf{1}(\abs{x}\hm>T_{\lambda})$ 
или мягкой пороговой обработки 
$\rho_{S}(x,T_{\lambda})\hm=\mathrm{sgn}\,(x)\left(\abs{x}\hm-
T_{\lambda}\right)_{+}$.

\pagebreak

Среднеквадратичный риск метода пороговой обработки определяется по формуле:

\vspace*{2pt}

\noindent
\begin{equation}
\label{Risk_Definition}
r_J = \sum\limits_{j = 0}^{J - 1}\sum\limits_{k_1=0}^{2^j-1}
\sum\limits_{k_2=0}^{2^j-1}\sum\limits_{\lambda=1}^3 2^j
{\sf E}\left(\widehat{\mu}_{j,k_1,k_2}^{[\lambda]}-
\mu_{j,k_1,k_2}^{[\lambda]} \right)^2.
\end{equation}

Выражение~(\ref{Risk_Definition}) можно использовать только 
для вычисления величины риска в~<<модельных>> ситуациях (при известной 
функции изображения) для тес\-ти\-ро\-ва\-ния оборудования, поскольку оно 
содержит значения <<чистых>> коэффициентов~$\mu_{j,k_1,k_2}^{[\lambda]}$. 
В~случае когда функция сигнала неизвестна, можно построить статистическую
 оценку~$r_J$. Если в~сла\-га\-емом $\vert X_{j,k_1,k_2}^{[\lambda]}\vert\hm>T$, 
 то вклад этого слагаемого в~риск составляет~$2^j\sigma^2$ в~случае жесткой 
 и~$2^j(\sigma^2+T^2)$ в~случае мягкой пороговой обработки, а~если 
 $\vert X_{j,k_1,k_2}^{[\lambda]}\vert\hm\leqslant T$, то вклад 
 составляет~$2^j(\mu_{j,k_1,k_2}^{[\lambda]})^2$ в~обоих случаях.
  Неизвестную величину~$(\mu_{j,k_1,k_2}^{[\lambda]})^2$ 
  можно\linebreak оценить разностью $(X_{j,k_1,k_2}^{[\lambda]})^2
  \hm-\sigma^2$, поскольку 
  
  \vspace*{3pt}
  
\noindent
  $$
  {\sf E} \left(X_{j,k_1,k_2}^{[\lambda]}\right)^2
  =\sigma^2+\left(\mu_{j,k_1,k_2}^{[\lambda]}\right)^2.
  $$
  
   Таким образом, 
  в~качестве оценки сред\-не\-квад\-ра\-тич\-но\-го риска можно использовать величину:
  
  \vspace*{2pt}
  
  \noindent
\begin{equation*}% \label{MSE_Estimate}
\widehat{r}_J=\sum\limits_{j = 0}^{J - 1}
\sum\limits_{k_1=0}^{2^j-1}\sum\limits_{k_2=0}^{2^j-1}
\sum\limits_{\lambda=1}^3 2^jF\left[X_{j,k_1,k_2}^{[\lambda]}\right],
\end{equation*}
где 

\vspace*{-5pt}

\noindent
\begin{multline*}
F\left[X_{j,k_1,k_2}^{[\lambda]}\right]={}\\
{}=
\begin{cases}
\left(\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2
-\sigma^2\right)\mathbf{1}\left(\left\vert
X_{j,k_1,k_2}^{[\lambda]}\right\vert \leqslant T\right)+{}&\\[6pt]
{}+
\sigma^2\mathbf{1}\left(\left\vert 
X_{j,k_1,k_2}^{[\lambda]}\right\vert >T\right)
&
\hspace*{-15mm}\mbox{в~случае}\\[3pt]
&\hspace*{-47mm}\mbox{жесткой\ пороговой\ обработки};\\[6pt]
\left(\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2-
\sigma^2\right)\mathbf{1}\left(\left\vert X_{j,k_1,k_2}^{[\lambda]}\right\vert
\leqslant T\right)
+{}&\\[3pt]
{}+\left(\sigma^2+T^2\right)\mathbf{1}\left(\left\vert
X_{j,k_1,k_2}^{[\lambda]}\right\vert >T\right) & 
\hspace*{-15mm}\mbox{в~случае}\\[6pt]
&\hspace*{-47mm}\mbox{мягкой\ пороговой\ обработки}.
\end{cases}
\end{multline*}

\vspace*{-3pt}

\noindent
 При мягкой пороговой обработке 
эта оценка оказывается несмещенной~\cite{Mall99}. Кроме того, 
справедливо утверждение об асимптотической нор\-маль\-ности~$\widehat{r}_J$~\cite{SH16-1}.

\vspace*{3pt}

\noindent
\textbf{Теорема~1.}\ \textit{Если $f\in\mathrm{Lip}(\gamma,L)$ c~$\gamma\hm>1/2$, 
то при выборе асимптотически оптимального порога} 

\vspace*{2pt}

\noindent
\begin{equation*}% \label{risk_norm}
\p\left(\fr{\widehat{r}_J - r_J}{ D_J }<x\right) \to \Phi(x) \enskip
\mbox{при } J \rightarrow \infty\,,
\end{equation*}
\textit{где $\Phi(x)$ --- 
функция распределения стандартного нормального закона, 
а $D_J\hm=C_R2^{2J}$, где константа~$C_R$ зависит от используемого базиса. 
Метод вычисления этой константы описан в}~\cite{SH16-1}.

\smallskip

Асимптотически оптимальный порог в~теореме~1 при $J\hm\to\infty$ 
удовлетворяет соотношению~\cite{Jan01}:
$$
T\simeq\sigma\sqrt{\fr{6\gamma+3}{2\gamma+3}\ln2^{2J}}\,.
$$

В следующем разделе показано, что в~модели со случайным числом 
вейв\-лет-ко\-эф\-фи\-ци\-ен\-тов предельное распределение оценки риска уже 
не обязано быть нормальным.

\vspace*{-6pt}

\section{Случайное число коэффициентов разложения}

Пусть $M$~--- положительная целочисленная случайная величина и~$N\hm=2^M$.
 Тогда оценка среднеквадратичного риска принимает вид:
 
 \vspace*{2pt}
 
 \noindent
\begin{equation}
\label{MSE_Estimate_Rand}
\widehat{R}_{M}=\sum\limits_{j=0}^{M-1}\sum\limits_{k_1=0}^{2^j-1}
\sum\limits_{k_2=0}^{2^j-1}\sum\limits_{\lambda=1}^3 2^j 
F\left[X_{j,k_1,k_2}^{[\lambda]}\right].
\end{equation}

Чтобы получились осмысленные асимптотические результаты для 
оценки~\eqref{MSE_Estimate_Rand}, величина~$M$ должна быть <<большой>>. 
Рассмотрим последовательность~$M_J$, $J\hm=1,\ldots$, и~исследуем 
поведение~\eqref{MSE_Estimate_Rand} при $J\hm\to \infty$.

\smallskip

\noindent
\textbf{Теорема 2.} \textit{Пусть выполнены условия теоремы~1. Пусть также
 $M_J\xrightarrow{{\sf P}}\infty$ и~для некоторой последовательности~$R_J$ 
 совместное распределение пар}
$$(U_J,V_J)\equiv\left(\fr{2^{4M_J}}{2^{4J}},\fr{r_{M_J}-R_J}{D_J}\right)$$  
\textit{сходится к~распределению некоторого случайного вектора}
$(U,V)$ \textit{при $J\to\infty$. Тогда}

\vspace*{-1pt}

\noindent
\begin{align}
\label{rand_risk_dist}
\p\left(\fr{\widehat{R}_{M_J} - R_J}{ D_J }<x\right) \to H(x) \enskip
\mbox{при } J \rightarrow \infty,
\end{align}

\vspace*{-2pt}

\noindent
\textit{где $H(x)$~--- функция распределения, соответствующая 
характеристической функции} $h(t)\hm={\sf E}\varphi(t\sqrt{U})e^{itV}$ 
($\varphi(t)$~--- \textit{характеристическая функция стандартного 
нормального закона)}.

\vspace*{2pt}

Таким образом, предельные распределения в~\eqref{rand_risk_dist} 
представляют собой сдвиг-масш\-таб\-ные смеси нормальных законов.

\vspace*{2pt}

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \ 
Запишем

\vspace*{2pt}

\noindent
$$
\fr{\widehat{R}_{M_J} - R_J}{ D_J}=
\fr{D_{M_J}}{D_J}\frac{\widehat{R}_{M_J} - 
r_{M_J}}{ D_{M_J}}+\fr{r_{M_J}-R_J}{D_J}\,.
$$
Тогда

\noindent
$$
\fr{D_{M_J}}{D_J}=\fr{2^{2M_J}}{2^{2J}}
$$
и характеристическая функция~$h_J(t)$ случайной
 величины~$({\widehat{R}_{M_J} \hm- R_J})/{D_J}$ запишется в~виде:
 
 \noindent
$$
h_J(t)=\sum\limits_{j=1}^{\infty}{\sf P}(M_J=j)
\exp\left(it\fr{r_{j}-R_J}{D_J}\right)\varphi_j\left(
t\fr{2^{2j}}{2^{2J}}\right),
$$
где $\varphi_j(t)$~--- характеристическая функция 
$({\widehat{r}_j \hm- r_j})/{ D_j }$. Обозначим

\noindent
\begin{multline*}
g_J(t)={\sf E}\varphi\left(t\sqrt{U_J}\right)e^{itV_J}={}\\
{}=\sum\limits_{j=1}^{\infty}
{\sf P}\left(M_J=j\right)\exp\left(it\fr{r_{j}-R_J}{D_J}\right)
\varphi\left(t\fr{2^{2j}}{2^{2J}}\right).
\end{multline*}

\vspace*{-2pt}

\noindent
Имеем

\vspace*{-4pt}

\noindent
\begin{multline*} % \label{aux_etimate}
\abs{h_J(t)-g_J(t)}=
\left\vert \sum\limits_{j=1}^{\infty}{\sf P}(M_J=j)\times{}\right.\\
\left.{}\times \exp\left(it\fr{r_{j}-
R_J}{D_J}\right)\left(\varphi_j\left(t\fr{2^{2j}}{2^{2J}}\right)-
\varphi\left(t\fr{2^{2j}}{2^{2J}}\right)\right)
\vphantom{\sum\limits_{j=1}^{\infty}}
\right\vert.
\end{multline*}
Фиксируем $t\neq0$. Рассуждая, как в~работе~\cite{KZ16}, 
для произвольного $\varepsilon\hm>0$ можно выбрать такое число 
$\kappa\hm>0$, что

\vspace*{4pt}

\noindent
\begin{equation*}
\sum\limits_{j>\kappa +J}\p(M_J=j)={\sf P}\left(U_J>2^{4\kappa}\right)<\varepsilon
\end{equation*}
и начиная с~некоторого~$J$, зависящего от~$\varepsilon$ и~$\kappa$,

\vspace*{-1pt}

\noindent
\begin{multline*}
\left\vert\sum\limits_{j>\kappa + J}{\sf P}(M_J=j)\exp\left(
it\fr{r_{j}-R_J}{D_J}\right)\times{}\right.\\
\left.{}\times \left(\varphi_j\left(t
\fr{2^{2j}}{2^{2J}}\right)-\varphi\left(t\fr{2^{2j}}{2^{2J}}\right)
\right)
\vphantom{\sum\limits_{j>\kappa + J} \fr{r_{j}-R_J}{D_J}}
\right\vert
<2\varepsilon\,.
\end{multline*}

\vspace*{-2pt}

\noindent
Далее в~силу теоремы~1

\vspace*{-3pt}

\noindent
\begin{multline*}
\left\vert \sum\limits_{j\leqslant\kappa + J}{\sf P}(M_J=j)
\exp\left(it\fr{r_{j}-R_J}{D_J}\right)\times{}\right.\\
\left. {}\times\left(\varphi_j
\left(t\fr{2^{2j}}{2^{2J}}\right)-\varphi\left(t\fr{2^{2j}}{2^{2J}}
\right)\right)
\vphantom{\sum\limits_{j>\kappa + J} \fr{r_{j}-R_J}{D_J}}
\right\vert 
\leqslant{}
\\
{}\leqslant\sum\limits_{j\leqslant\kappa +J}{\sf P}(M_J=j)
\sup\limits_{\tau\leqslant 2^{2\kappa} t}\abs{\varphi_j\left(
\tau\right)-\varphi\left(\tau\right)}<{}\\
{}<{\sf E}
\sup\limits_{\tau\leqslant 2^{2\kappa} t}
\abs{\varphi_{M_J}\left(\tau\right)-\varphi\left(\tau\right)}
<\varepsilon\,,
\end{multline*}

\vspace*{-6pt}

\noindent
так как $M_J\xrightarrow{{\sf P}}\infty$~\cite{KZ16}.

Таким образом, для произвольного~$t$
\begin{equation*}
\abs{h_J(t)-g_J(t)}\to 0  \enskip \mbox{при } J \rightarrow \infty\,.
\end{equation*}

\columnbreak

\noindent
Далее при любом фиксированном~$t$

\vspace*{-3pt}

\noindent
\begin{multline*}
\left\vert g_J(t)-h(t)\right\vert=\left\vert {\sf E}\varphi
\left(t\sqrt{U_J}\right)e^{itV_J}-{}\right.\\
\left.{}-{\sf E}
\varphi\left(t\sqrt{U}\right)e^{itV}\right\vert\to 0  \enskip
  \mbox{при } J \rightarrow \infty\,,
\end{multline*}
поскольку функция $q_t(u,v)\hm=\varphi(t\sqrt{u})e^{itv}$ 
непрерывна и~ограничена, и~$(U_J,V_J)\hm\Rightarrow(U,V)$ при $J\hm\to\infty$. 
Следовательно,

\noindent
$$
\abs{h_J(t)-h(t)}\to 0  \enskip \mbox{при } J \rightarrow \infty 
$$

\vspace*{-3pt}

\noindent
и имеет место~\eqref{rand_risk_dist}. Теорема доказана.

\vspace*{3pt}

% если $\gamma>1/2$, то не нужно центрировать, и~получается только масштабная смесь? В этом случае сходимость к~нормальному закону тогда и~только тогда, когда предельное распределение индекса вырождено. Так и~есть. Может переделать теорему?

\noindent
\textbf{Замечание.} 
Распределения, получаемые в~качестве предельных в~теореме~2, 
могут существенно отличаться по своим свойствам от нормального закона. 
В~частности, они могут иметь гораздо более тяжелые хвосты. Кроме того, 
порядок теоретического среднеквадратичного риска в~модели со 
случайным числом вейв\-лет-ко\-эф\-фи\-ци\-ен\-тов может оказаться 
существенно больше порядка риска в~модели с~фиксированным числом
 коэффициентов~\cite{SH19}.
 
 \vspace*{-12pt}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}



\bibitem{Kol94}
\Au{Kolaczyk E.\,D.} Wavelet methods for the inversion of certain homogeneous 
linear operators in the presence of noisy data.~--- 
Stanford, CA, USA: Stanford University, 1994.  PhD Diss. 152~p.

\bibitem{D94}
\Au{Donoho D.}  
Nonlinear solution of linear inverse problems by wavelet--vaguelette 
decomposition~// Appl. Comput. Harmon.~A., 1995. Vol.~2. P.~101--126.

\bibitem{Lee97}
\Au{Lee N.} Wavelet-vaguelette decompositions and homogenous equations.~--- 
West Lafayette, IN, USA: Purdue University, 1997. PhD Diss. 103~p.

\bibitem{SH16-1}
\Au{Шестаков О.\,В.} Ве\-ро\-ят\-ност\-но-ста\-ти\-сти\-че\-ские 
методы анализа и~обработки сигналов на основе вейв\-лет-ал\-го\-рит\-мов.~---  
М.:~Аргамак-Медиа, 2016. 200~с.

\bibitem{Mall99}
\Au{Mallat S.} A~wavelet tour of signal processing.~--- 
New York, NY, USA: Academic Press, 1999. 857~p.

\bibitem{ESH14}
\Au{Ерошенко А.\,А., Шестаков~О.\,В.} Асимптотические свойства 
оценки риска в~задаче восстановления изоб\-ра\-же\-ния с~коррелированным шумом
 при обращении преобразования Радона~// Информатика и~её 
 применения, 2014. Т.~8. Вып.~4. С.~32--40.

\bibitem{Jan01}
\Au{Jansen M.} Noise reduction by wavelet thresholding.~--- 
Lecture notes in statistics ser.~--- New York, NY, USA: Springer-Verlag, 
2001. Vol.~161. 217~p.

\bibitem{KZ16}
\Au{Korolev V.\,Yu., Zeifman~A.\,I.} 
On convergence of the distributions of random sequences with independent 
random indexes to variance-mean mixtures~// Stoch. Models, 2016. 
Vol.~32. Iss.~3. P.~414--432.

\bibitem{SH19}
\Au{Shestakov O.\,V.} Mean-square risk of the threshold processing in the 
problem of inverting the Radon transform with a~random sample size~// 
J.~Math. Sci., 2020. Vol.~248. No.\,1. P.~46--50.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-12pt}

\hfill{\small\textit{Поступила в~редакцию 01.07.20}}

%\vspace*{8pt}

%\pagebreak

\newpage

\vspace*{-28pt}

%\hrule

%\vspace*{2pt}

%\hrule

%\vspace*{-2pt}

\def\tit{ON THE STATISTICAL PROPERTIES OF~RISK ESTIMATE IN~THE~PROBLEM 
OF~INVERTING THE~RADON TRANSFORM WITH~A~RANDOM VOLUME OF~PROJECTION DATA}


\def\titkol{On the statistical properties of~risk estimate in~the~problem 
of~inverting the~Radon transform with~a~random volume of
%~projection 
data}

\def\aut{O.\,V.~Shestakov$^{1,2}$}

\def\autkol{O.\,V.~Shestakov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-15pt}


\noindent
$^1$Department of Mathematical Statistics, Faculty of Computational 
Mathematics and Cybernetics, M.\,V.~Lomo-\linebreak
$\hphantom{^1}$nosov Moscow State University, 
1-52~Leninskiye Gory, GSP-1, Moscow 119991, Russian Federation

\noindent
$^2$Institute of Informatics Problems, Federal Research Center
``Computer Science and Control'' of the Russian\linebreak
$\hphantom{^1}$Academy of Sciences,  44-2~Vavilov Str., Moscow 119333, Russian Federation

\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2020\ \ \ volume~14\ \ \ issue\ 3}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2020\ \ \ volume~14\ \ \ issue\ 3
\hfill \textbf{\thepage}}}

\vspace*{2pt} 




\Abste{When reconstructing tomographic images, 
it is necessary to solve the problem of suppressing the noise 
arising from registration of projection data. Methods for solving 
this problem based on wavelet algorithms and threshold processing 
procedures have several advantages, including computational
 efficiency and ability to adapt to local features of images. 
 An analysis of the errors of these methods is an important 
 practical task, since it makes it possible to evaluate the 
 quality of both the methods themselves and the equipment used. 
 When using threshold processing procedures, it is usually 
 assumed that the number of decomposition coefficients is 
 fixed and the noise distribution is Gaussian. This model 
 has been well studied in the literature, and the optimal threshold 
 values have been calculated for different classes of functions.
  However, in some situations, the sample size is not fixed in 
  advance and must be modeled with some random variable. 
  This paper considers a~model with a~random number of observations
   and investigates the asymptotic properties of the mean-square 
   risk estimate. It is proved that the limiting distribution of 
   this estimate belongs to the class of shift-scale mixtures of normal laws.}

\KWE{threshold processing; random sample size; Radon 
transform; grid; mean-square risk estimate}



\DOI{10.14357/19922264200306} 

\vspace*{-20pt}

\Ack

\vspace*{-6pt}
\noindent
The work is supported by the Russian Foundation 
for Basic Research (project No.\,19-07-00352). The research was conducted in accordance with the Program of Moscow Center
for Fundamental and Applied Mathematics.

%\vspace*{6pt}

 \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}

\bibitem{2-sh-1}
\Aue{Kolaczyk, E.\,D.}
 1994. {Wavelet methods for the inversion of certain 
 homogeneous linear operators in the presence of noisy data.} 
 Stanford, CA: Stanford University. PhD Diss. 152~p.
 
 \bibitem{1-sh-1}
\Aue{Donoho, D.} 1995. Nonlinear solution of linear 
inverse problems by wavelet-vaguelette decomposition. 
\textit{Appl. Comput. Harmon.~A} 2:101--126.

\bibitem{3-sh-1}
\Aue{Lee, N.} 1997. 
{Wavelet-vaguelette decompositions and homogenous equations}. 
West Lafayette, IN: Purdue University. PhD Diss. 103~p.
\bibitem{4-sh-1}
\Aue{Shestakov, O.\,V.}
 2016. \textit{Veroyatnostno-statisticheskie metody analiza 
 i~obrabotki signalov na osnove veyvlet-algoritmov} 
 [Probabilistic-statistical methods of signal analysis and 
 processing based on wavelet algorithms]. Moscow: ARGAMAK-MEDIA. 200~p.
\bibitem{5-sh-1}
\Aue{Mallat, S.} 1999. 
\textit{A~wavelet tour of signal processing}. New York, NY: 
Academic Press. 857~p.
\bibitem{6-sh-1}
\Aue{Eroshenko, A.\,A., and O.\,V.~Shestakov.}
 2014. Asimp\-to\-ti\-che\-skie svoystva otsenki riska v~zadache 
 vos\-sta\-nov\-le\-niya izob\-ra\-zhe\-niya s~korrelirovannym shumom pri 
 obrashchenii preobrazovaniya Radona 
 [Asymptotic properties of risk estimate in the problem 
 of reconstructing images with correlated noise by inverting 
 the Radon transform]. 
 \textit{Informatika i~ee Primeneniya~--- Inform. Appl.} 8(4):32--40.
\bibitem{7-sh-1}
\Aue{Jansen, M.} 2001. \textit{Noise reduction by wavelet thresholding}. 
Lecture notes in statistics ser.
New York, NY: Springer-Verlag. 217~p.
\bibitem{8-sh-1}
\Aue{Korolev, V.\,Yu., and A.\,I.~Zeifman.} 2016.
 On convergence of the distributions of random sequences 
 with independent random indexes to variance-mean mixtures.
 \textit{Stoch. Models} 32(3):414--432.
\bibitem{9-sh-1}
\Aue{Shestakov, O.\,V.} 2020. Mean-square risk of the threshold 
processing in the problem of inverting the Radon 
transform with a random sample size. \textit{J.~Math. Sci.} 248(1):46--50.
 \end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-9pt}

\hfill{\small\textit{Received July 1, 2020}}

%\pagebreak

\vspace*{-28pt}

\Contrl

\vspace*{-6pt}

\noindent
\textbf{Shestakov Oleg V.} (b.\ 1976)~--- 
Doctor of Science in physics and mathematics, professor, 
Department of Mathematical Statistics, Faculty of Computational 
Mathematics and Cybernetics, M.\,V.~Lomonosov Moscow State University, 
1-52~Leninskiye Gory, GSP-1, Moscow 119991, Russian Federation; 
senior scientist, Institute of Informatics Problems, 
Federal Research Center ``Computer Science and Control'' 
of the Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, 
Russian Federation; \mbox{oshestakov@cs.msu.su}
\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 