\def\stat{naumov}

\def\tit{О~МАРКОВСКИХ И~РАЦИОНАЛЬНЫХ ПОТОКАХ СЛУЧАЙНЫХ 
СОБЫТИЙ.~I$^*$}

\def\titkol{О марковских и рациональных потоках случайных 
событий.~I}

\def\aut{В.\,А.~Наумов$^1$, К.\,Е.~Самуйлов$^2$}

\def\autkol{В.\,А.~Наумов, К.\,Е.~Самуйлов}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Наумов В.\,А.}
\index{Самуйлов К.\,Е.}
\index{Naumov V.\,A.}
\index{Samouylov К.\,Е.}
 

{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Исследование выполнено при финансовой поддержке РФФИ в~рамках 
научного проекта №\,19-17-50126.}
%Публикация подготовлена при финансовой поддержке РФФИ (проект 19-17-50126).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Исследовательский институт инноваций, г.\ Хельсинки, Финляндия, 
\mbox{valeriy.naumov@pfu.fi}}
\footnotetext[2]{Российский университет дружбы народов; Институт проблем информатики Федерального 
исследовательского центра <<Информатика и управление>> Российской академии наук, 
\mbox{samouylov-ke@rudn.ru}}

%\vspace*{-6pt}
 

  \Abst{Статья представляет собой первую часть обзора, призванного ознакомить 
заинтересованных читателей с основами теории марковских потоков событий для более 
подробного изучения и облегчения применения этих моделей на практике. В~первой части 
приведены свойства общих марковских потоков событий и показана их связь с марковскими 
аддитивными процессами и процессами марковского восстановления. Во второй части 
обзора будут рассмотрены частные случаи таких потоков~--- подклассы марковских потоков 
событий, а~именно: простые и групповые потоки однородных и неоднородных событий, 
важные для приложений. Далее будет показано, как свойства марковских потоков событий 
связаны с мультипликативностью стационарных распределений марковских систем. 
В~завершение обзора будут обсуждены матрично-экспоненциальные распределения 
и~рациональные потоки событий, рас\-ши\-ря\-ющие возможности марковских потоков для 
моделирования сложных систем и при этом сохраняющие удобство их анализа с помощью 
вычислительной техники.}
  
  \KW{марковские процессы; марковские аддитивные процессы; потоки без последействия; 
МС-по\-токи}

\DOI{10.14357/19922264200302} 
 
%\vspace*{-6pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}
  
\section{Введение}

    При анализе стохастических систем применяются различные модели потоков 
случайных событий. Марковские потоки событий служат обобщением 
марковски-модулированных пуассоновских потоков~[1--3], образованных 
моментами изменения состояний цепей Маркова~[4, 5], и процессов 
восстановления фазового типа~[6].  Эти модели появились, когда стало ясным, 
что будущие методы анализа стохастических систем будут основаны на 
использовании вычислительной техники. Марковские потоки задаются 
с~помощью нескольких матриц, что делает удобным использование 
вы\-чис\-ли\-тель\-ной техники для их анализа. 
    
Свойства марковских потоков вытекают из общей теории двухкомпонентных 
марковских процессов, однородных во времени и по одной из компонент, 
сейчас известных под именем марковские аддитивные процессы (Markov 
Additive Processes). Считающий процесс марковских потоков~--- это процесс 
с~независимыми приращениями, заданный на цепи Маркова. Потоки событий,  
для которых считающий процесс имеет независимые приращения, были 
названы А.\,Я.~Хинчиным потоками без последействия~[7]. Поэтому 
марковские потоки назывались потоками без последействия, заданными на 
цепи Маркова~[8], до тех пор пока на одном из семинаров в~МГУ 
Г.\,П.~Климов не предложил для этого класса потоков сокращенное название 
\textit{МС-по\-то\-ки} (от Markov Chain). 

После того как M.\,F.~Neuts предложил свою модель марковских потоков~[9, 
10], такие модели стали называть N-про\-цес\-са\-ми~[11--14]. В~1990~г.\ для 
марковских потоков было придумано новое название Markovian Arrival Process 
и~стало использоваться неудачное сокращение MAP~[15]. Неудачное потому, 
что начиная с опубликованной в 1972~г.\ работы E.~Сinlar~[16] это сокращение 
уже использовалось для обозначения марковских аддитивных процессов. 
Чтобы избежать путаницы в 2003~г.\ S.~Asmussen в своей книге~[17] 
предложил использовать для Markovian Arrival Process сокращение MArP, но 
по-прежнему как для Markov Additive Processes, так и для Markovian Arrival 
Process чаще используется сокращение MAP. 

    Цель настоящего обзора, состоящего из двух частей,~--- ознакомление 
читателей с~основами тео\-рии марковских потоков, с тем чтобы облегчить\linebreak 
применение этих моделей на практике и, если потребуется, их более подробное 
изучение. На сегодня опубликовано большое число работ, посвященных 
марковским и рациональным потокам\linebreak событий, и~в~настоящем обзоре 
представлены лишь основные сведения о~них. Многие результаты были взяты 
непосредственно из ссылок, и их доказательства намеренно опущены. Их 
можно найти в~пуб\-ли\-ка\-ци\-ях, перечисленных в~списке литературы. Начинается 
обзор с рассмотрения случайных величин фазового типа в разд.~2. В~разд.~3 
определяются марковские потоки общего вида и~показана их связь 
с~марковскими аддитивными процессами и~процессами марковского 
восстановления. Во второй части обзора рассматриваются важные для 
приложений подклассы марковских потоков однородных и неоднородных 
событий. Далее там же обсуждаются мат\-рич\-но-экс\-по\-нен\-ци\-аль\-ные 
распределения и рациональные потоки событий, которые расширяют 
возможности марковских потоков для моделирования сложных систем и при 
этом сохраняют удобство их анализа. 

    В~этой работе жирные строчные буквы обозначают векторы, а жирные 
прописные буквы~--- мат\-ри\-цы. Неравенства $\mathbf{x}\hm\leq 
\mathbf{y}$ и~$\mathbf{x}\hm\geq \mathbf{y}$ понимаются поэлементно; 
$\delta(i,j)\hm=1$, если $i\hm=j$, и~$\delta(i,j)\hm=0$ в~противном случае; 
у~вектора~$\mathbf{e}_i$ $i$-я координата равна единице, а остальные равны 
нулю. Кроме того, используются следующие обозначения: $\mathbf{I}\hm= 
[\delta(i,j)]$~--- единичная матрица; $\mathbf{u}$~---  век\-тор-стол\-бец из 
единиц; $\mathrm{Ind}(A)$~---  индикатор события~$A$; 
$\boldsymbol{\mathcal{N}}^K$~---множество неотрицательных целочисленных 
векторов длины~$K$, $\boldsymbol{\mathcal{N}}_0^K\hm= 
\boldsymbol{\mathcal{N}}^K\backslash \{\mathbf{0}\}$. Для краткости вместо 
<<наступило~$n_1$ событий типа~1, $n_2$ событий типа~2, \ldots, $n_K$ 
событий типа~$K$>> будем писать <<наступило $\mathbf{n}$ событий>>, где 
$\mathbf{n}\hm= (n_1, n_2, \ldots , n_K)$.

\vspace*{-6pt}

\section{Случайные величины фазового~типа}

  Распределения фазового типа представляют собой обобщение хорошо 
известного распределения Эрланга, появившегося в~[18] и позднее названного 
по имени автора. Переводы этой и других работ A.\,К.~Эрланга на английский 
язык опубликованы в специальном издании~[19], посвященном его\linebreak 70-ле\-тию. 
Распределения фазового типа~--- это распределения времени до попадания 
конечной цепи Маркова в поглощающее состояние~\cite{6-n}. Пусть~$X(t)$,\linebreak 
$t\hm\geq 0$,~--- случайный процесс с конечным множеством состояний 
$\boldsymbol{\mathcal{X}} \hm= \{1, 2, \ldots , L\}$ и~$\tau$~--- 
не\-от\-ри\-ца\-тель\-ная случайная величина, ${\sf P}(\tau>0)\hm> 0$. Случайный 
процесс $X_0(t)\hm= X(t)\mathrm{Ind}(\tau>t)$ принимает значения $0, 1, 2, 
\ldots , L$, причем его нулевое\linebreak состояние~--- поглощающее. Случайная 
величина~$\tau$ называется случайной величиной фазового\linebreak типа с~фазовым 
процессом~$X(t)$, если процесс~$X_0(t)$~--- однородный марковский процесс, %\linebreak 
вероятности переходов которого

\noindent
\begin{multline*}
  p(i,j,t)={\sf P}\left(X(t)=j,\ \tau>t\vert X(0)=i,\
   \tau>0\right)\,,\\  i,j\in   \boldsymbol{\mathcal{X}}\,,
  \end{multline*}
удовлетворяют условиям: 
\begin{align}
\lim\limits_{t\to 0} p\left(i,j,t\right)&= \delta(i,j)\,,\ i,j\in \boldsymbol{\mathcal{X}}\,;
%\label{e1-n}\\
\notag\\
\lim\limits_{t\to \infty}\, p\left(i,j,t\right)&= 0\,,\ i,j\in \boldsymbol{\mathcal{X}}\,.
\label{e2-n}
\end{align}
  %
  В этом случае существует матрица интенсивностей переходов 
$\mathbf{S}\hm= [s(i,j)]$ такая, что
  $$
  p(i,j,\Delta t) =\delta(i,j)+s(i,j)\Delta t +o(\Delta t)\,,\ i,j,\in 
\boldsymbol{\mathcal{X}}\,,
  $$
и для матрицы $\mathbf{P}(t)\hm= [p(i,j,t)]$ справедливо выражение~\cite{20-n}:
\begin{equation}
\mathbf{P}(t)=\exp \left( t\mathbf{S}\right)\,.
\label{e3-n}
\end{equation}
  
  Из равенств~(\ref{e2-n}) и~(\ref{e3-n}) следует, что все собственные числа 
матрицы~$\mathbf{S}$ имеют отрицательные действительные  
части~\cite{21-n}. Матрица~$\mathbf{S}$ невырожденна, и матрица~$-
\mathbf{S}^{-1}$ неотрицательна. В~силу того что~0 является поглощающим 
состоянием процесса~$X_0(t)$, его матрица интенсивностей 
переходов~$\mathbf{S}_0$ и матрица вероятностей 
переходов~$\mathbf{P}_0(t)$ имеют следующий вид:
  $$
  \mathbf{S}_0=\begin{bmatrix}
  0&\mathbf{0}\\
  \mathbf{s} &\mathbf{S}
  \end{bmatrix}\,;\enskip
  \mathbf{P}_0(t)=\begin{bmatrix}
  1 &\mathbf{0}\\
  \mathbf{p}(t)& \mathbf{P}(t)
  \end{bmatrix}\,,
  $$
где $\mathbf{s}=-\mathbf{S}\mathbf{u}$ и~$\mathbf{p}(t)\hm= \mathbf{u}\hm- 
\mathbf{P}(t) \mathbf{u}$~---  век\-то\-ры-столб\-цы длины~$L$. 
    
Для функции распределения случайной величины фазового типа $F(t)\hm= 
P(\tau\leq t)$ справедливы следующие выражения:
\begin{gather}
F(t)=1-\mathbf{q}\exp (t\mathbf{S})\mathbf{u}\,;\label{e4-n}\\
F(0)=1-\mathbf{q}\mathbf{u}\,;\enskip
  \fr{d}{dt}\,F(t)= \mathbf{q}\exp (t\mathbf{S})\,,\enskip 
t>0\,,\notag
\end{gather}
где $\mathbf{q}=[q(i)]$~--- век\-тор-стро\-ка начальных вероятностей $q(i)\hm= 
{\sf P}(X(0)=i,\ \tau>0)$. По определению выражение вида~(\ref{e4-n}) 
представляет собой функцию распределения фазового типа, если 
вектор~$\mathbf{q}$  и мат\-ри\-ца~$\mathbf{S}$ удовлетворяют неравенствам: 
\begin{gather*}
%\left.
%\begin{array}{c}
\displaystyle 0<\sum\limits_{j\in\boldsymbol{\mathcal{X}}} q(j)\leq 1\,,\enskip 
q(i)\geq0\,,\enskip i\in \boldsymbol{\mathcal{X}}\,;\\
\displaystyle 
\sum\limits_{j\in\boldsymbol{\mathcal{X}}} s(i,j)\leq0\,,\ s(i,j)\geq 0\,,\ i\not= j\,,\ 
i,j\in \boldsymbol{\mathcal{X}}\,.
%\end{array}
%\right\}
%\label{e5-n}
\end{gather*} 
  
  Кроме того, необходимо, чтобы из любого состояния марковского процесса 
$X_0(t)$ с~мат\-ри\-цей интенсивностей переходов~$\mathbf{S}_0$ можно было 
попасть в~поглощающее состояние~0. Для этого достаточно, чтобы матрица 
$\mathbf{S}\hm+ \mathbf{s}\mathbf{q}$ была неразложимой, 
а~вектор~$\mathbf{s}$ ненулевым. Не будем здесь останавливаться на 
свойствах функций распределения фазового типа, поскольку они являются 
мат\-рич\-но-экс\-по\-нен\-ци\-аль\-ны\-ми функциями распределения, 
рассматриваемыми во второй части обзора. 

\section{Марковские потоки событий}

  Случайные величины фазового типа~--- это суммы некоторого числа 
случайных величин, име\-ющих экспоненциальные функции распределения. Это 
позволяет применять при анализе стохастических систем с такими случайными 
величинами метод этапов Эрланга. Использование марковских потоков 
событий позволяет распространить метод этапов Эрланга на потоки 
случайных событий.
  
  Рассмотрим некоторый поток групп неоднородных событий $(t_l, 
\boldsymbol{\sigma}_l)$, $l\hm=1,2,\ldots$\,, где $0\hm< t_1\hm< t_2<\cdots $~--- 
моменты наступления событий, также называемые вызывающими 
моментами~\cite{22-n}, а~$\boldsymbol{\sigma}_l$~--- это вектор 
$\boldsymbol{\sigma}_l\hm= (\sigma_{l,1},\ldots , \sigma_{l,K})$, 
в~котором~$\sigma_{l,k}$ есть размер группы событий типа~$k$, наступивших 
в~момент~$t_l$, $k=1,\ldots,K$. 
Обозначим через $N_k(t)\hm= \sum\nolimits_{t_l\leq t} 
\sigma_{l,k}$ число событий типа~$k$, наступивших за время~$t$, 
$\mathbf{N}(t)\hm= (N_1(t), N_2(t),\ldots , N_K(t))$.  Будем называть поток 
$(t_l,\boldsymbol{\sigma}_l)$ марковским, если для некоторого случайного 
процесса~$X(t)$ с конечным множеством состояний 
$\boldsymbol{\mathcal{X}}\hm= \{1,2,\ldots , L\}$ процесс $\xi(t)\hm= (X(t), 
\mathbf{N}(t))$ является однородным марковским процессом,  причем для 
любых моментов времени $0\hm\leq h\hm< t$ вектор числа событий 
$\mathbf{N}(t)\hm- \mathbf{N}(h)$, наступивших в интервале~$(h,t]$, при 
заданном~$X(h)$ не зависит от вектора числа событий~$\mathbf{N}(h)$, 
наступивших до момента~$h$~\cite{23-n}. Другими словами, для марковского 
потока процесс $\xi(t)\hm= (X(t), \mathbf{N}(t))$ однороден во времени и по 
второй компоненте~\cite{24-n}. Будем предполагать траектории процесса 
$\xi(t)\hm= (X(t),\mathbf{N}(t))$ непрерывными справа. Его вероятности 
переходов 
  \begin{multline}
  p_{\mathbf{k},\mathbf{n}}(i,j,t)={\sf P}\left (X(h+t)=j\,,\right.\\
\left.  \mathbf{N}(h+t)=\mathbf{n}\vert  X(h)=i\,,\ \mathbf{N}(h)=\mathbf{k}\right)
  \label{e6-n}
  \end{multline}
удовлетворяют условию:
\begin{multline}
p_{\mathbf{k},\mathbf{n}}(i,j,t)= p_{\mathbf{0},\mathbf{n}-\mathbf{k}}(i,j,t)\,,\ 
i,j\in \boldsymbol{\mathcal{X}}\,,\\
 \mathbf{k},\mathbf{n}\in 
\boldsymbol{\mathcal{N}}^K\,,\mathbf{k}\leq \mathbf{n}\,,
\label{e7-n}
\end{multline}
поэтому они однозначно определяются функциями
\begin{equation*}
p_{\mathbf{n}}(i,j,t)=p_{\mathbf{0},\mathbf{n}}(i,j,t)\,,\ i,j\in 
\boldsymbol{\mathcal{X}}\,,\ \mathbf{n}\in \boldsymbol{\mathcal{N}}^K\,.
%\label{e8-n}
\end{equation*}
  
  Из~(\ref{e6-n})--(\ref{e7-n}) следует, что интенсивности переходов 
процесса~$\xi(t)$
  \begin{multline*}
  a_{\mathbf{k},\mathbf{n}}(i,j)=\lim\limits_{t\to0} \fr{1}{t}\left( 
p_{\mathbf{k},\mathbf{n}}(i,j,t)-\delta (\mathbf{k},\mathbf{n})\delta(i,j)\right)\,,\\
  i,j\in \boldsymbol{\mathcal{X}}\,,\ \mathbf{k},\mathbf{n}\in 
\boldsymbol{\mathcal{N}}^K\,,\ \mathbf{k}\leq \mathbf{n}\,,
  %\label{e9-n}
  \end{multline*}
имеют следующий вид:
\begin{equation*}
a_{\mathbf{k},\mathbf{n}}(i,j)=\begin{cases}
a_{\mathbf{n}-\mathbf{k}}(i,j)\,, & 
\mbox{если } \mathbf{k}\leq \mathbf{n}\,;\\
0 & \mbox{в\ остальных\ случаях},
\end{cases}
%\label{e10-n}
\end{equation*}
где
\begin{align*}
a_{\mathbf{0}} (i,j) &= \lim\limits_{t\to 0}\fr{1}{t}\left( p_{\mathbf{0}}
(i,j,t)-\delta(i,j)\right)\,,\ i,j\in \boldsymbol{\mathcal{X}}\,;
%\label{e11-n}
\\
a_{\mathbf{n}} (i,j) & =\lim\limits_{t\to 0}\fr{1}{t}\,
p_{\mathbf{n}}(i,j,t)\,,\ i,j\in 
\boldsymbol{\mathcal{X}}\,,\ \mathbf{n}\in \boldsymbol{\mathcal{N}}^K_0\,.
%\label{e12-n}
\end{align*}
  
  Матрицы вероятностей переходов $\mathbf{P}_{\mathbf{n}}(t)\hm= 
[p_{\mathbf{n}}(i,j,t)]$ однозначно определяются матрицами интенсивностей 
переходов $\mathbf{A}_{\mathbf{n}}\hm= [a_{\mathbf{n}}(i, j)]$,\linebreak 
$\mathbf{n}\hm\geq 0$. Действительно, 
матрицы~$\mathbf{P}_{\mathbf{n}}(t)$ образуют единственное решение 
системы уравнений Кол\-мо\-го\-рова
  \begin{equation}
  \fr{d}{dt}\,\mathbf{P}_{\mathbf{n}}(t)=
  \sum\limits_{{\substack{{\mathbf{i}\in 
\boldsymbol{\mathcal{N}}^K},\\
{\mathbf{i}\leq\mathbf{n}}}} }\mathbf{A}_{\mathbf{i}}\mathbf{P}_{\mathbf{n}-
\mathbf{i}} (t)\,,\enskip \mathbf{n}\in \boldsymbol{\mathcal{N}}^K\,,
  \label{e13-n}
  \end{equation}
удовлетворяющее начальным условиям:
\begin{equation}
\mathbf{P}_{\mathbf{
0}}(0)= \mathbf{I}\,,\enskip \mathbf{P}_{\mathbf{n}}(0)= \mathbf{0}\,,\enskip 
\mathbf{n}\in \boldsymbol{\mathcal{N}}_0^K\,.
\label{e14-n}
\end{equation}
  
  Решение системы уравнений~(\ref{e13-n})--(\ref{e14-n}) можно найти 
с~помощью рекуррентной формулы 
  \begin{align*}
  \mathbf{P}_{\mathbf{0}}(t)&=\exp (t\mathbf{A}_{\mathbf{0}})\,,\\
  \mathbf{P}_{\mathbf{n}}(t)&=\sum\limits_{\substack{{\mathbf{i}\in 
\boldsymbol{\mathcal{N}}_0^k,}\\
{\mathbf{i}\leq \mathbf{n}}}} \displaystyle
  \int\limits_0^t \mathbf{P}_0(t-h) 
\mathbf{A}_{\mathbf{i}} \mathbf{P}_{\mathbf{n}-\mathbf{i}}(h)\,dh\,,\
\mathbf{n}\in \boldsymbol{\mathcal{N}}_0^K\,.
  %  \label{e15-n}
  \end{align*}
                    
  
  Из~(\ref{e13-n}) следует, что матрицы 
 \begin{align*}
  \mathbf{P}(\mathbf{z},t) &=\sum\limits_{\mathbf{n}\in 
\boldsymbol{\mathcal{N}}^K} \mathbf{P}_{\mathbf{n}}(t) z_1^{n_1}\cdots 
z_K^{n_K}\,;\\
  \mathbf{A}(\mathbf{z})&=\sum\limits_{\mathbf{n}\in 
\boldsymbol{\mathcal{N}}^K}  \mathbf{A}_\mathbf{n} z_1^{n_1}\cdots 
z_K^{n_K}\,,
 \end{align*}
где $\mathbf{n}=(n_1, \ldots , n_K)$, $\mathbf{z}\hm= (z_1, \ldots , z_K)$, $\vert 
z_k\vert \hm\leq 1$, $k\hm=1,\ldots , K$, связаны простым равенством: 
\begin{equation*}
\mathbf{P}(\mathbf{z},t) =\exp (t\mathbf{A}(\mathbf{z}))\,.
%\label{e16-n}
\end{equation*}
  
  Первая компонента $X(t)$ однородного во времени и по второй компоненте 
процесса $\xi(t)\hm= (X(t), \mathbf{N}(t))$ сама является однородным 
мар\-ковским процессом~\cite{24-n}. Будем называть~$X(t)$\linebreak фазовым процессом 
марковского потока. Матрица вероятностей переходов~$\mathbf{P}(t)$ этого 
процесса дается формулой:
  \begin{equation*}
  \mathbf{P}(t)=\sum\limits_{\mathbf{n}\in \boldsymbol{\mathcal{N}}^K} 
\mathbf{P}_{\mathbf{n}} (t)\,.
 % \label{e17-n}
  \end{equation*}
  
  Матрицы интенсивностей переходов~$\mathbf{A}_{\mathbf{n}}$ обладают 
следующими свойствами:
  \begin{enumerate}[(1)]
\item внедиагональные элементы матрицы~$\mathbf{A}_{\mathbf{0}}$ 
не\-от\-ри\-ца\-тельны;
\item матрицы~$\mathbf{A}_{\mathbf{n}}$, $\mathbf{n}\hm\in 
\boldsymbol{\mathcal{N}}_0^K$, не\-от\-ри\-ца\-тельны;
\item матрица 

\vspace*{-2pt}

\noindent
\begin{equation*}
\mathbf{A}=\sum\limits_{\mathbf{n}\in \boldsymbol{\mathcal{N}}^K} 
\mathbf{A}_{\mathbf{n}}
%\label{e18-n}
\end{equation*}
является матрицей интенсивностей переходов фазового процесса~$X(t)$.
  \end{enumerate}
  
  В дальнейшем будем предполагать, что  матрица интенсивностей 
переходов~$\mathbf{A}$ неразложима, $\boldsymbol{\Lambda}\hm= 
\mathbf{A}\hm- \mathbf{A}_{\mathbf{0}}\not= \mathbf{0}$, и~обозначать 
через~$\mathbf{p}$ век\-тор-стро\-ку стационарных вероятностей фазового 
процесса. Этот вектор является единственным решением сис\-те\-мы линейных 
уравнений
  \begin{equation*}
  \mathbf{p}\mathbf{A}=\mathbf{0}\,;\enskip \mathbf{p}\mathbf{u}=1\,.
  %\label{e19-n}
  \end{equation*}
  
  Существуют два основных способа задания марковского потока. Обычно он 
задается набором матриц~$\mathbf{A}_{\mathbf{n}}$, $\mathbf{n}\hm\in 
\boldsymbol{\mathcal{N}}^K$. При другом способе, называемом 
конструктивным, поток задается с помощью  набора чисел $\gamma(i)\hm>0$, 
$i\hm\in \boldsymbol{\mathcal{X}}$, и неотрицательных матриц 
$\boldsymbol{\Psi}_{\mathbf{n}}\hm= 
[\psi_{\mathbf{n}}(i,j)]$, $\mathbf{n}\hm\in 
\boldsymbol{\mathcal{N}}^K$, таких что  
  $$
  \sum\limits_{j\in \boldsymbol{\mathcal{X}}} \sum\limits_{\mathbf{n}\in 
\boldsymbol{\mathcal{N}}^K} \psi_{\mathbf{n}}(i,j)=1\,,\ i\in 
\boldsymbol{\mathcal{X}}\,.
  $$
  %
  Эти параметры описывают однородный марковский процесс, у которого 
время пребывания в каж\-дом состоянии~$i$ имеет экспоненциальное 
распределение с параметром~$\gamma(i)$. В~момент его окончания 
с~вероятностью $\psi_{\mathbf{n}}(i,j)$ наступает~$\mathbf{n}$~событий 
потока и процесс переходит из состояния~$i$ в состояние~$j$. Так 
определенный марковский поток имеет матрицы~$\mathbf{A}_{\mathbf{n}}$ c 
элементами:

\noindent
  \begin{multline*}
  %\boldsymbol{A}
  a_{\mathbf{n}}(i,j)=\gamma(i)(\psi_{\mathbf{n}}(i,j)-\delta 
(\mathbf{n},\mathbf{0})\delta(i,j))\,,\\ 
  i,j\in \boldsymbol{\mathcal{X}}\,,\enskip
   \mathbf{n}\in 
\boldsymbol{\mathcal{N}}^K\,.
  %\label{e20-n}
  \end{multline*}                         
  
  При заданных матрицах~$\mathbf{A}_{\mathbf{n}}$ параметры 
конструктивного способа задания потока можно получить следующим образом. 
Сначала надо выбрать величины~$\gamma(i)$ так, чтобы выполнялись 
неравенства $\gamma(i)\hm\geq -a_{\mathbf{0}}(i,i)$ для всех~$i$. После этого 
вероятности переходов~$\psi_{\mathbf{n}}(i,j)$ найти по формуле:

\noindent
  \begin{multline*}
  \psi_{\mathbf{n}}(i,j)=\fr{%\mathbf{A}
  a_{\mathbf{n}}(i,j)}{\gamma(i)}+ 
\delta(\mathbf{n},\mathbf{0})\delta(i,j)\,,\\
  i,j\in \boldsymbol{\mathcal{X}}\,,\enskip \mathbf{n}\in 
\boldsymbol{\mathcal{N}}^K\,.
  %\label{e21-n}
  \end{multline*}
    
  Ясно, что параметры конструктивного способа задания потока не 
единственны и зависят от выбранных величин~$\gamma(i)$. Их, например, 
можно взять равными $\gamma(i)\hm= \gamma$, $i\hm\in 
\boldsymbol{\mathcal{X}}$, где $\gamma\hm\geq \max\nolimits_i \vert 
a_{\mathbf{0}}(i,i)\vert$. Тогда моменты времени, в которые возможно 
наступление событий заданного таким способом мар-\linebreak\vspace*{-12pt}

\columnbreak

\noindent
ковского потока, образуют 
пуассоновский поток интенсивности~$\gamma$.  
  
  Зная матрицы вероятностей переходов~$\mathbf{P}_{\mathbf{n}}(t)$, можно 
найти распределение числа событий, наступивших в непересекающиеся 
интервалы времени:

\vspace*{-9pt}

\noindent
  \begin{multline}
  p_{\mathbf{k}_1, \mathbf{k}_2,\ldots , \mathbf{k}_m}(x_0,x_1,\ldots , 
x_m)={}\\
{}={\sf P} \left(\mathbf{N}\left(
\sum\limits^r_{j=0} x_j\right) -\mathbf{N}\left( 
\sum\limits^{r-1}_{j=0} x_j\right) =\mathbf{k}_r,\right.\\
\left.r=1,2,\ldots , m
\vphantom{\left(
\sum\limits^r_{j=0} x_j\right)}
\right)={}\\
  {}=
  \boldsymbol{\alpha}\mathbf{P}(x_0) \mathbf{P}_{\mathbf{k}_1}(x_1) 
\mathbf{P}_{\mathbf{k}_2}(x_2)\cdots \mathbf{P}_{\mathbf{k}_m}(x_m) 
\mathbf{u}\,,\\
  \mathbf{k}_1, \mathbf{k}_2,\ldots , \mathbf{k}_m\in 
\boldsymbol{\mathcal{N}}^K\,,\ x_0, x_1, \ldots , x_m>0\,,\\
 m=1,2,\ldots ,
  \label{e22-n}
  \end{multline}
  
  \vspace*{-4pt}
  
  \noindent
где $\boldsymbol{\alpha}=[\alpha(i)]$~--- начальное распределение фазового процесса, 
$\alpha(i)\hm= {\sf P}(X(0)\hm=i)$. Разным начальным распределениям фазового 
процесса соответствуют разные марковские потоки. В~случае $\boldsymbol{\alpha}
\hm= 
\mathbf{p}$ говорят о стационарной версии марковского потока~\cite{23-n}. 
При начальном распределении фазового процесса $\boldsymbol{\alpha}\hm=\mathbf{p}$ 
считающий процесс~$\mathbf{N}(t)$ марковского потока является процессом 
со стационарными приращениями, поскольку распределение~(\ref{e22-n}) 
числа событий, наступивших в интервалах длины $x_1,\ldots ,x_m$, не зависит 
от начального положения~$x_0$ этих интервалов на оси времени. 
Параметр~$\lambda$ стационарной версии марковского потока и вектор 
математических ожиданий числа одновременно наступивших событий 
$\mathbf{m}\hm= {\sf M} (\boldsymbol{\sigma}_l)$ 
вычисляются по формулам:

\vspace*{2pt}

\noindent
\begin{equation*}
\lambda=\mathbf{p}\boldsymbol{\Lambda} \mathbf{u}\,;\enskip
\mathbf{m}=\fr{1}{\lambda}\sum\limits_{\mathbf{n}\in 
\boldsymbol{\mathcal{N}}_0^K} 
(\mathbf{p}\mathbf{a}_{\mathbf{n}})\mathbf{n}\,,
%\label{e23-n}
\end{equation*}

\vspace*{-4pt}

\noindent
где $\mathbf{a}_{\mathbf{n}}=\mathbf{A}_{\mathbf{n}}\mathbf{u}$. 
  
  Полагая $t_0=0$, обозначим через $\tau_l\hm= t_l\hm- t_{l-1}$, 
$l\hm=1,2,\ldots$\,, длины интервалов между моментами наступления событий 
и~через $X_l\hm= X(t_l)$, $l\hm=1,2,\ldots$\,, состояния фазового процесса 
в~моменты после наступления событий потока. Марковский поток групп 
событий является полумарковским потоком, поскольку последовательность 
$(X_l, \boldsymbol{\sigma}_l,\tau_l)$, $l\hm=1,2,\ldots$\,,~--- процесс марковского 
восстановления~\cite{25-n}. Условное распределение последующего состояния 
этого процесса зависит только от текущего состояния фазового процесса:

\vspace*{-3pt}

\noindent
  \begin{multline*}
  {\sf P}\left(X_l=j,\ \boldsymbol{\sigma}_l=\mathbf{n}\,,\ 
  \tau_l<x\vert X_{l-1}=i\,, \boldsymbol{\sigma}_{l-1} =\mathbf{k}\,,\right.\\
\left.  \tau_{l-1}<y\right)={}\\
{}=
   {\sf P} \left( X_l=j,\ \boldsymbol{\sigma}_l=\mathbf{n}\,,\tau_l<x\vert 
X_{l-1}=i\right) = G_{\mathbf{n}}(i,j,x).\hspace*{-6.44518pt}
  \end{multline*}
  
  Матрицы $\mathbf{G}_{\mathbf{n}}(x)\hm= [G_{\mathbf{n}}(i,j,x)]$, 
описывающие связанный с марковским потоком процесс марков-\linebreak\vspace*{-12pt}

\pagebreak

\noindent
ского 
восстановления $(X_l, \boldsymbol{\sigma}_l,\tau_l)$,  и~их преобразования 
Лап\-ла\-са-Стилть\-еса имеют следующий вид:
\begin{multline}
  \mathbf{G}_{\mathbf{n}}(x) = \int\limits_0^x \exp 
(z\mathbf{A}_{\mathbf{0}}) \mathbf{A}_{\mathbf{n}}\,dz={}\\
{}= \left( \exp 
(x\mathbf{A}_{\mathbf{0}})-\mathbf{I}\right) \mathbf{A}_{\mathbf{0}}^{-1} 
\mathbf{A}_{\mathbf{n}}\,,\enskip
  \mathbf{n}\in \boldsymbol{\mathcal{N}}_0^K\,;
  \label{e24-n}
  \end{multline}
  
  \noindent
  \begin{equation*}
  \int\limits_0^\infty e^{-vx} d\mathbf{G}_{\mathbf{n}}(x) = (v\mathbf{I}-
\mathbf{A}_{\mathbf{0}})^{-1} \mathbf{A}_{\mathbf{n}}\,,\enskip
  \mathbf{n}\in \boldsymbol{\mathcal{N}}_0^K\,.
 % \label{e25-n}
  \end{equation*}
  
  Используя матрицы $\mathbf{G}_{\mathbf{n}}(x)$, можно найти совместное 
распределение числа~$\boldsymbol{\sigma}_l$ наступивших событий 
и~длин~$\tau_l$ интервалов между вызывающими моментами, а также 
плотность этого распределения: 
  \begin{multline}
F_{\mathbf{k}_1, \mathbf{k}_2, \ldots , \mathbf{k}_m}(x_1, x_2,\ldots , x_m) ={}\\
{}=  {\sf P} \left(\boldsymbol{\sigma}_l=\mathbf{k}_l,\ \tau_l<x_l,\ l=1,2,\ldots , 
m\right)={}\\
{}=  \boldsymbol{\alpha}\mathbf{G}_{\mathbf{k}_1}(x_1) 
\mathbf{G}_{\mathbf{k}_2}(x_2)\cdots \mathbf{G}_{\mathbf{k}_m}(x_m) 
\mathbf{u}\,;
  \label{e26-n}
  \end{multline}
  
  \vspace*{-12pt}
  
  \noindent
  \begin{multline*}
  f_{\mathbf{k}_1, \mathbf{k}_2,\ldots , 
  \mathbf{k}_m}(x_1,x_2,\ldots , x_m) ={}\\ 
{}=\boldsymbol{\alpha}\exp (x_1\mathbf{A}_{\mathbf{0}}) \mathbf{A}_{\mathbf{k}_1}\exp (
x_2 \mathbf{A}_{\mathbf{0}}) \mathbf{A}_{\mathbf{k}_2}\cdots{}\\
{}\cdots  \exp 
(x_m\mathbf{A}_{\mathbf{0}})\mathbf{A}_{\mathbf{k}_m} \mathbf{u}\,,
  %\label{e27-u}
  \end{multline*}
  где
  $$
  \mathbf{k}_1, \mathbf{k}_2, \ldots , \mathbf{k}_m\in 
\boldsymbol{\mathcal{N}}_0^K\,;
$$
$$ x_0, x_1, \ldots , x_m>0\,,\ m=1,2,\ldots
  $$
  
  Вероятности переходов вложенной цепи Маркова 
$(X_l,\boldsymbol{\sigma}_l)$ зависят лишь от состояния фазового процесса 
после предыдущего вызывающего мо\-мента:
  \begin{multline*}
  {\sf P} \left(X_l =j,\ \boldsymbol{\sigma}_l= \mathbf{n}
  \vert X_{l-1}=i, \boldsymbol{\sigma}_{l-1}= 
\mathbf{k}\right) ={}\\
  {}= {\sf P}\left( X_l=j,\ \boldsymbol{\sigma}_l= \mathbf{n} 
\vert X_{l-1}=i\right) =Q_{\mathbf{n}}(i,j)\,,
  \end{multline*}
где $Q_{\mathbf{n}}(i,j)\hm= 
\lim\nolimits_{x\to\infty} G_{\mathbf{n}}(i,j,x)$. 
Из~(\ref{e24-n}) следует, что матрица вероятностей переходов 
$\mathbf{Q}_{\mathbf{n}}\hm= [Q_{\mathbf{n}}(i,j)]$ вложенной цепи Маркова 
$(X_l, \boldsymbol{\sigma}_l)$ и матрица вероятностей 
переходов~$\mathbf{Q}$ цепи Маркова~$X_l$ имеют следующий вид:
\begin{equation*}
\mathbf{Q}=-\mathbf{A}_{\mathbf{0}}^{-1}\boldsymbol{\Lambda}\,,\enskip
\mathbf{Q}_{\mathbf{n}}= 
-\mathbf{A}_{\mathbf{0}}^{-1}\mathbf{A}_{\mathbf{n}}\,,\enskip
\mathbf{n}\in\boldsymbol{\mathcal{N}}_0^K\,.
%\label{e28-n}
\end{equation*}
                       
  Стационарные распределения $\mathbf{q}\hm= [q(i)]$ 
и~$\mathbf{q}_{\mathbf{n}}\hm= [q_{\mathbf{n}}(i)]$, $\mathbf{n}\hm\in 
\boldsymbol{\mathcal{N}}_0^K$, вложенных цепей Маркова~$X_l$ 
и~$(X_l,\boldsymbol{\sigma}_l)$ связаны со стационарным 
распределением~$\mathbf{p}$ процесса~$X(t)$ следующими равенствами:
 \begin{alignat*}{2}
  \mathbf{q}&=\fr{1}{\lambda}\,\mathbf{p}\boldsymbol{\Lambda}\,;&\quad
  \mathbf{p}&=-\lambda \mathbf{q}\mathbf{A}_{\mathbf{0}}^{-1}\,,\\
  \mathbf{q}&=\sum\limits_{\mathbf{n}\in \boldsymbol{\mathcal{N}}_0^K} 
\mathbf{q}_{\mathbf{n}}\,; &\quad
  \mathbf{q}_{\mathbf{n}}& = 
\fr{1}{\lambda}\,\mathbf{p}\mathbf{A}_{\mathbf{n}}\,,\enskip
  \mathbf{n}\in \boldsymbol{\mathcal{N}}_0^K\,.
  \end{alignat*}
  
  Если вектор из единиц~$\mathbf{u}$ является правым собственным вектором 
каждой из матриц~$\mathbf{A}_{\mathbf{n}}$ и выполняются равенства 

\noindent
  \begin{equation*}
  \mathbf{A}_{\mathbf{n}} \mathbf{u} =\lambda_{\mathbf{n}} 
\mathbf{u}\,,\enskip \mathbf{n}\in \boldsymbol{\mathcal{N}}_0^K\,,
  %\label{e29-n}
  \end{equation*}
то из~(\ref{e26-n}) следует, что при любом начальном 
распределении~$\boldsymbol{\alpha}$ марковский поток будет стационарным потоком 
без последействия. Аналогично, если вектор стационарных 
вероятностей~$\mathbf{p}$ является левым собственным вектором 
матриц~$\mathbf{A}_{\mathbf{n}}$  и выполняются равенства 

\noindent
\begin{equation*}
\mathbf{p}\mathbf{A}_{\mathbf{n}}=\lambda_{\mathbf{n}}\mathbf{p}\,,\enskip
\mathbf{n}\in \boldsymbol{\mathcal{N}}_0^K\,,
%\label{e30-n}
\end{equation*}
то при начальном распределении $\boldsymbol{\alpha}\hm=\mathbf{p}$ марковский 
поток будет стационарным потоком без последействия. В~обоих случаях 
вызывающие моменты марковского потока образуют пуассоновский поток 
интенсивности 

\noindent
\begin{equation*}
\lambda=\sum\limits_{\mathbf{n}\in \boldsymbol{\mathcal{N}}_0^K} 
\lambda_{\mathbf{n}}\,,
%\label{e31-n}
\end{equation*}
а векторы~$\boldsymbol{\sigma}_l$ числа наступивших в эти моменты событий 
независимы и имеют распределение вероятностей 

\noindent
\begin{equation*}
{\sf P}\left( \boldsymbol{\sigma}_l=\mathbf{n}\right) = 
\fr{\lambda_{\mathbf{n}}}{\lambda}\,,\enskip
\mathbf{n}\in \boldsymbol{\mathcal{N}}_0^K\,.
%\label{e32-n}
\end{equation*}
  
  Различные операции над марковскими потоками, такие как суперпозиция, 
прореживание, линейные преобразования и др., рассмотрены в~\cite{23-n}.

\vspace*{-12pt}

\section{Заключение}

\vspace*{-2pt}

  В первой части обзора показано, как марковские модели потоков событий 
могут быть построены на базе теории двухкомпонентных марковских 
процессов, однородных по второй компоненте. Здесь также представлены 
основные свойства и характеристики марковских потоков событий. Вторая 
часть обзора посвящена описанию важных для приложений подклассов 
марковских потоков как однородных, так и неоднородных событий. Кроме 
того, в ней будут рассмотрены современные модели  
мат\-рич\-но-экс\-по\-нен\-ци\-аль\-ных распределений и~рациональных потоков 
событий.

\vspace*{-12pt}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
 
 \vspace*{-2pt}
 
\bibitem{1-n}
\Au{Башарин Г.\,П.} О~вычислении моментов избыточной нагрузки сложной системы~// 
Электросвязь, 1970. №\,4. С.~68--77.

%\pagebreak

\bibitem{2-n}
\Au{Башарин Г.\,П., Кокотушкин~В.\,А.} Об условиях усиленного статистического 
равновесия для сложных сис-\linebreak\vspace*{-12pt}

\pagebreak

\noindent
тем массового обслуживания~// Проблемы передачи 
информации, 1971. Т.~7. №\,3. С.~67--75.
\bibitem{3-n}
\Au{Neuts M.\,F.} A~queue subject to extraneous phase changes~// Adv.
Appl. Probab., 
1971. Vol.~3. P.~78--119.
\bibitem{4-n}
\Au{Башарин Г.\,П.} О~вычислении моментов обслуженной и избыточной нагрузок сложной 
системы~// Техническая кибернетика, 1972. №\,1. С.~42--51.
\bibitem{5-n}
\Au{Rudemo M.} Point processes generated by transitions of Markov chains~// 
Adv. Appl. Probab., 1973. Vol.~5. Iss.~2. P.~262--286.
\bibitem{6-n}
\Au{Neuts M.\,F.} Probability distribution of phase type~// 
Liber amicorum Professor emeritus  Dr.\
H.~Florin~/ Ed. R.~Holvoet.~---
Louvain-la-Neuve, Belgium: Department of Mathematics, University of Louvain, 
1975. P.~173--206.
\bibitem{7-n}
\Au{Хинчин A.\,Я.} Потоки случайных событий без последействия~// Теория вероятностей и 
ее применения, 1956. Т.~1. №\,1. С.~3--18. 
\bibitem{8-n}
\Au{Наумов В.\,А.} Исследование некоторых многофазных систем массового 
обслуживания:~Дис.~$\ldots$~канд.\linebreak физ.-мат. наук.~--- М.: УДН, 1978. 98~с.
\bibitem{9-n}
\Au{Neuts M.\,F.} A~versatile Markovian point process.~--- Newark, DE, 
USA: Department of Statistics and Computer Science, University of Delaware, 1977.
 Technical Report 77/13. 29~p.
\bibitem{10-n}
\Au{Neuts M.\,F.} A~versatile Markovian point process~// J.~Appl. Probab., 1979. Vol.~16. 
Iss.~4. P.~764--779.
\bibitem{11-n}
\Au{Ramaswami V.} The $N/G/1$ queue and its detailed analysis~// Adv. Appl. Probab., 
1980. Vol.~12. Iss.~1. P.~222--261.
\bibitem{12-n}
\Au{Blondia C.} The $N/G/1$ finite capacity queue~// Commun. Stat. Stochastic 
Models, 1989. Vol.~5. Iss.~2. P.~273--294. 
\bibitem{13-n}
\Au{Saito H.} The departure process of an $N/G/1$ queue~// Perform. Evaluation, 1990. 
Vol.~11. Iss.~4. P.~241--251.
\bibitem{14-n}
\Au{Lee G., Jeon~J.} A~new approach to an $N/G/1$ queue~// Queueing Syst., 2000. Vol.~35. 
Iss.~1-4. P.~317--322.
\bibitem{15-n}
\Au{Lucantoni D.\,M., Meier-Hellstern~K., Neuts~M.\,F.} A~single-server queue with server 
vacations and a class of non-renewal arrival processes~// Adv. Appl. Probab., 1990. 
Vol.~22. Iss.~3. P.~676--705.
\bibitem{16-n}
\Au{\mbox{\!\!{\ptb{\c{C}}}inlar E.}} Markov additive processes~// 
Z.~Wahrscheinlichkeit., 1972. Iss.~24. P.~85--93; 95--121. 
\bibitem{17-n}
\Au{Asmussen S.} Applied probability and queues.~--- New York, NY, USA: Springer, 2003. 
438~p.
\bibitem{18-n}
\Au{Erlang A.\,K.} \mbox{L{\!\ptb{\o}}sning} af nogle Problemer fra Sandsynlighedsregningen af 
Betydning for de automatiske Telefoncentraler~// Elektroteknikeren, 1917. Iss.~13. P.~5--13.
\bibitem{19-n}
\Au{Erlang A.\,K.} Solution of some problems in the theory of probabilities of significance in 
automatic telephone exchanges~// T.~Danish Acad. Technical Sci., 
1948. Iss.~2. P.~138--155. 
\bibitem{20-n}
\Au{Булинский А.\,В., Ширяев~А.\,Н.} Теория случайных процессов.~--- М.:  Физматлит, 2005, 
402~с.
\bibitem{21-n}
\Au{Гантмахер Ф.\,Р.} Теория матриц.~--- М.: Наука, 1966. 576~с.
\bibitem{22-n}
\Au{Хинчин A.\,Я.} Математические методы теории массового обслуживания.~--- М.: АН 
СССР, 1955. 124~с.
\bibitem{23-n}
\Au{Pacheco~A., Prabhu~N.\,U.} Markov-additive processes of arrivals~// Advances in queueing 
theory, methods, and open problems~/ Ed. J.\,H.~Dshalalow.~--- Boca Raton, FL,
USA: CRC Press, 
1995. P.~167--194.
\bibitem{24-n}
\Au{Ежов И.\,И., Скороход~А.\,В.} Марковские процессы, однородные по второй 
компоненте~// Теория вероятностей и ее применения, 1969. Т.~14. №\,1. С.~3--14;  
№\,4. С.~679--692.
\bibitem{25-n}
\Au{Королюк В.\,С., Турбин~А.\,Ф.} Полумарковские процессы и их приложения.~--- Киев: 
Haукoвa Дyмкa, 1976. 184~с.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 02.07.20}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{-2pt}

\def\tit{ON MARKOVIAN AND~RATIONAL ARRIVAL PROCESSES.~I}


\def\titkol{On Markovian and~rational arrival processes.~I}

\def\aut{V.\,A.~Naumov$^1$ and К.\,Е.~Samouylov$^{2,3}$}

\def\autkol{V.\,A.~Naumov and К.\,Е.~Samouylov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-9pt}


\noindent
$^1$Service Innovation Research Institute, 
8A~Annankatu, Helsinki 00120, Finland
   
\noindent
$^2$Peoples' Friendship University of Russia (RUDN University), 
6~Miklukho-Maklaya Str., Moscow 117198, Russian\linebreak
$\hphantom{^1}$Federation
   
\noindent
$^3$Institute of Informatics Problems, Federal Research Center 
``Computer Science and Control'' of the Russian\linebreak
$\hphantom{^1}$Academy of Sciences, 
44-2~Vavilov Str., Moscow 119333, Russian Federation
  

\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2020\ \ \ volume~14\ \ \ issue\ 3}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2020\ \ \ volume~14\ \ \ issue\ 3
\hfill \textbf{\thepage}}}

\vspace*{3pt} 


  
  
\Abste{This article is the first part of a review carried out 
within the framework of the RFBR project No.\,19-17-50126. 
The purpose of this review is to get the interested readers familiar 
with the basics of the theory of Markovian arrival processes to 
facilitate the application of these models in practice and, 
if necessary, to study them in detail. In the first part of the 
review, the properties of general Markovian arrival processes are 
presented and their relationship with Markov additive processes 
and Markov renewal processes is shown. In the second part of the 
review, the important for applications subclasses of Markovian 
arrival processes, i.\,e., simple and batch arrival processes 
of homogeneous and heterogeneous arrivals, are considered. After that, 
it is shown how the properties
of Markovian arrival processes are 
associated with the product form of stationary distributions of Markov 
systems. In\linebreak\vspace*{-12pt}}

\Abstend{conclusion, matrix-exponential distributions and rational 
arrival processes are discussed that expand the capabilities of 
Markovian arrival processes for modeling complex systems, while 
preserving the convenience of analyzing them using computations.}
  
\KWE{Markov chain; Markovian arrival process; 
Markov additive process; MAP; MArP}
  
 
  
\DOI{10.14357/19922264200302} 

\vspace*{-20pt}

 \Ack
 
 \vspace*{-4pt}
 
  \noindent
%  The reported study was funded by the Russian Foundation for 
%Basic Research (project No.\,19-17-50126). 
The reported study was funded by RFBR, project number 19-17-50126. 

%\vspace*{6pt}

 \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
 
 \bibitem{1-n-1}
  \Aue{Basharin, G.\,P.} 1970. O vychislenii momentov izbytochnoy nagruzki slozhnoy sistemy 
[On calculating the moments of excessive load of a complex system]. \textit{Elektrosvyaz'} 
[Electrosvyaz Magazine] 4:68--77.
  \bibitem{2-n-1}
  \Aue{Basharin, G.\,P., and V.\,A.~Kokotushkin}. 1971. 
  Conditions for strong statistical equilibrium of complex mass 
  servicing systems. \textit{Probl. Inform. Transm.} 7(3):242--248.
  \bibitem{3-n-1}
  \Aue{Neuts, M.\,F.} 1971. A~queue subject to extraneous phase changes. \textit{Adv. Appl. 
Probab.} 3:78--119.
  \bibitem{4-n-1}
  \Aue{Basharin, G.\,P.} 1972. O~vychislenii momentov obsluzhennoy i~izbytochnoy nagruzok 
slozhnoy sistemy [On calculating the moments of serviced and redundant loads of a~complex 
system]. \textit{Tekhnicheskaya kibernetika} [Technical Cybernetics] 1:42--51.
  \bibitem{5-n-1}
  \Aue{Rudemo, M.} 1973. Point processes generated by transitions of Markov chains. \textit{Adv. 
Appl. Probab.} 5(2):262--286.
  \bibitem{6-n-1}
  \Aue{Neuts, M.\,F.} 1975. Probability distribution of phase type. 
  \textit{Liber amicorum 
Professor emeritus Dr.\ H.~Florin.} Ed. R.~Holvoet. 
Louvain-la-Neuve, 
Belgium: Department of Mathematics, University of Louvain. 173--206.
  \bibitem{7-n-1}
  \Aue{Khinchin, A.\,Ya}. 1956.
  Sequences of chance events without after-effects.
\textit{Theor. Probab. Appl}. 1(1):1--15.

  \bibitem{8-n-1}
  \Aue{Naumov, V.\,A.} 1978. Issledovanie nekotorykh mnogofaznykh sistem massovogo 
obsluzhivaniya [Research of some multiphase queuing systems].  Moscow: UDN. 
 PhD Thesis. 98~p.
  \bibitem{9-n-1}
  \Aue{Neuts, M.\,F.} 1977. A~versatile Markovian point process. 
  Newark, DE: Department of Statistics and Computer Science, 
  University of Delaware. Technical Report 77/13.  29~p.
  \bibitem{10-n-1}
  \Aue{Neuts, M.\,F.} 1979. A~versatile Markovian point process. 
  \textit{J.~Appl. Probab.} 
16(4):764--779.
  \bibitem{11-n-1}
  \Aue{Ramaswami, V.} 1980. The $N/G/1$ queue and its detailed analysis. \textit{Adv. Appl. 
Probab.} 12(1):222--261.
  \bibitem{12-n-1}
  \Aue{Blondia, C.} 1989. The $N/G/1$ finite capacity queue. \textit{Commun. 
Stat. Stochastic Models} 5(2):273--294.
  \bibitem{13-n-1}
  \Aue{Saito, H.} 1990. The departure process of an $N/G/1$ queue. \textit{Perform. 
Evaluation} 11(4):241--251.
  \bibitem{14-n-1}
  \Aue{Lee, G., and J.~Jeon.} 2000. A~new approach to an $N/G/1$ queue. \textit{Queueing 
Syst.} 35(1-4):317--322.
  \bibitem{15-n-1}
  \Aue{Lucantoni, D.\,M., K.~Meier-Hellstern, and M.\,F.~Neuts.} 1990. A~single-server queue 
with server vacations and a~class of non-renewal arrival processes. 
\textit{Adv. Appl. Probab.} 
22(3):676--705.
  \bibitem{16-n-1}
  \Aue{\mbox{\!\!{\ptb{\c{C}}}inlar, E.}} 1972. Markov additive processes. \textit{Z.~Wahrscheinlichkeit.}
  24:85--93; 95--121. 
  \bibitem{17-n-1}
  \Aue{Asmussen, S.} 2003. \textit{Applied probability and queues}. New York, NY:  Springer. 
438~p.
  \bibitem{18-n-1}
  \Aue{Erlang, A.\,K.} 1917. \mbox{L{\!\ptb{\o}}\,sning} af nogle Problemer fra 
Sandsynlighedsregningen af \textit{Betydning for de automatiske Telefoncentraler. 
Elektroteknikeren} 13:5--13.
  \bibitem{19-n-1}
  \Aue{Erlang, A.\,K.} 1948. Solution of some problems in the theory of probabilities of 
significance in automatic telephone exchanges. \textit{T.~Danish Acad. 
Technical Sci.} 2:138--155.
  \bibitem{20-n-1}
  \Aue{Bulinskiy, A.\,V., and A.\,N.~Shiryaev.} 2005. \textit{Teoriya sluchaynykh protsessov} 
[Theory of random processes]. Moscow: Fizmatlit. 402~p.
  \bibitem{21-n-1}
  \Aue{Gantmakher, F.\,R.} 1966. \textit{Teoriya matrits} [Matrix theory]. Moscow: Nauka. 
576~p.
  \bibitem{22-n-1}
  \Aue{Khinchin, A.\,Ya}. 1955. \textit{Matematicheskie metody teorii massovogo 
obsluzhivaniya} [Mathematical methods of queuing theory]. Moscow: 
AS USSR. 124~p. 
  \bibitem{23-n-1}
  \Aue{Pacheco, A., and N.\,U.~Prabhu}. 1995. 
  Markov-additive processes of arrivals. 
\textit{Advances in queueing theory, methods, and open problems.} 
Ed. J.\,H.~Dshalalow. Boca 
Raton, FL: CRC Press. 167--194.
  \bibitem{24-n-1}
  \Aue{Ezhov, I.\,I., and A.\,V.~Skorokhod.} 1969. 
  Markov processes with homogeneous second component. \textit{Theor.
   Probab. Appl.} 14(1):1--13;  
14(4):652--667.
  \bibitem{25-n-1}
  \Aue{Korolyuk, V.\,S., and A.\,F.~Turbin.} 1976. \textit{Polumarkovskie protsessy i~ikh 
prilozheniya} [Semi-Markov processes and their applications]. Kiev: Naukova Dumka. 184~p.

 \end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-9pt}

\hfill{\small\textit{Received July 2, 2020}}

%\pagebreak

\vspace*{-18pt}

  
  \Contr
  
  \vspace*{-4pt}
  
  \noindent
  \textbf{Naumov Valeriy A.} (b.\ 1950)~--- 
  Candidate of Science (PhD) in physics and mathematics, scientific director, Service Innovation 
Research Institute, 8A~Annankatu, Helsinki 00120, Finland; \mbox{valeriy.naumov@pfu.fi}
  
  \vspace*{3pt}
  
  \noindent
  \textbf{Samouylov Konstantin E.} (b.\ 1955)~--- 
  Doctor of Science in technology, professor, Head of Department, 
  Peoples' Friendship University of Russia (RUDN University), 
  6~Miklukho-Maklaya St., Moscow 117198, Russian Federation;
   senior scientist, Institute of Informatics Problems, Federal 
   Research Center ``Computer Sciences and Control'' 
   of the Russian Academy of Sciences; 44-2~Vavilov Str., 
   Moscow 119133, Russian Federation; \mbox{samuylov\_ke@rudn.university}


\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 
  