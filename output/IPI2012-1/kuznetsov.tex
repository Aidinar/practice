\def\stat{kuznetsov}

\def\tit{ВЫЯВЛЕНИЕ ИМПЛИЦИТНОЙ ИНФОРМАЦИИ ИЗ~ТЕКСТОВ 
НА~ЕСТЕСТВЕННОМ ЯЗЫКЕ: ПРОБЛЕМЫ И~МЕТОДЫ}

\def\titkol{Выявление имплицитной информации из~текстов 
на~естественном языке: проблемы и~методы}

\def\autkol{И.\,П.~Кузнецов, Н.\,В.~Сомин}
\def\aut{И.\,П.~Кузнецов$^1$, Н.\,В.~Сомин$^2$}

\titel{\tit}{\aut}{\autkol}{\titkol}

%{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
%{Работа выполнена при поддержке РФФИ (гранты 09-07-12098, 09-07-00212-а и
%09-07-00211-а) и Минобрнауки РФ (контракт №\,07.514.11.4001).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Институт проблем информатики Российской академии наук, igor-kuz@mtu-net.ru}
\footnotetext[2]{Институт проблем информатики Российской академии наук, somin@post.ru}


\Abst{Рассматривается семантико-ориентированный лингвистический процессор (ЛП), 
осуществляющий глубинный анализ текстов естественного языка 
(ЕЯ) и формирующий на этой 
основе структуры знаний. Одно из направлений развития таких процессоров связано с 
выявлением имплицитной информации, которая рассматривается в узком плане~--- как 
извлечение из текстов информационных объектов, их свойств и связей, заданных в неявном 
виде. Предлагаются методики, обеспечивающие такое извлечение на различных уровнях 
анализа текстов~--- лексико-морфологическом, синтактико-се\-ман\-ти\-ческом и структурном.} 

\KW{лингвистические процессоры; извлечение знаний; имплицитная информация}

 \vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}


\section{Постановка задачи выявления имплицитной информации}

\subsection{Цели проекта <<Лингво-ИИ>>}

     На протяжении 20~лет в ИПИ РАН развивается направление, связанное с 
автоматической обработкой потоков (корпусов) текстов на ЕЯ 
с целью выявления из текстов информационных объектов, их свойств и 
связей. В~результате формируются структуры, которые служат основой для 
выполнения различных видов объектных (семантических) поисков, а также 
экспертных решений, составляющих круг задач пользователей~[1--5]. Это 
направление связано с формализацией текстов и относится к области 
{\bfseries\textit{извлечения знаний}} (\textit{knowledge extraction}). При этом 
важно, чтобы знания были представлены в форме, предусматривающей 
характер последующей обработки. 
     
     Следует учитывать особенности ЕЯ, носители которого обладают такими 
возможностями, до моделирования которых науке еще нужно пройти очень 
большой путь. Это, прежде всего, видение мира. За текстами ЕЯ человек видит 
картины внешнего мира, которые несут гораздо больше информации, чем сам 
текст. Человек способен по отдельным компонентам, присутствующим в 
тексте, вос\-ста\-нав\-ли\-вать эти картины, дополнять их, использовать 
при\-чин\-но-след\-ст\-вен\-ные зависимости для прослеживания последующих изменений, 
динамики. Такая возможность выходит далеко за рамки моделей, основанных 
на логическом выводе. Отсюда следует особенность текстов ЕЯ. Как правило, в 
них умалчивается то, что известно адресатам, для которых предназначен текст, 
и что легко восстанавливается по тексту. 
     
     Другими словами, большое количество нужной пользователю 
информации дается в текстах ЕЯ в скрытом виде. Такая 
{\bfseries\textit{информация}} называется {\bfseries\textit{имплицитной}}. 
Помимо этого, в текстах имеет место множество 
{\bfseries\textit{неопределенностей}}, когда имеет место несколько вариантов 
анализа и требуется выбор одного из них. Многие неопределенности человек 
просто не замечает, но при автоматизации требуется разработка специальных 
методик и процедур для их разрешения. Важной научной и практической 
проблемой в области извлечения знаний из текстов ЕЯ является представление 
такой информации в явном виде: преобразование имплицитной информации в 
эксплицитную и устранение возникающих при этом неопределенностей, что 
является важным фактором в плане повышения качества решения 
пользовательских задач. 

В~связи с многоплановостью проблемы ее решение 
возможно только при существенных ограничениях. Речь будет идти о такой 
имплицитной информации, которую можно восстановить путем глубинного 
анализа текстов и логического вывода. Экстралингвистическая информация 
останется за пределами рассмотрения. 
     
     Работа является логическим продолжением исследований, имеющих 
целью создание нового \mbox{класса} интеллектуальных сис\-тем, основанных на 
автоматической формализации текстов ЕЯ с формированием структур знаний 
для решения ло\-ги\-ко-ана\-ли\-ти\-че\-ских задач, по проектам ИПИ РАН 
<<Криминал>>, <<Аналитик>>, <<Поток>>, <<Лингвопроцессор>>. В~рамках 
этих проектов созданы новые методы формализации и извлечения знаний из 
текстов ЕЯ, разработан и постоянно совершенствуется уникальный 
{\bfseries\textit{семантико-ориентированный ЛП}}, 
выделяющий информацию для пользователей, которые интересуются 
конкретными объектами, их свойствами и связями (другое название~--- 
объект\-но-ори\-ен\-ти\-ро\-ван\-ный ЛП). Такая информация\linebreak отоб\-ра\-жа\-ет\-ся на 
структуры знаний. Лингвисти\-ческий процессор реализован средствами языка ДЕКЛ и 
управляется лингвистическими знаниями (ЛЗ) в виде предметных словарей, 
средств параметрической настройки, а также правил выделения объектов и 
связей~[1--5]. С~помощью ЛЗ осуществляется настройка ЛП на 
соответствующие категории пользователей и корпусы текстов. В~результате 
возникает конкретная реализация. Таким образом, речь идет о средствах 
построения класса процессоров нового типа. 
     
     Проект <<Лингво-ИИ>> ставит целью дальнейшее развитие таких 
процессоров, совершенствование методик и средств автоматизации для более 
точного и полного выявления объектов, их признаков и связей, устранения 
неопределенностей на всех уровнях формализации, дополнения структур 
знаний новой информацией, отсутствующей или заданной в неявном виде. 
 
\subsection{Виды имплицитной информации}
     
     В проекте <<Лингво-ИИ>> затрагивается только та часть имплицитной 
информации, которая поддается автоматизации в рамках процедур, 
обеспечивающих работу ЛП и решение задач на 
основе технологии баз знаний. В~реальности имплицитная информация далеко 
выходит за рамки такой интерпретации. 
     
     Понятие <<\textit{имплицитный}>> возникло от латинского слова 
\textit{implicito}, которое переводится как <<\textit{внут\-ри заложенное}>>, и 
применительно к информации означающее <<\textit{скрытый, 
подразумеваемый, неявный}>>. В~лингвистике {\bfseries\textit{имплицитной}} 
называется {\bfseries\textit{информация}}, которая в явном виде не выражается, 
но извлекается адресатом при интерпретации сообщения~[6, 7]. Существуют 
различные подходы к классификации имплицитной информации. 
     В~част\-ности, некоторые из них представлены в~[6--11]. Рассмотрим, 
какие виды имплицитной информации различаются в лингвистике.
     
     Пресуппозиция~--- это термин лингвистической семантики. Различают 
семантическую, прагматическую и лексическую 
     пресуппозиции~\cite{7kuz, 9kuz}. Семантическая пресуппозиция (в 
логике~--- импликация) предполагает элементы логического вывода для 
порождения новых знаний на основе имеющейся информации. Как правило, 
такое порождение осуществляется на уровне суждений или фактов, которые 
описываются на ЕЯ с помощью глаголов и управляемых ими форм. Со многими 
глаголами связаны действия, которые вызывают определенные изменения 
ситуации. Например, <<\textit{Купить вещь}>> (означает, что вещь будет у 
субъекта действия, но количество денег у него уменьшится), <<\textit{Взять 
книгу у}~$A_1$>> (означает, что книга будет у субъекта действия и ее не будет 
у $A_1$) и~т.\,д. Описанные изменения задаются с помощью правил, которые 
являются основой логического вывода. Другие примеры: <<\textit{Мы 
работаем, чтобы сохранить Ваше доверие}>> (означает, что такое доверие 
было), <<\textit{Воссоединение Белоруссии и России}>> (означает, что раньше 
они были вместе). Глаголы типа <<\textit{видеть}>>, <<\textit{знать}>> 
подразумевают истинность суждения и~т.\,д. 
     
     Прагматическая пресуппозиция учитывает знания и убеждения адресата. 
Суждение~P является прагматической пресуппозицией суждения~S, если, 
высказывая суждение~S, адресант считает~P само собой разумеющимся и 
известным адресату. Лексическая пресуппозиция предполагает выводы на 
уровне лексического анализа. Например, из <<\textit{истерический}>> следует 
<<\textit{нервный}>>, <<\textit{больной}>>, <<\textit{псих}>> и~т.\,д. 
     
     Анафоры (от греч.\ \textit{anapheren}~--- относить назад) являются 
разновидностью имплицитной информации. Они задаются в текстах с помощью 
анафорических местоимений, связок <<\textit{тот, который}>>, кратких имен 
и отличительных свойств. Например, <<\ldots\textit{Медведев}\ldots\ \textit{Он} 
(или \textit{президент}, или \textit{который})\ldots>>. Разрешение анафор~--- 
это соотнесение местоимений с соответствующими лицами или объектами. 
Различаются синтаксические анафоры, для разрешения которых достаточно 
морфологических признаков, и семантические анафоры, где учитываются 
семантические категории слов и возможность участия соответствующих 
объектов в тех или иных действиях.
     
     Коммуникативные импликатуры учитывают коммуникативное 
воздействие языка на человека~\cite{10kuz}. Это, прежде всего, жанровые и 
стилистические смещения, которые в наибольшей степени проявляются в 
скрытой рекламе. Например, когда рекламное сообщение о лекарствах 
маскируется под рекомендации врача или больной говорит об их 
положительном воздействии при лечении. Коммуникативные импликатуры при 
манипулировании сознанием человека учитывают многие его свойства. Человек 
лучше запоминает информацию в начале и в конце текстового материала, при 
повторах. Критичность к сообщению снижается, если имеет место доверие к 
носителю информации, если оно по каким-то причинам нравится (эффект 
эмоциональности), если человек предрасположен к ее восприятию. 
     
     Подобная классификация далеко не полная. Но она иллюстрирует всю 
сложность языка и его восприятия. Многие виды имплицитной информации 
доступны только для человека. У~компьютера нет фоновых знаний (как у 
человека). Компьютером невозможно манипулировать перечисленными выше 
способами. Вне сферы автоматизации остаются метафоры, аналогии, многие 
сравнительные конструкции и~др. Поэтому и само понятие <<имплицитный>> 
трансформируется с учетом возможностей и задач ЛП и баз знаний.
 
\subsection{Проблемы извлечения имплицитной информации}
     
     Проект <<Лингво-ИИ>> направлен на разработку методик 
автоматического извлечения имплицитной информации в рамках 
существующего инструментария~--- языка {\bfseries\textit{расширенных 
семантических сетей}} (РСС) и средств их обработки ({\bfseries\textit{язык 
ДЕКЛ}}). Язык РСС состоит из фрагментов, которые в прос\-тей\-шем случае 
имеют вид предикатов. В~отличие от предикатов каждый фрагмент имеет свой 
уникальный код, который может стоять на аргументных местах других 
фрагментов. Это необходимо для представления семантических составляющих 
ЕЯ, когда действия включают в себя объекты или другие действия и~т.\,д. 
Возникают сложные структуры, выходящие за рамки языка логики предикатов. 
При этом логический вывод осуществляется с помощью правил преобразования 
таких структур, реализованных в инструментальной среде ДЕКЛ~\cite{3kuz}. 
     
     Понятие {\bfseries\textit{имплицитный}} рассматривается с точки зрения 
дополнения и уточнения информационных объектов и связей, которые 
выделяются ЛП в процессе формализации текстов ЕЯ и которые необходимы 
для решения задач. Остаются в стороне многие виды пресуппозиций, 
коммуникативные импликатуры и~др. При этом акцент смещается в сторону 
импликатур, которые порождаются с по\-мощью логического вывода, 
осуществляемого путем анализа и преобразования структур знаний. 
     
     Отметим два важных момента. Во-пер\-вых, на основе логического 
вывода осуществляется принятие многих решений, в том числе экспертных. 
В~результате формируются экспертные знания, которые в явном виде не 
присутствуют в текстах документов и которые будем считать разновидностью 
имплицитной информации. А~во-вто\-рых, при работе ЛП (на всех уровнях 
анализа) требуются специальные методики для автоматического устранения 
разного рода неопределенностей~--- лексической, морфологической, 
синтаксической и семантической. Это необходимо для повышения качества 
работы ЛП при формировании структур знаний, на основе которых выявляется 
имплицитная информация. 
     
     Итак, автоматическое извлечение имплицитной информации связано с 
решением ряда достаточно сложных лингвистических задач: выявлением 
подразумеваемых объектов и связей, идентификацией на основе анафорических 
ссылок, разрешением различного рода полисемии и неопределенностей и~др. 
Для этих задач требуются нетривиальные ме-\linebreak ханизмы принятия решений и 
соответствующая техника логического вывода. Их наличие сущест\-венно 
повышает научный уровень исследований в области создания ЛП. Для 
уточнения задач рас\-смот\-рим структуру ЛП, 
разрабатываемых в ИПИ РАН. 
     
     Семантико-ориентированный ЛП состоит из четырех основных 
компонентов.
     
\smallskip

     \textbf{1.}\ {\bfseries\textit{Блок лексико-морфологического анализа}} (ЛМА). 
Выделяет из документа слова и предложения и выдает в виде семантической 
сети, пред\-став\-ля\-ющей собой последовательность компонентов (слов в 
нормальной форме, чисел, знаков) и их основные признаки~--- лексические, 
морфологические и~др.~\cite{13kuz, 15kuz}. Такая сеть названа 
{\bfseries\textit{пространственной структурой $($ПС$)$ документа}}. 
Более того, блок использует набор предметных словарей (стран, 
регионов России, имен, профессий и~др.)\ для придания словам и 
словосочетаниям дополнительных семантических признаков~\cite{12kuz}.

\smallskip
     
\textbf{2.}\      {\bfseries\textit{Блок синтактико-семантического анализа}} (ССА). 
Путем анализа ПС документа он выделяет объекты и связи. На их основе 
строит другую семантическую сеть, представляющую семантическую 
структуру (СС) документа, называемую {\bfseries\textit{содержательным 
портретом документа}}~[2--5]. В~СС документа представляются не только 
объекты и связи, но и их участие в действиях, из каких предложений взяты 
тексты их описания и многое другое. По СС документа можно восстановить 
сам текст. 
     
     Содержательные портреты образуют структуры знаний, которые 
запоминаются в базе знаний. Блок управляется ЛЗ, за счет которых 
обеспечивается: извлечение информационных объектов (лиц, организаций, 
событий, мест и~др.), выявление связей объектов (каким образом лица связаны 
с организациями, адресами и~др.), анализ глагольных форм, причастных и 
деепричастных оборотов с выявлением фактов участия объектов в тех или иных 
действиях, идентификация объектов (с учетом анафорических ссылок и 
сокращенных наименований), выявление связей действий с местом или 
временем, анализ при\-чин\-но-след\-ст\-вен\-ных и временн$\acute{\mbox{ы}}$х связей между 
действиями и событиями.

\pagebreak
     
     Этот блок включает в себя базу ЛЗ, которая 
содержит правила анализа текста во внутреннем представлении (РСС). Они 
определяют работу ЛП.

\smallskip
     
\textbf{3.}\      {\bfseries\textit{Блок экспертных решений}}. Анализирует 
структуры знаний, решает ло\-ги\-ко-ана\-ли\-ти\-че\-ские задачи и формирует 
дополнительную (экспертную) информацию, необходимую пользователю. 

\smallskip
     
\textbf{4.}\      {\bfseries\textit{Обратный лингвистический процессор}} (ОЛП). 
Преобразует структуры знаний в тексты ЕЯ, которые должны быть выданы 
пользователю.
     
     Выявление имплицитной информации и устранение неопределенностей 
осуществляется (в рамках ЛП) на всех уровнях преобразования текстов 
документов в СС документов с их последующей обработкой.

\subsection{Задачи выявления имплицитной информации}
     
     Автоматическое выявление имплицитной информации на основе анализа 
текстов ЕЯ и разработанных методов их формализации требует проведения 
следующих работ.
     \begin{itemize}
\item  Совершенствование блока ЛМА. 
Разработка методик (с доработкой соответствующих алгоритмов и программ) 
для устранения неопределенностей при следующих видах анализа:
\begin{itemize}
\item разбиении текста на словоформы и предложения (неопределенности 
вызваны наличием в корпусах текстов лексем, содержащих буквы, цифры и 
разделители практически в произвольной последовательности); 
\item присвоении словам морфологических и ряда семантических 
признаков за счет анализа составных частей словоформы (выделение фамилий); 
\item ранжировании вариантов ЛМА (разрешение лексической полисемии);
\item присвоении словам семантических признаков на основе предметных 
каталогов (в случае наличия несколько вариантов такого присвоения, взятых из 
различных каталогов);
\item выделении объектов фиксированной структуры (адресов, мейлов, 
имен сайтов и~др.);
\item приведении выделенных объектов к стандартной форме (для адресов).
\end{itemize}
\item  Разработка и реализация методик выявления объектов и их ролевых 
функций (потерпевший, преступник, террорист, сотрудник милиции и~др.)\ по 
косвенным признакам и контексту. Создание правил такого выявления в 
структуре ЛЗ блока  ССА. Проверка их 
работоспособности на документах области <<Криминалистика>>. 
\item Разработка и реализация методик выявления объектов, заданных в 
неявном виде, при отсутствии характеристических признаков объекта. 
Использование предположений о возможном их появлении. Создание правил 
такого выявления в структуре ЛЗ блока  ССА. 
\item Разработка и реализация методик выявления связей объектов путем 
предположения их наличия (например, если выявлена автомашина, то поиск ее 
обладателя и~т.\,д.). Создание правил такого выявления. Совершенствование 
блока ССА для поддержки этих  правил. 
\item Разработка методов идентификации объектов с учетом анафорических 
ссылок (местоимений) и их краткого описания. Создание правил 
идентификации в структуре ЛЗ. Совершенствование 
блока ССА и предметных словарей  для поддержки этих правил. 
\item Исследование явления переноса объектов (когда объект отсутствует, но 
подразумевается) и возможности его реализации в рамках ЛП. 
\item Разработка и реализация методик анализа происшествий и событий, 
представленных в виде структуры знаний (СС документов), с выявлением их 
значимых признаков и особенностей, отсутствующих в тексте описания. 
\item Разработка экспертных систем, использующих\linebreak
структуры знаний для 
порождения новой информации об объектах. Создание соответ\-ст\-вующей 
оболочки и ее применение для клас\-сификации организаций (<<Место учебы>>, 
\mbox{<<Место} работы>>, <<Курсы>>), оценки степени знания языков и~др. 
\item Разработка методик классификации объектов по текстам их описания на 
примере распознавания профессиональной области лица по описанию его 
функциональных обязанностей. 
\item Разработка ОЛП для выдачи объектов 
и результатов, представленных в виде РСС (в СС документов), на ЕЯ. 
Разработка блока, обеспечивающего выдачу описаний объектов в нормальной 
форме (в единственном чис\-ле, именительном падеже). 
     \end{itemize}
     
     В данной статье рассматриваются методы решения ряда таких задач, 
предложенных в рамках проекта <<Лингво-ИИ>>. 

\section{Методы и алгоритмы устранения лексической полисемии}

\subsection{Проблемы лексической полисемии}

     Читая текст, человек легко определяет в нем абзацы, предложения, 
лексемы и прочие элементы текста. Однако при разработке алгоритмов их 
автоматического распознавания возникают проблемы, вызванные наличием 
различного рода неоднозначностей. Например, знак <<.>> (точка) может 
выступать как конец предложения, как признак сокращения (<<\textit{г}.>>, 
<<\textit{прил}.>>), как инициалы в ФИО (типа <<\textit{И}.>>, <<\textit{А}.>>), 
как разделитель целой и дробной части чис\-ла в английских текстах
(\textit{3.14}), как разделитель в 
датах, как элемент электронного или Ин\-тер\-нет-ад\-ре\-са и в ряде других 
ролей. 
     
     В то же время для выявления имплицитной информации крайне важным 
является корректное определение начала и конца предложения или абзаца. 
Абзац является той максимальной рамкой, в которой имеет смысл искать 
имплицитную информацию для уже найденных объектов, но не име\-ющих 
достаточного количества характеристик. Для ряда важных характеристик такой 
рамкой служит более узкий контекст~--- предложение. 
     
     Однако именно аккуратное определение границ предложения является 
наиболее проблематичным. Как видно из приведенного примера, точка <<.>> 
не может служить надежным признаком конца предложения. Более того, в 
современных текстах в качестве признака конца предложения зачастую 
используются другие знаки. Это может быть <<конец ячейки>> таблицы, 
который при преобразованиях потерялся, или совершенно неожиданная 
комбинация символов. Отсюда следует необходимость разработки специальных 
методик.

\subsection{Методики снятия неопределенности на~лексическом уровне}

     Опыт разработки и использования ЛП показал, что главным способом 
борьбы с лексической полисемией является правильная классификация 
лексических единиц. Классификация должна помогать в решении основной 
задачи~--- выявления в тексте информационных (семантических) объектов. Но 
поскольку этот процесс многоуровневый, то хорошая классификация должна 
быть ориентирована не только на семантический анализ, но и на 
промежуточные уровни~--- морфологический и синтаксический анализ. 

В~разработанных ЛП классификация включает в себя более 20~лексических 
типов: слово из русских или латинских букв, в кавычках, с большой буквы или 
из больших букв, с точкой в конце и~т.\,д. 
     
     Определение конца предложения осуществляется еще до лексического 
анализа и определения типологии лексем. Уточнение, является ли данная точка 
концом предложения, осуществляется после проведения 
морфологического анализа лексем с привлечением лексической и 
морфологической информации. Для этого в рамках блока ЛМА разработаны 
соответствующие рекурсивные алго\-ритмы. 
{\looseness=1

}
     
     Для корректной фиксации границ предложений, <<точкой>> не 
заканчивающихся, наиболее эффективным оказалось использование операторов 
настройки алгоритмов на особенности задачи и предметной области~\cite{13kuz, 15kuz, 14kuz}. 

Примерами таких операторов являются следу\-ющие:
     \begin{itemize}
     \item NEW\_SENT (произвольное число аргументов). Семантика: если указанное 
во фрагменте слово записано с прописной буквы и находится в начале строки 
текста, то оно рассматривается как начало нового предложения. Допустимы 
знаки <<*>>, заменяющие окончание или указание части речи, типа 
$^*$V, $^*$T. Пример записи: NEW\_SENT(ANALYSIS, ASSUR$^*$). 
Действие: если слово <<\textit{Analysis}>> или <<\textit{Assurance}>> стоит в 
начале строки, то оно рассматривается как начало предложения;
\item  END\_SENT (произвольное число аргументов). Семантика: если в тексте 
встречается одно из указанных слов (символов, знаков), то оно считается 
концом предложения. Пример записи: END\_SENT(`;'). Действие: точка с 
запятой <<;>> рассматривается как конец предложения;
\item ABBR (произвольное число аргументов). Список сокращений с точками на 
конце, которые считаются цельными словами, и точки не рас\-смат\-ри\-ва\-ют\-ся как 
конец предложения. Пример записи: ABBR(Inc., Ltd.). Действие: 
словосочетания <<\textit{Inc}.>> и <<\textit{Ltd}.>> рассматриваются как 
сокращения; 
\item  SEPARATOR (произвольное число аргументов). Семантика: указание символов, 
которые всегда являются разделителями. Пример записи: \mbox{SEPARATOR} (`+', 
`:').
\end{itemize}

     Полную систему операторов параметрической настройки можно найти 
в~\cite{13kuz}.

\section{Методы устранения неопределенностей морфологического 
анализа}

\vspace*{-6pt}

\subsection{О проблеме морфологической омонимии} 
     
     Выявление имплицитной информации связано с глубинным анализом 
текста ЕЯ. И~немаловажную роль в этом процессе играет устранение 
омонимии морфологического анализа. Схема и особенности используемого в 
предлагаемом ЛП морфологического анализа описаны в~\cite{15kuz, 16kuz}. 
Дело в том, что сам по себе морфологический анализ принципиально 
омонимичен (многовариантен). Например, лексема <<\textit{стекло}>> может 
означать и существительное, и глагол. Лексема <<\textit{связи}>> дает 
несколько вариантов морфологического анализа с разными падежами и числом. 
Более того, для многих лексем возможно несколько вариантов 
морфологического анализа~--- их чис\-ло может превышать~20. Случаи 
однозначного морфологического анализа являются исключениями. Однако 
человек умеет из всех вариантов уверенно выбирать единственно правильный. 
Для этого требуется анализ контекста~--- лексического, синтаксического, 
семантического и ситуационного. Ниже будут рассматриваться методы, 
которые используются в блоке ЛМА. 
     
     В первую очередь полнота морфологического анализа обеспечивается 
использованием широкой номенклатуры морфологических признаков 
(см.\ п.~3.2).
     
     Другой используемый метод~--- комбинаторный анализ, заключающийся 
в определении только допустимых комбинаций. Для этого авторами 
разработаны алгоритмы, основанные на эвристических решениях, пусть не 
всегда безупречных, но срабатывающих в ряде самых значимых случаев 
(см.\ п.~3.3).

Однако наиболее эффективным методом устра\-не\-ния неопределенностей, как 
показала \mbox{практика}, является учет контекста. Для этого в блоке 
морфологического анализа широко используются средства частичного 
синтаксического анализа (см.\ п.~3.4).

%\vspace*{-6pt}

\subsection{Система морфологических признаков}
     
     Блок морфологического анализа обеспечивает выделение множества 
морфологических признаков~--- их более~100 (часть речи, род--чис\-ло--па\-деж, 
форма глагола, указатель мейла и многое другое). Для одной лексемы этот блок 
выдает несколько признаков. Их набор и характеризует морфологический тип. 
Кроме чисто морфологических блок выдает еще несколько лексических 
признаков, а также ряд фонетических признаков, которые могут быть 
использованы для синтеза речи.
     
     Разработанная в ИПИ РАН система морфологических признаков 
традиционна и в то же время обладает достаточной полнотой. 

Особое место 
занимает признак <<\#>>. Он означает, что данный набор признаков 
сформирован <<по аналогии>>, т.\,е.\ была найдена словоформа с таким же 
окончанием, как у данной лексемы, и набор признаков словоформы приписан 
данной лексеме. Варианты разбора <<по аналогии>> применяются для лексем, 
которых нет в морфологическом словаре. 

%\vspace*{-12pt}

\subsection{Устранение морфологической омонимии методами 
комбинаторного~анализа} 
     
     \textbf{Правило 1.} Если есть два альтернативных варианта 
морфологического разбора, несовместимых между собой или практически 
несовместимых, то оставляется только один из них. Например, если один из 
вариантов разбора имеет признак <<$f$>>~--- фамилия, то все варианты с 
признаком <<\#>> вычеркиваются. 

\smallskip

\textbf{Правило 2.} После сравнения двух вариантов разбора один из них 
ранжируется как <<старший>>, т.\,е.\ ставится на первое место. Отметим, что в 
принципе все варианты разбора равноправны. Однако для некоторых задач 
(например, генерации текстов) используется только один~--- старший вариант 
разбора. Поэтому далеко не безразлично, какой именно вариант станет 
старшим.
     
     Например, если какой-либо вариант разбора имеет признак <<г>>~--- 
географическое название, то он ставится на первое место. 
     
     Отметим, что если ни одно из такого рода правил не срабатывает, то по 
умолчанию старший вариант разбора высчитывается по специальному 
алгорит\-му, учитывающему достоверность морфологического анализа. 

\smallskip
     
     \textbf{Правило 3.} Склеивание вариантов. Если варианты разбора 
совпадают с точностью до падежа, то они склеиваются в один вариант, где 
присутствуют оба падежа. Склеивание, по сути дела, является технической 
процедурой сокращения записи. Однако оно начинает играть существенную 
роль с учетом алгоритмов по первым двум правилам.
     
     Опыт использования комбинаторных алгоритмов, которых разработано 
уже около двух десятков, показал их высокую эффективность.

%\vspace*{-12pt}

\subsection{Устранение неопределенностей методами синтаксического 
анализа}
     
     Другим эффективным методом устранения морфологической омонимии 
является использование элементов синтаксического анализа. Хорошо известно, 
что омонимию слова можно устранить в контексте словосочетаний. Так, если 
говорят <<\textit{большое стекло}>>, то вариант анализа последнего слова как 
глагола <<\textit{стекать}>> отпадает. Исходя из этой идеи, было предложено:
     \begin{itemize}
     \item проверять на полное согласование (по роду, чис\-лу и падежу) 
существительное со стоящими перед ним прилагательными или причастиями. 
Если указанная связь обнаруживается, то у обеих лексем оставлять только 
варианты разбора, совпадающие по роду, числу и падежу; 
     \item проверять на наличие <<генитивной цепочки>> 
существительное (или группу существительных) и стоящие за ним дополнения 
в родительном падеже. Если такая связь обнаруживается, то у дополнения 
оставлять варианты разбора только с родительным падежом. 
     \end{itemize}
     
     Последнее правило можно проиллюстрировать следующим примером. 
Если слово <<\textit{связи}>> стоит в\linebreak
словосочетании <<\textit{лейтенант 
связи}>>, то морфологически многозначное слово <<связи>> (это 
существительное в родительном, дательном, предложном\linebreak падежах 
единственного числа и винительном, именительном падежах множественного 
числа) приводится к однозначному разбору~--- родительный падеж 
единственного числа. 
     
     Использование элементов синтаксического анализа для устранения 
морфологической омонимии является очень эффективным методом, резко 
повышающим качество разбора. 

\vspace*{-6pt}

\subsection{Особенности распознавания имен и~фамилий}
     
     Используемый морфологический словарь содержит около 500~различных 
имен, отчеств и фамилий~--- как русских, так и иностранных. Однако ясно, что 
этого явно недостаточно для уверенного\linebreak распознавания этих очень важных 
элементов текс\-та. Поэтому в рамках <<постморфологического>> анализа 
действует специальная программа распознавания фамилий. Она основана на 
анализе окончаний и суффиксов, характерных для русских фамилий 
(<<\textit{ов}>>, <<\textit{ев}>>, <<\textit{ин}>>, <<\textit{ын}>> и~др.), а также 
фамилий, часто встречающихся в русскоязычных текстах.
     
     Были выявлены все встречающиеся в фамилиях суффиксы и с каждым 
суффиксом сопоставлена парадигма возможных окончаний. Отметим, что 
<<суффиксы>> и <<окончания>>~--- услов\-ные названия хвостов лексем, 
играющие определенную роль в распознавании фамилий.
     
     Алгоритм программы сводится к следующему. Выявляется слово с 
прописной буквы. Для него в массивах окончаний ищется подходящее 
окончание, а для данного окончания~--- подходящий суффикс. Если эти 
проверки (плюс некоторые дополнительные) прошли успешно, то слову 
присваивается признак <<$f$>>~--- фамилия и с помощью суффикса 
формируется каноническая форма этой фамилии. 
     
     С помощью данного алгоритма удается выявить основную массу 
встречающихся в текстах русских фамилий (по предварительным оценкам~--- 
до 90\%). Однако фамилии европейского типа или фамилии восточных и 
среднеазиатских народов (например, \textit{Смит}, \textit{Линкольн}, 
\textit{Абу-Оглы}) этим алгоритмом не охватываются. Тем не менее, в связи с 
на\-рас\-та\-ющей глобализацией количество такого рода фамилий увеличивается с 
каждым годом. Поэтому в разработках ИПИ РАН применяются 
дополнительные словари тюркских и западных имен, которые 
увеличивают вероятность распознавания ФИО, но не могут охватить множество 
возможных вариаций.

\vspace*{-6pt}

\section{Семантические методы извлечения имплицитной 
информации}
     
     Автоматическое извлечение из текстов ЕЯ имплицитной информации 
связано с решением целого ряда сложных задач: выявлением информационных 
объектов и связей, в том числе заданных в\linebreak \mbox{неявном} виде; выявлением действий, 
в которых участвуют объекты; дополнением объектов новыми признаками на 
основе классификации и экспертных решений; идентификацией объектов путем 
анализа анафорических ссылок и~др. 

Решение данных задач осуществляется на 
син\-так\-ти\-ко-се\-ман\-ти\-че\-ском уровне: в процессе построения 
содержательного портрета (СС документа) и его последующего анализа. 
     
     Еще раз отметим, что качество решения во многом определяется блоком 
ЛМА~--- методами устранения 
неопределенностей (см.\ разд.~2 и~3). Любые ошибки и неоднозначности на 
этом уровне сказываются на решении вышеупомянутых задач.

\vspace*{-6pt}
     
\subsection{Задача <<оценки>> и~<<окраски>> информационных 
объектов} 
     
     Задача <<оценки>> и <<окраски>> связана с по\-рож\-де\-нием новых 
признаков или свойств информационных объектов на основе текстов ЕЯ. 
Например, оценка стабильности предприятия по информации из Интернета, 
окраска политических деятелей (положительная или отрицательная) в 
зависимости от высказываний в прессе, оценка качества изделия по 
высказываниям пользователей и~т.\,д. Часто напрямую не говорится: это 
плохо, а это хорошо. Как правило, в текстах ЕЯ описываются события, 
ситуации, в которых участвовал тот или иной информационный объект. По ним 
и делается оценка, которая зачастую представляется в виде нового 
(порожденного) свойства объекта. Частным случаем этой задачи является 
выявление ролевых функций объектов. 
     
     Для решения данной задачи используются различные 
     методы~\cite{11kuz, 17kuz}. Наиболее распространенный~--- метод 
выявления новых свойств объектов путем использования 
{\bfseries\textit{синтактико-семантических форм}}. Например: 
     
\noindent
  $<$\textit{что~--- лекарство}$>$ \textit{вызывает аллергию у} 
$<$\textit{кого}~--- \textit{человека}$>$\ldots;
  
\noindent
  $<$\textit{что~--- лекарство}$>$ \textit{имеет побочные эффекты}\ldots;
  
\noindent
  $<$\textit{кто~--- человек}$>$ \textit{учинил скандал}\ldots и~т.\,д.
     
     Применение таких форм к текстам ЕЯ заклю\-ча\-ется в поиске 
<<оценочных>> или <<характеристи\-ческих>> слов (типа <<\textit{скандал}>>) 
или словосочетаний\linebreak типа <<\textit{вызывает аллергию}>> (<<\textit{может 
вызывать аллергию}>>), <<\textit{имеет побочные эффекты}>> 
(<<\textit{побочные воздействия}>>), <<\textit{учинить скандал}>> 
(<<\textit{скандалить}>>)\ldots И~затем анализируется окрестность, т.\,е.\ 
слова, стоящие слева и справа, их семантические классы (по ним распознаются 
объекты) и па\-дежные формы. В~результате даются оценки информационных 
объектов. По первым двум формам~--- это <<качество лекарств>>, а по 
последней~--- человек совершил <<хулиганские действия>> или что он 
<<подозреваемый>>. 
     
     Использование синтактико-семантических форм связано с 
определенными трудностями, вызванными особенностями ЕЯ: наличием в 
текстах причастных, деепричастных оборотов, различных пояснений, 
факультативных компонентов (время, место, цель), анафорических ссылок и 
многого другого. В~результате информационные объекты часто оказываются 
на значительном расстоянии от оценочных слов. Отсюда~--- значительные 
потери, влияющие на качество оценивания. 

\medskip

\noindent
\textbf{Пример 1} (текст взят из сводок происшествий ГУВД г.\ Москвы):
     
     \ldots \textit{Горелов Петр Сергеевич, 01.03.76 г/р, прож.: г.~Москва, 
ул.~Юных Ленинцев, д.~71-6-12, не работает, 01.02.1998~г.\ в 14.30 у своего 
дома из хулиганских побуждений в состоянии алкогольного опьянения}\linebreak\vspace*{-12pt}
\columnbreak

\noindent
\textit{учинил 
скандал и разбил оконное стекло в квартире Литвиновой Галины Ивановны, 
20.07.1961~г/р\ldots}
     
     В данном примере оценочные (характеристические) слова 
<<\textit{учинил скандал}>> и <<\textit{разбил оконное стекло}>> находятся на 
значительном расстоянии от оцениваемого лица~--- <<\textit{Горелов Петр 
Сергеевич}>>. Это ограничивает возможности применения форм. Требуется 
первоначальное выделение компонентов, которые не должны учитываться в 
формах: годов рождения, адресов, свойств (<<\textit{не работает}>>, 
<<\textit{в состоянии алкогольного опьянения}>>), времени, мес\-та и~др., что 
предполагает достаточно глубокий анализ текста с выделением объектов, их 
свойств и атрибутов. 
     
     В связи со сказанным более перспективным представляется другой 
метод~--- когда оценивание осуществляется на уровне структур знаний. Для их 
построения используется се\-ман\-ти\-ко-ориен\-ти\-ро\-ван\-ный ЛП, который 
осуществляет глубинный анализ текстов ЕЯ с приведением синонимичных 
групп к одному виду, выявлением объектов и их свойств, идентификацией 
объектов, выявлением и унификацией различных форм, представляющих 
события или действия (в том числе форм с отглагольными существительными, 
причастных и деепричастных оборотов), которые связываются с временем и 
местом. В~результате формируются структуры знаний, в которых объекты 
напрямую связываются с событиями и действиями, что исключает потери, о 
которых говорилось выше. Последующий анализ осуществляется с помощью 
правил языка ДЕКЛ, ориентированных на обработку таких структур (РСС), что 
делает простым процесс разработки программ <<оценки>> и реализации 
соответствующих правил анализа и вывода. При этом структура знаний не 
изменяется, а только пополняется новыми (полезными) фрагментами. 
     
     Проиллюстрируем предлагаемый метод применительно к задаче 
выявления ролевых функций\linebreak лиц из сводок происшествий, взятых из области 
<<Криминалистика>>. Имеется в виду задача присвоения лицам (по их участию 
в различного рода деяниях) свойств~--- <<потерпевший>>, <<подозреваемый>> 
или <<преступник>>, <<заложник>>, если описание таких %\linebreak 
свойств отсутствует 
в тексте в явном виде. На\-пример, если в тексте говорится 
<<\textit{потерпевший %\linebreak 
Иванов~И.\,И.}>>, то возникает другая задача~--- 
выявление свойства в процессе лингвистического анализа и формирование 
соответствующего фрагмента в структуре знаний. 
     
     Как уже говорилось, в рамках пред\-ла\-га\-емой методики (вместо 
применения синтактико-се\-ман\-ти\-че\-ских форм к документам) используются 
правила логического вывода и преобразования структур знаний (СС 
документов), в которых нет морфологических признаков (типа \textit{кто}, 
\textit{кого}\ldots), но с помощью фрагментов РСС представлены объекты и их 
участие в действиях. Имена таких фрагментов представляют характер действий. 
Например, в примере~1, где фигурантом является <<\textit{Горелов Петр 
Сергеевич}>>, его свойства и деяния представляются в виде фрагментов:

\smallskip
     
{\small
\noindent
     ПЬЯНЫЙ($<$код фигуранта$>$)
     
\noindent
     БЕЗРАБОТНЫЙ($<$код фигуранта$>$)
     
\noindent
     УЧИНИТЬ($<$код фигуранта$>$,СКАНДАЛ)
     
\noindent
     РАЗБИТЬ($<$код фигуранта$>$,ОКОННЫЙ,СТЕКЛО). 
     }
     
     \smallskip
     
     Выявление ролевых функций фигуранта сводится к анализу таких 
фрагментов. Анализ осуществляется с помощью 
     {\bfseries\textit{логико-семантической оболочки}}, которая осуществляет 
необходимые преобразования фрагментов РСС и логический вывод. Оболочка 
состоит из продукций языка ДЕКЛ и управляется фрагментами РСС, 
образующими {\bfseries\textit{управляющие знания}}. Пример управляющих 
фрагментов: 

\smallskip
     
{\small 

\noindent
РАЗБИТЬ(ОКНО,СТЕКЛО,ДВЕРЬ\ldots)
     
\noindent
УЧИНИТЬ(ССОРА,СКАНДАЛ\ldots)

}

\smallskip
     
Первый фрагмент означает, что если фигурант разбил окно, стекло или дверь, 
то ему присваивается свойство, связанное с этим фрагментом, например 
<<подозреваемый>>. Правило реализуется в рамках оболочки, которая 
осуществляет поиск в СС документа фрагмента с именем РАЗБИТЬ и наличием 
в нем одного из аргументов~--- ОКНО, СТЕКЛО, ДВЕРЬ\ldots Если данное 
условие выполняется, то к СС документа добавляется фрагмент 
ПОДОЗРЕВАЕМЫЙ($<$код фигуранта$>$). Это прос\-тей\-ший случай. 
     
     В более сложных случаях учитываются отрица\-ния, отношения 
принадлежности, совокупность действий. Например, <<\ldots\textit{ушла из 
дому}\ldots \textit{не вернулась}\ldots>> или <<\ldots\textit{автомашина}\ldots 
\textit{под управ\-ле\-ни\-ем}\ldots \textit{выехала на полосу встречного 
движения}\ldots \textit{произошло столкновение}\ldots>> В~последнем 
происшествии в действиях участвует автомашина, а <<нарушитель>>~--- это 
человек, который ею управляет. 
{\looseness=-1

}
     
     Отметим, что в приведенных примерах (для прос\-то\-ты понимания) 
фрагменты записаны в виде предикатов. В~реальной системе каждый фрагмент 
РСС имеет свой уникальный код. Такие коды используются для представления 
классов слов, словосочетаний и указания их связи с ролевыми функциями. 

\vspace*{-6pt}

\subsection{Выявление объектов и~связей, заданных в~неявном виде} 
     
     Выявление объектов и связей осуществляется в процессе 
ССА~--- преобразования ПС 
документа в структуру знаний, т.\,е.\ СС документа (см.\ п.~1.3). Такой анализ 
заключается в последовательном применении правил выделения объектов или 
их компонентов из текстов ЕЯ. Каждое правило ориентировано на выделение 
объектов определенного типа (фигурантов, адресов, организаций\ldots). 
Выделение объектов начинается с поиска {\bfseries\textit{характеристических 
слов}}. Например, для объектов типа <<адрес>> такими словами являются 
<<\textit{город}>>, <<\textit{улица}>>, <<\textit{дом}>> и~др. Далее 
анализируется окрестность этих слов, выбираются допустимые слова, которые 
и составляют объект. 
     
     Довольно часто характеристические слова в\linebreak тексте отсутствуют~--- 
подразумеваются. В~таких случаях возникают трудности выделения объектов.\linebreak 
Например, если в тексте встречаются лица с иностранными ФИО. 
У~английских фамилий (\textit{Буш},\linebreak \textit{Блэк}\ldots) нет характерных 
суффиксов, как в русском языке. Более того, в качестве фамилии может 
фигурировать любое слово, называющее или определяющее ка\-кой-ли\-бо 
предмет внешнего мира. При анализе текстов ЕЯ такие фамилии вносят 
элементы неопределенности~--- омонимии. В~азиатских языках компоненты 
ФИО~--- это просто слова с большой буквы (\textit{Ден Сяо Пин}, \textit{Хун 
Вай}\ldots). В~таких ФИО отсутствуют характеристические слова. Требуются 
другие методики выделения. Аналогично адреса могут иметь вид~--- 
<<\textit{Семеновская, 2-44}>>. Сказанное относится и к другим объектам. 
     
     Для выявления объектов без характеристических слов предлагается 
методика, основанная на принципе {\bfseries\textit{ожидания}}. Учитывается 
тот факт, что часто в ЕЯ после одних слов или объектов ожидается наличие 
других. Например, если после слова <<\textit{инженер}>> стоит слово с 
большой буквы, то, скорее всего, оно относится к ФИО. Таким образом, 
начинается выделение объектов, у которых не распознаны компоненты ФИО. 
     
     Реализация соответствующей методики осуществляется в процессе 
ССА. При этом используется  оператор следующего вида:
$$     
     \mathrm{GO}\_(\langle\mathrm{правило}~1\rangle,\langle\mathrm{правило}~2\rangle)\,, 
     $$
где правило~1 выявляет в тексте соответствующий объект. И~если оно 
применилось (объект выявлен), то вызывается правило~2, выявляющее 
ожидаемый объект.
     
     Методика <<ожидания>> используется и при выделении 
{\bfseries\textit{связей между объектами}}, которые в явном\linebreak виде не задаются. 
В~текстах ЕЯ многие связи подразумеваются и привязаны к типу выявленных 
объектов. Например, если выявлен адрес, то, скорее всего, он относится к 
какому-либо определенному\linebreak лицу (или учреждению), которое нужно искать. 
При результативном поиске формируется новая связь. 
     
     На этом основана методика формирования новых связей. Она 
заключается в следующем. В~процессе анализа текста строятся <<временные>> 
фрагменты, представляющие связи выявленных \mbox{объектов} с пока что 
неизвестными объектами, которые специальным образом отмечаются. 
В~дальнейшем осуществляется их поиск. Если соответст\-ву\-ющий объект не 
найден, то <<временный>> фрагмент удаляется из СС документа. Если найден, 
то фрагмент остается и вводится в структуру СС документа.
     
     Поиск неизвестных объектов осуществляется на одном из этапов
ССА и управ\-ля\-ет\-ся с помощью 
фрагментов, посредством которых задается на\-прав\-ле\-ние поиска, число шагов и 
условия окончания поиска~--- недопустимые слова, знаки или объекты.
     
     Более детализированное описание методики, а также другие 
семантические методы выявления имплицитной информации предполагается 
рас\-смот\-реть в последующих работах. 

\vspace*{-9pt}

\section{Заключение}
     
     Автоматическое извлечение из текстов ЕЯ 
имплицитной информации~--- это область искусственного интеллекта, 
связанная с развитием моделей языка, ЛП, 
методов устранения неопределенностей и принятия решений. Успешное 
решение этой сложнейшей задачи возможно лишь при комплексном подходе, 
когда анализ не сосредоточен в какой-то одной точке, а совершается постоянно, 
на всех уровнях работы ЛП. 
     
     В данной статье рассмотрен ряд методик, позволивших существенно 
продвинуться в данном направлении~\cite{18kuz}. 

Практическая ценность выполненных работ определяется возрастающей 
потребностью автоматической формализации быстро растущих потоков 
документов на ЕЯ, особенно в среде всемирной сети Интернет.

\vspace*{-9pt}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{99}

\bibitem{1kuz}
\Au{Kuznetsov I., Kozerenko E.} The system for extracting semantic information 
from natural language texts~// Conference (International) on Machine Learning 
(MLMTA-03) Proceedings.~--- Las Vegas, 2003. P.~75--80. 

\bibitem{2kuz}
\Au{Кузнецов И.\,П.}
Семантико-ори\-ен\-ти\-ро\-ван\-ная сис\-те\-ма обработки неформализованной 
информации с выдачей результатов на естественном языке~// Сис\-те\-мы и 
средства информатики.~--- М.: Наука, 2006. Вып.~16. С.~235--253.

\bibitem{3kuz}
\Au{Кузнецов И.\,П., Мацкевич А.\,Г.}
Се\-ман\-ти\-ко-ори\-ен\-ти\-ро\-ван\-ные системы на основе баз знаний.~--- М.: 
\mbox{МТУСИ}, 2007. 173~с.

\bibitem{4kuz}
\Au{Кузнецов И.\,П.}
Объектно-ориен\-ти\-ро\-ван\-ная сис\-те\-ма, основанная на знаниях в виде 
XML-пред\-став\-ле\-ний~// Системы и средства информатики.~--- М.: Наука, 
2008. Вып.~18. С.~96--118.

\bibitem{5kuz}
\Au{Kuznetsov I.\,P., Kozerenko E.\,B.}
Linguistic processor Semantix for knowledge extraction from natural texts in Russian 
and English~//  Conference (International) on Artificial Intelligence (ICAI 2008) 
Proceedings.~--- Las Vegas: CSREA Press, 2008. P.~835--841.

\bibitem{6kuz}
\Au{Падучева Е.\,В.}
Высказывание и его соотнесенность с действительностью.~--- М.: Наука, 1985.

\bibitem{7kuz}
\Au{Кондрашова~Д.\,С.}
К~проблеме классификации типов имплицитной информации~// Cognitive 
Modelling in Linguistics: Мат-лы VIII Междунар. конф.~--- Варна, 2005. Т.~1. 
С.~245--252.


\bibitem{10kuz} %8
\Au{Пирогова Ю.\,К.}
Имплицитная информация как средство коммуникативного воздействия и 
манипулирования~// Проблемы прикладной лингвистики.~--- М., 2001. 
С.~209--227.

\bibitem{8kuz} %9
\Au{Asher~N., Lascarides~A.}
Logics of conversation.~--- Cambridge: Cambridge University Press, 2003.

\bibitem{11kuz} %10
\Au{Clark~P., Harrison P., Thompson~J.}
A~knowledge-driven approach to text meaning processing~// HLT-NAACL 2003 
Workshop on Text Meaning Proceedings, 2003. P.~1--6.

\bibitem{9kuz} %11
\Au{Анохина Н.\,В.}
Роль пресуппозиции и импликации в процессе понимания научно-популярного 
текста~// Вестник Башкирского ун-та, 2009. Т.~14. №\,1. С.~92--94.


\bibitem{13kuz} %12
\Au{Кузнецов И.\,П., Сомин Н.\,В.}
Средства настройки се\-ман\-ти\-ко-ориен\-ти\-ро\-ван\-ной сис\-те\-мы на 
выделение и поиск объектов~// Системы и средства информатики.~--- М.: 
Наука, 2008. Вып.~18. С.~119--143.

\bibitem{15kuz} %13
\Au{Сомин Н.\,В., Кузнецов И.\,П., Мацкевич~А.\,Г., Николаев~В.\,Г.}
Методы и средства настройки мор\-фо-лек\-си\-че\-ско\-го анализатора на 
предметную область~// Системы и средства информатики.~--- М.: Наука, 2009. 
Вып.~19. С.~96--118. 

\bibitem{12kuz} %14
\Au{Кузнецов И.\,П., Сомин Н.\,В.}
Анг\-ло-рус\-ская сис\-те\-ма извлечения знаний из потоков информации в 
ин\-тер\-нет-сре\-де~// Системы и средства информатики.~--- М.: Наука, 2007. 
Вып.~17. С.~236--254.

\bibitem{14kuz} %15
\Au{Кузнецов И.\,П., Сомин Н.\,В.}
Особенности лек\-си\-ко-мор\-фо\-ло\-ги\-че\-ско\-го анализа при извлечении 
информационных объектов и связей из текстов естественного языка~// 
Компьютерная лингвистика и интеллектуаль\-ные технологии:  по 
мат-лам междунар. конф. <<Диалог 2010>>.~--- М.: РГГУ, 2010. Вып.~9(16). С.~254--264.

\bibitem{16kuz}
\Au{Сомин Н.\,В., Соловьева Н.\,С., Шарнин~М.\,М.}
Система морфологического анализа: опыт эксплуатации и модификации~// 
Системы и средства информатики.~--- М.: Наука, 2005. Вып.~15. С.~20--30.

\label{end\stat}

\bibitem{17kuz}
\Au{Banko~M., Cafarella M., Soderland~S., Broadhead~M., Etzioni~O.}
Open information extraction from the Web~// 20th Joint Conference (International) 
on Artificial Intelligence (IJCAI-07) Proceedings, 2007. P.~2670--2676.



\bibitem{18kuz}
Лаборатория компьютерной лингвистики ИПИ РАН: Официальный сайт. {\sf 
www.IpiranLogos.com}.
 \end{thebibliography}
}
}


\end{multicols}