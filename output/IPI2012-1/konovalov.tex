\def\stat{konovalov}

\def\tit{ОПТИМИЗАЦИЯ РАБОТЫ ВЫЧИСЛИТЕЛЬНОГО КОМПЛЕКСА 
С~ПОМОЩЬЮ ИМИТАЦИОННОЙ МОДЕЛИ И~АДАПТИВНЫХ 
АЛГОРИТМОВ$^*$}

\def\titkol{Оптимизация работы вычислительного комплекса 
с~помощью имитационной модели и~адаптивных 
алгоритмов}

\def\autkol{М.\,Г.~Коновалов}
\def\aut{М.\,Г.~Коновалов$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
{Работа выполнена при поддержке РФФИ, грант 11-07-00112.}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Институт проблем информатики Российской академии наук, mkonovalov@ipiran.ru}


      \Abst{Рассматривается проблема эффективного управления 
процессом выполнения заданий, поступающих в единый комплекс 
вычислительных ресурсов. Предлагается подход к решению проблемы, 
основанный на применении адаптивных стратегий в имитационной 
модели. На примере вычислительного комплекса излагается 
оригинальная методология построения и использования 
имитационных моделей. В~качестве адаптивных стратегий 
используются алгоритмы, разработанные в теории частично 
наблюдаемого марковского процесса принятия решений. Приведены 
результаты вычислительного эксперимента.}
      
      \KW{системы вычислительных ресурсов; имитационные модели; 
адаптивные алгоритмы}

 \vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}

\section{Введение}

  Одно из направлений развития современных 
  ин\-фор\-ма\-ци\-он\-но-вы\-чис\-ли\-тель\-ных сис\-тем заключается в 
их слиянии в мощные комплексы, объединяющие большое чис\-ло 
разнородных, географически распределенных компьютеров и 
компьютерных сис\-тем. Примерами могут служить системы самого широкого 
спектра~--- от глобальных гридов и клаудов и заканчивая локальными 
специализированными вычислительными центрами, обладающими 
автономными парками вычислительных ресурсов. Для большинства таких 
систем характерна проблема эффективности использования 
вычислительной техники, которая лишь обостряется, несмотря на 
интенсивное развитие последней. 

Общая краткая характеристика проблемы 
может быть выражена словами <<что, где и когда вычислять>>, и в этом 
широком аспекте поиск ее решения является предметом интенсивных 
усилий. С~некоторыми направлениями и результатами исследований можно 
ознакомиться в работах~[1--3] и содержащихся в них обзорах. Данная работа 
также относится к указанной области.
  
  Используемые в статье соображения вкратце сво\-дят\-ся к следующему. 
Всякий вычислительный\linebreak комплекс, обслуживающий потоки заданий, 
ха\-рак\-те\-ри\-зу\-ет\-ся набором параметров. Некоторые из них\linebreak могут трактоваться 
как статические (на\-при\-мер, емкость и производительность про\-цес\-со\-ров), в 
то время как другие носят более выраженный динамический характер 
(например, па\-ра\-мет\-ры, определяющие размещение заданий на процессорах). 
Таких параметров очень много, и их взаимосвязь труднообозрима, что 
затрудняет построение чисто математических моделей и получение чисто 
математических решений, связанных с выбором оптимальных значений 
параметров. Имитационное компьютерное моделирование существенно 
расширяет возможности адекватного описания объекта. В~част\-ности, 
появляется возможность получать потенциально неограниченное 
количество траекторий функционирования системы, свойства которых 
зависят от упомянутых параметров. Используя эти траектории, можно 
попытаться оптимизировать значения параметров по выбранным 
критериям.
  
  Изложенные соображения являются, в принципе, достаточно 
традиционными и широко используемыми. В~данной работе, однако, 
делается акцент на двух сравнительно мало освещаемых обстоятельствах.
  
  Во-первых, в подавляющем числе работ наличие имитационной модели 
лишь констатируется, а ее описание и, как следствие, степень соответствия 
описанию моделируемого объекта остаются как бы за кадром. Это в 
принципе затрудняет возможность воспроизводить результаты 
экспериментов с мо\-делью и оценивать сделанные с ее помощью выводы. 
В~предлагаемой работе уделяется значительное внимание способу задания 
имитационной модели.
  
  Второй момент заключается в способе использования имитационной 
модели. Как правило, в экспериментах с моделью апробируются различные 
<<готовые>> алгоритмы, с тем чтобы выбрать лучший среди них. В~данном 
случае предлагается <<настраивать>> алгоритмы, используя специальные 
стратегии адаптивной обработки информации, поступающей с имитируемых 
траекторий объекта.
  
  Настоящая работа является продолжением работ~\cite{1kon, 2kon}. Объектом 
моделирования и оптимизации служит абстрактный вычислительный 
комплекс со свойствами, присущими реальным системам, который 
рассматривался также в~\cite{3kon}. Основное внимание уделяется 
построению имитационной модели и выбору параметров, подлежащих 
оптимизации. Используемые адаптивные алгоритмы базируются на 
теоретических предпосылках, изложенных в~\cite{4kon}. Приведены 
некоторые результаты численных экспериментов.

\section{Общее описание}
   
   \textbf{Вычислительный комплекс} предназначен для 
обработки \textbf{потоков заданий}, постоянно поступающих на него. 
Комплекс состоит из совокупности \textbf{вычислительных 
устройств}, на которых происходит выполнение заданий, \textbf{центра 
управления}, а также \textbf{среды передачи}, через которую 
осуществляется сообщение между центром управления и вычислительными 
устрой\-ст\-вами.
   
   Вычислительные устройства, вообще говоря, представляют собой особым 
образом структурированную и организованную совокупность 
вычислительных ресурсов, имеющих к тому же достаточно сложную 
внутреннюю структуру. Однако в данном случае ограничимся 
представлением об упорядоченном массиве независимо работающих 
вычислительных устройств, которые будем называть для краткости также 
\textbf{компьютерами}. Вычислительные устройства не являются 
абсолютно надежными и могут частично или полностью выходить из строя.
   
   Роль центра управления с точки зрения выполнения заданий 
заключается в реализации сле\-ду\-ющих функций:
   \begin{enumerate}[(1)]
\item приемки заданий (извне);
\item управления очередью заданий;
\item управления процессом выполнения отдельного задания на 
вычислительных устройствах;
\item управления средой передачи;
\item отправки обработанных заданий (вовне);
\item технического обслуживания вычислительных устройств.
\end{enumerate}

   Эти функции будут в определенной мере отражены в излагаемой ниже 
модели. Однако с точки зрения оптимизации из данного перечня будут 
представлять интерес, главным образом, второй и третий пункты.
   
   Среда передачи является локальной коммуникационной сетью, которая в 
дальнейших рас\-смот\-ре\-ни\-ях будет фигурировать в качестве источника 
задержек в обмене информацией между центром управления и 
компьютерами.
   
   \textbf{Задание} состоит из некоторого числа (элементарных) 
\textbf{задач}, каждая из которых может выполняться независимо от 
остальных и на произвольном компьютере. (Это соответствует часто 
исполь\-зу\-емо\-му в литературе понятию <<делимой нагрузки>>.) Решение, 
или, по-дру\-го\-му, выполнение задания, заключается в решении 
(выполнении) задач. В~некоторых случаях необходимо решить все задачи. 
Но может оказаться, что в задании существует одна или несколько 
элементарных задач, которые пред\-став\-ля\-ют особый интерес и которые 
будем называть \textbf{ключевыми} задачами. Поиск и решение 
ключевых задач представляют собой основную цель задания. Какие из задач 
являются ключевыми и существуют ли вообще ключевые задачи в данном 
задании, заранее не известно.
   
   Пребывание задания в вычислительном комплексе складывается из 
чередования промежутков времени ожидания обслуживания и 
непосредственного решения на вычислительных устройствах. Промежуток 
времени второго типа, т.\,е.\ период, когда задание выполняется на 
компьютерах, будем называть \textbf{запуском}. Запусков одного и того 
же задания может быть несколько.
   
   Любой запуск задания может оканчиваться следующими исходами:
   \begin{itemize}
   \item найдено заданное множество ключевых задач (одна, несколько или 
все);
   \item решены все задачи и установлено, что ключевые задачи отсутствуют (не 
найдены);
\item истекло \textbf{время жизни} задания (наступил 
\textbf{дедлайн});
   \item запуск задания принудительно прерван по решению центра 
управления;
   \item произошел сбой или отказ вычислительного комплекса или его 
элементов.
   \end{itemize}
   
   Весь процесс выполнения задания может оканчиваться одним из 
следующих исходов:
   \begin{itemize}
   \item задание выполнено (найдены ключевые задачи или решены все 
задачи);
   \item задание не выполнено, но наступил дедлайн;
   \item задание не выполнено, но удаляется из системы по решению 
вычислительного центра.
   \end{itemize}
   
   Окончание процесса выполнения задания при любом его варианте 
означает уход задания из вы\-чис\-ли\-тельного комплекса.
   
   Организация процесса решения задач, со\-став\-ля\-ющих задание, обладает 
следующими особенностями.
   
   При подготовке задания к запуску центр управ\-ле\-ния разбивает задание 
на отдельные блоки, со\-сто\-ящие из некоторого количества элементарных 
задач. В~дальнейшем для обозначения таких блоков используется термин 
\textbf{пакет}.
   
   Одновременно составляется список вычислительных устройств, на 
которых будут обрабатываться пакеты, составленные из элементарных 
задач. В~ходе конкретного запуска данного задания со\-став\-лен\-ный список не 
может увеличиваться, а может лишь сокращаться (в случае выхода из строя 
отдельных компьютеров). В~ходе выполнения задания центр 
   управ\-ле\-ния периодически посылает на вы\-чис\-ли\-тель\-ные устрой\-ст\-ва 
порции пакетов, по одному на каждый исправный компьютер из указанного 
списка. Для обозначения указанной порции пакетов используется термин 
\textbf{посылка}. Промежуток времени между отправлением посылки и 
приемом результатов ее выполнения называется \textbf{контрольным 
временем} и устанавливается в начале каждого запуска задания.
   
   Пересылка пакетов к компьютерам осуществляется через среду передачи. 
На пересылку пакета затрачивается некоторое время, которое, вообще 
говоря, является случайным и соизмеримым со временем обработки пакета 
задач. Таким образом, отправление посылки занимает значимое время.
   
   Предполагается, что результаты обработки пакетов из посылки 
доставляются центру управления за пренебрежимо малое время по 
истечении контрольного времени.
   
   Обработка пакета на вычислительном устройстве происходит во многих 
отношениях независимо от работы остальной части системы и может 
заканчиваться одним из следующих исходов:
   \begin{itemize}
   \item выполнены все задачи из пакета (при этом обнаружены или не 
обнаружены ключевые задачи);
   \item истекло \textbf{контрольное время}, отведенное на 
выполнение задач из пакета, но задачи решены не все.
   \end{itemize}
   
   Невыполнение задач из пакета может наступать по следующим 
причинам:
   \begin{itemize}
   \item произошел \textbf{отказ} компьютера, вызвавший его полную 
остановку;
   \item произошел частичный отказ процессора (\textbf{сбой}), 
вследствие чего уменьшилась производительность;
   \item контрольного времени не хватило для решения всех задач из 
пакета по причинам, не связанным с отказами аппаратуры.
   \end{itemize}
   
   В~любом случае неполного выполнения задач из пакета считается, что 
все входящие в пакет задачи должны быть выполнены заново без учета 
результатов предыдущей попытки и в составе новых пакетов.

\section{Принципы формального описания имитационной 
модели}
    
    Под словами <<формальная модель>> будем понимать алгоритмически 
точное описание, которое позволяет независимому исследователю 
однозначно воспроизводить (в частности, на компьютере) задуманные и 
заложенные в модель особенности поведения системы. С~этой точки зрения 
идеально подходил бы реализующий модель компьютерный код, но он 
занимает слишком много места, содержит не относящуюся к модели 
информацию и к тому же не очень нагляден. Можно воспользоваться одним 
из многочисленных и распространенных приемов описания (таких как 
псевдокод или блок-схе\-ма или более изощренных, таких как сети Петри, 
специальные языки моделирования и~т.\,п.). Тем не менее здесь 
используется оригинальный подход, использующий, однако, сравнительно 
известные идеи.
    
    Изложенную в предыдущем разделе модель можно представлять себе 
как совокупность взаимосвязанных параметров, которые изменяются\linebreak 
вполне определенным образом в процессе мо\-де\-лирования. Исходная 
посылка для дальнейших\linebreak рассуждений заимствована из обычного 
программирования и заключается в том, что моделирование системы на 
компьютере представляет собой чередование неких событий, наступление 
которых знаменуется пересчетом параметров. Формальное задание модели 
должно поэтому содержать два основных раздела: в одном должна быть 
указана совокупность событий и закономерность их чередования, а во 
втором~--- обработчики событий, т.\,е.\ алгоритмы пересчета параметров. 
Второй раздел, по-видимому, не требует особых комментариев, поскольку 
представляется идейно вполне ясным. Что касается первого раздела, то его 
обсуждение сейчас последует и оно основано на некоторых идеях, 
содержащихся в~\cite{5kon}. Впрочем, из теории Хоара взято немного, 
причем безоговорочно~--- только общее определение процесса, 
использование рекурсии и понятие параллельного взаимодействия 
процессов.
    
    \noindent
    \textbf{Определение 1.} \textit{Процессом называется пара символов 
    $\mathrm{P}\hm= (\mathrm{A},\Pi)$,  где $\mathrm{A}$~--- не более чем счетное 
множество, называемое алфавитом, а $\Pi$~--- подмножество множества 
всех конечных и бесконечных последовательностей из~$\mathrm{A}$. Элементы 
алфавита будем называть также событиями, а элементы множества $\Pi$~--- 
протоколами.}
    
    В дальнейшем будем иногда обозначать алфавит процесса~P как $\alpha 
\mathrm{P}$, а множество протоколов~--- как $\pi \mathrm{P}$.
    
    Интуитивно процесс соответствует представлению об объекте, который 
в процессе эволюции может принимать участие в событиях из своего 
алфавита, причем чередование событий обязано в точности соответствовать 
ка\-ко\-му-ни\-будь протоколу. Иначе говоря, определение 
процесса, соответствующего некоторому объекту, задает потенциально 
возможное развитие этого объекта.
    
    Задание протоколов путем перечисления не конструктивно, поэтому для 
этой цели используются специальные приемы, среди которых здесь 
используются рекурсия, композиция процессов в виде <<выбора>>, 
параллельная композиция, а также переименование.
    
    \medskip
    
    \noindent
    \textbf{Определение 2.} \textit{Пусть $\mathrm{P}\hm=(\mathrm{A},\Pi)$~--- 
некоторый процесс и пусть $a$~--- событие, необязательно содержащееся в 
алфавите процесса~$\mathrm{P}$. Новый процесс, обозначаемый}
    $\mathrm{P}_1=a\rightarrow \mathrm{P} $
(\textit{читается <<$\mathrm{P}$ следует за~$a$>>}), \textit{определяется как 
$\mathrm{P}_1\hm=(\mathrm{A}_1,\Pi_1)$, где $\mathrm{A}_1\hm=A\cup 
\{a\}$, а $\Pi_1$ получается из множества~$\Pi$ добавлением в начало 
каждого протокола элемента~$a$.}
    
    Интерпретация процесса $\mathrm{P}_1$ такова: <<этот процесс вначале 
участвует в событии~$a$, а затем ведет себя в точности, как процесс~P>>.
    
    Определение~2 можно обобщить, предлагая, например,  для процесса 
$\mathrm{P}_1$ в качестве первого события выбор из некоторого множества.
    
    Отметим важное обстоятельство: в правой части уравнения может 
фигурировать тот же самый процесс, который определяется в левой части: 
$\mathrm{P}\hm=a\hm\rightarrow \mathrm{P}$. В~этом случае определяемый 
процесс имеет единственный протокол: $(a, a, \ldots)$. Это пример так 
называемого рекурсивного задания процесса. Принципиально, что рекурсия 
может использоваться и во всех последующих конструкциях.
    
    \medskip
    
    \noindent
    \textbf{Определение~3.} \textit{Пусть $\mathrm{P}_1$  и 
$\mathrm{P}_2$~--- некоторые процессы, такие что у любой пары 
протоколов $p_1\hm\in \pi \mathrm{P}_1$ и $p_2\hm\in \pi\mathrm{P}_2$ 
начальные элементы различны. Новый процесс, обозначаемый}
    $    \mathrm{P}=\mathrm{P}_1\vert \mathrm{P}_2
    $
(\textit{читается <<$\mathrm{P}$ есть выбор между  $\mathrm{P}_1$  и $\mathrm{P}_2$>>}), \textit{определяется как 
процесс с алфавитом $\alpha \mathrm{P}\hm=\alpha \mathrm{P}_1\cup 
\alpha\mathrm{P}_2$ и множеством протоколов 
$\pi\mathrm{P}\hm=\pi\mathrm{P}_1\cup \pi\mathrm{P}_2$.}
    
    Процесс~P <<ведет себя либо как процесс P$_1$, либо как процесс P$_2$, 
причем выбор зависит от начального события, которое определяется 
<<окружением>> процесса~P, т.\,е.\ другими процессами, с которыми он 
взаимодействует>>.
    
    \medskip
    
    \noindent
    \textbf{Определение~4.} \textit{Пусть $\mathrm{P}_1$  и $\mathrm{P}_2$~--- некоторые 
процессы. Новый процесс, обозначаемый}
    $
    \mathrm{P}=\mathrm{P}_1\Vert \mathrm{P}_2
    $
(\textit{читается <<$\mathrm{P}$ есть параллельная композиция $\mathrm{P}_1$ и~$\mathrm{P}_2$>>}), 
\textit{определяется следующим образом. Его алфавит имеет вид $\alpha 
\mathrm{P}\hm=\alpha\mathrm{P}_1\cup \alpha\mathrm{P}_2$. Множество 
протоколов $\pi\mathrm{P}$ состоит из всех упорядоченных наборов 
событий из множеств $\alpha\mathrm{P}_1$ и $\alpha\mathrm{P}_2$, 
которые обладают следующим свойством: после удаления из набора всех 
символов, не принадлежащих алфавиту $\alpha\mathrm{P}_1$ 
$(\alpha\mathrm{P}_2)$, получается протокол, принадлежащий 
множеству}~$\pi\mathrm{P}_1$ (\textit{соответственно}~$\pi\mathrm{P}_2$).
    
    Параллельные процессы <<обязаны принимать совместное участие во 
всех событиях, принадлежащих пересечению их алфавитов>>. В~остальных 
случаях каждый процесс <<ведет себя так, как будто другого не 
существует>>.
    
    Полезным приемом, с помощью которого можно задавать новые 
процессы, является переименование. Пусть $f$~--- взаимно однозначная 
функция, отображающая алфавит~A процесса во множество символов 
$f(\mathrm{A})$.
    
    \medskip
    
    \noindent
    \textbf{Определение~5.} \textit{Переименованием процесса 
$(\mathrm{A},\Pi)$ с помощью функции~$f$ называется процесс 
$(\mathrm{A}_f,\Pi_f)$, где $\mathrm{A}_{f}\hm=f(\mathrm{A})$, а 
множество~$\Pi_f$ образовано из протоколов множества~$\Pi$ путем 
замены всех символов на их $f$-об\-разы.}
    
    Заданное последним определением переименование особенно полезно 
при создании групп сходных процессов, которые функционируют 
идентичным образом, никак не взаимодействуя друг с \mbox{другом}. Это означает, 
что все они должны иметь различные и взаимно непересекающиеся 
алфавиты. С~этой целью каждый процесс снабжается меткой, которая 
добавляется к общему для всех процессов имени. Процесс с именем~P и с 
меткой~$l$ обозначается $l:\mathrm{P}$. Каждое событие помеченного 
процесса имеет ту же метку и выглядит как $l.a$, где $a$~--- название 
события, а $l$~--- метка.
    
    \medskip
    
    \noindent
    \textbf{Определение 6.} \textit{Пусть $\mathrm{P}$~--- процесс, а $l$~--- метка. 
Помеченный процесс $l:\mathrm{P}$ задается функцией $f_l(a)\hm=l.a$ для 
всех~$a$ из алфавита процесса~$\mathrm{P}$ и пометкой 
$l:\mathrm{P}\hm=f_l(\mathrm{P})$.}
    
    Приведенные определения можно обобщать, расширяя выразительные 
свойства данного языка. Например, если L~--- множество меток, то 
процесс $\mathrm{L}:\mathrm{P}$ <<ведет себя как процесс $l:\mathrm{P}$ каж\-дый раз, когда окружение 
процесса выбрало метку~$l$>>. Другой пример~--- это процесс $\Vert_{l\in 
\mathrm{L}}l.\mathrm{P}$, который пред\-став\-ля\-ет собой параллельную композицию 
процессов из совокупности $\{l.\mathrm{P};\ l\in \mathrm{L}\}$.
    
    Сформулированные в определениях~2--6 операции можно применять 
многократно, получая уравнения, у которых в левой части стоит вновь 
определяемый процесс, а в правой~--- сколь угодно сложная суперпозиция 
других процессов. 
    
    Вернемся к вопросу о способе описания имитационной модели.
    
    \medskip
    
    \noindent
    \textbf{Определение~7.} \textit{(Формальной) имитационной моделью 
некоторой системы назовем тройку символов
    $$
    \mathbb{M}=\left( \mathfrak{P},\mathrm{P},\mathrm{H}\right)\,,
    $$
где $\mathfrak{P}$~--- множество параметров модели $($системы$)$;
    $\mathrm{P}$~--- процесс $($в смысле определения~$1)$;
    $\mathrm{H}\hm=\left\{\mathrm{H}_{a,\mathfrak{p}},\ a\in \alpha 
\mathrm{P},\ \mathfrak{p}\in\mathfrak{P}\right\}$~--- семейство операторов, 
каждый из которых действует из множества значений соответствующего 
параметра в то же множество. Совокупность $\mathrm{H}_a\hm=\left\{ 
\mathrm{H}_{a,\mathfrak{p}},\ \mathfrak{p}\in \mathfrak{P}\right\}$ будем 
называть обработчиком события $a\in \alpha\mathrm{P}$.}
    
    Приведенное определение имитационной модели соответствует 
представлению о ее функ\-ци\-онировании как о чередовании событий из 
мно\-жества~$\alpha \mathrm{P}$. Допустимые последовательности\linebreak 
    \mbox{событий}~--- это протоколы процесса~P. При наступлении события 
$a\in \alpha\mathrm{P}$ текущее значение~$x$ каждого параметра 
$\mathfrak{p}\hm\in\mathfrak{P}$ заменяется на (вообще говоря, новое) 
значение $x^\prime\hm=\mathrm{Q}_{a,\mathfrak{p}}(x)$.

\section{Имитационная модель вычислительного комплекса}

\subsection{Основные параметры}
    
    Множество параметров $\mathfrak{P}$ естественным образом 
разбивается на подмножества, относящиеся к составным частям объекта, как 
они были описаны в разд.~2, как-то: компьютеры, задания и~т.\,д. В~этом 
подразделе задаются основные элементы каждого из этих подмножеств.

\medskip
\textbf{Вычислительные устройства}
\smallskip

    Множество всех вычислительных устройств (компьютеров) 
обозначается через~$\mathcal{C}$. Каждый компьютер $c\hm\in \mathcal{C}$ характеризуется 
следующими па\-ра\-мет\-рами:
    \begin{description}
    \item[\,] $c.v$~--- емкость, т.\,е.\ максимальное количество 
элементарных задач, которое данное вычислительное устройство может 
единовременно принять для обработки;
    \item[\,] $c.r$~---производительность, под которой подразумевается 
безразмерный коэффициент, показывающий, во сколько раз скорость 
обработки элементарной задачи на данном процессоре отличается от 
скорости обработки на стандартном компьютере;
    \item[\,] $c.s$~--- состояние, которое может принимать одно из трех 
значений: 0 ({\sf operable}), 1 ({\sf fail}), 2 ({\sf fault}).
    \item[\,] $c.t_{\mathrm{trans}}$~--- время перехода в следующее 
состояние.
    \end{description}
    
    Переходы между состояниями процессора регулируются мат\-ри\-цей 
вероятностей, которая имеет вид:
    $$
    \begin{pmatrix}
    0 & c.\mathrm{P}_{01} & 1-c.\mathrm{P}_{01}\\
    c.\mathrm{P}_{10} & 0 & 1-c.\mathrm{P}_{10}\\
    0 & 0 & 1
    \end{pmatrix}\,,
    $$
а продолжительности пребывания в каждом из состояний образуют 
последовательность условно независимых случайных величин с функциями 
распределения~--- компонентами вектора $c.\mathrm{H}\hm=(c.\mathrm{H}_0, c.\mathrm{H}_1, c.\mathrm{H}_2)$.

\medskip
\textbf{Задания}
\smallskip

    Пусть $j$ обозначает задание. Следующие параметры задания 
определяются в момент его возникновения и остаются неизменными в 
течение всего времени пребывания задания в системе:
    \begin{description}
    \item[\,] $j.f$~--- поток, породивший задание;
    \item[\,] $j.t_{1t}$~--- время жизни задания;
    \item[\,] $j.k$~--- ключ~--- индикатор наличия ключевой задачи в 
задании. Предполагается, что в каждом задании имеется не более одной 
ключевой задачи. Если значение данного параметра равно~1, то ключевая 
задача существует; если параметр равен~0, то ключевой задачи в задании 
нет;
    \item[\,] $j.l$~--- длина, которая определяется как количество 
элементарных задач в задании;
    \item[\,] $j.t_{\mathrm{prep}}$~--- время, необходимое для подготовки 
задания к очередному запуску. Этот параметр устанавливается в момент 
поступления задания в систему и остается неизменным независимо от числа 
запусков.
    \end{description}
    
    Кроме того, задание характеризуется набором параметров, которые 
изменяются в процессе выполнения задания:
    \begin{description}
    \item[\,] $j.\mathcal{C}$~--- список вычислительных устройств, на которых 
выполняется задание;
    \item[\,] $j.\mathcal{P}$~--- список пакетов, составляющих очередную посылку, т.\,е.\ 
    партия пакетов, направляемых единовременно для обработки на 
компьютеры. Число пакетов в посылке совпадает с количеством 
компьютеров в предыдущем списке;
    \item[\,] $j.t_{\mathrm{check}}$~---  контрольное время, через которое 
происходит проверка результатов выполнения всех пакетов задач из 
посылки.
    \end{description}

\smallskip
\textbf{Потоки заданий}
\smallskip

    Множество всех потоков обозначается через~$\mathcal{F}$. Пусть $t_0\hm=0$, а 
$0\leq t_1\leq t_2\leq\ldots$~--- последовательные моменты поступления 
заданий некоторого потока $f\hm\in F$. Тогда последовательность $t_n-t_{n-
1}$, $n\hm=1, 2, \ldots$, интервалов между последовательными 
поступлениями заданий является по\-сле\-до\-ва\-тель\-ностью независимых 
случайных величин, имеющих одинаковое распределение 
$f.\mathcal{D}_{\mathrm{in}}$. Текущее значение\linebreak промежутка времени между 
поступлениями заданий обозначается через $f.t_{\mathrm{in}}$. 
Неизменяемые параметры вновь поступившего задания данного потока 
определяются с помощью набора функций распределе\-ния 
$(f.\mathcal{D}_{1t}, f.\mathcal{D}_{\mathrm{key}}, f.\mathcal{D}_{\mathrm{len}}, 
f.\mathcal{D}_{\mathrm{prep}})$. В~качестве 
значений параметров <<время жизни>>, <<ключ>>, <<длина>> и <<время 
подготовки>> задание получает реализации случайных величин с 
соответствующими функциями распределения.
    
    Еще два статических параметра потока $f.\mu$ и $f.\sigma$ определяют 
соответственно среднее значение и дисперсию времени выполнения 
элементарной задачи на стандартном вычислительном устройстве.
    
    Очередное задание, порождаемое потоком $f$, обозначается через $f.j$.

\medskip
\textbf{Пакеты}
\smallskip

    Пакетом называется набор задач, который отправляется единовременно 
на определенный процессор в составе посылки~--- совокупности пакетов,\linebreak 
образованных из одного задания. Параметры па\-кета:
    \begin{description}
      \item[\,] $p.j$~--- задание, из которого сформирован пакет;
      \item[\,] $p.c$~--- компьютер, на котором выполняется пакет;
      \item[\,] $p.l$~--- длина, т.\,е.\ чис\-ло входящих в пакет задач;
      \item[\,]  $p.t_{\mathrm{send}}$~--- время передачи пакета на выбранный 
компьютер, которое определяется функцией распределения 
$\mathcal{D}_{\mathrm{send}}$, общей для всей сис\-те\-мы и имеющей в качестве 
аргумента длину пакета;
      \item[\,] $p.t_{\mathrm{exe}}$~--- время выполнения пакета заданий 
на выбранном компьютере при условии, что последний находится в 
исправном состоянии (об этом параметре ниже).
      \end{description}
      
\smallskip
\textbf{Центр управления}
\smallskip

    Работа центра управления фактически определяется совокупностью 
правил принятия решений, касающихся следующих аспектов.
    \begin{enumerate}[1.]
    \item Управление очередью заданий (запуск, прерывание запуска, 
удаление из системы), с которым связаны следующие параметры:
    \begin{description}
    \item[\,] $t_{\mathrm{dec}}$~--- момент принятия решения об 
обслуживании очереди заданий;
    \item[\,] $\Delta t_{\mathrm{dec}}$~--- интервал времени между 
последовательными моментами принятия решения об обслуживании 
очереди;
    \item[\,] $\mathcal{J}_{\mathrm{out}}$~--- множество заданий, удаляемых из 
сис\-те\-мы как выполненных или просроченных;
    \item[\,] $\mathcal{J}_{\mathrm{break}}$~--- множество заданий, запуск которых 
прерывается;
    \item[\,] $\mathcal{J}_{\mathrm{run}}$~--- множество заданий, выбранных для 
запуска.
    \end{description}
    \item Управление запуском задания (назначение вычислительных 
устройств, обслуживающих задание, установление размеров пакетов, 
определение контрольного времени для проверки\linebreak результатов посылок). 
Соответствующие параметры были определены в разделах, относящихся к 
заданиям и пакетам.
    \item Техническое обслуживание компьютеров (ремонт, замена). Этот 
вид деятельности центра управления в данной работе не рассматривается. 
В~дальнейшем предполагается, что вышедшие из строя компьютеры могут 
либо самопроизвольно восстановиться через некоторое время, либо 
окончательно ломаются и больше не принимают участия в работе.
    \end{enumerate}
    
\subsection{События и~процессы}

    В этом пункте формулируется основной процесс~P, определяющий 
допустимые последовательности рассматриваемых событий в 
вычислительном комплексе. Вначале выделяются определенные события, с 
которыми связано функционирование объекта. Затем устанавливаются 
потенциально возможные траектории событий с помощью системы 
уравнений, определяющих вспомогательные процессы. Эти уравнения 
основаны на конструкциях из разд.~3 и включают рекурсию.
    
    Условимся рассматривать следующие события в системе:
    \begin{description}
    \item[\,]  decision~--- момент принятия решения центром 
управления об обслуживании очереди задач;
    \item[\,]  $f.{\mathrm{input}}$~--- поступление в систему задания из 
потока~$f$;
    \item[\,] $j.{\mathrm{run}}$~--- подготовка к запуску задания~$j$;
    \item[\,] $j.{\mathrm{package}}$~--- отправление посылки из задания~$j$ 
на вычислительные устройства;
    \item[\,] $j.{\mathrm{replay}}$~--- проверка результатов посылки из 
задания~$j$;
    \item[\,] $j.\mathrm{break}$~--- прерывание запуска задания~$j$;
    \item[\,] $j.\mathrm{output}$~--- уход из системы задания~$j$;
    \item[\,] $p.\mathrm{start}$~--- начало выполнения пакета~$p$;
    \item[\,] $p.\mathrm{finish}$~--- завершение выполнения пакета~$p$;
\item[\,] $c.\mathrm{fail}$~--- сбой компьютера~$c$;
\item[\,] $c.\mathrm{fault}$~--- отказ компьютера~$c$;
    \item[\,] $c.\mathrm{reneval}$~--- восстановление компьютера~$c$.
    \end{description}
    
    Совокупность перечисленных событий со\-став\-ля\-ет множество событий 
$\alpha\mathrm{P}$ процесса~P.
    
    Далее используются дополнительные соглашения и обозначения. 
Считается, что операция $\rightarrow$ связывает аргументы сильнее, чем 
операции~$\vert$ и~$\Vert$, которые имеют одинаковый ранг и, если не 
расставлены скобки, выполняются слева направо. Например, записи
    $
    a\rightarrow \mathrm{P}_1\vert b\rightarrow 
\mathrm{P}_2\Vert\mathrm{P}_3
    $
    и
    $
    (a\hm\rightarrow \mathrm{P}_1)\vert \left(\left(b\hm\rightarrow 
\mathrm{P}_2\right)\Vert \mathrm{P}_3\right)
    $
равносильны.
    
    Множественная пометка перед уравнением процесса означает, что 
задано множество уравнений, в каждом из которых все события, 
подпроцессы и параметры имеют одинаковую метку. Например, запись $\mathcal{G}:\ 
\mathrm{P}_1\hm=a\hm\rightarrow \mathrm{P}_2$ равносильна системе 
$g.\mathrm{P}_1\hm=g.a\hm\rightarrow  g.\mathrm{P}_2$, $g\in \mathcal{G}$.
    
    Обозначение $[\![\ldots]\!]$ используется для перечисления событий, 
которые все должны произойти, но в произвольном порядке. Например, 
запись $[\![a,b]\!]\hm\rightarrow \mathrm{P}$ равносильна выражению 
$a\hm\rightarrow b\hm\rightarrow \mathrm{P}\vert b \hm\rightarrow 
a\rightarrow \mathrm{P}$.
    
    Обозначение $\langle\ldots\rangle$ используется для перечисления 
событий, которые предоставляются в качестве возможного, но 
необязательного выбора. Например, если протоколы процесса~P не 
начинаются с символа~$b$, то запись $a\hm\rightarrow \langle b\rangle 
\hm\rightarrow \mathrm{P}$ равносильна выражению $a\hm\rightarrow 
\left( \mathrm{P}\vert b\hm\rightarrow \mathrm{P}\right)$.
    
    Символ $\boxdot$ указывает на завершение процесса.
    
    Через $\mathcal{J}$ обозначается множество всех потенциально возможных 
заданий, поступающих в систему. 

Аналогично $\mathcal{P}$~--- множество всех 
потенциальных пакетов, которые могут быть образованы в сис\-теме.
    
    Все потенциальные траектории событий в модели задаются следующим 
набором соотношений:

\end{multicols}

\hrule

\noindent
    \begin{align*}
    &\  \ \mathrm{P}=\mbox{COMPUTER\_SYSTEM} = \mbox{FLOWS}\Vert 
\mbox{COMPUTERS}\Vert \mbox{CONTROL\_CENTER}
    \\
   &\ \ \mbox{FLOWS} = \Vert_{f\in \mathcal{F}} f.\mbox{FLOW}
   \\
  \mathcal{F}: &\ \ \mbox{FLOW}\;= \mathrm{input} \rightarrow \left(j.\mathrm{JOB}\Vert 
\mathrm{FLOW}\right)\\
\mathcal{J}: &\ \ \mbox{JOB}\;= \mathrm{run} \rightarrow \mathrm{EXECUTION}\vert \mathrm{output} 
\rightarrow\boxdot\\
\mathcal{J}: &\ \ \mbox{EXECUTION}\;= \mathrm{package} \rightarrow \left( \mathrm{PACKAGE}\Vert \mathrm{replay} 
\rightarrow  \mathrm{EXECUTION}\right) \vert \mathrm{BREAK}\\
\mathcal{J}: &\  \ \mbox{PACKAGE}\;= \Vert_{p\in \mathcal{P}}p.\mbox{PACKET}\\
\mathcal{J}: &\ \ \mbox{BREAK}\;= \mathrm{break} \rightarrow \left( \mathrm{JOB}\vert \mathrm{output} 
\rightarrow \boxdot \right)\\
\mathcal{P}: &\ \ \mbox{PACKET}\;= \mathrm{start} \rightarrow \langle \mathrm{finish}, 
c.\mathrm{fail}, c.\mathrm{fault}\rangle 
\rightarrow j.\mathrm{replay} \rightarrow \boxdot\\
   &\ \ \mbox{COMPUTERS}\,= \Vert_{c\in \mathcal{C}} c.\mbox{COMPUTER}\\
\mathcal{C}: &\ \ \mbox{COMPUTER}\;= p.\mbox{PACKET} \Vert \mbox{CYCLE}\\
\mathcal{C}:&\  \ \mbox{CYCLE}\;= \mathrm{fail} \rightarrow  \mathrm{reneval} 
\rightarrow \mbox{COMPUTER} \vert 
\mathrm{fail} \rightarrow \mathrm{fault} \rightarrow \boxdot \vert \mathrm{fault} 
\rightarrow \boxdot\\
   &\ \ \hspace{17mm} \mbox{CONTROL\_CENTER}\;=\mathrm{decision} \rightarrow 
\mbox{DECISION}\Vert \mbox{CONTROL\_CENTER}\\
   &\ \ \mbox{DECISION}\;=[\![j.\mathrm{output},\ j\in 
   \mathcal{J}_{\mathrm{out}}]\!] \rightarrow [\![j.\mathrm{break},\ j\in 
\mathcal{J}_{\mathrm{break}}]\!] \rightarrow [\![j.\mathrm{run},\ j\in 
\mathcal{J}_{\mathrm{run}}]\!]\rightarrow \boxdot
   \end{align*}
   
   \hrule
   
   \begin{multicols}{2}

\subsection{Обработка событий}

    Обработка события связана с выполнением определенных действий, 
которые по аналогии с обычным программированием будем называть 
процедурами. Обработчик~H$_a$ события~$a$ представляет собой 
процедуру, объединяющую эти действия. 

    \begin{table*}[b]\small
    \begin{center}
    \vspace*{-12pt}
    \Caption{Построение множества <<ближайших>> событий}
    \vspace*{2ex}
    
    \begin{tabular}{|l|c|c|c|}
    \hline
\multicolumn{1}{|c|}{Событие $a_n$}&$a\in \mathcal{B}_n$&\multicolumn{2}{c|}{$\top(a)-\top(a_n)$}\\
\hline
\multicolumn{1}{|l|}{\raisebox{-16pt}[0pt][0pt]{decision}}&decision&$\Delta t_{\mathrm{dec}}$&Определяется процедурой
{\sf PeriodDecision}\\
\cline{2-4}
&$j.\mathrm{output}$&& \\
\cline{2-2}
&$j.\mathrm{break}$&$t_\varepsilon$& Константа в той же процедуре \\
\cline{2-2}
&$j.\mathrm{run}$&&\\
\hline
$j.\mathrm{input}$&$j.\mathrm{input}$&$(j.f).t_{\mathrm{in}}$&
\tabcolsep=0pt\begin{tabular}{c}Реализация случайной величины\\ с 
распределением $(j.f).\mathcal{D}_{\mathrm{in}}$\end{tabular}\\
\hline
$j.\mathrm{run}$&$j.\mathrm{package}$&$j.t_{\mathrm{prep}}$&
\tabcolsep=0pt\begin{tabular}{c}Реализация случайной величины\\ с 
распределением $f.\mathcal{D}_{\mathrm{prep}}$\end{tabular}\\
\hline
\multicolumn{1}{|l|}{\raisebox{-12pt}[0pt][0pt]{$j.\mathrm{package}$}}&$j.\mathrm{replay}$&$j.t_{\mathrm{check}}$&Определяется процедурой
{\sf CheckDecision}\\
\cline{2-4}
&$p.\mathrm{start}$, $p\in j.\mathcal{P}$&$p.t_{\mathrm{send}}$&
\tabcolsep=0pt\begin{tabular}{c}Реализация случайной величины\\ с 
распределением $\mathcal{D}_{\mathrm{send}}$\end{tabular}\\
\hline
$p.\mathrm{start}$&$p.\mathrm{finish}$&$p.t_{\mathrm{exe}}$&Определяется процедурой
{\sf ProcessingTime}\\
\hline
$c.\mathrm{fail}$&\tabcolsep=0pt\begin{tabular}{l}if $\alpha=1$\\ then 
$c.\mathrm{reneval}$\\ else  $c.\mathrm{fault}$\end{tabular}&
$c.t_{\mathrm{trans}}$&
\tabcolsep=0pt\begin{tabular}{c}$\alpha$~--- бернуллиевская случайная величина\\ 
с распределением $c.\mathrm{P}_{10}$,\\
$t_{\mathrm{trans}}$~--- реализация случайной\\ 
величины с распределением $c.\mathrm{H}_1$\end{tabular}\\
\hline
$c.\mathrm{reneval}$&\tabcolsep=0pt\begin{tabular}{l}
if $\alpha=1$\\ then $c.\mathrm{fail}$\\ else  $c.\mathrm{fault}$\end{tabular}&
$c.t_{\mathrm{trans}}$&
\tabcolsep=0pt\begin{tabular}{c}$\alpha$~--- бернуллиевская случайная величина\\ 
с распределением $c.\mathrm{P}_{01}$,\\ $t_{\mathrm{trans}}$~--- реализация случайной\\ 
величины с распределением $c.\mathrm{H}_0$\end{tabular}\\
\hline
\end{tabular}
\end{center}
\end{table*}


Опишем кратко обработчики 
некоторых из определенных выше событий, опуская не самые существенные 
подробности.
    
    Обработка события decision связана с принятием решений 
относительно обслуживания очереди заданий. Предполагается, что эта 
процедура выполняется в определенные моменты времени (в п.~4.1 
обозначенные с помощью переменного параметра~$t_{\mathrm{dec}}$), 
причем назначение этих моментов также является составной частью 
принимаемого решения. Обработка заключается в выполнении следующих 
процедур:
    \begin{multline*}
    \mathrm{H}_{\mathrm{decision}}=\left\{
\mbox{\sf 
BreakDecision;\,RunDecision;}\right.\\
\left.\mbox{\sf CheckDecision;\,PeriodDecision}\right \}\,.
\end{multline*}
    
    Процедура {\sf BreakDecision} определяет множества заданий 
$\mathcal{J}_{\mathrm{out}}$ и~$\mathcal{J}_{\mathrm{break}}$.
    
    Процедура {\sf RunDecision} определяет множество заданий 
$\mathcal{J}_{\mathrm{run}}$ и определяет множества компьютеров $j.\mathcal{C}$, $j\in 
\mathcal{J}_{\mathrm{run}}$, на которых эти задания будут выполняться. При 
составлении списка~$j.\mathcal{C}$ используется информация о степени готовности 
(исправности) компьютеров, а также об их загруженности. Компьютер может 
быть включен в указанный список только в том случае, если он не занят 
решением задач и находится в состоянии {\sf operable}. Этот список может 
обновляться при каждом новом запуске задания. В~течение одного запуска 
данный список может лишь уменьшаться (в случае выхода из строя 
вычислительных устройств).
    
    Процедура {\sf СheckDecision} определяет размер посылаемых пакетов, 
а также контрольное время, через которое будут проверяться результаты 
посылок.
    
    Процедура {\sf PeriodDecision} устанавливает промежуток времени 
$\Delta t_{\mathrm{dec}}$ до следующего момента принятия решения.
    
    Обработчик события $f.\mathrm{input}$ порождает новое задание $f.j$ и 
устанавливает его параметры: $(f.j).t_{1t}$ (время жизни), $(f.j).k$ 
(ключ), $(f.j).l$ (длину), $(f.j).t_{\mathrm{prep}}$ (время на подготовку 
запуска). Пребывание задания~$j$ в системе оканчивается с наступлением 
события $j.\mathrm{output}$.
    
    Событие $j.\mathrm{run}$ означает начало запуска задания~$j$.
    
    Обработка события $j.\mathrm{package}$ заключается в образовании множества 
пакетов $j.\mathcal{P}$ и отправке их на соответствующие компьютеры из 
множества~$j.\mathcal{C}$.
    
    Событие $j.\mathrm{replay}$ влечет обработку результатов выполнения партии 
пакетов. Выполненные пакеты уменьшают размер невыполненной части 
задания. В~случае решения ключевой задачи задание считается 
выполненным. Если задание не выполнено, то организуется новая посылка.
    
    Событие $p.\mathrm{start}$ означает, что пакет $p$ до\-став\-лен на соответствующее 
вычислительное устройство. При обработке этого события выполняется 
процедура {\sf ProcessingTime}, которая определяет время 
$p.t_{\mathrm{exe}}$ выполнения пакета. Событие $p.\mathrm{finish}$ означает, что 
пакет~$p$ успешно выполнен.
    
    Обработка события~$j.\mathrm{break}$ заключается в прерывании запуска 
задания. Освобождаются все компьютеры, занятые его выполнением.
    
    Наступление события $c.\mathrm{fail}$ ($c.\mathrm{fault}$) означает переход 
компьютера~$c$ в состояние~1~(2). Если этот компьютер был закреплен за 
заданием~$j$, то он вычеркивается из списка $j.\mathcal{C}$ и в дальнейшем не 
участвует в обслуживании заданий. Событие $c.\mathrm{reneval}$, которое может 
наступить после события $c.\mathrm{fail}$, означает восстановление компьютера 
(переход в состояние~0).

\subsection{Реализация}
    
    Процесс~P, построенный в п.~4.2, задает множество возможных 
траекторий (протоколов), по которым могут реализовываться события из 
алфавита~$\alpha\mathrm{P}$. Однако для имитации поведения системы 
необходимо выделять из этого множества единственную траекторию, 
которую будем обозначать $\pi\hm=(a_0,a_1, \ldots) \hm\in \pi\mathrm{P}$, 
$a_n\hm\in \alpha\mathrm{P}$.
    
    Считаем, что имитационная траектория раз-\linebreak ворачивается в непрерывном 
времени $t\hm\geq 0$.\linebreak С~каж\-дым событием~$a_n$ из протокола~$\pi$ 
свяжем обозначение $\top (a_n)$, указывающее момент времени, в который 
оно происходит (или должно про\-изойти). Сопоставим моменту~$\top(a_n)$ 
множество <<ближайших>> событий $\mathcal{A}_{n+1}\subset \alpha\mathrm{P}$, 
которые должны произойти непосредственно вслед за событием~$a_n$. 
Каждый элемент множества $a\hm\in \mathcal{A}_{n+1}$ обладает характеристикой 
$\top(a_n)$, причем обязательно $\top(a)\hm>\top(a_n)$. При этом первое за 
моментом~$\top(a_n)$ событие~$a_{n+1}$ определяется как элемент 
$a_{n+1}\hm=a\hm\in \mathcal{A}_{n+1}$ с минимальным значением~$\top(a)$.
    
    Множество $\mathcal{A}_{n+1}$ образуется из множества~$\mathcal{A}_n$ следующим 
образом: $\mathcal{A}_{n+1}\hm=\left( \mathcal{A}_n\backslash \{a_n\}\right)\cup \mathcal{B}_n$, причем 
состав множества добавляемых событий~$\mathcal{B}_n$ определяется 
событием~$a_n$. В~это множество~$\mathcal{B}_n$ входят события, которые 
обязательно должны произойти непосредственно за событием~$a_n$ в 
соответствии с протоколами процесса~P. В~табл.~1 показан состав 
множества~$\mathcal{B}_n$ в зависимости от события~$a_n$.
    

\section{Оптимизация}

\subsection{Параметры процедур принятия решений}

    Рассмотрим подробнее процедуры, которые связаны с принятием 
решений и входят в обработчик события decision (см.\ п.~4.3).
    
    \smallskip
    
\textbf{Процедура {\sf BreakDecision}}. Эта процедура уста\-нав\-ли\-ва\-ет, какие 
задания следует удалить из системы, а для каких следует прервать запуск. 
Первая со\-став\-ля\-ющая вполне ясна: удаляются задания, выполненные или 
просроченные к моменту наступления очередного события decision. Вопрос 
с прерыванием более интересен. Дело в том, что по мере выполнения 
задания (без обнаружения ключевой задачи) может увеличиваться 
вероятность того, что задание вообще ее не содержит, т.\,е.\ имеет малую 
ценность. Возможно, выгоднее прервать его запуск и обратиться к другим 
заданиям. Работа процедуры определяется параметром, который 
обозначается $p_{\mathrm{break}}$. Если доля выполненной части задания 
превысила порог~$p_{\mathrm{break}}$, а ключевая задача не обнаружена, 
то запуск задания прерывается (задание включается в 
множество~$\mathcal{J}_{\mathrm{break}}$).
    
    \smallskip
    
\textbf{Процедура {\sf RunDecision}}. Рассмотрим сле\-ду\-ющую процедуру 
выбора запускаемых заданий. Упорядочим множество заданий согласно 
некоторому <<рейтингу>> $r_{\mathrm{run}}$ (параметр процедуры), 
который вычисляется в момент принятия решения о запуске. Множество 
запускаемых заданий~$\mathcal{J}_{\mathrm{run}}$ составляется из первых $n$ 
заданий с наибольшим рейтингом. Величина~$n$ зависит от 
целочисленного параметра процедуры $n_{\mathrm{run}}$:
    $$
    n=\begin{cases}
    N\,, & \mbox{если}\ n_{\mathrm{run}}=0\,;\\
    \min \{ n_{\mathrm{run}},N,M\}\,, & \mbox{если}\ n_{\mathrm{run}}>0\,,
    \end{cases}
    $$
где $N$~--- количество заданий, ожидающих запуска; $M$~--- чис\-ло 
свободных компьютеров.
    
    \smallskip
    
\textbf{Процедура {\sf CheckDecision}}. Пусть $j$~--- выполняемое задание. 
Время выполнения пакета~$p$, имеющего длину $p.l$ на процессоре 
$c\hm\in j.\mathcal{C}$ составляет $(j.f).\mu\cdot (p.l)/c.r$, где $(j.f).\mu$~--- среднее 
время выполнения элементарной задачи для данного задания (на 
стандартном процессоре), а $c.r$~--- производительность компьютера. 
Потребуем, чтобы указанное время было одинаковым для всех компьютеров 
из множества $j.\mathcal{C}$, и обозначим его через~$\vartheta$. Учтем ограничения 
на размеры пакетов, связанные с емкостью компьютеров: $1\hm\leq 
p.l\hm\leq c.v$. Для возможных значений~$\vartheta$ получим соотношения 
$(j.\mu)\cdot \max\limits_{c\in \mathcal{C}} (1/(c.r))\hm\leq \vartheta\hm\leq 
(j.\mu)\cdot \min\limits_{c\in \mathcal{C}}((c.v)/(c.r))$. Таким образом, если обозначить 
левую и правую части последнего неравенства соответственно через~$m$ 
и~$M$, то $\vartheta\hm= m+k^1_{\mathrm{check}}M$, где 
$k^1_{\mathrm{check}}\hm\in [0,\,1]$~--- параметр процедуры.
    
    Если зафиксировано значение $\vartheta$ из указанного диапазона, то 
размер пакета~$p$ определяется как $p.l\hm=\vartheta\cdot (c.r)/((j.f).\mu)$. 
Кроме того, значение~$\vartheta$ является основанием для выбора 
контрольного времени проверки результатов посылки, которое 
устанавливается в момент запуска. Полагаем, что $j.t_{\mathrm{check}}\hm= 
k^2_{\mathrm{check}}\vartheta$, где $k^2_{\mathrm{check}}$~--- еще один 
параметр про\-це\-дуры.
    
    \smallskip
    Процедура {\sf PeriodDecision}. Эта процедура характеризуется 
единственным параметром $\Delta t_{\mathrm{dec}}$, который показывает, 
через какое время произойдет очередное принятие решения по управлению 
очередью заданий и выбором параметров запуска.

\subsection{Целевая функция}

    Как изложено в предыдущем пункте, принятие решений центром 
управления определяется набором параметров
    $$
\mathcal{P}=\left( p_{\mathrm{break}}, r_{\mathrm{run}}, n_{\mathrm{run}}, 
k^1_{\mathrm{check}}, k^2_{\mathrm{check}}, \Delta t_{\mathrm{dec}}\right)\,,
    $$
входящих в определение процедур из обработчика $
\mathrm{H}_{\mathrm{decision}}$. Соответственно, оптимизация работы центра 
управления сводится к оптимизации выбора этих параметров.
    
    Любой из параметров $p\in \mathcal{P}$ может, вообще говоря, изменяться в ходе 
работы системы, и в общем случае зависимость от времени может быть не 
только явная, но и опосредованная через зависимость от предыстории 
наблюдаемых параметров системы. Совокупность $\{p\hm= p(t),\ p\in \mathcal{P}\}$ 
зависимостей параметров от времени будем обозначать буквой~$\mathcal{S}$ и 
называть стратегией центра управления.
    
    Для того чтобы охарактеризовать эффективность стратегии центра 
управления, введем следующие обозначения:
    \begin{description}
    \item[\,] $x_1(t)$~--- количество найденных ключевых задач к 
моменту~$t$;
    \item[\,] $x_2(t)$~--- количество выполненных к моменту $t$ заданий, в 
которых не оказалось ключевой за\-дачи;
    \item[\,] $x_3(t)$~--- общее количество решенных к моменту~$t$ 
элементарных задач;
\item    $x_4(t)$~--- количество незавершенных заданий, которые превысили 
время жизни и были удалены из системы к моменту~$t$.
    \end{description}
    
    Определим <<доход>> за стратегию~$\mathcal{S}$ формулой
     $$
w(\mathcal{S}) =\sum\limits_{i=1}^4 \mathcal{C}_i 
\mathop{\underline{\lim}}_{T\rightarrow\infty} T^{-
1}\sum\limits_{t=0}^T \mathbf{E}_{\mathcal{S}} x_i(t)\,,
    $$
где $\mathbf{E}_{\mathcal{S}}$~--- оператор усреднения, порожденный стратегией~$\mathcal{S}$, 
а $\mathcal{C}_i$~--- весовые коэффициенты, соответствующие <<стоимости>> 
различных показателей~$x_i$. 

Требуется найти стратегию, обес\-пе\-чи\-ва\-ющую 
доход, близкий к величине (или равный) $w\hm=\sup\limits_{\mathcal{S}\in 
\mathbf{S}} w(S)$, где $\mathbf{S}$~--- некоторое заданное множество 
стратегий.

%\vspace*{-6pt}

\subsection{Адаптивная стратегия}

    Ограничимся задачей оптимизации целевой функции на следующем 
множестве статических стратегий~\textbf{S}. Предположим, что множества 
до\-пус\-ти\-мых значений каждого из параметров $p\hm\in \mathcal{P}$ конечны. Пусть 
$s_p$ означает вероятностное распределение на множестве значений 
параметра~$p$, $\mathcal{S}\hm=\{ s_p,\ p\in \mathcal{P}\}$. Совокупность~$\mathcal{S}$ можно 
трактовать как стратегию, при которой выбор параметра~$p$ каждый раз 
осуществляется в виде реализации случайной величины с распределением 
$s_p$. Положим $\mathbf{S}\hm=\{\mathcal{S}\}$.
    
    Стратегия~$S$ может быть представлена в виде вектора в 
конечномерном пространстве. Соответственно, максимизацию функции 
$w(\mathcal{S})$ на множестве~$\mathbf{S}$ можно трактовать как классическую 
задачу оптимизации и решать ее, например, с помощью алгоритма проекции 
градиента. Однако в данном случае такой подход затруднен, поскольку 
невозможно получить явное аналитическое представление функции~$w$ и 
ее производных. Выход заключается в том, чтобы вместо точного значения 
градиента использовать его оценку по результатам наблюдений за 
имитируемой траекторией. И~на этом пути имеются принципиальные 
трудности, в част\-ности, из-за того, что значения функции~$w$, 
опреде\-ля\-емой как предел, не наблюдаемы. Для построения ал\-горитмов 
максимизации функции~$w$, в которых\linebreak вектор~$\mathcal{S}$ пересчитывается на 
основе доступных\linebreak наблюдений, можно воспользоваться теорией, 
изложенной в~[4]. Подобные алгоритмы, которые действуют в условиях 
минимальной априорной информации об объекте, трактуются как 
адаптивные стратегии управления частично наблюдаемыми марковскими 
цепями. Изложение этих алгоритмов не предусмотрено форматом статьи, 
поэтому ограничимся численным примером использования адаптивной 
стратегии для оптимизации дохода в построенной модели вычислительного 
комплекса.

\vspace*{-6pt}

\section{Пример}

\vspace*{-3pt}

\subsection{Параметры модели}

    Имеются 10 вычислительных устройств~$c_i$, $i\hm=1,\ldots , 10$, и 
2~потока заданий, $f_1$ и~$f_2$. Эти объекты имеют следующие параметры.
    
    Емкость: $c_1.v=100$, $c_2.v=\cdots =c_5.v\hm=50$, $c_6.v\hm=\cdots = 
c_{10}.v\hm=10$.
    
    Производительность: $c_1=10$, $c_2\hm=c_3\hm=5$, $c_4\hm=c_5\hm=2$, 
$c_6\hm=\cdots = c_{10}\hm=1$.
    
    Распределение времени пребывания в исправном состоянии: 
    $c_i.\mathrm{H}_0$~--- экспоненциальное с параметром~0,01. Вероятность сбоя в 
исправном состоянии: $c_i.P_{01}\hm=1$, $i\hm=1,\ldots , 10$. Распределение 
времени пребывания в состоянии сбоя: $c_i.\mathrm{H}_1$~--- экспоненциальное с 
параметром~0,5. Вероятность восстановления после сбоя: 
$c_i.\mathrm{P}_{10}\hm=1$, $i\hm=1,\ldots , 10$. (Таким образом, предполагается, что 
компьютеры время от времени оказываются в несправном состоянии, а 
затем самопроизвольно восстанавливаются.)
    
    Распределение промежутка между поступлениями заданий: 
$f_1.\mathcal{D}_{\mathrm{in}}$~--- экспоненциальное с па\-ра\-мет\-ром~0,7; 
$f_2.\mathcal{D}_{\mathrm{in}}$~--- экспоненциальное с па\-ра\-мет\-ром~0,3.
    
    Распределение времени жизни задания ($f_1.\mathcal{D}_{1t}$ 
и~$f_2.\mathcal{D}_{1t}$): равномерное на отрезке [10,\,30].
    
    Параметры $f_1.\mathcal{D}_{\mathrm{key}}$ и $f_2.\mathcal{D}_{\mathrm{key}}$: в заданиях 
из потока~$f_1$ всегда присутствует (единственная) ключевая задача, ее 
местонахождение в задании распределено равномерно и заранее неизвестно; 
в заданиях из потока~$f_2$ ключевые задачи отсутствуют. Принадлежность 
заданий какому-либо потоку заранее не известна.

    \begin{table*}[b]\small
    \begin{center}
    \Caption{Показатели адаптивной и переборной стратегий}
    \vspace*{2ex}
    
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
Стратегия&
\tabcolsep=0pt\begin{tabular}{c}Целевая\\ функция\end{tabular}&
\tabcolsep=0pt\begin{tabular}{c}Решено\\ ключевых задач, \%\end{tabular}&
\tabcolsep=0pt\begin{tabular}{c}Выполнено\\ заданий, \%\end{tabular}&
\tabcolsep=0pt\begin{tabular}{c}Решено\\ задач, \%\end{tabular}&Потери, \%\\
\hline
$\mathcal{S}_{\mathrm{адап}}$&47,76&68,75&96,71&63,88&3,22\\
$\mathcal{S}_{\mathrm{макс}}$&42,09&67,49&94,58&69,08&5,39\\
$\mathcal{S}_{\mathrm{мин}}$&25,40&48,15&68,41&35,36&31,55\hphantom{9}\\
\hline
\end{tabular}
\end{center}
\end{table*}
    
    Распределение длины заданий ($f_1.\mathcal{D}_{\mathrm{len}}$ 
и~$f_2.\mathcal{D}_{\mathrm{len}}$): равномерное на отрезке $[10^4,\,2\cdot 10^4]$.
    
    Распределение времени подготовки задания к запуску 
($f_1.\mathcal{D}_{\mathrm{prep}}$ и~$f_2.\mathcal{D}_{\mathrm{prep}}$): фиксированное 
значение, равное~0,01.
    
    Распределение времени передачи пакета ($\mathcal{D}_{\mathrm{send}}$): 
равномерное на отрезке $[10^{-3},\, 2\cdot 10^{-3}]$.
    
    Время выполнения пакета моделируется следующим образом. Пусть 
$g\hm=(p.j).f$~---поток, породивший задание, из которого сформирован 
пакет длиной $p.l$. Пусть $\tilde{z}$~--- сумма~$p.l$ независимых 
положительных случайных слагаемых со средним значением 
$g.\mu\hm=1{,}5\cdot 10^{-3}$ и дисперсией $g.\sigma \hm= 10^{-4}$, 
    а $z$~--- случайная величина с нормальным распределением, 
аппроксимирующим распределение~$\tilde{z}$. Тогда 
$p.t_{\mathrm{exec}}\hm=\max(0,\,z)$.
    
    Константа $t_\varepsilon$ в процедуре {\sf PeriodDecision} 
равна~10$^{-7}$.
    
    Коэффициенты целевой функции: $\mathcal{C}_1\hm=20$, $\mathcal{C}_2\hm=2$, 
$\mathcal{C}_{3}\hm=10^{-3}$, $\mathcal{C}_4\hm=10$.
    
    Множества значений параметров, отвечающих за принятие решений и 
определенных в п.~5.1, представляются в виде конечных наборов 
следующим образом.
    
    Порог прерывания запуска: $p_{\mathrm{break}}\hm\in \{0{,}5; 0{,}6; 
0{,}7; 0{,}8; 0{,}9; 1\}$.
    
    Рейтинг предпочтения выбора задания для запуска: 
$r_{\mathrm{run}}\hm\in \{R_{\max rs}, R_{\min rs}, R_{\max crs}, R_{\min 
crs}$. Здесь $R_{\max rs}$ ($R_{\min rs}$)~--- упорядочение по наибольшему 
(наименьшему) числу невыполненных задач; $R_{\max crs}$ ($R_{\min 
crs}$)~--- упорядочение по наибольшему (наименьшему) относительному 
числу невыполненных задач по отношению к первоначальной длине 
задания.
    
    Параметр, определяющий количество одновременно запускаемых 
заданий: $n_{\mathrm{run}}\hm\in \{0,\ldots , 4\}$.
    
    Параметры, определяющие контрольное время проверки результатов 
посылок: $k^1_{\mathrm{check}}\hm\in \{0,\ldots ,4\}$, 
$k^2_{\mathrm{check}}\hm\in \{1; 1{,}5; 2; 2{,}5; 3\}$.
    
    Интервал между последовательными принятиями решений центром 
управления: $\Delta t_{\mathrm{dec}}\hm\in \{0{,}1; 0{,}2; \ldots ; 1\}$.
    
    Выбор значений оптимизируемых параметров в процессе имитации 
производится с помощью распределений на указанных множествах 
значений.

\subsection{Эксперимент}
    
    Достижение цели, указанной в п.~5.2, сводится к поиску максимума 
целевой функции на произведении симплексов $\mathbf{S}$ общей 
размерностью $6\hm+4\hm+5\hm+5\hm+10\hm=30$. Традиционными 
методами оптимизации воспользоваться невозможно, поскольку нет явного 
аналитического представления функции, а ее значения принципиально не 
наблюдаемы при имитации. Интуитивные соображения относительно 
расположения точки максимума отсутствуют, поскольку система является 
достаточно сложной и гетерогенной. В~этих условиях адаптивный подход 
представляется единственно возможным способом рационального 
поведения.
    
    Теоретически адаптивная стратегия сходится в пределе к 
максимуму~[4], и это подтверждается экспериментально на более простых 
примерах, в которых доступно нахождение решения иными методами. 
Поскольку в данном случае <<правильный ответ>> не известен по 
указанным выше причинам, то пришлось сравнивать показатели 
адаптивной стратегии с результатами, полученными случайным перебором 
точек из континуального множества~$\mathbf{S}$. Заметим, что последний 
метод крайне неэффективен, потому что <<испытание>> каждой точки 
требует прогона имитационной траектории, а одних только крайних точек 
множества~$\mathbf{S}$ насчитывается $6\cdot 4\cdot 5\cdot 5\cdot 10 
\hm= 6000$.
    
    Эксперимент проводился на персональном компьютере с тактовой 
частотой 2,6~ГГц. Работа адаптив\-но\-го алгоритма заняла около 10~мин 
моделирования траектории смены событий в системе и завершилась 
получением устойчивого значения стратегии (точки) из 
множества~$\mathbf{S}$ (с точностью до третьего знака в вероятностях 
выбора значений параметров). Эта стратегия обозначена через 
$\mathcal{S}_{\mathrm{адап}}$. Случайный перебор производился в течение примерно 
3~ч. Полученные этим способом наилучшая и наихудшая стратегии 
обозначены соответственно $\mathcal{S}_{\mathrm{макс}}$ 
и~$\mathcal{S}_{\mathrm{мин}}$. Показатели, 
соответствующие различным стратегиям, приведены в табл.~2, в которой 
данные по решенным и потерянным заданиям и задачам приведены в 
процентах к их общему количеству, поступившему за время моделирования.
    

    
    Как видно из табл.~2, разброс между наилучшим  и наихудшим  
вариантами, полученными случайным перебором, оказался достаточно 
велик. Это означает, что сама постановка оптимизационной задачи 
оправдана, поскольку система существенно управляема с помощью 
выбранных параметров. (Более того, в ходе эксперимента выяснилось, что 
целевая функция и другие показатели оказались чувствительными к 
изменению любого из выбранных шести управляющих параметров при 
фиксированных остальных.)
    
    Самый важный итог эксперимента заключается в том, что с помощью 
случайного перебора, занявшего на порядок больше времени, получены 
результаты хуже, чем с помощью адаптивной стратегии. Это относится ко 
всем показателям, кроме второстепенного <<общего количества решенных 
задач>>.
    
    Интересно также отметить, что стратегия $\mathcal{S}_{\mathrm{адап}}$, 
полученная в результате работы адаптивного алгоритма, оказалась 
внутренней точкой множества~$\mathbf{S}$, т.\,е.\ она предписывает 
выбирать управляющие параметры с помощью невырожденных 
распределений.

\section{Заключение}

    Рассмотрена проблема эффективного управ\-ления процессом 
обслуживания заданий в специализированном вычислительном комплексе. 
Использованный подход заключается в построении\linebreak
имитационной модели 
объекта с последующим использованием адаптивных алгоритмов. 
Имитационная модель отражает необходимые аспекты устройства и 
функционирования системы, которая является слишком сложной для 
исследования чисто математическими методами. В~модели выделены 
управ\-ля\-ющие параметры, значения которых влияют на производительность 
вычислительного комплекса. В~ходе реализации имитационной траектории 
осуществляется адаптивная коррекция параметров, которая приводит к 
оптимизирующим значениям.
    
    При моделировании были использованы специальные определения и 
подходы. В~част\-ности, существенную роль сыграли конструкции языка 
взаимодействующих последовательных процессов\linebreak
Хоара, которые были 
модернизированы с учетом потребностей имитационного моделирования. 
Примененные средства описания имитационной модели обладают такими 
преимуществами, как компактность и наглядность, удобство для перевода в 
компьютерный код, возможность трансформации и развития модели.
    
    Оптимизационные алгоритмы основаны на результатах адаптивного 
варианта теории частично наблюдаемых управляемых марковских цепей. 
Особенностью их работы является отсутствие необходимости в априорной 
информации о характеристиках объекта. Вычислительный эксперимент 
показал, что адаптивные стратегии способны решать многомерную 
оптимизационную задачу с фактически неизвестной и ненаблюдаемой 
целевой функцией.
    
    Сфера применения представленной в работе методологии не 
ограничивается конкретным примером рассмотренного вычислительного 
комплекса. Аналогичным образом можно действовать с целью оптимизации 
самых разнообразных 
    ин\-фор\-ма\-ци\-он\-но-те\-ле\-ком\-му\-ни\-ка\-ци\-он\-ных, 
производственных и иных систем.

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{9}

    \bibitem{1kon}
    \Au{Коновалов М.\,Г., Малашенко Ю.\,Е., Назарова~И.\,А.}
    Модели и методы управления заданиями в системах распределенных 
вычислительных ресурсов.~--- М.: ВЦ РАН, 2009. 110~с. (Сообщения по 
прикладной математике.)

    \bibitem{3kon} %2
    \Au{Голосов~П.\,Е., Козлов~М.\,В., Малашенко~Ю.\,Е., Назарова~И.\,А., 
Ронжин~А.\,Ф.}
    Модель системы управления специализированным вычислительным 
комплексом.~--- М.: ВЦ РАН, 2010. 48~с. (Сообщения по прикладной 
математике.)
  
  \bibitem{2kon} %3
  \Au{Коновалов М.\,Г., Малашенко Ю.\,Е., Назарова~И.\,А.}
  Управ\-ле\-ние заданиями в гетерогенных вычислительных системах~// Известия 
РАН. Теория и системы управ\-ле\-ния, 2011. №\,2. С.~72--90.
    
    
    \bibitem{4kon}
    \Au{Коновалов М.\,Г.}
    Методы адаптивной обработки информации и их приложения.~--- М.: ИПИ 
РАН, 2007. 212~с.

\label{end\stat}
    
    \bibitem{5kon}
    \Au{Хоар Ч.}
    Взаимодействующие последовательные процессы.~--- М.: Мир, 1989.
 \end{thebibliography}
}
}


\end{multicols}
    