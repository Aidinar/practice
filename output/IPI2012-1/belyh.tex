\def\stat{belyh}

\def\tit{СИСТЕМА ИДЕНТИФИКАЦИИ ДИКТОРОВ ПО~ГОЛОСУ ДЛЯ~КОНКУРСА 
\textit{NIST SRE 2010}}

\def\titkol{Система идентификации дикторов по~голосу для~конкурса 
\textit{NIST SRE 2010}}

\def\autkol{И.\,Н.~Белых, А.\,И.~Капустин, А.\,В.~Козлов и др.}
\def\aut{И.\,Н.~Белых$^1$, А.\,И.~Капустин$^2$, А.\,В.~Козлов$^3$, 
А.\,И.~Лоханова$^4$, Ю.\,Н.~Матвеев$^5$,\\ Т.\,С.~Пеховский$^6$, 
К.\,К.~Симончик$^7$, А.\,К.~Шулипа$^8$}

\titel{\tit}{\aut}{\autkol}{\titkol}

%{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
%{Работа выполнена при поддержке РФФИ (гранты 09-07-12098, 09-07-00212-а и 
%09-07-00211-а) и Минобрнауки РФ (контракт №\,07.514.11.4001).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{<<Центр речевых технологий>>, Санкт-Петербург, belykh@speechpro.com}
\footnotetext[2]{<<Центр речевых технологий>>, Санкт-Петербург, kapustin@speechpro.com}
\footnotetext[3]{<<Центр речевых технологий>>, Санкт-Петербург, kozlov-a@speechpro.com}
\footnotetext[4]{<<Центр речевых технологий>>, Санкт-Петербург, lohanova@speechpro.com}
\footnotetext[5]{<<Центр речевых технологий>>, Санкт-Петербург, matveev@speechpro.com}
\footnotetext[6]{<<Центр речевых технологий>>, Санкт-Петербург, tim@speechpro.com}
\footnotetext[7]{<<Центр речевых технологий>>, Санкт-Петербург, simonchik@speechpro.com}
\footnotetext[8]{<<Центр речевых технологий>>, Санкт-Петербург, shulipa@speechpro.com}


  \Abst{Приведено описание системы идентификации дикторов по голосу, разработанной для 
конкурса по оцениванию систем распознавания дикторов \textit{NIST SRE 2010}.}
  
  \KW{биометрическая идентификация; идентификация диктора; распознавание по голосу; 
GMM; SVM; NIST}

 \vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}
      
            \label{st\stat}

\section{Введение}

  Системы идентификации (распознавания, верификации) дикторов по голосу 
относятся к классу биометрических систем, достоинством которых является то, 
что они чаще всего не требуют дополнительного оборудования для регистрации 
голоса и могут быть реализованы с использованием телефонных сетей или 
устройств вво\-да--вы\-во\-да разных типов (микрофонов). 
  
  Область использования такого рода приложений обширна:
  \begin{itemize}
\item автоматическая идентификация подозреваемого по телефонному каналу;
\item автоматическая верификация клиентов при удаленном доступе по 
телефонному каналу;
\item обработка речевых баз данных;
\item криминалистические исследования.
\end{itemize}

  В данной работе представлено описание текстонезависимой системы 
автоматической идентификации дикторов по голосу, разработанной ООО 
<<Центр речевых технологий>> для участия в международном конкурсе по 
оцениванию систем распознавания дикторов \textit{NIST SRE 2010}.
  
  В профессиональной среде \textit{NIST SRE} (speaker recognition evaluation) 
называют неофициальным чемпионатом мира по голосовой идентификации. 
Начиная с 1996~г.\ этот конкурс ежегодно проводится американским 
Национальным институтом стандартов и технологий (National Institute of 
Standards and Technology, NIST). Его основная цель~--- оценить уровень 
существующих технологий и определить перспективные направления развития 
индустрии. Регулярно в конкурсе принимают участие ведущие компании, 
университеты и лаборатории со всего мира. В~2010~г.\ в конкурсе участвовало 
46~научных команд.
  
  Первой особенностью оценивания \textit{NIST SRE 2010} являлось 
использование баз речевых данных, собранных по различным каналам связи и в 
акустике помещений, а потому характеризующихся широким диапазоном 
значений отношения сиг\-нал--шум и уровня реверберации (рис.~1). Точка на 
скаттерограмме обозначает присутствие в речевом корпусе фонограммы с 
определенным соотношением сигнал/шум (ОСШ) и временем реверберации.

  \begin{figure*} %fig1
   \vspace*{1pt}
 \begin{center}
 \mbox{%
 \epsfxsize=150.382mm
 \epsfbox{bel-1.eps}
 }
 \end{center}
 \vspace*{-9pt}
  \Caption{Скаттерограмма корпусов речевых данных {NIST} различных годов: 
сравнительная характеристика параметров речевых данных телефонного корпуса {SRE} 
2010~г.~(\textit{1}) и в акустике помещений SRE 2005--2010~гг.~(\textit{2})}
  \end{figure*}

  Второй особенностью \textit{NIST SRE 2010} в сравнении с предыдущими 
конкурсами стало то, что организаторы задали новую функцию минимизации 
ошибки идентификации, суть которой состояла в крайне высокой стоимости 
ошибки ложного пропуска нецелевого диктора:

\noindent
  $$
\mathrm{DCF = FR + 999 FA}\,,
$$
где FR (false rejection error rate)~--- вероятность \mbox{ошибки} ложного отклонения;
FA (false acceptance error rate)~--- вероятность ошибки ложного про\-пуска.

  Введение новых значений весов параметров потребовало значительных 
объемов данных для калиб\-ров\-ки порога принятия решения системы 
идентификации в связи с тем, что число попыток\linebreak\vspace*{-12pt}
\pagebreak

\noindent идентификации нецелевого 
диктора должно быть достаточно большим для статистически устойчивой оценки 
DCF. 
  
  Точность калибровки особенно важна при применении голосовой 
идентификации в реальных условиях и зачастую играет критическую роль, так как 
позволяет максимально точно адаптироваться под прикладные задачи.
  
  В данной работе описывается система, которая показала один из лучших 
результатов по качеству идентификации, в том числе заняла первое место по 
уровню калибровки среди коммерческих систем.
  
\section{Методы идентификации диктора}

  Принцип работы системы идентификации диктора основан на выделении речи 
из фонограмм и последующем попарном сравнении биометрических признаков 
(содержащихся в голосе индивидуальных, идентификационно значимых 
признаков личности). 
  
  Выделение и сравнение биометрических признаков производится с 
использованием различных язы\-ко- и текстонезависимых методов идентификации 
дикторов по голосу. Система распознавания диктора называется 
текстонезависимой, если она не содержит информации о том, что именно диктор 
будет произносить (система обучается и тестируется на произвольных речевых 
данных).
  
  На данный момент наиболее распространенным подходом к решению задач 
текстонезависимой идентификации является подход на основе использования 
моделей гауссовых смесей (\textit{Gaussian mixture models}, GMM)~[1]. 
В~качестве речевых признаков в подавляющем большинстве систем 
идентификации используются мэл-час\-тот\-ные кепстральные коэффициенты 
(mel-frequency cepstral coefficients, MFCC)~[2]. 
  
  В текстонезависимых приложениях идентификации диктора наибольшую 
надежность показывают GMM-сис\-те\-мы, основанные на использовании 
совместного факторного анализа (\textit{joint factor analysis}, JFA), предложенного и 
исследованного в работах~[3--5].
  
  В этих системах решение идентификации диктора основано на использовании 
отношения правдоподобия. Модели дикторов вычисляются или с по\-мощью 
классической MAP-адап\-та\-ции~[6]\linebreak GMM-мо\-де\-ли от 
UBM-мо\-де\-ли (\textit{universal background model}), или с использованием более 
мощных методов создания каналонезависимых моделей дик\-то\-ра~\cite{3b, 4b}.
{ %\looseness=1

}
  
  Очень перспективным для идентификации дикторов является метод опорных 
векторов (\textit{support vector machine}, SVM)~[7]. Метод SVM дискриминантный, 
в отличие от порождающего метода~GMM. 
  
  Современное развитие данного направления показало, что вариант гибридной 
системы GMM--SVM, где SVM действует не в пространстве акус\-ти\-че\-ских 
векторов, а в модельном пространстве супервекторов средних GMM, 
оказывается самым эффективным для задачи идентификации диктора. 
О~супервекторе средних GMM можно говорить как об отображении 
совокупности векторов MFCC произнесения диктора $O\hm=\{\vec{o}_1,\ldots , 
\vec{o}_t, \ldots ,\vec{o}_T\}$ в высокоразмерный вектор~$\vec\mu$.
  
  В данной работе для GMM-под\-сис\-те\-мы представляется редуцированная 
версия JFA (без собственных голосов~\cite{3b}), а именно: ML (\textit{maximum 
likelihood}) модификация~\cite{9b} версии метода Фогта~\cite{4b} (для 
краткости ML\_Vogt). 
  
  Как и в работе~\cite{9b}, будем исходить из сле\-ду\-юще\-го представления 
супервектора средних для $h$-й сессии $s$-го диктора:
  \begin{align*}
  \vec{\mu}(s) &=\vec{\mu}_0+\hat{D}\cdot \vec{z}(s)\,,\\
  \vec{\mu}(s,h) &= \vec{\mu}(s)+\hat{U}\cdot \vec{x}(s,h)\,.
%  \label{e1b}
  \end{align*}
  Здесь $\vec{\mu}_0$~--- супервектор средних дикторонезависимой 
UBM-мо\-де\-ли; $\vec{z}(s)$~--- вектор диктора (размерностью $MF$); 
$\vec{\mu}(s)$~--- супервектор сессионезависимой модели диктора~$s$; 
$\vec{x}(s,h)$~--- низкоразмерный вектор подпространства ка\-на\-лов-сес\-сий 
(размерностью~$R_x$), который находится методом MLED (\textit{maximum likelihood 
eigen-decomposition})~\cite{8b}. 
  
  Матрица собственных каналов $\hat{U}$ определяется методом MLES 
(\textit{maximum likelihood eigen-space})~\cite{8b}. Диагональная матрица~$\hat{D}$ 
(размерностью $MF\times MF$) находится из уравнения:
  $$
  \hat{I} = \tau \hat{D}^T\Sigma^{-1}\hat{D}\,,
  $$
где $\tau$~--- фактор релевантности в классической MAP-адап\-та\-ции; $M$~--- 
размерность GMM; $F$~--- размерность MFCC-век\-тора. 
  
  Метод~\cite{9b}, как и метод Фогта~\cite{4b},  благодаря 
использованию информации в $\hat{U}$-мат\-ри\-це собственных каналов 
корпуса позволяет получать GMM-су\-пер\-век\-тор диктора, свободный от эффектов 
канала корпуса (и даже на одном эталоне диктора).
  
  Для SVM-подсистемы в данной работе используется 
  SVM-клас\-си\-фи\-ка\-тор, работающий в пространстве супервектора средних 
GMM двух классов~--- \textit{Target} (целевой диктор) и \textit{Imposter} (нецелевой диктор). 
В~терминах ядра SVM-клас\-си\-фи\-ка\-тор данных двух классов может быть 
построен согласно 
  \begin{equation}
  \Lambda = f_a(\vec{\mu}(b))=\sum\limits_{q=1}^Q \lambda_q y_q 
K(\vec{\mu}(b),\vec{\mu}_q(a))-w_0\,,
  \label{e2b}
  \end{equation}
где $\vec{\mu}_q$~--- GMM-супервекторы (это $Q$ опорных векторов, 
полученных при обучении SVM-мо\-де\-ли диктора~\textit{а}), $y_q$~--- 
целевые значения двух классов: $\{+1\}$ для класса \textit{Target} и $\{-1\}$ для класса 
\textit{Imposter} к заданному диктору. 
  
  Тогда $f(\vec{\mu}(b))$ дает расстояние (с учетом знака~$y_q$) от 
разделяющей гиперплоскости диктора~\textit{а}, определяемой набором 
$\{\vec{\mu}_q,\lambda_q,w_0\}$, до GMM-су\-пер\-век\-то\-ра спорной записи 
$\vec{\mu}(b)$. Здесь в~(1) используется линейное ядро, предложенное 
Кампбеллом~\cite{10b}:
  \begin{multline*}
  K(\vec{\mu}(b)\vec{\mu}(a))={}\\
  {}=\sum\limits_{m=1}^M \left( \sqrt{a_m}\,
  \hat{\Sigma}_m^{-1} \cdot \vec{\mu}_m(b)\right) \left( 
\sqrt{a_m}\,\hat{\Sigma}_m^{-1}\vec{\mu}_m(a)\right)^{\mathrm{T}}\,.
%  \label{e3b}
  \end{multline*}
  %  
  Это линейное ядро основано на верхней границе дивергенции 
  Куль\-ба\-ка--Лейб\-не\-ра между двумя GMM. Выбор простого линейного 
ядра оправдан высокой размерностью GMM-су\-пер\-век\-то\-ра (порядка 
40\,000).
  
  Таким образом, работа представленной системы начинается с генерации 
GMM-сис\-те\-мой каналонезависимых супервекторов средних $\vec{\mu}$ 
для каждой\linebreak спорной и эталонной фонограммы. Далее на осно-\linebreak ве супервектора 
эталонной фонограммы (класс\linebreak
 целевого диктора) и аналогичных супервекторов 
класса базы независимых импостеров (их число порядка 1000--2000) для каждого 
целевого диктора строится SVM-мо\-дель~--- своя разделяющая 
SVM-ги\-пер\-плос\-кость. И,~наконец, в качестве ре\-зуль\-ти\-ру\-ющей оценки 
спорного произнесения рассчитывается SVM-дис\-тан\-ция~(2) между 
супервектором спорной фонограммы и SVM-ги\-пер\-плос\-костью целевого 
диктора.
  
  На основании таких оценок по всем парам сравнения на тестовой базе строится 
итоговый DET-гра\-фик, по которому можно сделать оценку мощности 
исследуемой системы идентификации.
  
  Значения равновероятной ошибки (\textit{equal error rate}, EER) принятия чужого и 
отбрасывания своего диктора для метода на основе MFCC--GMM зависят от 
длительности сравниваемых речевых фрагментов и могут достигать величины 
4\%--5\%.
  
  В настоящее время рассматриваемый метод является преобладающим в 
системах текстонезависимой идентификации диктора. Стоит отметить, что 
существуют и альтернативные методы, такие как спект\-раль\-но-фор\-мант\-ный 
(СФ)~\cite{11b} и метод идентификации на основе статистик основного тона 
(СОТ)~\cite{12b}. Однако только в случае коротких и сильно зашумленных 
фонограмм они обеспечивают точность, сопоставимую с методом 
MFCC--GMM--SVM. Сравнительные характеристики перечисленных 
методов приведены в табл.~1 (число знаков <<$+$>> отражает степень 
зависимости метода от параметров сигнала).

\begin{figure*}[b] %fig2
   \vspace*{-2pt}
 \begin{center}
 \mbox{%
 \epsfxsize=159.086mm
 \epsfbox{bel-2.eps}
 }
 \end{center}
 \vspace*{-9pt}
\Caption{Структурная схема GMM--SVM--MFCC-сис\-те\-мы идентификации дикторов 
по голосу на открытом множестве}
\end{figure*}
  
\begin{table*}\small %tabl1 %\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{
\begin{center}
\Caption{Сравнительные характеристики методов идентификации дикторов}
\vspace*{2ex}

\tabcolsep=8pt
\begin{tabular}{|l|c|c|c|}
\hline
\multicolumn{1}{|c|}{\raisebox{-18pt}[0pt][0pt]{Метод}}&\multicolumn{3}{c|}{Параметры сигнала}\\
\cline{2-4}
&Длительность&Качество&\tabcolsep=0pt\begin{tabular}{c}Физическое\\
и эмоциональное\\ состояние диктора\end{tabular}\\
\hline
СФ&+++&++&+\\
СОТ&++&+&++++\\
MFCC--GMM--SVM&++&+&++\\
\hline
\end{tabular}
\end{center}
\vspace*{-4pt}
\end{table*}

\section{Описание системы}



\subsection{Структура системы} %3.1
  
  В системе автоматической идентификации личности по голосовым признакам в 
естественной \mbox{речи} осуществляется сравнение одной или нескольких записей 
(моделей) голоса неизвестного диктора с одной или несколькими записями 
(моделями) голоса известного диктора. В~результате такого сравнения 
определяется, насколько похож голос неизвестного диктора на голос известного 
и, следовательно, принадлежат ли записи речи одному человеку или разным 
людям.
  
  Если тестируемая фонограмма речи диктора может не принадлежать ни одному 
из кандидатов, то в систему дополнительно вводится модель <<самозванца>> (в 
настоящей системе это 1000--2000 супервекторов SVM-им\-пос\-те\-ров) и она 
называется системой идентификации дикторов на открытом множестве. Схема 
такой системы представлена на рис.~2.
  

  
  Как уже было сказано ранее, для каждого целевого диктора строится 
SVM-мо\-дель~--- своя разделяющая SVM-ги\-пер\-плос\-кость. Для 
каждого дик\-то\-ра-кан\-ди\-да\-та проводится сравнение речевого сигнала с 
SVM-мо\-делью голоса данного диктора и получается оценка сравнения в 
виде SVM-дис\-тан\-ции между супервектором спорной фонограммы и 
  SVM-ги\-пер\-плос\-костью целевого диктора. Если полученная оценка 
оказывается выше порога принятия решения, то спорная фонограмма кандидата 
приписывается целевому диктору. Если иначе, то заявленный кандидат 
признается самозванцем.

\vspace*{-6pt}

\subsection{Описание системы} %3.2
  
  Представленная на конкурс \textit{NIST SRE 2010} сис\-те\-ма состояла из 
6~различных гендеро- и каналозависимых подсистем. Подсистемы 
адаптировались под различные каналы получения фонограмм:\\[-15pt]
  \begin{itemize}
\item телефонные;\\[-15pt]
\item микрофонные;\\[-15pt]
\item смешанные (телефон--мик\-ро\-фон).\\[-15pt]
\end{itemize}

  Кроме того, в рамках одного канала производилось дополнительное деление 
подсистем на две гендерозависимые (для женских и мужских голосов) 
подсистемы. 
  
  В качест\-ве обучающих данных \mbox{были} взяты ре\-че\-вые базы {NIST SRE} 
прошлых лет (2004, 2006 и 2008~гг.)\ общим объемом более 20~тыс.\ фонограмм.
  
  Для повышения надежности системы в каче\-ст\-ве дополнительных речевых 
признаков \mbox{были} использованы ли\-ней\-но-час\-тот\-ные кепстральные 
коэффициенты (\textit{linear-frequency cepstral coefficients}, LFCC)~\cite{2b}, что 
обеспечило повышение качества идентификации в микрофонном канале. 
 \begin{figure*} %fig3
     \vspace*{1pt}
 \begin{center}
 \mbox{%
 \epsfxsize=134.412mm
 \epsfbox{bel-3.eps}
 }
 \end{center}
 \vspace*{-9pt}
  \Caption{Структура системы идентификации диктора ООО <<Центр речевых 
технологий>>}
  \end{figure*}

  
  Результирующее решение (\textit{decision}) по обоим признакам (MFCC и LFCC) 
получалось путем вычисления <<обобщенного решения>> (\textit{fusion}), получаемого 
методом взвешенного голосования, когда результату работы каждой подсистемы 
присваивается некоторый вес (рис.~3). Для определения этих весов на этапе 
обучения системы использовался инструментарий собственной разработки. 
Обучение и точная калибровка системы производилась на речевой базе 
{NIST SRE 2005}.
  

GMM-супервекторы дикторов обучались методом максимального 
правдоподобия ML\_Vogt~\cite{9b} с использованием компенсации канальных 
искажений. Размерность пространства собственных каналов для разных 
подсистем варьировалось от~50 до~80. В~качестве классификатора использовался 
SVM с классической $zt$-нор\-ма\-ли\-за\-ци\-ей~\cite{4b}, которая 
представляла собой нормирование выходной дистанции SVM по случайным 
произнесениям дикторов из речевой базы объемом 1000--2000~фонограмм.

\vspace*{-6pt}
  
\section{Смешивание подсистем и~систем}

\subsection{Основные характеристики систем и~подсистем} %4.1

  На конкурс \textit{NIST SRE 2010} были предоставлены три системы 
(SVID-1, SVID-2 и SVID-3), которые отличались корпусами 
речевых данных, ис\-поль\-зу\-емых для обучения и настройки систем.
  
  \subsubsection{Primary system (SVID-1)}
  
  Базовая (\textit{primary}) система являлась комбинацией двух подсистем, каждая из 
которых строилась на отдельных наборах речевых признаков:
  \begin{enumerate}[(1)]
  \item
  первая подсистема~--- на базе 39-мер\-ных векторов признаков, составленных из 
13~MFCC-ко\-эф\-фи\-ци\-ен\-тов, дополненных их первыми и вторыми 
производными. Для каждого из векторов применялась процедура вычитания 
кепстрального среднего (CMS);
  \item
  вторая подсистема~--- на базе 39-мер\-ных векторов признаков, составленных 
из 13~LFCC-ко\-эф\-фи\-ци\-ен\-тов, дополненных их первыми и вторыми 
производными. Для каждого из векторов применялась процедура вычитания 
кепстрального среднего (CMS).
\end{enumerate}

\begin{table*}\small %tabl2
\begin{center}
\Caption{Характеристики базы обучения}
\vspace*{2ex}

\begin{tabular}{|l|l|c|l|c|}
\hline
&\multicolumn{4}{c|}{Общее 
количество}\\
\cline{2-5}
\multicolumn{1}{|c|}{Каналы}&\multicolumn{2}{c|}{Дикторов} & \multicolumn{2}{c|}{Фонограмм}\\
\cline{2-5}
&\multicolumn{1}{c|}{Мужской пол} & \multicolumn{1}{c|}{Женский пол}
&\multicolumn{1}{c|}{Мужской пол} & \multicolumn{1}{c|}{Женский пол}\\
\hline
Телефон--телефон&788 & 6546& 1042& 8589\\
Микрофон--микрофон& 158 & 1516& \hphantom{9}203& 1955\\
Телефон--микрофон& 280 (153~тел\;+\;158~мик) & 2290 &
\hphantom{9}371 (201~тел\;+\;203~мик) &3050\\
\hline
\end{tabular}
\end{center}
\end{table*}
  
  Каждая из подсистем, в свою очередь, имела 6~ген\-де\-ро- и каналозависимых 
UBM. При обучении UBM использовались 1024-ком\-по\-нент\-ные гауссовы 
смеси. База обучения UBM состояла из речевых корпусов Switchboard~II Phases 
2~\&~3, Switchboard Cellular Parts 1~\&~2, NIST~SRE 2004, 2006 и 2008, из\linebreak\vspace*{-12pt}

\setcounter{table}{3}
\begin{table*}[b]\small %tabl4
\vspace*{-12pt}
\begin{center}
\Caption{Характеристики систем идентификации дикторов на различных корпусах}
\vspace*{2ex}

\begin{tabular}{|l|c|c|} 
\hline
\multicolumn{1}{|c|}{\raisebox{-12pt}[0pt][0pt]{Каналы}}&\multicolumn{2}{c|}{EER, \%}\\
\cline{2-3}
&\tabcolsep=0pt\begin{tabular}{c}Система\\ до конкурса
\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}Система\\ после конкурса\end{tabular}\\
\hline
Микрофон--микрофон (различные микрофоны)&&6,0\\
\cline{1-1}
\cline{3-3}
Микрофон--телефон (различные телефонные каналы)&15--18&4,9\\\cline{1-1}
\cline{3-3}
Телефон--телефон (различные телефонные трубки и каналы)&&5,0\\
\hline
\end{tabular}
\end{center}
\end{table*}

\pagebreak


\noindent
%\begin{table*}
{\small %tabl3
\begin{center}
{{\tablename~3}\ \ \small{Характеристики базы импостеров}}
\vspace*{2ex}

\tabcolsep=5.8pt
\begin{tabular}{|l|c|c|}
\hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Каналы}}&\multicolumn{2}{c|}{\tabcolsep=0pt\begin{tabular}{c}Общее
количество\\ дикторов\end{tabular}}\\
\cline{2-3}
& Мужской пол & Женский пол\\
\hline
Телефон&1070& 1227\\
Микрофон&1450 & 2236\\
Телефон--микрофон &1000&1000\\
\hline
\end{tabular}
\end{center}}
%\end{table*}

\vspace*{12pt}

%\addtocounter{table}{1}



\noindent 
которых отбирались фонограммы дикторов, име\-ющих по 5--10 сессий записи 
речи. Характеристики базы обучения представлены в табл.~2.



  Импостеры отбирались из РБД {NIST SRE 2006, 2008}. Характеристики 
базы импостеров пред\-став\-ле\-ны в табл.~3.
  


  Для сегментации дикторов использовалась информация из ASR (\textit{automatic 
speech recognition}) транскрипции, предоставленной~NIST.
  
  Для получения обобщенного по всем под\-сис\-темам результирующего решения 
использовался инструментарий собственной разработки для смешивания по 
критерию минимизации функции сто\-и\-мости~DCF.

\vspace*{-1pt}

\subsubsection{Secondary system (SVID-2)}
  
  Вторичная (\textit{secondary}) система отличается использованием на этапе обучения 
UBM речевой базы NIST SRE 2005 вместо NIST SRE 2008.

\vspace*{-1pt}
  
\subsubsection{Secondary system (SVID-3)}
  
  Еще одна вторичная (\textit{secondary}) система была сформирована путем 
комбинирования первичной (SVID-1) и вторичной (SVID-2) систем.
  
\subsection{Смешивание подсистем} %4.2
  
  Обобщенное решение по всем подсистемам было основано на методе 
взвешенного голосования:

\noindent
  $$
  d(x) =\sum\limits_{i=1}^S \alpha_i d_i(x)+\Theta\,,
  $$
  где $d_i(x)$~--- выходное значение $i$-й подсистемы; $\alpha_i$~--- весовой 
коэффициент для $i$-й подсистемы; $\Theta$~--- пороговое значение; $S$~--- 
чис\-ло подсистем.
  
  Калибровка общего решения производилась на речевой базе {NIST SRE 
2005}, которая не использовалась для обучения базовых 
GMM--SVM-под\-систем.
  
  В связи с тем, что оценка DCF при высокой стоимости ошибки ложного 
пропуска не является статистически устойчивой, оптимизация 
коэффициентов~$\alpha_i$ производилась простейшим методом перебора. При 
этом в качестве функции минимизации ошибки использовалась непосредственно 
функция~DCF.

\vspace*{-6pt}

\section{Результаты}
  
  В табл.~4 и~5 приведены характеристики сис\-тем идентификации дикторов 
ООО <<Центр речевых технологий>> до конкурса и представленной на конкурс 
\textit{NIST SRE 2010}. 


  
  Как следует из приведенных данных, было обеспечено:\\[-14pt]
  \begin{itemize}
\item повышение точности идентификации (снижение EER) в 3--4 раза;\\[-14pt]
\item улучшение робастности идентификации в различных условиях (шумы, 
реверберация);
\end{itemize}

\end{multicols}

\begin{table*}\small %tabl5
\begin{center}
\parbox{357pt}{\Caption{Характеристики систем идентификации дикторов на смешанном корпусе 
мик\-ро\-фон--GSM-ка\-нал (EER, \%)}

}


\vspace*{2ex}

\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{Система до конкурса}&\multicolumn{4}{c|}{Система после конкурса}\\
\hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{\tabcolsep=0pt\begin{tabular}{c}Длительность\\ чистой речи\\ целевого диктора,\\ с\end{tabular}}}&
\multicolumn{3}{c|}{\tabcolsep=0pt\begin{tabular}{c}Длительность\\ чистой
речи\\ диктора-кандидата,\\ с\end{tabular}}& 
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{\tabcolsep=0pt\begin{tabular}{c}Длительность\\ чистой речи\\ целевого диктора,\\ с\end{tabular}}}&
\multicolumn{3}{c|}{\tabcolsep=0pt\begin{tabular}{c}Длительность\\ чистой
речи\\ диктора-кандидата,\\ с\end{tabular}}\\
\cline{2-4}
\cline{6-8}
& 16 & 32& 80 &&17&29&77\\
\hline
16&15,2&14,0&14,0&17&8,0&6,3&3,8\\
32&&12,9&11,4&29&&4,5&2,7\\
80&&&8,9&77&&&1,3\\
\hline
\end{tabular}
\end{center}
%\end{table*}
%\renewcommand{\figurename}{\protect\bf Рис.}
\renewcommand{\tablename}{\protect\bf Рис.}
\setcounter{table}{3}
%  \begin{figure*}[b] %fig4
   \vspace*{6pt}
 \begin{center}
 \mbox{%
 \epsfxsize=144.719mm
 \epsfbox{bel-4.eps}
 }
 \end{center}
 \vspace*{-9pt}
  \Caption{Среднее отношение фактической стоимости системы (определяется
  участником) к минимальным затратам (определяется NIST)~(\textit{1})
   и средняя фактическая стоимость системы~(\textit{2})
   }
   \vspace*{6pt}
  \end{table*}
  
  \renewcommand{\figurename}{\protect\bf Рис.}
\renewcommand{\tablename}{\protect\bf Таблица}

\begin{multicols}{2}

\noindent
\begin{itemize}
\item сохранение достигнутых параметров точности и робастности при 
кросс-ка\-наль\-ных сравнениях.
\end{itemize}


  Исходя из официально предоставленных {NIST} материалов (рис.~4), 
система идентификации дикторов ООО <<Центр речевых технологий>> заняла на 
конкурсе \textit{NIST SRE 2010}:
  \begin{itemize}
\item 2-е место по уровню калибровки (1-е место среди коммерческих 
компаний);
\item 7-е место по фактической стоимости (\textit{actual cost}) технологии~--- 
официальной метрике {NIST} (2-е место среди коммерческих компаний).
\end{itemize}

%\vspace*{-6pt}
  
\section{Заключение}

  В рамках подготовки к конкурсу \textit{NIST SRE 2010} была произведена 
модернизация системы идентификации дикторов ООО <<Центр речевых 
технологий>>, что обеспечило значительное повышение точности идентификации 
(снижение EER)~--- в 3--4~раза, повышение робастности идентификации в различных 
условиях (шумы, реверберация) и повышение скорости системы при построении 
голосовых моделей по фонограмме.
  
  В настоящее время предложенный в рамках \textit{NIST SRE 2010} подход к 
идентификации дикторов используется в системе ведения и автоматизации 
национального фоноучета Мексики.

%\vspace*{-6pt}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{99}
  
  \bibitem{1b}
  \Au{Bimbot F., Bonastre~J.-F., Fredouille~C., \textit{et al}.}
  A tutorial on text-independent speaker verification~// EURASIP J.~Appl. Signal 
Processing, 2004. No.\,4. P.~430--451.
  
  \bibitem{2b}
  \Au{Reynolds~D.} Experimental evaluation of features for robust speaker 
identification~// IEEE Trans. Speech Audio Processing, 1994. Vol.~2. 
No.\,4. P.~639--643.

\bibitem{5b} %3
\Au{Burget L., Matejka P., Glembek~O., \textit{et al}.}
 Analysis of feature extraction and channel compensation in GMM speaker recognition 
system~// IEEE Trans. Audio Speech Language Processing, 2007. Vol.~15. 
Iss.~7. P.~1979--1986.
  
  \bibitem{3b} %4
  \Au{Kenny P., Ouellet P., Dehak~N., \textit{et al}.}
  A~study of inter-speaker variability in speaker verification~// IEEE Trans. 
Audio Speech Language Processing, 2008. Vol.~16. Iss.~5. P.~980--988.
  
  \bibitem{4b} %5
  \Au{Vogt R., Sridharan S.} Explicit modelling of session variability for speaker 
verification~// Computer Speech Language, 2008. Vol.~22 (I). P.~17--38. 


\bibitem{6b}
\Au{Reynolds D.\,A., Quatieri T.\,F., Dunn R.\,B.}
Speaker verification using adapted Gaussian mixture models~// Digital Signal 
Processing, 2000. No.\,10. P.~19--41.
  
  \bibitem{7b}
  \Au{Vapnik V.} The nature of statistical learning theory.~--- Springer, 1995.
  
 
  \bibitem{9b} %8
  \Au{Pekhovsky T., Oparin I.}
  Maximum likelihood estimations in the session-independent modelling of the 
speaker~// Speech and Computer (SpeCom'09):  XIII 
Conference (International) Proceedings.~--- St.-Petersburg, 2009. P.~267--270.

  \bibitem{8b} %9
  \Au{Pekhovsky T., Oparin I.} Eigen channel method for text-independent Russian 
speaker verification~// Speech and Computer (SpeCom'08): XII 
 Conference (International) Proceedings.~--- Moscow, 2008. P.~385--390.
  
  \bibitem{10b}
  \Au{Campbell W., Sturim D., Reynolds~D.} Support vector machines using GMM 
supervectors for speaker verification~// IEEE Signal Processing Lett., 2006. Vol.~13. 
No.\,5. P.~308--311.

  \bibitem{11b}
  \Au{Коваль С.\,Л., Лабутин П.\,В., Раев А.\,Н.}
  Метод распознавания диктора и устройство для его осуществления. Патент РФ 
2230375 от 10.06.2004.

\label{end\stat}
  
  \bibitem{12b}
  \Au{Коваль С.\,Л., Лабутин П.\,В., Малая Е.\,В., Прощина~Е.\,А.} 
Идентификация дикторов на основе сравнения статистик основного тона голоса~// 
Информатизация и информационная безопасность правоохранительных органов: 
Мат-лы XV Междунар. научн. конф.~--- М.: Академия управления МВД России, 
2006. С.~324--327. 
 \end{thebibliography}
}
}


\end{multicols}       