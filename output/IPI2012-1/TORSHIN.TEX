\def\stat{torshin}

\def\tit{АНАЛИЗ ИНФОРМАТИВНОСТИ МОТИВОВ НА~ОСНОВЕ КРИТЕРИЯ
РАЗРЕШИМОСТИ В~ЗАДАЧЕ РАСПОЗНАВАНИЯ ВТОРИЧНОЙ
СТРУКТУРЫ БЕЛКА$^*$}

\def\titkol{Анализ информативности мотивов на~основе критерия
разрешимости в~задаче распознавания %вторичной
структуры белка}

\def\autkol{К.\,В.~Рудаков, И.\,Ю.~Торшин}
\def\aut{К.\,В.~Рудаков$^1$, И.\,Ю.~Торшин$^2$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
{Работа выполнена при поддержке РФФИ (гранты 09-07-12098, 09-07-00212-а и
09-07-00211-а) и Минобрнауки РФ (контракт №\,07.514.11.4001).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Вычислительный центр Российской академии наук им.~А.\,А.~Дородницына; Московский
фи\-зи\-ко-тех\-ни\-че\-ский институт, rudakov@ccas.ru}
\footnotetext[2]{Московский физико-технический институт; Центр систем прогнозирования и
распознавания (ЦСПР), tiy135@yahoo.com}


\Abst{Представлено развитие формального описания задачи
распознавания вторичной структуры белка. Вводятся ключевые понятия (мотив, оценка
информативности мотива, порядок на мотивах), позволяющие использовать
разрабатываемый формализм для анализа реально существующих множеств прецедентов.
Приведены результаты экспериментов по тестированию разрешимости задачи. Показано,
что анализ разрешимости позволяет проводить эффективный отбор наиболее
информативных мотивов.}

\KW{алгебраический подход; биоинформатика; локальность; разрешимость; теория
классификации значений признаков}


 \vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}

\section{Введение}

Распознавание вторичной структуры белка на основе его первичной
структуры (аминокислотной последовательности)~--- одна из важнейших
задач современной теоретической биологии~[1--3]. Актуальность задачи
обусловлена значительным объемом данных по первичной структуре белка
(миллионы аминокислотных последовательностей) и в сотни раз меньшим
количеством экспериментальных данных по третичной и, следовательно,
вторичной структуре белка. Это позволяет рассматривать накопленный
материал о третичном и вторичном уровнях структуры белка как обучающую
выборку для задачи распознавания вторичной структуры белка по его
первичной структуре. В~рамках настоящего исследования данная задача
рассматривается как перевод последовательности символов из одного
алфавита в другой~\cite{3-t} (рис.~\ref{f1-t}).

\begin{figure*} %fig1
\vspace*{1pt}
 \begin{center}
 \mbox{%
 \epsfxsize=163.944mm
 \epsfbox{tor-1.eps}
 }
 \end{center}
 \vspace*{-9pt}
\Caption{Задача распознавания вторичной структуры белка
\label{f1-t}}
\end{figure*}

Данная статья является продолжением работы~\cite{3-t}, где были подробно
рассмотрены мотивация и постановка проблемы. Приведем краткое введение
в проблемную область.

Клетка~--- мельчайшая структурная единица организма, а белки~--- активные
молекулярные образования, поддерживающие жизнь клетки. В~современной
биологии любой белок рассматривается с нескольких точек зрения: (1)~как
одномерная аминокислотная последовательность (так на\-зы\-ва\-емая <<первичная
структура белка>>, 1D); (2)~как одномерная последовательность характерных
локальных конфигураций (<<вторичная структура>>, 2D); (3)~как
трехмерный объект (<<третичная структура>>, <<пространственная
структура>>, 3D) и (4)~как особый механизм, выполняющий определенную
роль в функционировании клетки~\cite{1-t}. Одной из основных задач
биоинформатики считается установление закономерностей, определяющих
взаимосвязь первичной, вторичной и третичной структур.

Следует отметить, что имеющиеся данные о первичном, вторичном и
третичном уровнях описания структуры белка получены на основании
суще\-ст\-венно различных экспериментов. 

Первичная структура
(последовательность символов в 20-бук\-вен\-ном алфавите) \mbox{устанавливается}
посредством <<секвенирования>> (\textit{досл.}\ <<уста\-нов\-ления
по\-сле\-до\-ва\-тель\-ности>>)~--- процедуры после\-довательной химической
деградации молекулы\linebreak белка. Вторичная структура (последовательность %\linebreak
локальных конфигураций) и третичная структура (набор координат атомов)
устанавливаются\linebreak
 дифракционными методами (как правило,
рентгеноструктурным анализом) или посредством исследования
внут\-ри\-мо\-ле\-ку\-ляр\-но\-го спин-спи\-но\-во\-го расщепления с использованием
ЯМР (ядерного магнитного резонанса).

В то время как точность секвенирования определяется однозначно как
совпадение--не\-сов\-па\-де\-ние символов и достигает 100\%, в различных
экспериментах по определению структуры одного и того же белка
устанавливаются отличающиеся друг от друга наборы координат атомов
молекул этого белка. Эти отличия зависят от многочисленных условий
проведения структурного эксперимента: выбора метода (дифракция, ЯМР),
температуры, кислотности среды (pH), качества кристалла (в случае
дифракционного метода), присутствия других молекул и~др.

Экспертный анализ третичных структур белков указал на существование
ряда характерных пространственных конфигураций локальных участков
молекулы белка: <<спиралей>>, <<стрэндов>> и <<петель>>.
Последовательности этих пространственных конфигураций были названы
<<вторичной структурой белка>>. Вторичная структура как
последовательность символов некоего алфавита (различные способы
определения этого алфавита рассмотрены далее)~--- результат интерпретации
набора координат атомов молекулы белка. Так как координаты атомов и
межатомные расстояния подвержены вариациям вследствие упомянутых
выше особенностей структурного эксперимента, то и вторичная структура
как последовательность символов также подвержена вариациям. Это
обуславливает противоречивость имеющихся выборок экспериментальных
данных (в соответствии с данными из PDB, \textit{Protein Data
Bank}~\cite{4-t}) и приводит к необходимости формирования
непротиворечивых множеств прецедентов.

Применение современных физических методов для исследования структуры
и свойств белковых молекул позволяет предположить \textit{локальный
характер зависимости вторичной структуры от первичной}. Гипотеза о
локальности подразумевает, что вторичная структура в данной позиции
последовательности определяется не всей аминокислотной
последовательностью, а некой окрестностью данной позиции (локальным
контекстом).

     Таким образом, противоречивость экспериментальных данных,
обусловленная изменениями структуры белка в различных условиях и
особенностями структурного эксперимента, и необходимость
систематического исследования гипотезы о локальном характере
взаимосвязи между первичной и вторичной структурой указали на
целесообразность разработки специализированного формализма для
корректной постановки изучаемой проблемы. В~работах~\cite{2-t, 3-t} было
предложено точное описание данной задачи распознавания и рассмотрена ее
разрешимость, регулярность и локальность. Введение ключевых понятий для
анализа локальности (окрестность, маска, система масок, монотонность и
тупиковость систем масок) позволило предложить метод построения
безызбыточных систем масок.

Одним из основных результатов работ~\cite{2-t, 3-t} является формулировка
критериев разрешимости задачи распознавания вторичной структуры.
В~настоящей статье представлено дальнейшее развитие формализма и
результаты вычислительных экспериментов по тестированию разрешимости.
Осуществляется переход к разрешимости на мотивах; для сокращения
полного перебора при комбинаторном тестировании условия разрешимости
вводится понятие информативности мотива. На основе информативности
предлагается метод формирования непротиворечивых множеств
прецедентов. Приведены результаты экспериментов для отбора множеств
информативных мотивов, которые являются основой для построения
корректных алгоритмов в рамках алгебраического подхода к распознаванию.
Эксперименты проводились на подвыборках общедоступных
экспериментальных данных по первичной, вторичной и третичной
структурам белков~\cite{4-t}.

\section{Критерий разрешимости на~объектах и~мегасловах}

В рамках разрабатываемого формализма используются два алфавита:
алфавит~\textbf{A} для описания первичной структуры белка (<<верхнего
слова>>) и алфавит~\textbf{B} для описания вторичной структуры (<<нижнего
слова>>). Пусть $\mathbf{A} \hm= \{a_1, a_2, \ldots , a_{n(\mathbf{A})}\}$,
$n(\mathbf{A})\hm=\vert \mathbf{A}\vert \hm> 0$ и $\mathbf{B} \hm= \{b_1, b_2, \ldots
, b_{n(\mathbf{B})}\}$, $n(\mathbf{B})\hm=\vert \mathbf{B} \hm> 0$. Алфавит~\textbf{A}
(однобуквенные обозначения аминокислот) обычно определяется как
$\mathbf{A} \hm= \{A, C, D, E, F, G, H, I, K, L, M, N, P, R, S, T, V,$\linebreak $ W, Y\}$.
Алфавит~$\mathbf{B}$ может быть определен разными способами~\cite{3-t}.
Для целей настоящей работы вполне приемлем трехбуквенный алфавит
$\mathbf{B} \hm= \{S, H, L\}$, описывающий три принципиально различных
вида последовательной организации пространственных структур белков:
<<стрэнды>> ($S$, англ.\ \textit{strand}), <<спирали>> ($H$, \textit{helix}), и
<<петли>> ($L$, \textit{loop}).

Произвольное слово в алфавите~$\mathbf{А}$ будем обозначать
$V=v_1v_2\ldots v_{n(V)}$, в алфавите~$\mathbf{В}$~--- $W\hm=w_1w_2\ldots
w_{n(W)}$, где $n(V)$ и $n(W)$~--- длины слов. Критерий локальной
разрешимости с использованием отдельных масок (выражение
(6$^{\prime\prime}$) в работе~\cite{3-t}) был сформулирован следующим
образом:
\begin{multline}
\forallb\limits_{\mathbf{Pr}} \left( V^1,W^1\right), \left(V^2,W^2\right) \forallb (i,j):\\
 \left(
\forallb_{k=1}^{|\mathbf{M}|}\hat{m}_k:\ \eta\left( i,\hat{m}_k,V^1\right) =\eta \left(
j,\hat{m}_k,V^2\right)\right) \Rightarrow{}\\
{}\Rightarrow w_i^1=w_j^2\,,\enskip
l(\mathbf{M})<i\leq \vert V^1\vert -r(\mathbf{M})\,,\\
l(\mathbf{M})<j\leq \vert V^2\vert -r(\mathbf{M})\,,\enskip
i\not=j\,,
\label{e1-t}
\end{multline}
где $\left(V^1,W^1\right)$ и $\left (V^2,W^2\right)$~--- произвольные элементы
\textit{множества прецедентов} \textbf{Pr}; $i$ и $j$~--- \textit{ведущие позиции}\linebreak в
прецедентах; $\mathbf{M}\hm =\{ \hat{m}_1,\hat{m}_2, \ldots , \hat{m}_{|\mathbf{M}|}\}$~---
\textit{множество (система) масок};
$\hat{m}_k=\{\mu_1^k, \mu_2^k,\ldots , \mu^k_{m(k)}\}$~--- $k$-я
\textit{маска} ($\mu_i^k\in Z$, $\mu_1^k<\mu_2^k<\ldots < \mu^k_{m(k)}$,
$k\hm=1, \ldots , \vert \mathbf{M}\vert$); $\mu_i^k$~--- $i$-я позиция $k$-й маски;\linebreak
$m(k)=\vert \hat{m}_k\vert$~--- \textit{размерность маски $\hat{m}_k$};
$\eta$~--- \textit{оператор выбора подслова}; $l(\mathbf{M})$ и $r(\mathbf{M})$~--- границы
для описания краевых эффектов, $l(\mathbf{M}) \hm=\max \left(-
\max\limits_{k=1,\vert \mathbf{M}\vert} \mu_1^k,0\right)$, $r(\mathbf{M}) \hm = \max \left(
\min\limits_{k=1,\vert \mathbf{M}\vert} \mu^k_{\vert m(k)\vert},0\right)$. В~дальнейшем
предполагается выполнение указанных в~(\ref{e1-t}) ограничений по $l(\mathbf{M})$
и $r(\mathbf{M})$ на значения~$i$ и~$j$. Будем также использовать обозначение
$[\hat{m}_k]$~--- \textit{протяженность} маски~$\hat{m}_k$:
$[\hat{m}_k]\hm= \mu^k_{m(k)}\hm-\mu_1^k\hm+1$.

Утверждение~(\ref{e1-t}) соответствует локальной форме задачи
распознавания вторичной структуры, т.\,е.\ существованию функции $f:\
\mathbf{A}^{\vert \hat{m}_\Sigma(\mathbf{M})\vert}\rightarrow \mathbf{B}$,
где $\hat{m}_\Sigma(\mathbf{M})$~---
\textit{объединенная маска}~\textbf{M}, $\hat{m}_\Sigma(\mathbf{M})\hm=\cupb\limits_{k=1}
^{\vert \mathbf{M}\vert} \hat{m}_k$~\cite{3-t}.

\textit{Элементарными объектами}~$q$ (в дальнейшем прос\-то объектами)
будем называть элементы множества $\mathbf{Q}=\mathbf{A}^{\vert \hat{m}_\Sigma(\mathbf{M})}\times
\mathbf{B}$. Множество объектов $\mathbf{Q}(\mathbf{Pr},\,\mathbf{M})\hm=
\{q_1, q_2, \ldots , q_N\}$, $N\hm=\vert
\mathbf{Q}(\mathbf{Pr}, \mathbf{M}\vert$ однозначно получается при переборе всех до\-пус\-ти\-мых
значений~$i$ в прецедентах, причем допустимость~$i$ определяется
упомянутыми выше $l(\mathbf{M})$ и $r(\mathbf{M})$. Иначе говоря, элементами
\textit{наблюдаемых множеств объектов} $\mathbf{Q}(\mathbf{Pr},\mathbf{M})$
являются пары $q_i^j
\hm=(\eta (i,\hat{m}_\Sigma(\mathbf{M}),V^j),w_i^j)$; каждая пара есть совокупность
подслова, выбранного по $\hat{m}_\Sigma(\mathbf{M})$ в $i$-й ведущей позиции
верхнего слова $(V^j=v_1^j v_2^j\ldots v^j_{n(V^j)})$ и $i$-й литеры
нижнего слова $(W^j=w_1^j w_2^j\ldots w^j_{n(W^j)})$ $j$-го прецедента.

В $i$-й позиции произвольного прецедента $(V, W)$ по системе масок~\textbf{M}
фактически считывается \textit{мегаслово} или \textit{вектор подслов}
$\vec{V}_i \hm=(V_1(i),V_2(i),\ldots , V_{\vert \mathbf{M}\vert} (i))$, где
$V_k(i)=\eta(i,\hat{m}_k,V)$. Мегаслово также может быть считано с нулевой
позиции произвольного объекта $q_j\in \mathbf{Q}(\mathbf{Pr},\mathbf{M})$,
$q_j\hm=(V_j,w_j)$, так что
$\vec{V}_j\hm=(V_{j,1}, V_{j,2}, \ldots , V_{j,\vert \mathbf{M}\vert})$, где
$V_{j,k}\hm= \eta(0,\hat{m}_k,V_j)$. Введение элементарных объектов и
мегаслов позволяет значительно упростить запись критерия разрешимости,
заменив в~(\ref{e1-t}) сравнение прецедентов сравнением объектов, а
сравнение подслов~--- сравнением мегаслов.

Назовем \textit{мотивами}~$\kappa$ элементы множества
$\mathbf{K}\hm=\{(\hat{m},V)\vert \hat{m} \in \mathbf{M}, n(V)\hm=\vert \hat{m}\vert\}$. Будем
говорить, что мотив $\kappa\hm=(\hat{m},V^\prime)$ \textit{присутствует в
объекте} $q\hm=(V,w)$, если $\eta (0,\hat{m},V)\hm = V^\prime$. Обозначим
принадлежность мотива объекту $q$ как $\kappa\in^* q$. Аналогично мотив
$\kappa \hm=(\hat{m},V)$ \textit{присутствует в мегаслове} $\vec{V}_i \hm=
(V_1(i), V_2(i), \ldots , V_{\vert \mathbf{M}\vert}(i))$, если для $k$-й маски
$\hat{m}\hm=\hat{m}_k$ и $V\hm=V_k(i)$. Вхождение мотива в мегаслово
обозначим $\kappa\in^* \vec{V}_i$. Для произвольной пары объектов~$q_1$
и~$q_2$ мотив~$\kappa$ назовем \textit{отличающим}, если $\kappa$
присутствует в одном из объектов и отсутствует во втором. Пусть $\mathbf{K}(\mathbf{Pr},
\mathbf{M})$~--- множество всех мотивов, присутствующих в словах из $\mathbf{Pr}$ при
данной системе масок~$\mathbf{M}$.

\medskip

\noindent
\textbf{Теорема 1.} \textit{Условие локальной разрещимости задачи
выполнено тогда и только тогда, когда для каждой пары объектов
$q_1\hm=(V_1,w_1)$ и $q_2\hm=(V_2,w_2)$ при $w_1\not=w_2$ существует
хотя бы один отличающий мотив.}

\medskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ Запишем критерий
разрешимости~(\ref{e1-t}) с использованием мегаслов:
\addtocounter{equation}{-1}
\renewcommand{\theequation}{\arabic{equation}$^\prime$}
\begin{multline*}
\forallb\limits_{\mathbf{Pr}} \left( V^1, W^1\right) , \left( V^2,W^2\right) \forallb(i,j):\\
\left( V_1^1(i),V_2^1(i), \ldots , V^1_{\vert \mathbf{M}\vert }(i)\right) ={}\\
{}= \left(
V_1^2(i),V_2^2(i),\ldots , V^2_{\vert \mathbf{M}\vert} (i)\right)\Rightarrow
w_i^1=w_j^2\,.
\end{multline*}
\renewcommand{\theequation}{\arabic{equation}}
\setcounter{equation}{1}

Заменяя перебор различных ведущих позиций по всем парам прецедентов на
перебор пар объектов из $\mathbf{Q}(\mathbf{Pr}, \mathbf{M})$, а сравнение мегаслов
пре\-це\-ден\-тов~--- на
сравнение мегаслов объектов, получим:

\noindent
\begin{multline}
\forallb\limits_{\mathbf{Q}(\mathbf{Pr},\mathbf{M})} (i,j):\
\left( V_{i,1}, V_{i,2},\ldots , V_{i,\vert
\mathbf{M}\vert}\right) ={}\\
{}= \left( V_{j,1},V_{j,2},\ldots , V_{j,\vert
\mathbf{M}\vert}\right)\Rightarrow w_i=w_j\,.
\label{e2-t}
\end{multline}

Будем считать, что $\mathbf{Q}(\mathbf{Pr}, \mathbf{M})$~--- непроти\-во\-речиво, т.\,е.\ для всех пар
объектов выполнено\linebreak
усло\-вие~(\ref{e2-t}). Применив логический оператор НЕ
и обозначив мегаслова $i$-го и $j$-го объектов как $\vec{V}_i\hm = \left(V_{i,1},
V_{i,2},\ldots , V_{i,\vert \mathbf{M}\vert}\right )$ и $\vec{V}_j\hm= \left(
V_{j,1},V_{j,2},\ldots , V_{j,\vert \mathbf{M}\vert}\right)$, получим обратную форму
утверждения~(\ref{e2-t}):
\addtocounter{equation}{-1}
\renewcommand{\theequation}{\arabic{equation}$^{\prime}$}
\begin{equation}
\forallb\limits_{\mathbf{Q}(\mathbf{Pr},\mathbf{M})} (i,j):\ w_i\not= w_j\Rightarrow \vec{V}_i\not=
\vec{V}_j\,.
\label{e2-1}
\end{equation}
\renewcommand{\theequation}{\arabic{equation}}
\setcounter{equation}{1}
Очевидно, что два мегаслова в выражении~(\ref{e2-1}) различны, если при
попарном сравнении подслов в соответствующих позициях мегаслов не
совпадает хотя бы одно из этих подслов, т.\,е.
\setcounter{equation}{1}
\renewcommand{\theequation}{\arabic{equation}$^{\prime\prime}$}
\begin{equation}
\forallb\limits_\mathbf{Q} (i,j):\ w_i\not=w_j\Rightarrow
\existsb\limits_{k=1}^{\vert \mathbf{M}\vert } k:\ V_{i,k}\not= V_{j,k}\,,
\label{e2-2}
\end{equation}
где $V_{j,k}=\eta(0,\hat{m}_k,V_j)$. Очевидно, что $k$-я позиция в $j$-м
мегаслове соответствует маске~$\hat{m}_k$ и подслову~$V_{j,k}$, т.\,е.\
некоторому мотиву $\kappa \hm=(\hat{m}_k,V_{j,k})$, $\kappa \in \mathbf{K}(\mathbf{Pr},\mathbf{M})$.
Таким образом, условие~(\ref{e2-2}) записывается как критерий
\textit{разрешимости на множестве мотивов}:
\renewcommand{\theequation}{\arabic{equation}}
\setcounter{equation}{2}
\begin{multline}
\forallb\limits_{\mathbf{Q}(\mathbf{Pr},\mathbf{M})} (i,j): w_i\not=w_j\Rightarrow\!
\existsb\limits_{\mathbf{K}(\mathbf{Pr},\mathbf{M})} \!\kappa:\
\left (\kappa\in^* \vec{V}_i\right)\not= {}\\
{}\not=
\left(\kappa\in^* \vec{V}_j\right)\,.
\label{e3-t}
\end{multline}

Выражение~(\ref{e3-t}) доказывает необходимость. Достаточность
доказывается от противного. Предположим, что~(\ref{e3-t}) не выполнено и
для определенной пары объектов~$q_1$, $q_2$ из $\mathbf{Q}(\mathbf{Pr}, \mathbf{M})$
при  $w_1\not= w_2$ не существует отличающего мотива. Тогда мегаслова для данной пары
объектов будут равны~(\ref{e2-2}) и в соответствии с~(\ref{e2-1}) одному и
тому же мегаслову будут соответствовать различные литеры нижнего слова.
Последнее противоречит критерию разрешимости~(\ref{e1-t}), (\ref{e2-t}).
Теорема доказана.
\medskip

Теорема~1 имеет принципиальное значение как для дальнейшего развития
разрабатываемого формализма, так и для его практических приложений.
Утверждение~(\ref{e3-t}) соответствует переходу от задачи
$\mathbf{Z}(\mathbf{Pr},\mathbf{M})$~\cite{3-t} к эквивалентной задаче
$\mathbf{Z}(\mathbf{Q}, \mathbf{K})$, в которой в качестве
параметров выступают множество объектов $\mathbf{Q}\hm = \mathbf{Q}(\mathbf{Pr}, \mathbf{M})$
и множество  мотивов $\mathbf{K} \hm= \mathbf{K}(\mathbf{Pr}, \mathbf{M})$.

Для практического применения разраба\-ты\-ва\-емо\-го формализма особый
интерес представляет поиск минимальных наборов мотивов, га\-ран\-ти\-ру\-ющих
разрешимость. Подобно тому, как в работе~\cite{3-t} анализировалась
монотонность условия разрешимости по системам масок и исследовалась
тупиковость систем масок, здесь рассматривается монотонность условия
разрешимости~(\ref{e3-t}) по отношению <<быть подмножеством>> на
множестве всех подмножеств множества мотивов.

\section{Монотонность условия разрешимости и~тупиковые
системы мотивов} %3

Разрешимость задачи $\mathbf{Z}(\mathbf{Q}, \mathbf{K})$ по~(\ref{e3-t}) зависит, естественно, от~$\mathbf{Q}$
и~$\mathbf{K}$. Множество объектов~$\mathbf{Q}$ \textit{непротиворечиво} при
определенной $\hat{m}_\Sigma(\mathbf{M})$, если $\mathbf{Q}$ удовлетворяет
условию~(2$^\prime$). Способы формирования непротиворечивых~$\mathbf{Q}$
будут рассмотрены отдельно. Ниже рассматриваются возможности
варь\-и\-ро\-ва\-ния множества мотивов~$\mathbf{K}$ при непротиворечивых множествах
объектов.

Варьирование~$\mathbf{K}$ сводится к добавлению или удалению отдельных
мотивов. Добавление мотивов к~$\mathbf{K}$ при постоянных $l(\mathbf{M})$ и $r(\mathbf{M})$ не
нарушает истинности~(\ref{e3-t}), т.\,е.\ \textit{условие}~(\ref{e3-t})
\textit{монотонно по~$\mathbf{K}$ при $\mathbf{K} \subseteq \mathbf{K}^\prime$}.

\textit{Монотонность} условия~(\ref{e3-t}) важна для нахождения
безызбыточных и тупиковых множеств мотивов. Действительно, множество
мотивов~$\mathbf{K}$, при котором условие~(\ref{e3-t}) выполнено на всех парах
объектов из~$\mathbf{Q}$, может быть избыточно в том смысле, что разрешимость
сохранится при удалении некоторых мотивов. Если условие~(\ref{e3-t})
выполнено для~$\mathbf{K}$, но не выполнено для любого $\mathbf{K}^\prime \subset \mathbf{K}$, то
такое множество мотивов назовем \textit{тупиковым}.

Для исследования монотонности условия разрешимости~(\ref{e1-t}) в
работе~\cite{3-t} были введены понятия 0-ту\-пи\-ко\-вости, тупиковости и
ядерности сис\-тем масок. Было показано, что любая тупиковая~$\mathbf{M}$ (потеря
разрешимости при удалении любой маски из~$\mathbf{M}$) является также
0-ту\-пи\-ко\-вой (изменение $\hat{m}_\Sigma(\mathbf{M})$ при удалении любой
маски) и ядерной (каж\-дая маска однозначно соответствует уникальной
позиции в $\hat{m}_\Sigma(\mathbf{M})$). Были сформулированы принципы
построения алгоритма поиска безызбыточных систем масок.

Важно отметить, что изучение монотонности условия разрешимости на
множествах мотивов~--- гораздо более <<тонкий>> исследовательский
инструмент. Действительно, удаление даже одной маски из системы
масок~$\mathbf{M}$ соответствует удалению всех мотивов, порожденных данной
маской. Пусть, например, $M_n^m$~--- сис\-те\-ма масок, образованная
всеми сочетаниями $m$~позиций из $n$ возможных в соответствующей
объединенной маске (т.\,е.\ $m$~--- размерность каждой маски~$M_n^m$, а
$n$~--- протяженность объединенной маски), так что $\vert M_n^m\vert
=C_n^m$. Удаление любой маски из~$\mathbf{M}$ повлечет за собой удаление всех
$\vert \mathbf{A}\vert^m$~мотивов, порожденных данной маской. В~практически
интересных случаях $m\hm=3$ или $m\hm=4$, $\vert \mathbf{A}\vert \hm=20$, так что
$\vert \mathbf{A}\vert^3\hm=8000$, $\vert \mathbf{A}\vert^4\hm=160\,000$. В~то же время
изучение монотонности критерия разрешимости~(\ref{e3-t}) на множествах
мотивов позволяет удалять отдельные мотивы.

Вообще говоря, определение тупиковых множеств мотивов~$\mathbf{K}$
безызбыточной системы масок~$\mathbf{M}$~--- задача, разрешимая полным
перебором. Однако полный перебор подмножеств множества из $C_n^m \vert
\mathbf{A}\vert^m$ мотивов не представляется возможным практически. Редукция
множества мотивов $\mathbf{K}(\mathbf{Pr}, \mathbf{M})$ и нахождение тупиковых множеств
мотивов~$\mathbf{K}$ может рассматриваться как частный случай выделения
информативных значений признаков в теории классификации значений
признаков~\cite{7-t, 8-t}. В~рамках этой тео\-рии значения признаков
объектов в задачах обучения по прецедентам рассматриваются как объекты
некоторой задачи классификации, в которой требуется выделить во
множестве всех значений всех исследуемых признаков подкласс
<<информативных>>.

\section{Эвристические оценки информативности мотивов} %4

При исследовании монотонности условия разрешимости возникает
очевидный вопрос: какие мотивы следует удалять, а какие~--- оставлять?
В~духе тео\-рии классификации значений признаков можно сказать, что
следует оставлять мотивы с <<высокой\linebreak
информативностью>> и удалять
мотивы с <<доста\-точ\-но низкой>> информативностью. При этом кри\-терий
разрешимости задачи распознавания~(\ref{e3-t}) \mbox{служит} усло\-ви\-ем,
предотвращающим удаление отличающих мотивов, обеспечивающих
разрешимость задачи. Редукцию множества $\mathbf{K}(\mathbf{Pr}, \mathbf{M})$ можно, в част\-ности,
проводить на базе эвристических оценок информативности.

\textit{Оценка информативности мотивов}~$D:\ \mathbf{K}\rightarrow
\mathbf{R}_+$ может быть введена различными способами так,\linebreak что\-бы
б$\acute{\mbox{о}}$льшая <<информативность>> мотива соотвествовала
б$\acute{\mbox{о}}$льшим значениям~$D$. Строгое
тео\-ре\-ти\-ко-мно\-же\-ст\-вен\-ное обоснование формы соответствующего
функционала является отдельным\linebreak направлением исследований и лежит за
рамками настоящей статьи. Здесь вводится несколько эвристических оценок
информативности мотивов, основанных на частоте их встречаемости в
различных классах объектов.

Пусть $\mathbf{K}(\mathbf{Pr}, \mathbf{M})$~--- множество мотивов для заданных~$\mathbf{Pr}$
и~$\mathbf{M}$, а $\mathbf{Q} \hm= \mathbf{Q}(\mathbf{Pr}, \mathbf{M})$~---
множество объектов. Каждый мотив $\kappa_\alpha\in  \mathbf{K}(\mathbf{Pr},
\mathbf{M})$ входит в состав $N_\Sigma^\alpha$ объектов из~$\mathbf{Q}$. При этом $N_\Sigma^\alpha
=\sum\limits_{l=1}^{m=\vert \mathbf{B}\vert} N_l^\alpha$, где $N_l^\alpha$ соответствует числу
объектов $q=(\vec{a},b)$, у которых $b=b_l$, $b_l\in B$, так что мотиву
$\kappa_a$ по\-став\-лен в соответствие вектор ($N_1^\alpha, N_2^\alpha, \ldots , N_m^\alpha,
N_\Sigma^\alpha$). \textit{Частота встречаемости} каждого значения $b_l\in \mathbf{B}$
определяется как $\nu_l^\alpha =N_l^\alpha/N_\Sigma^\alpha$, и, таким образом,
мотиву~$\kappa_\alpha$ оказывается сопоставлен вектор частот ($\nu_1^\alpha,
\nu_1^\alpha, \ldots , \nu_m^\alpha, N_\Sigma^\alpha$).

Пусть частоты встречаемости литер $b_l\hm\in \mathbf{B}$ во всем множестве объектов
$\mathbf{Q}$ составляют ($\nu_1^0,\nu_2^0,\ldots ,\nu_m^0$). Будем считать, что
<<информативность>> мотива~$\kappa_\alpha$ по данному~$b_l$ монотонна по
$\vert\nu_l^\alpha-\nu_l^0\vert$: т.\,е.\ чем сильнее отличается~$\nu_l^\alpha$ от
$\nu_l^0$~--- частоты~$b_l$ в среднем по~$\mathbf{Q}$, тем более информативен
мотив по литере~$b_l$. Тогда $D_l^\alpha$, оценку информативности $\alpha$-го мотива
по литере~$b_l$ (или по $l$-му классу вторичной структуры) естественно
определить как некоторую V-образную функцию с единственным
минимумом при $v_l^\alpha\hm= \nu_l^0$ и такую, что $D_l^\alpha\hm=1$ при
$v_l^\alpha\hm =1{,}0$ и~0. Этим требованиям удовлетворяет,
например, кусочно-линейная функция
\begin{equation*}
D_l^\alpha=
\begin{cases}
1-\fr{\nu_l^\alpha}{\nu_l^0} & \mbox{\ при\ }\nu_l^\alpha\leq \nu_l^0\,;\\
\fr{\nu_l^\alpha-v_l^0}{1-\nu_l^0} & \mbox{\ при\ }\nu_l^\alpha> \nu_l^0\,.\\
\end{cases}
%\label{e4-t}
\end{equation*}

Величина $D_l^\alpha$, т.\,е.\ информативность $a$-го мотива по литере~$b_l$,
указывает, насколько чаще данный мотив встречается в $l$-м классе
объектов, чем в других, или, иначе говоря, отражает распределение
вхождений мотива в объекты разных классов. Например, $D_l^\alpha \hm =1{,}0$
соответствует тому, что мотив встречается только среди объектов $l$-го
класса или ни разу не встречается в данном классе. Отметим, что важным
вариантом оценки~$D_l^\alpha$ является оценка
%\addtocounter{equation}{-1}
%\renewcommand{\theequation}{\arabic{equation}$^\prime$}
\begin{equation*}
D_l^\alpha =\begin{cases}
\nu_l^\alpha\leq \nu_l^0: & 0\,;\\
\nu_l^\alpha> \nu_l^0: & \fr{\nu_l^\alpha-\nu_l^0}{1-\nu_l^0}\,.
\end{cases}
\end{equation*}
%\renewcommand{\theequation}{\arabic{equation}}
%\setcounter{equation}{3}

Кроме сравнительных оценок распределения объектов между классами на
информативность мотива влияет частота его встречаемости среди объектов.
Иначе говоря, при фиксированном $D_l^\alpha$ более информативным будем
считать мотив с б$\acute{\mbox{о}}$льшим~$N_\Sigma^\alpha$. Используя введенные обозначения,
можно предложить, по меньшей мере, три способа общей оценки
информативности $\alpha$-го мотива:

\noindent
\begin{align*}
D_1(\alpha) &= \sum\limits_{l=1}^m D_l^\alpha\,;\\
D_2(\alpha) &= N_\Sigma^\alpha D_1(\alpha) = N_\Sigma^\alpha \sum\limits_{l=1}^m D_l^\alpha\,;\\
D(\alpha,D_0) &= \begin{cases}
N_\Sigma^\alpha & \mbox{\ при \ } D_1(\alpha)>D_0\,;\\
0 & \mbox{\ при \ } D_1(\alpha)\leq D_0\,.
\end{cases}
\end{align*}

Помимо сформулированных выше эвристических оценок информативности
мотива могут быть предложены и другие. Интуитивно ясно, что
<<информативный>> мотив должен выделять <<достаточно много>>
объектов $l$-го класса~$N_l^\alpha$ и <<достаточно мало>> объектов всех
остальных классов $N_\Sigma^\alpha-N_l^\alpha$~\cite{9-t}. В~работе~\cite{10-t}
приведено около 20~различных эвристических оценок информативности,
представляющих собой разного рода эвристические функции от пары
величин, аналогичных~$N_l^\alpha$ и $N_\Sigma^\alpha-N_l^\alpha$, таких как
энтропийный критерий <<информационного выигрыша>> (\textit{information
gain}), общеизвестные статистические критерии хи-квадрат, точный тест
Фишера и~др.~\cite{9-t, 10-t}.

Эвристические оценки информативности мотивов необходимы для
нахождения тупиковых множеств мотивов с учетом критерия разрешимости
задачи. Кроме того, оценки информативности также могут быть
использованы для формирования непротиворечивых множеств объектов.

\section{Информативность мотивов и~условие разрешимости} %5

Пусть $D$~--- эвристическая оценка информативности мотивов, $D:\
\mathbf{K}\rightarrow \mathbf{R_+}$. Функция~$D$ ставит в соответствие
каждому мотиву множества~$\mathbf{K}$ его информативность из определенного
подмножества~$\mathbf{R_+}$. Отношение порядка на $\mathbf{R_+}$
порождает линейный порядок на множестве мотивов~$\mathbf{K}$.

При наличии упорядоченного множества мотивов отбор наиболее
информативных может быть осуществлен (1)~как определение границы
информативности такой, что при удалении <<менее информативных>>
мотивов сохраняется разрешимость, или (2)~как отбор достаточного для
разрешимости количества <<наиболее информативных>> мотивов.

\textit{Определение скалярной границы и удаление <<менее
информативных>> мотивов} подразумевает введение некоторой системы
пороговых значений на информативность мотивов. Мотивы,
удовлетворяющие данным ограничениям, являются <<информативными>>.
В~простейшем случае ограничением является введение некоторого порога
$D_{\min}$ для значения используемой оценки информативности~$D$.
Порог $D_{\min}$ может быть вычислен с использованием итеративной процедуры с
фиксированным инкрементом или же методом дихотомии. На каждом шаге
истинность выражения~(\ref{e3-t}) вычисляется для текущего значения~$D$
до достижения сходимости.

Возможно использование нескольких функций оценок информативности
($D_1$, $N_\Sigma, D_2$ и~т.\,д.), и в качестве критериев отбора мотивов
будут выступать несколько пороговых значений. Для нахождения пороговых
значений могут быть использованы жадные алгоритмы или семейства
поверхностей, подобных поверхности Парето в
пространстве~$\mathbf{R}^n$, где $n$~--- число используемых
функций~$D$.

\textit{Отбор <<наиболее информативных>> мотивов}.
Введение линейного порядка на можестве мотивов позволяет использовать
данные об информативности мотивов при тестировании условия
разрешимости в форме~(\ref{e3-t}). Принцип отбора мотивов состоит в том,
что для каждой пары объектов из~$\mathbf{Q}$ находится различающий мотив с
наивысшей информативностью. Отобранные таким образом мотивы
образуют некоторое \textit{множество различающих мотивов}~$\mathbf{K}^0$
\textit{с наивысшей информативностью} такое, что
$\mathbf{K}^0\subseteq \mathbf{K}(\mathbf{Pr}, \mathbf{M})$.

\medskip

\noindent
\textbf{Теорема 2.} \textit{Множество~$\mathbf{K}^0$ является тупиковым тогда и
только тогда, когда для каждого мотива из~$\mathbf{K}^0$ в~$\mathbf{Q}$ существует хотя
бы одна пара объектов, для которой данный мотив~--- единственный
различающий.}

\medskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ Сначала докажем достаточность. Любые
два мотива $\kappa_\alpha\hm= (\hat{m}_\alpha,V_\alpha)$ и
$\kappa_\beta\hm=(\hat{m}_\beta,V_\beta)$ могут быть упорядочены в
соответствии со значениями $D(\alpha)$и $D(\beta)$. Перенумеруем все
элементы $\mathbf{K} = \mathbf{K}(\mathbf{Pr}, \mathbf{M})$ так, чтобы линейный порядок мотивов
соответствовал убыванию значений~$D$: $\kappa_1, \kappa_2, \kappa_3, \ldots
, \kappa_\alpha\ldots , \kappa_{\vert \mathbf{K}\vert}$, $D(\kappa_\alpha) \hm\geq
D(\kappa_{\alpha+1})$.

Пусть на исходном множестве мотивов~$\mathbf{K}$ выполнено условие
разрешимости~(\ref{e3-t}). Определим функцию $K_f (i, j)$, находящую
единственный мотив с максимальным~$D$ (и, следовательно, с
минимальным номером мотива~$\alpha$), который позволит различить $i$-й
и $j$-й объекты из~$\mathbf{Q}$:
%\setcounter{equation}{4}
\begin{equation}
K_f(i,j) =\min\limits_{1,\ldots , \vert \mathbf{K}\vert}\alpha:\  \left( \kappa_\alpha \in^*
V_i\right) \not= \left( \kappa_\alpha\in^* V_j\right)\,.
\label{e5-t}
\end{equation}
Тогда минимальное множество мотивов $\mathbf{K}^0$, на котором сохраняется
разрешимость, $\mathbf{K}^0\subseteq \mathbf{K}(\mathbf{Pr},\mathbf{M})$, определяется через
\textit{характеристическую функцию} $T(\alpha)$ следующим образом:
\begin{equation}
T(\alpha) =
\begin{cases}
1 \equiv \existsb\limits_\mathbf{Q} (i,j): \ (K_f(i,j)=\alpha)\,;\\
0 \ \ \mbox{в противном случае}\,.
\end{cases}
\label{e6-t}
\end{equation}

Для каждой пары из $i$-го и $j$-го объектов множества~$Q$ функция $K_f (i,
j)$ находит наиболее информативный раз\-ли\-ча\-ющий мотив. Для всех таких
мотивов $T(\alpha)\hm =1$, т.\,е.\ эти мотивы образуют~$\mathbf{K}^0$. После
вычисления~$T(\alpha)$ для всех пар объектов из~$\mathbf{Q}$ каждому $i$-му
объекту из~$\mathbf{Q}$ соответствует $n_i^{rm}$ раз\-ли\-ча\-ющих мотивов из~$\mathbf{K}^0$,
$n_i^{rm} \hm = \vert \{ T(\alpha)=1\}_i\vert$. Объекты с $n_i^{rm}\hm=0$
назовем <<0-\textit{объек\-та\-ми}>>, а с $n_i^{rm}\hm=1$~---
<<1-\textit{объек\-та\-ми}>>. Очевидно, что различающий мотив единствен только в
парах объектов, составленных из 0-объек\-та и 1-объек\-та (т.\,е.\
$n_i^{rm}+n_j^{rm}\hm=1$).

Теперь представим, что из $\mathbf{K}^0$ удаляется $k$-й мотив, найденный в
$N_\Sigma^k$ объектах. Если $n_i^{rm}\hm>1$ для всех $N_\Sigma^k$
объектов, то и $n_i^{rm}\hm+n_j^{rm}\hm>1$ и удаление мотива может и не
приводить к потере разрешимости. Когда же $n_i^{rm}\hm=1$ для одного из
$N_\Sigma^k$ объектов, то при сравнении этого объекта с произвольным
0-объек\-том другого класса $k$-й мотив будет единствен в этой паре
объектов и удаление этого мотива неизбежно приведет к потере
разрешимости. Множество $\mathbf{K}^0$ не может не быть тупиковым, когда последнее
утверждение справедливо для всех мотивов.

Необходимость доказывается от противного. Пусть $\mathbf{K}^0$~--- тупиковое
множество мотивов. Условием тупиковости~$\mathbf{K}^0$ является потеря
раз\-ре\-ши\-мости при удалении произвольного мотива. В~соответствии
с~(\ref{e3-t}) разрешимость теряется, когда при $W_i\not=W_j$ не
существует различающих мотивов, т.\,е.\ $n_i^{rm}\hm+n_j^{rm}\hm=0$.
Пусть произвольный $k$-й мотив из тупикового~$\mathbf{K}^0$ встречается в
$N_\Sigma^k$ объектах и для всех этих объектов $n_i^{rm}\hm>1$ (иными
словами, для $k$-го мотива не существует пары объектов, для которой
данный мотив~--- единственный различающий). Тогда при удалении $k$-го
мотива $n_i^{rm}\hm+n_j^{rm}\hm>0$, т.\,е.\ возможно удаление из~$\mathbf{K}^0$
произвольного мотива без потери разрешимости, и, следовательно, $\mathbf{K}^0$ не
является тупиковым. Теорема доказана.

\medskip

\noindent
\textbf{Следствие 1.}
\textit{В общем случае множество~$\mathbf{K}^0$ не является тупиковым}.
Множество $\mathbf{K}^0$,
вычисленное по выражению~(\ref{e6-t}), будет тупиковым только при
условии соответствия каждому мотиву, по крайней мере, одной пары
объектов с единственным различающим мотивом. Различающий мотив
единствен только в частном случае, когда пара объектов состоит из
0-объек\-та и 1-объек\-та различных классов. Построение~$\mathbf{K}^0$
по~(\ref{e6-t}) не гарантирует существования этого частного случая для
каждого мотива.

\medskip

\noindent
\textbf{Следствие 2.}
\textit{Тупиковое множество мотивов может быть найдено путем
итеративного удаления из $\mathbf{K}^0$ мотивов с наименьшей
информативностью}. Существование в~$\mathbf{Q}$ пар
<<0-объект\,--\,1-объект>> различных классов для произвольного
мотива~--- условие тупиковости~$\mathbf{K}^0$. Каждый $\alpha$-й мотив
встречается в $N_\Sigma^\alpha$ объектах, каждому из этих объектов
соответствует число найденных в нем различающих мотивов ($n_i^{rm}$ для
$i$-объек\-та). Мотивы, входящие в объекты с $n_i^{rm}\hm =1$, не могут
быть удалены из~$\mathbf{K}^0$ без потери разрешимости. В~то же время удаление
мотивов для всех объектов, у которых $n_i^{rm}\hm>1$, не нарушает
условия тупиковости. Так как целью является на\-хож\-де\-ние тупиковых
множеств мотивов с \textit{наибольшей информативностью}, то удаляться
должны мотивы с наименьшими~$D$.

\medskip

\noindent
\textbf{Следствие 3.}
\textit{Наличие всех 0-объектов в одном классе~--- необходимое условие
разрешимости задачи}. Предположим, что все 0-объек\-ты, кроме $i$-го,
сосредоточены в классе~1, а $i$-й 0-объект~--- в классе~2. Тогда при
сравнении пар объектов $W_i^2\not= W_j^1$ будет происходить потеря
разрешимости для всех~$j$, соответствующих 0-объек\-там
($n_j^{rm}\hm=0$).

\medskip

\noindent
\textbf{Следствие 4.}
\textit{Наличие всех нуль-объектов в одном классе~--- необходимое условие
тупиковости множества мотивов~$\mathbf{K}^0$}. Тупиковость~$\mathbf{K}^0$
подразумевает разрешимость задачи. При нарушении необходимого условия
разрешимости (следствие~3) о тупиковости не может идти и речи.

\medskip

\noindent
\textbf{Следствие 5.}
\textit{Тупиковость множества~$\mathbf{K}^0$ гарантирована только при
постановке задачи в двухклассовой форме}. Предположим, что задача
распознавания поставлена для трех классов ($\vert \mathbf{B}\vert \hm=3$~---
типичный пример). Из следствий~3 и~4 очевидно, что все 0-объек\-ты
должны быть сосредоточены в одном классе. Пусть это будет класс~3.
Классы~1 и~2 содержат только 1-объек\-ты и объекты с $n_i^{rm}\hm>1$.
Тогда при попарном сравнении объектов классов~1 и~2 необходимое
условие тупиковости $n_i^{rm}\hm+n_j^{rm}\hm =1$ никогда не будет
выполнено.

\smallskip

Теорема~2 и ее следствия позволяют не только вычислить минимальное и
тупиковое множества мотивов максимальной информативности, но и
накладывают существенные структурные ограничения на процедуры
тестирования разрешимости. При заданных непротиворечивом~$\mathbf{Q}$ и
функции~$D$ для оценки информативности мотивов следствие~2 позволяет
определить тупиковое множество мотивов~$\mathbf{K}^0$, используя, по сути дела,
<<жадный>> алгоритм.

    По следствию~5, для анализа тупиковости необходимо исследование
разрешимости задачи в двуклассовой форме. При $\vert \mathbf{B}\vert\hm = 3$ и
более это требование соответствует сведению задачи поиска\linebreak
тупиковых~$\mathbf{K}^0$ к исследованию разрешимости таких задач, как <<$H$/не
$H$>>, <<$S$/не $S$>> и~т.\,д.\ по от\-дель\-ности. При этом
$\mathbf{K}^0\hm=\sup\limits_{l=1}^{\vert \mathbf{B}\vert} \mathbf{K}_l^0$; для
$\mathbf{B}\hm=\{S, H, L\}$ $\mathbf{K}^0
\hm = \mathbf{K}^0_{H/\neg H}\cupb \mathbf{K}^0_{S/\neg S}\cupb \mathbf{K}^0_{L/\neg L}$. В~теории
классификации значений признаков~[5, 6, 9], разбиение~$\mathbf{K}^0$ на
подмножества~$\mathbf{K}^0_l$ соответствует существованию ядерной
эквивалентности функ\-ций-пре\-дик\-то\-ров, отображающих множества
значений признаков во множества классов.

В~основе разрабатываемого формализма лежат два принципиальных
допущения, анализ которых представляет собой отдельные направления
дальнейших исследований. Во-пер\-вых, разрешимость на множестве мотивов
определяется через введение $D$-функций, эвристических оценок
информативности мотивов. Необходимо проведение строгого
тео\-ре\-ти\-ко-мно\-же\-ст\-вен\-но\-го обоснования возможных форм соответствующего
функционала, по\-рож\-да\-юще\-го $D$-функции.

    Во-вторых, условие $D(\kappa_\alpha)\geq D(\kappa_{\alpha+1})$ в процедуре
вычисления $K_f(i,j)$ (выражение~(\ref{e5-t})) соответствует некоторому
произволу в выборе мотива при
$D(\kappa_\alpha)\hm=D(\kappa_{\alpha+1})\hm=D(\kappa_{\alpha+2})$ и~т.\,д. Произвол в
выборе мотива поднимает вопрос о взаимосвязи тупиковости~$\mathbf{K}^0$,
построенных на разных выборках объектов, и проблем переобучения при
построении алгоритмов распознавания. Варьирование встречаемости
мотивов в различных выборках объектов также делает необходимым
введение комбинаторных оценок значений~$D$.


\section{Об оценках информативности и~непротиворечивых
множествах объектов}

Помимо нахождения тупиковых множеств мотивов эвристические оценки
информативности мо\-ти\-вов могут также использоваться для решения важной
промежуточной задачи~--- формирования непротиворечивых множеств
объектов.

Пусть в произвольном $\mathbf{Q}(\mathbf{Pr}, \mathbf{M})$ имеются объекты с одинаковыми
верхними словами~--- ситуация, типичная для множеств объектов,
полученных на основе реальных экспериментальных данных по структуре
белка~\cite{3-t}. Некоторое $k$-е подмножество объектов из~$\mathbf{Q}$, в котором
верхние слова равны определенному слову~$V$, назовем
\textit{клас\-тер-объек\-том} $qc_k$, $qc_k=\{(V, w_1), (V, w_2), \ldots , (V,
w_m)\}$, $m\hm = \vert qc_k\vert$. Множество~$\mathbf{Q}$ разбивается на $N_{qc}$
клас\-тер-объек\-тов, так что $\mathbf{Q}=\cupb\limits_{k=1}^{N_{qc}} qc_k$.

В произвольном кластер-объекте каждому верхнему слову соответствует
множество литер $\mathbf{B}$-ал\-фа\-ви\-та. В~непротиворечивом множестве
объектов все эти литеры попарно равны. В~противоречивых множествах
объектов некоторые из литер будут попарно различны. \textit{Условие
непротиворечивости~$\mathbf{Q}$ по клас\-тер-объек\-там} записывается
следующим образом:
\begin{equation}
\forallb\limits_{k=1}^{N_{qc}} qc_k \forallb\limits_{i,j=1}^{\vert qc_k\vert}
q_i,q_j:\ w_i=w_j\,.
\label{e7-t}
\end{equation}


С~физической точки зрения $\vert qc_k\vert$ является чис\-лом независимых
экспериментов, в которых\linebreak
 наблюдались объекты, составляющие клас\-тер-объ\-ект~$qc_k$.
Вследствие рассмотренных ранее особенностей структурного
эксперимента~\cite{3-t} выполнение условия~(\ref{e7-t}) будет наблюдаться
не для всех клас\-тер-объ\-ек\-тов, так что наряду с числом экспериментов $\vert
qc_k\vert$ имеет смысл характеризовать кластер-объекты и по степени их
непротиворечивости. Для этого также могут применяться эвристические
оценки информативности мотивов.

Действительно, любой объект из $\mathbf{Q}$ можно рассматривать как мотив,
выбранный по объединенной маске $\hat{m}_\Sigma(\mathbf{M})$ в определенной
ведущей позиции верхнего слова некоторого прецедента.
При этом $N_\Sigma^\alpha =\sum\limits_{l=1}^{\vert \mathbf{B}\vert} N_l^\alpha$,
$N_l^\alpha$~---  чис\-ло объектов  $q=(V,w)$ с $w=b_l$ в $\alpha$-м клас\-тер-объ\-ек\-те.
Как и любой
другой мотив, клас\-тер-объект характеризуется вектором ($N_1^\alpha, N_2^\alpha,
\ldots , N^\alpha_{\vert \mathbf{B}\vert}, N_\Sigma^\alpha$), что позволяет вы\-чис\-лять
предложенные ранее оценки ин\-фор\-ма\-тив\-ности мотивов~$D_1(\alpha)$,
$D_2(\alpha)\hm=N_\Sigma^\alpha D(\alpha)$ и~др. Полученные значения~$D$
характеризуют <<степень непротиворечивости>> или же
<<информативность>> клас\-тер-объ\-ек\-тов. С~использованием $D_1(\alpha)$ запись
условия непротиворечивости~$\mathbf{Q}$~(\ref{e7-t}) упрощается:
%\addtocounter{equation}{-1}
%\renewcommand{\theequation}{\arabic{equation}$^{\prime}$}
\begin{equation*}
\forallb\limits_{\alpha=1}^{N_{qc}}  qc_\alpha:\ D_1(\alpha)=\vert \mathbf{B}\vert\,.
%\label{e7-1}
\end{equation*}
%\renewcommand{\theequation}{\arabic{equation}}
%\setcounter{equation}{7}

Для формирования непротиворечивых множеств объектов на практике
наиболее приемлемой представляется упомянутая ранее стратегия
исключения <<менее информативных>> (или <<наиболее
противоречивых>>) клас\-тер-объек\-тов путем введения скалярных границ.
В~качестве ограничений могут выступать фиксированное пороговое
значение~$D$, диаграмма Парето или же совокупность значений порогов для
различных~$D$:
\begin{equation}
\left.
\begin{array}{rl}
\forallb\limits_{\alpha=1}^{N_{qc}} qc_a: & \ D_1(\alpha)>D_{\min}^{\mathrm{obj}}\,;\\
\forallb\limits_{\alpha=1}^{N_{qc}} qc_a: & \ N_\Sigma^\alpha>N_{\min}^{\mathrm{obj}}\,.
\end{array}
\right\}
\label{e8-t}
\end{equation}
Параметр $D_{\min}^{\mathrm{obj}}$ характеризует минимально до\-пус\-тимую
информативность объекта, а $N_{\min}^{\mathrm{obj}}$~--- минимальное чис\-ло
независимых структурных экспериментов, в которых наблюдался объект.

\section{Приложение формализма к~тестовым выборкам
экспериментальных данных$^1$}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext{$^1$Экспериментальная часть работы полностью выполнена
И.\,Ю.~Торшиным.}}

Для проведения экспериментов по тестрированию условия
разрешимости~(\ref{e3-t}) и вычисления характеристических функций
множеств наиболее информативных мотивов~(\ref{e6-t}) прежде всего
необходимо формирование непротиворечивого множества
объектов~$\mathbf{Q}^{\mathrm{нп}}$ в соответствии с~(\ref{e8-t}). Для обоснованного
выбора значений параметров~$D_{\min}^{\mathrm{obj}}$ и~$N_{\min}^{\mathrm{obj}}$
необходимо ввести некоторое формальное описание <<качества>>
получаемого~$\mathbf{Q}^{\mathrm{нп}}$.

Критерии~(\ref{e8-t}) позволяют выбрать в исходном $\mathbf{Q}(\mathbf{Pr}, \mathbf{M})$ некоторое
подмножество клас\-тер-объек\-тов~$\mathbf{Q}^0$. Формирование
непротиворечивого~$\mathbf{Q}^{\mathrm{нп}}$ из клас\-тер-объек\-тов $\mathbf{Q}(\mathbf{Pr}, \mathbf{M})$~---
это, по сути дела, выбор множества представителей (т.\,е.\ каждому
клас\-тер-объек\-ту в $\mathbf{Q}^0 \subseteq  \mathbf{Q} (\mathbf{Pr},\mathbf{M})$
соответствует единственный
объект в~$\mathbf{Q}^{\mathrm{нп}}$). На интуитивном уровне понятно:
качество~$\mathbf{Q}^{\mathrm{нп}}$ тем выше, чем больше клас\-тер-объек\-тов из
$\mathbf{Q}(\mathbf{Pr}, \mathbf{M})$ представлено в $\mathbf{Q}^{\mathrm{нп}}$ и чем меньше чис\-ло
противоречий между экспериментами (т.\,е.\ выше информативность каждого
объекта в~$\mathbf{Q}^{\mathrm{нп}}$).

Формальными показателями <<качества>> множества
объектов~$\mathbf{Q}^{\mathrm{нп}}$, получаемого отображением $h:\ \mathbf{Q}^0 \subseteq
\mathbf{Q}(\mathbf{Pr},\mathbf{M})\rightarrow \mathbf{Q}^{\mathrm{нп}}$, служат,
во-пер\-вых, соотношение
между числом отобранных клас\-тер-объек\-тов ($\vert \mathbf{Q}^{\mathrm{нп}}\vert$) и
общим числом клас\-тер-объек\-тов~$N_{qc}$ в исходном множестве $\mathbf{Q}(\mathbf{Pr},\mathbf{M})$,
$\vert \mathbf{Q}^{\mathrm{нп}}\vert/N_{qc}\hm\rightarrow \max$; во-вто\-рых, соотношение
между числом объектов в~$\mathbf{Q}^0$, включаемых в
$\mathbf{Q}^{\mathrm{нп}}(N_{\mathrm{вкл}})$, и общим числом объектов в~$\mathbf{Q}^0$,
$N_{\mathrm{вкл}}/\vert \mathbf{Q}^0\vert \rightarrow \max$.

Критерий разрешимости задачи распознавания~(\ref{e1-t}) и~(\ref{e2-t}) и
следующий из него критерий непро\-ти\-во\-речивости~(\ref{e7-t}) требуют
однозначного отнесения\linebreak любого объекта (клас\-тер-объек\-та) к
определенной литере алфавита~$\mathbf{B}$. Естественно определить\linebreak
 $\mathbf{B}$-ли\-те\-ру
$\alpha$-го клас\-тер-объек\-та как класс, со\-от\-вет\-ст\-ву\-ющий большинству
объектов. Тогда $N_{\mathrm{вкл}}$ определяется суммированием по~$\alpha$
величин $N_{\max}^\alpha \hm=\max\limits_{l=1,\ldots , \vert \mathbf{B}\vert} N_l^\alpha$,
а $\vert  \mathbf{Q}^0\vert$~--- суммированием~$N_\Sigma^a$. Задача нахождения
непротиворечивого множества объектов~$\mathbf{Q}^{\mathrm{нп}}$ может быть
сформулирована как

\vspace*{2.5pt}

\noindent
\begin{equation}
\underset{D_{\min}^{\mathrm{obj}}, N_{\min}^{\mathrm{obj}}}{\arg\max}\left(  \fr{\vert
\mathbf{Q}^{\mathrm{нп}}\vert}{N_{qc}}+\fr{N_{\mathrm{вкл}}}{\vert
\mathbf{Q}^0\vert}\right)\,.
\label{e9-t}
\end{equation}

\vspace*{-2.5pt}

В проведенных экспериментах в качестве множества прецедентов были
использованы все 165\,000 прецедентов, представленных в базе данных
PDB~\cite{4-t} на октябрь~2010~г. При этом число клас-\linebreak\vspace*{-12pt}
\columnbreak

\noindent
тер-объек\-тов
превысило 5~млн ($N_{qc}\hm=5{,}42\cdot 10^6$). \textit{Формирование
непротиворечивых множеств объектов} осуществлялось решением
задачи~(\ref{e9-t}). При оптимальных значениях параметров
$D_{\min}^{\mathrm{obj}}\hm=2{,}5$ и $N_{\min}^{\mathrm{obj}}\hm=4$ число отобранных
объектов составило $\vert \mathbf{Q}^{\mathrm{нп}}\vert\hm =2{,}01\cdot 10^6$.

На основе множества $\mathbf{Q}^{\mathrm{нп}}$ формировались тес\-товые
множества~$\mathbf{Q}$ для вычисления характеристических функций~$T(\alpha)$. Были
исследованы выборки размером 10\,000, 20\,000, 30\,000, 50\,000, 100\,000 и
200\,000 объектов, сформированные путем случайного отбора объектов без
возвращения. В~общей сложности было проанализировано
60~различных~$\mathbf{Pr}$, т.\,е.\ по 10~выборок для каждого из шести
приведенных выше значений~$\vert \mathbf{Q}\vert$. Исследование
б$\acute{\mbox{о}}$льших выборок объектов в настоящее время не
представляется возможным вследствие значительных вычислительных
трудностей.

Каждая из \textit{использованных систем масок} имела фиксированную
размерность всех масок. Максимальная протяженность масок во всех
системах составила 8~позиций. Изученные системы масок были получены на
основе системы масок с размерностью всех масок, равной $m\hm=2$ (система
$M_8^1$) и $m\hm=3$ ($M_8^3$), в которых нулевая позиция каждой маски
соответствовала позиции $\lfloor n/2\rfloor +1$ в верхнем слове каждого
объекта. Очевидно, что $\vert M_8^2\vert \hm= C_8^2$ и $\vert M_8^3\vert
\hm=C_8^3$. Была произведена частичная редукция систем масок путем
удаления сдвиг-экви\-ва\-лент\-ных масок, и для вычисления $T(\alpha)$
использовались сис\-те\-мы масок $M_8^{\prime2}, \vert M_8^{\prime
2}\vert\hm=11$ и $M_8^{\prime 3}, \vert M_8^{\prime 3}\vert\hm =25$. Ниже
представлены результаты для сис\-те\-мы масок~$M_8^{\prime 3}$.

Была исследована целесообразность использования трех
\textit{эвристических оценок ин\-фор\-ма\-тив\-ности}\linebreak \textit{мотивов} $D_1(\alpha)$,
$D_2(\alpha)$ и $D_{D0}(\alpha)$. Предварительные эксперименты показали, что
оценка $D_2(\alpha)\hm=N_\Sigma D_1(\alpha)$ приводит к тупиковым множествам\linebreak
мотивов наименьшей размерности, так что в дальнейших экспериментах
использовалась именно~$D_2(\alpha)$.

Вычисления $T(\alpha)$ показали, что предложенный формализм позволяет
значительно сократить множество мотивов $\mathbf{K}(\mathbf{Pr}, \mathbf{M})$ без потери
раз\-ре\-ши\-мости. Например, в $\mathbf{MO}(\mathbf{Pr}(\vert \mathbf{Q}\vert \hm=200\,000),
M_8^{\prime 3})$ содержалось 201\,000 мотивов. Число отобранных мотивов
(т.\,е.\ $\vert \mathbf{MO}^0\vert \hm =\vert \{T(\alpha)=1\}\vert )$ составило $\sim 25\,000$.
Логарифмический характер зави\-си\-мости числа отобранных мотивов от~$\vert
\mathbf{Q}\vert$ (рис.~\ref{f2-t}) поз\-во\-ля\-ет предположить, что высокая эффективность
редукции множества мотивов сохранится и при значительно
б$\acute{\mbox{о}}$льших~$\mathbf{Q}$. Отметим, что оценки $\vert \mathbf{K}^0\vert$,
полученные на разных выборках одного размера, отличались не более чем
на~5\%.

\begin{figure*} %fig2
\vspace*{1pt}
\begin{minipage}[t]{79mm}
 \begin{center}
 \mbox{%
 \epsfxsize=77.128mm
 \epsfbox{tor-2.eps}
 }
 \end{center}
 \vspace*{-9pt}
\Caption{Зависимость числа отобранных мотивов от размера выборки объектов:
$y\hm=6989{,}9\ln\,x\hm-60\,548$; $R^2\hm=0{,}9897$. Было
исследовано по 10~независимых выборок объектов каждого размера
\label{f2-t}}
\end{minipage}
%\end{figure*}
%\begin{figure*} %fig3
\hfill
\vspace*{1pt}
\begin{minipage}[t]{79mm}
 \begin{center}
 \mbox{%
 \epsfxsize=68.736mm
 \epsfbox{tor-3.eps}
 }
 \end{center}
 \vspace*{-9pt}
\Caption{Распределение мотивов тупиковых $\mathbf{K}^0$ среди мотивов $\mathbf{K}(\mathbf{Pr}, \mathbf{M})$
($\alpha$~--- порядковый номер мотива) для
выборок объектов различного размера:
\textit{1}~--- 10\,000; \textit{2}~--- 50\,000; \textit{3}~--- 100\,000; \textit{4}~--- 200\,000
\label{f3-t}}
\end{minipage}
\end{figure*}
\begin{figure*}[b] %fig4
\vspace*{1pt}
 \begin{center}
 \mbox{%
 \epsfxsize=160.683mm
 \epsfbox{tor-4.eps}
 }
 \end{center}
 \vspace*{-9pt}
\Caption{Число распознаваемых пар объектов для выборок разных размеров:
(\textit{а})~выборки разного размера (\textit{1}~---  из 10\,000 объектов;
\textit{2}~--- из 30\,000; \textit{3}~--- из 50\,000; \textit{4}~--- из
100\,000; \textit{5}~--- из 200\,000 объектов);
(\textit{б})~выборки из 200\,000 объектов
\label{f4-t}}
\end{figure*}

Исследуем структуру получаемых $\mathbf{K}^0$ более подробно. В~$\mathbf{K}(\mathbf{Pr}, \mathbf{M})$
мотивы упорядочены по убыванию информативности. Как и следовало
ожидать, мотивы~$\mathbf{K}^0$ (т.\,е.\ мотивы c $T(\alpha)\hm=1$) встречаются наиболее
часто среди мотивов с высокой информативностью (наименьшими~$\alpha$,
рис.~\ref{f3-t}). Во множествах с 200\,000 объектов практически все 8000
наиболее информативных мотивов входят в~$\mathbf{K}^0$.

Представляет интерес рассмотрение зави\-си\-мости числа пар объектов, на
которых достигнута разрешимость (максимально $\vert \mathbf{Q}^2\vert $), от чис\-ла
мотивов с максимальной информативностью. Так как очевидно, что чис\-ло
мотивов в~$\mathbf{K}^0$ зависит от числа объектов (см.\ рис.~\ref{f2-t}), то для
сравнения результатов следует использовать процентные соотношения
(рис.~\ref{f4-t}).


Результаты, представленные на рис.~\ref{f4-t}, указывают на существование
некоторого <<ядра>> в тупиковых множествах мотивов. Мотивы, входящие в
такое <<ядро>>, обеспечивают разрешимость на большинстве пар объектов.
Например, в выборках по 200\,000 объектов 50\% наиболее информативных
мотивов в тупиковом~$\mathbf{K}^0$ обеспечивают разрешимость почти на 90\% пар
объектов (<<90\% ядро>>).

Логарифмический характер зависимости $\vert \mathbf{Q}^2\vert$--$\vert \mathbf{K}^0\vert$
указывает на то, что полная разрешимость дости\-га\-ется добавлением к
<<ядру>> некоторых низкоинформативных мотивов, каждый из которых
обеспечивает разрешимость всего лишь на нескольких парах объектов.
Действительно, число пар объектов на мотив резко падает по мере
увеличения порядкового номера мотива в~$\mathbf{K}^0$ (рис.~\ref{f5-t}). Согласно
данным рис.~\ref{f5-t},\,\textit{б}, мотивы 90\% <<ядра>> ($\vert \mathbf{Q}\vert \hm
=200\,000$) обеспечивают разрешимость более чем на 5~парах объектов.

\begin{figure*} %fig5
\vspace*{1pt}
 \begin{center}
 \mbox{%
 \epsfxsize=160.657mm
 \epsfbox{tor-5.eps}
 }
 \end{center}
 \vspace*{-9pt}
\Caption{Зависимость среднего числа <<разрешаемых>> по условию~(\ref{e3-t}) пар
объектов на один мотив от информативности мотива (его порядкового номера в~$\mathbf{K}^0$):
 (\textit{а})~количество пар
объектов на 1~мотив (\textit{1}~--- 10\,000;  \textit{2}~--- 50\,000; \textit{3}~--- 100\,000;
\textit{4}~--- 200\,000); (\textit{б})~доля мотивов в $\mathbf{K}^0$, имеющих заданное число пар
объектов на мотив (\textit{1}~--- $>1$~п/м;  \textit{2}~--- $>5$; \textit{3}~---
$>10$~п/м)
\label{f5-t}}
\vspace*{12pt}
\end{figure*}

Можно предположить, что мотивы, входящие в <<ядра>>, будут гораздо
чаще встречаться в произвольных обучающих выборках. Исследуем
\textit{заполненность} (англ.\ \textit{occupancy}, термин заимствован из
физики твердого тела) мотивов во множествах~$\mathbf{K}^0$,\linebreak\vspace*{-12pt}
\begin{center} %fig6
\vspace*{2pt}
\mbox{%
 \epsfxsize=72.852mm
 \epsfbox{tor-6.eps}
}
\end{center}
%\begin{center}
\vspace*{3pt}
{{\figurename~6}\ \ \small{Информативность и заполненность мотивов. Мотивы с более низкими
порядковыми номерами мотива в $\mathbf{K}(\mathbf{Pr},\mathbf{M})$~$\alpha$
чаще входят в~$\mathbf{K}^0(\mathbf{Q})$ при произвольном~$\mathbf{Q}$:
\textit{1}~--- $p(\mbox{осс}\leq 0{,}8)$,
200\,000; \textit{2}~--- $p(\mbox{осс}\leq 0{,}9)$, 200\,000; \textit{3}~--- $p(\mbox{осс}\hm=
1)$, 200\,000; \textit{4}~--- $p(\mbox{осс}\hm =1)$, 100\,000; \textit{5}~---
$p(\mbox{осс}\hm=1)$, 50\,000}}
%\end{center}
\vspace*{11pt}

%\smallskip
\addtocounter{figure}{1}

\noindent
полученных для
разных~$\mathbf{Q}$ одного размера (если мотив имел $T(\alpha)=1$ в
8~множествах~$\mathbf{Q}$ из~10, то его заполненность 0,8 и~т.\,д.). Сравнение
множеств мотивов, полученных на различных~$\mathbf{Q}$ (например, $10\mathbf{Q}$, $\vert
\mathbf{Q}\vert =200\,000$), показало: чем выше информативность мотива (т.\,е.\ чем
ниже~$k$), тем более вероятно, что мотив входит в тупиковое~$\mathbf{K}^0$,
построенное на произвольном~$\mathbf{Q}$ (рис.~6). Например, во
множествах объектов с $\vert \mathbf{Q} \vert \hm=200\,000$ пер\-вые 5000~наиболее
информативных мотивов встречались в каждом полученном~$\mathbf{K}^0$. Мотивы
<<95\% ядра>> имеют занятость не менее~0,8, а мотивы с
заполненностью~1,0 (т.\,е.\ встречающиеся в~$\mathbf{K}^0$, построенном на
произвольном~$\mathbf{Q}$) обеспечивают разрешимость 90\% пар объектов (так как
образуют <<90\% ядро>>).


\section{Выводы}

\vspace*{-6pt}

В настоящей работе проведено развитие формализма для исследования
разрешимости задачи распознавания вторичной структуры белка на
множествах аминокислотных мотивов. Показано, что введение порядка на
множестве мотивов посредством эвристических оценок информативности
позволяет проводить эффективное сокращение множества мотивов без
потери разрешимости задачи. Разработанный формализм позволил провести
эксперименты по нахождению тупиковых множеств наиболее
информативных мотивов. Установлены перспективные направления
дальнейших исследований: создание тео\-ре\-ти\-ко-мно\-же\-ст\-вен\-но\-го
обосно\-ва\-ния оценок информативности~$D$, введение комбинаторных
оценок значений~$D$, исследование ядерной эквивалентности функ\-ций-пре\-дик\-то\-ров,
построенных на мотивах. Разработанный формализм также
позволяет провести систематическое исследование для рационального
выбора значений параметров используемых систем масок. Нахождение
тупиковых множеств наиболее информативных мотивов существенно важно
для следу\-юще\-го этапа представленного исследования~--- синтеза алгоритмов
в рамках алгебраического подхода к распознаванию.

\vspace*{-12pt}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{9}

\bibitem{1-t}
\Au{Torshin I.\,Y.}
Bioinformatics in the post-genomic era: The role of biophysics.~--- N.Y.: Nova
Biomedical Books, 2006.

\bibitem{2-t}
\Au{Рудаков К.\,В., Торшин И.\,Ю.}
О разрешимости формальной задачи распознавания вторичной структуры
белка~// ММРО-14, Суздаль, 2009. С.~596--597.

\bibitem{3-t}
\Au{Рудаков К.\,В., Торшин И.\,Ю.}
Вопросы разрешимости задачи распознавания вторичной структуры белка~//
Информатика и её применения, 2010. Т.~4. Вып.~2. С.~25--35.

\bibitem{4-t}
\Au{Berman H.\,M., Henrick~K., Nakamura~H.}
Announcing the worldwide Protein Data Bank~// Nature Structural Biology, 2003.
Vol.~10. No.\,12. P.~980--982.

%\bibitem{5-t}
%\Au{Журавлев Ю.\,И.}
%Об алгебраическом подходе к решению задач распознавания или
%классификации~// Проблемы кибернетики.~--- М.: Наука, 1978. Вып.~33.
%С.~5--68.

\bibitem{7-t} %5
\Au{Рудаков К.\,В.}
Универсальные и локальные ограничения в проблеме коррекции
эвристических алгоритмов~// Кибернетика, 1987. №\,2. С.~30--35.

\bibitem{8-t} %6
\Au{Рудаков К.\,В.}
О~проблемах классификации значений признаков в задачах распознавания~//
Интеллектуализация обработки информации (ИОИ-8): VIII Междунар.
конф. (Пафос, Кипр): Сб. докл.~--- М.: МАКС
Пресс, 2010. С.~81--82.

\bibitem{9-t} %7
\Au{Воронцов К.\,В.}
Комбинаторная теория надежности обучения по прецедентам. Дис.\ \ldots\
докт. физ.-мат. наук.~--- М.: ВЦ РАН, 2010. 271~с.

\bibitem{10-t} %8
\Au{Furnkranz J., Flach P.\,A.}
Roc`n' rule learning~--- towards a better understanding of covering algorithms~//
Machine Learning, 2005. Vol.~58. No.\,1. P.~39--77.

\label{end\stat}

\bibitem{6-t} %9
\Au{Журавлев Ю.\,И., Рудаков К.\,В.}
Об алгебраической коррекции процедур обработки (преобразования)
информации~// Проблемы прикладной математики и информатики.~--- М.:
Наука, 1987. С.~187--198.
 \end{thebibliography}
}
}


\end{multicols}