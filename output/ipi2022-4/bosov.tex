\def\stat{bosov}

\def\tit{ТЕХНОЛОГИЯ КЛАССИФИКАЦИИ ТИПОВ КОНТЕНТА ЭЛЕКТРОННОГО УЧЕБНИКА$^*$}

\def\titkol{Технология классификации типов контента электронного учебника}

\def\aut{А.\,В.~Босов$^1$, А.\,В.~Иванов$^2$}

\def\autkol{А.\,В.~Босов, А.\,В.~Иванов}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Босов А.\,В.}
\index{Иванов А.\,В.}
\index{Bosov A.\,V.}
\index{Ivanov A.\,V.}


{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Исследование выполнено за счет гранта Российского научного фонда (проект 22-28-00588). Работа 
выполнялась с~использованием ин\-фра\-струк\-ту\-ры Цент\-ра коллективного пользования 
<<Высокопроизводительные вы\-чис\-ле\-ния и~большие данные>> (ЦКП <<Информатика>> ФИЦ ИУ РАН, 
Москва).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{avbosov@ipiran.ru}}
\footnotetext[2]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии 
наук, \mbox{aivanov@ipiran.ru}}


\vspace*{-12pt}


  

\Abst{Решается задача классификации контента электронной обуча\-ющей сис\-те\-мы 
(ЭОС), относящегося к~блокам задач или практических примеров. Не\-об\-хо\-ди\-мость 
автоматизированного классификатора обосно\-ва\-на перспективным на\-прав\-ле\-ни\-ем 
развития ЭОС~--- оцениванием качества обуча\-юще\-го контента.  
Ключевая идея~--- моделирование контента объектом с~двумя свойствами: 
текс\-то\-вым описанием на традиционном языке и~набором формульных выражений 
на языке научной компьютерной верст\-ки \TeX. На основе электронного учебника 
по тео\-рии функций комплексного переменного выполнено формирование 
раз\-ме\-чен\-ных в~соответствии с~данной мо\-делью образцов задач. Проведено 
обуче\-ние четырех алгоритмов классификации текс\-то\-во\-го контента~--- на\-ив\-но\-го 
байесовского классификатора, логистической регрессии, однослойной 
и~многослойной нейронных сетей прямого рас\-про\-стра\-не\-ния. Проведен комплекс 
сравнительных экспериментов на реализованных классификаторах как в~условиях 
ограниченных моделей, содержащих только контент одного типа, текс\-то\-вый или 
формульный, так и~пол\-ной модели. В~результате эксперимента выполнено не 
толь\-ко формальное сравнение алгоритмов, но и~показано принципиальное 
преимущество пол\-ной модели: при учете обоих свойств контента, текс\-то\-во\-го 
и~формульного, качество классификации существенно превосходит 
однофакторные ал\-го\-рит\-мы и~обеспечивает показатели, под\-тверж\-да\-ющие 
го\-тов\-ность технологии к~практическому применению.}

\KW{электронная обучающая сис\-те\-ма; обучающий контент; задача и~алгоритмы 
классификации; оценка качества контента; машинное обучение}

 \DOI{10.14357/19922264220410} 
  
\vspace*{-6pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}

\section{Введение}

     Учебный процесс сегодня невозможно пред\-ста\-вить без средств 
дистанционного обучения, на что, несомненно, повлияла пандемия 
по\-след\-них лет~[1]. Формально эти средства могут быть различны: от 
прос\-то\-го электронного учебника для школьника до интегрированной  
элект\-рон\-но-обуча\-ющей среды вуза. И,~конечно, любая форма 
пред\-став\-ле\-ния учебного материала должна обеспечивать его высокое 
качество. Значит, нужны определенные правила его формирования, 
стандарты, поз\-во\-ля\-ющие контролировать качество контента ЭОС.
     
     На данный момент довольно ограниченное внимание 
профессионального сообщества привлекал только анализ качества 
традиционных учебников~[2]. Электронные обуча\-ющие сис\-те\-мы за счет средств автоматизации имеют 
гораздо более разнообразный контент, обес\-пе\-чи\-ва\-емый в~значительной 
степени функциональными инструментами. Анализ качества их контента 
в~этой связи пред\-став\-ля\-ет\-ся, с~одной стороны, более слож\-ной задачей, но 
с~другой стороны, электронный контент по своей сущ\-ности лучше 
подготовлен для исследования техническими методами, которые могут быть 
автоматизированы и~потому не требуют привлечения экспертов. Некоторые 
принципиальные рекомендации для оценивания контента ЭОС приведены 
в~[3, 4]. Говорить о~воз\-мож\-ности автоматизации таких методик в~пол\-ном 
объ\-еме пока преждевременно, но выделить некоторые задачи мож\-но. Одной 
из них по\-свя\-ще\-на данная \mbox{статья}.
     
     Важным инструментом системы анализа качества контента ЭОС 
долж\-на стать технология классификации элементов контента по тематикам 
изуча\-емой дисциплины. Средство автоматического определения раздела 
курса, к~которому относится задача, тест, пример, вопрос экзаменационного 
билета, будет ключевой частью как методик анализа\linebreak качества контента, так 
и~самого процесса обуче\-ния. Это, например, анализ полноты 
и~до\-ста\-точ\-ности ЭОС, определение слож\-ности комплекта заданий 
(контрольной работы, \mbox{экзаменационного} билета), генерации заданий 
необходимого уровня слож\-ности и/или тематической на\-прав\-лен\-ности и~пр. 
В~статье рас\-смат\-ри\-ва\-ет\-ся наиболее типовая по\-ста\-нов\-ка задачи тематической 
классификации контента, когда имеется фиксированный перечень разделов 
кур\-са (оглав\-ле\-ние учебника), образцы заданий (примеров, тес\-тов, задач) для 
этих разделов и~требуется \mbox{обучить} автоматический классификатор, который 
будет относить задания к~разделам. Если бы задания имели исключительно 
текс\-то\-вые\linebreak (традиционно языковые) формулировки, то проб\-ле\-ма сводилась 
бы к~типовой классификации текс\-тов. Но классифицировать требуется 
математический контент, т.\,е.\ формульные выражения. \mbox{Формальное} 
использование техник текс\-то\-вой классификации приемлемых результатов не 
даст. Мож\-но ли и~каким образом применять эти техники, \mbox{какая} потребуется 
адап\-та\-ция~--- это вопросы исследования, результаты которого пред\-став\-ле\-ны в~\mbox{статье}.
     
     Когда речь заходит об автоматических средствах обработки 
формульных выражений, то первыми в~их чис\-ле обнаруживаются средства 
распознавания набранных и~рукописных математических выражений. Среди 
многих работ на эту тему мож\-но отметить~[5], где сис\-те\-ма распознавания 
образов использует естественное для формул пред\-став\-ле\-ние в~виде 
древовидных струк\-тур. По\-дроб\-но\-сти есть в~обзорах~[6, 7]. Для темы статьи 
важ\-но то, что конечная задача в~таких проектах со\-сто\-ит в~получении формул 
в~формате электронных редакторов текс\-тов, например в~\LaTeX. 
Потребителю здесь нуж\-ны в~основном инструменты распознавания в~об\-ласти 
рукописного ввода.
     
     Наиболее близка к~рас\-смат\-ри\-ва\-емой тематика поиска математических 
знаний (хороший обзор дан в~[8]). Заметим, что и~на сегодняшний день 
поисковые сис\-те\-мы не имеют функций поиска с~использованием формул, 
хотя этой проб\-ле\-мой много лет занимаются специалисты и~выполнено много 
впол\-не содержательных проектов. Наиболее продуктивными оказывались те, 
что опирались на формульное пред\-став\-ле\-ние на языке научной раз\-мет\-ки 
\TeX~[9]. В~таких проектах речь идет, как правило, о~пол\-но\-текс\-то\-вом поиске 
с~использованием математических выражений. В~некоторый период такая 
сис\-те\-ма \mbox{LaTeXSearch} была пред\-став\-ле\-на издательством Springer, поиск 
формул реализовывался в~своей биб\-лио\-те\-ке (к~сожалению, сейчас проект 
недоступен и~сведений о~нем больше нет). 
     
     Можно выделить два вида стратегий реализации математического 
поиска. Первая заключается в~расширении существующей сис\-те\-мы 
текс\-то\-во\-го поиска путем преобразования двумерных формул в~линейные 
строки, такие как \mbox{LeActiveMath}~[10, 11], \mbox{MathDex}~[12], \mbox{EgoMath}~[13], 
\mbox{DLMFSearch}~[14] и~MIaS~[15]. Все эти методы на\-прав\-ле\-ны на то, чтобы 
превратить формулу в~символьный поток и~включить его в~пол\-но\-текс\-то\-вой 
поиск. Вторая стратегия заключается в~реализации некоторой модели 
извлечения знаний для математических выражений и~осуществлена, 
например, в~\mbox{MathWebSearch}~[16] и~\mbox{WikiMirs}~[17]. Еще один пример  
бо\-лее-ме\-нее актуального исследования пред\-став\-лен в~[18, 19], где 
реализовано онтологическое описание формул TeX, основанное на присущей 
математическим формулам иерархии. На ее основе строится набор 
при\-зна\-ков, которые индексируются и~участвуют в~поиске. Использование 
иерархической структуры гораздо лучше передает семантику, но 
используется это все рав\-но для по\-стро\-ения пол\-но\-текс\-то\-во\-го индекса. Еще 
одна любопытная идея пред\-став\-ле\-на в~[20, 21], где предлагается объединить 
в~поиске и~формульные пред\-став\-ле\-ния, и~текс\-то\-вые данные, из\-вле\-ка\-емые из 
текс\-та с~этой формулой. Кроме того, об\-суж\-да\-ет\-ся выполнение запросов на 
естественном языке.
     
     Применить процитированные работы и~другие результаты в~об\-ласти 
поиска математических знаний в~по\-ста\-нов\-ках по классификации 
математических текс\-тов вряд ли получится. Так, могло бы быть интересным 
определять по формулам об\-ласть знаний, хотя бы в~фор\-ме  
ма\-те\-ма\-ти\-ка--фи\-зи\-ка--хи\-мия. Более глубокий вопрос мог бы звучать 
так: к~какой об\-ласти математики относится формула~--- алгебра, 
дифференциальные урав\-не\-ния, сто\-ха\-сти\-че\-ский анализ и~т.\,д. Такого рода 
задачи тематически ближе к~пред\-став\-лен\-но\-му в~\mbox{статье} исследованию. 
Наверное, как и~в~пред\-став\-лен\-ном далее результате, мож\-но \mbox{обучить} такой 
классификации подходящую нейронную сеть, но проб\-ле\-мой будет не столько 
технология, сколько создание репрезентативного обуча\-юще\-го набора. 
В~рас\-смат\-ри\-ва\-емой задаче ситуация проще, так как ограничена 
тематической классификацией текс\-то\-во-фор\-муль\-но\-го контента 
в~рамках конкретной математической дис\-цип\-ли\-ны. Эту роль выполняет 
тео\-рия функций комплексного переменного, выбранная по той причине, что 
авторы участвуют в~общем проекте с~авторами актуального учеб\-ни\-ка по 
данной дисциплине, раз\-ра\-бо\-тан\-но\-го для применения в~со\-ста\-ве дей\-ст\-ву\-юще\-го 
ЭСО. Это обеспечило работу содержательным электронным кон\-тен\-том, 
отсутствие которого в~любой другой по\-ста\-нов\-ке сделало бы задачу 
неподъемной, поскольку реальных ресурсов для создания обуча\-юще\-го 
набора требуется гораздо больше, чем на само исследование. В~данном 
случае благодаря до\-ступ\-ности учебного материала в~электронной форме 
задачу удалось не только по\-ста\-вить и~предложить для нее модель и~алгоритм, 
но и~выполнить реальные расчеты для нескольких вариантов решения 
и~сравнить результаты.
     
     Статья организована сле\-ду\-ющим образом. В~разд.~2 дано 
описание использованного учебного контента и~процесса его 
предварительной подготовки для формирования обуча\-юще\-го набора. 
В~разд.~3 описана модель для выделения при\-зна\-ков из формульной 
час\-ти контента. В~разд.~4 приведены результаты классификации, 
выполненной для текс\-то\-вой, формульной и~текс\-то\-во-фор\-муль\-ной 
моделей четырьмя типовыми алгоритмами классификации.
     
\section{Исходные данные и~предварительная подготовка}

      Основной использованный учебный материал (рис.~1)~--- это 
пособие~[22], пред\-остав\-лен\-ное для обработки его авторами в~файле формата 
MS~Word.
      


      В пособии по дисциплине <<Теория функций комплексного 
переменного>> материал сгруппирован по~9~разделам (главам). Это 
оглав\-ле\-ние и~было использовано для классификации контента. В~каж\-дом 
разделе есть задания для аудиторной работы (с~решениями) и~задания для 
самостоятельного решения. Суммарно из~[22] были получены~174~задачи. 
При этом чис\-ло задач в~разделах со\-ста\-ви\-ло от~6 до~42, т.\,е.\ задачи 
оказались распределены по разделам довольно неравномерно. Поэтому 
к~задачам, выделенным из~[22] автоматически, были вруч\-ную до\-бав\-ле\-ны 
задачи в~наиболее <<бед\-ные>> разделы. Источником этих 
<<дополнительных>> задач стали пособия~[23, 24]. В~итоге удалось 
сформировать достаточный обуча\-ющий блок из~200~задач, рас\-пре\-де\-лен\-ных 
по име\-ющим\-ся~9~разделам сле\-ду\-ющим образом. 
      \begin{enumerate}[1.]
\item  Комплексные числа и~действия~--- 42. 
\item  Функции комплексного переменного~--- 31. 
\item Дифференцируемость. Аналитические функции~--- 18. 
\item Интегрирование~--- 31. 
\item Ряды~--- 15. 
\end{enumerate}

{ \begin{center}  %fig1
 \vspace*{9pt}
    \mbox{%
\epsfxsize=79mm
\epsfbox{bos-1.eps}
}

\vspace*{6pt}



\noindent
{{\figurename~1}\ \ \small{Учебный материал
}}
\end{center}
}


\addtocounter{figure}{1}



\begin{enumerate}[1.]
\setcounter{enumi}{5}
\item Нули~--- 16. 
\item Вычеты~--- 16. 
\item Преобразование Лапласа~--- 15. 
\item Применение операционного метода~--- 16.
\end{enumerate}
       % 
      С учетом объема формульного материала данное распределение 
оказалось практически равномерным. 
      
      Задачи из каждого раздела сохранялись как отдельный документ. 
Далее документы были конвертированы в~формат \TeX с~по\-мощью 
приложения Pandoc. Каждая задача со\-сто\-ит из текс\-то\-вой формулировки 
и~нескольких формул, поэтому модель задач пред\-став\-ле\-на двумя наборами 
признаков, которые используются для обуче\-ния классификаторов. Первый 
набор при\-зна\-ков формируется на основе текс\-то\-вой час\-ти задачи 
с~использованием типовых средств обработки текс\-тов на естественном 
языке. Второй набор формируется на основе формул, для чего предложены 
специальные (кас\-том\-ные) процедуры.
      


      Процедура формирования описаний задач из файлов формата TeX 
включает сле\-ду\-ющие этапы:
      \begin{itemize}
\item разбиение документа на отдельные задачи;
\item выделение текстовой час\-ти задачи (удаляются все формулы);
\item выделение и~объединение всех формул, относящихся к~задаче;
\item уточнение формульной семантики.
\end{itemize}

      В качестве основного инструмента для реализации этих этапов 
использовались регулярные выражения. Сами процедуры реализованы на 
языке Python. Для этапа выделения задач нуж\-но идентифицировать 
отличительные признаки текс\-та, поз\-во\-ля\-ющие принять решение о~том, 
является ли фрагмент текс\-та номером задачи, формулой или описанием. 
Например, уникальным признаком номера задачи служит наличие символа~<<№>>. 
Как правило, данный сим\-вол выделен жир\-ным шриф\-том с~по\-мощью 
тега <<$\backslash$textbf>>. В~ряде заданий име\-ют\-ся отсылки к~номерам других 
заданий, которые следует исключать. Ре\-зуль\-ти\-ру\-ющие регулярное 
выражение имеет вид: 

\begin{center}
\noindent
{\small \verb![^ ](\\textbf{)?(!{\sf №}\verb!){(.*?\})?!}
\end{center}

      
      Для выделения и/или исключения формул использовались сле\-ду\-ющие 
регулярные выражения:
{\small      \begin{verbatim}
             \\\(([\s\S]+?)\\\ )
             \\\[([\s\S]+?)\\\ ]
             \$([\s\S]+?)\$
\end{verbatim}
}

     \noindent
      Эти выражения позволяют выделить типичные для формата \TeX 
способы определения формул~--- пар\-ные теги <<$\backslash$(>> 
и~<<$\backslash$)>>, <<$\backslash[$>> и~<<$\backslash$]>>, <<\$>> 
и~<<\$>>.
      Кроме того, при формировании описаний задач пришлось учитывать 
воз\-мож\-ность наличия нескольких вариантов для одной формулировки. 
Каж\-дое задание может вклю\-чать несколько вариантов, обозначенных <<а)>>, 
<<б)>>, <<в)>> или <<1)>>, <<2)>>, <<3)>>. В~некоторых заданиях эта 
структура имеет два уровня, например нужно вы\-чис\-лить интеграл для 
нескольких областей. В~ряде заданий все варианты объединены в~одну 
формулу через символ~<<;>>. Из таких заданий выделялось столько задач, 
сколько вариантов пред\-став\-ле\-но фактически. В~итоговое описание каж\-дой 
задачи попадают все формулы, от\-но\-ся\-щи\-еся отдельно к~каж\-до\-му варианту 
и~имеющиеся в~общей формулировке задания. Выделение всех вариантов из 
задания обеспечивают:
      \begin{enumerate}[(1)]
\item регулярные выражения для по\-сле\-до\-ва\-тель\-ности символов вида <<1)>>, <<2)>>, <<3)>>:

{\small \begin{verbatim}
\s\d+\)(?=[\s\*]*\\\(|[\s\*]*\\\[|[\s\*]*\$)
       \end{verbatim}
       }
       
       \vspace*{-12pt}
       
\item регулярные выражения для по\-сле\-до\-ва\-тель\-ности символов вида <<а)>>,  <<б)>>, <<в)>>:

{\small \begin{verbatim}
          \s[а-я]\)(?=[\s\*~]*.)
       \end{verbatim}
       }

       
       
       \vspace*{-12pt}
       
\item процедура разбиения формул для случая, когда все варианты 
объединены в~одну формулу через символ <<;>>.
\end{enumerate}

      Наконец, отдельных преобразований потребовало сохранение 
семантики формулы, например запись функции косинус, которая может 
быть реализована тегом <<$\backslash$cos>> или по\-сле\-до\-ва\-тель\-ностью символов 
<<cos>>. Также надо было учитывать воз\-мож\-ные пропуски некоторых 
операций, например умножения, и~скобок вокруг аргументов функций. Если 
не учитывать такие ситуации при подготовке описаний задач, то это 
приведет к~не\-од\-но\-знач\-ностям на сле\-ду\-ющем этапе подготовки формул. Так, при 
токенизации будут выделены знаки операций, теги \TeX, последовательности 
латинских букв и~цифр. Соответственно, такие элементы, как <<xe>>, 
<<iy>>, <<zdz>>, <<cost>>, долж\-ны содержать два токена. Для этого 
требуется предварительная подготовка формул перед их помещением в~набор 
описаний задач: для учета особенностей формульной семантики выполняется 
процедура, вклю\-ча\-ющая
      \begin{enumerate}[(1)]
\item стандартизацию форматирования (удаляются не\-зна\-чи\-мые сим\-во\-лы, 
такие как неразрывные пробелы, точ\-ки и~запятые в~конце формулы; группы 
из нескольких пробелов заменяются одним; символы перевода строки 
и~возврата каретки заменяются на пробелы; символ <<;>> меняется на~<<,>>);
\item разбиение формулы на базовые токены с~использованием сле\-ду\-юще\-го 
регулярного выражения:
{\small \begin{verbatim}
(\d+|\d+\.?\d+|[\s,/\+\-\|\:\.\_\^\(\)\{\}
<>]|\\\{|\\[a-zA-Z\-\.]+)
\end{verbatim}
}



\noindent
Данное выражение позволяет выделить сле\-ду\-ющие типы токенов: 
пробельные символы, знаки пунктуации <<,>>, <<.>>, <<:>>; знаки операций 
<<$+$>>, <<$-$>>, <<$\backslash$>>, <<$<$>>, <<$>$>>; знаки ниж\-не\-го и~верх\-не\-го индекса <<\_>>, 
<<\!{\ptb{\^{\,}}}\!>>; скобки <<(>>, <<)>>, <<$\{$>>, <<$\}$>>, 
<<$\vert$>>; теги \TeX; целые и~вещественные чис\-ла;
\item разбиение элементов типа <<по\-сле\-до\-ва\-тель\-ность латинских букв>>, 
в~результате которого выделяются и~стандартизируются элементы, 
содержащие тригонометрические, \mbox{ги\-пер\-бо\-ли\-че\-ские} функ\-ции и~логарифмы, 
например элемент <<coshy>> заменяется на <<$\backslash\mathrm{cosh}$~y>>, 
а~также обрабатываются специальные имена <<Re>>, <<Im>>, <<matrix>>, 
<<res>> с~использованием сле\-ду\-юще\-го регулярного выражения:
{\small 
\begin{verbatim}
         ^(d[a-z]|Re|Im|matrix|res)
\end{verbatim}
}


\noindent
Данное выражение используется процедурой, поз\-во\-ля\-ющей, например, 
заменить элементы <<xdx>> на <<x~dx>>, <<Imz>> на <<Im~z>> и~т.\,д. 
Элементы, не относящиеся к~специальным именам, дробятся по\-бук\-вен\-но и~образуют отдельные токены.
\end{enumerate}

      Каждое сформированное описание задачи, естественно, включает 
и~правильный результат классификации~--- номер раздела учебного 
пособия, из которого было выделено задание.



\vspace*{-6pt}
      
      \section{Выделение признаков в~модели~задачи}
      
      \vspace*{-4pt}
      
      Обе части описания задач, текс\-то\-вая и~формульная, далее 
использовались для по\-стро\-ения двух векторов признаков.
      
      Вектор признаков из текстового описания задачи~--- это типичное 
пред\-став\-ле\-ние текс\-то\-вых данных на естественном языке в~машинном 
обуче\-нии, а~именно: модель по методу <<мешок слов>>~[25]. Тексты задач 
разбиваются на токены, из токенов формируется словарь, и~модель текс\-та 
получается как гис\-то\-грам\-ма~--- вектор весов всех элементов словаря, 
входящих в~описание задачи. В~качестве весов слов использовалась мера  
tf-idf~[26], т.\,е.\ час\-то\-та слова в~описании, умноженная на инверсную 
час\-то\-ту слова во всех описаниях (в~документе). Для выполнения токенизации 
текс\-та (лексического анализа) и~лемматизации (нормализации формы слова) 
использовалась биб\-лио\-те\-ка spaCy, {\sf https://spacy.io/},\linebreak\vspace*{-12pt}

\pagebreak

\end{multicols}

\begin{figure*} %fig2
\vspace*{1pt}
\begin{center}
   \mbox{%
\epsfxsize=153.297mm
\epsfbox{bos-2.eps}
}
\end{center}
\vspace*{-11pt}
\Caption{Модель описания задач}
\vspace*{-10pt}
\end{figure*}

\begin{multicols}{2}

\noindent
 для формирования 
словаря и~векторов~--- биб\-лио\-те\-ка scikit-learn, {\sf https://scikit-learn.org/stable/}. 
Из формируемого списка токенов исключались про\-белы, стоп-сло\-ва, знаки 
пунктуации, циф\-ры.\linebreak В~качестве токенов использовались леммы слов. 
В~со\-став словаря не включались слова, встре\-ча\-ющи\-еся более чем в~70\% 
описаний задач. Поскольку пред\-став\-ле\-ние типа <<мешок слов>> 
нечувствительно к~порядку слов в~предложении, дополнитель\-но задействовался 
механизм $n$-грамм. Наилучший результат дали биграммы, т.\,е.\ в~словарь 
помимо слов включались и~пары соседних слов.
{\looseness=1

}
      
      Вектор признаков из формульного описания задачи так\-же 
формировался методом <<мешок слов>>, но б$\acute{\mbox{о}}$льшая часть операций 
с~токенами по\-тре\-бо\-ва\-ла существенной кастомизации, словарь  
и~век\-тор-гис\-то\-грамма с~мерой tf-idf получались пол\-ностью аналогично 
текс\-то\-вой части.
      
      Для разбиения текс\-та формул на токены уже на этапе 
предварительной подготовки использовалось регулярное выражение, которое 
подготовило формульное описание для выделения базовых токенов (см.\ 
разд.~2). Далее для формирования ре\-зуль\-ти\-ру\-юще\-го спис\-ка токенов из него 
исключались пробельные символы, знак <<.>>, теги \TeX <<$\backslash$left>>, 
<<$\backslash$right>>, <<$\backslash$left.>> и~<<$\backslash$right.>>, которые влияют только на 
визуальное пред\-став\-ле\-ние формулы. Кроме того, в~процессе токенизации 
формул все элементы, со\-от\-вет\-ст\-ву\-ющие целым и~вещественным чис\-лам, 
заменялись на токен <<[number]>>, что позволило со\-кра\-тить объем словаря 
и~повысить точ\-ность классификации.
      
      В состав словаря включались все токены, вне за\-ви\-си\-мости от час\-то\-ты 
их появления в~описаниях. По\-пыт\-ка применить механизм $n$-грамм была 
сделана и~для формульного описания задачи, но она не привела к~успеху: 
результат классификации со словарем, содержащим $n$-грам\-мы ($n\hm=2, 
\ldots , 9$) оказался хуже. Также был опробован механизм формирования 
полиномиальных признаков, ока\-зав\-ший\-ся таким же нерезультативным.
      
      Два вектора признаков конкатенируются (рис.~2) и~передаются 
алгоритму обуче\-ния классификатора.

     \begin{table*}\small
     \begin{center}
     \tabcolsep=5.2pt
     \begin{tabular}{|c|c|c|c|c|c|c|}
     \multicolumn{7}{c}{Анализ качества классификации}\\
      \multicolumn{7}{c}{\ }\\[-6pt]
      \hline
Метод&C\_Text&Примечание&C\_Form&Примечание&C\_Comm&Примечание\\
\hline
\tabcolsep=0pt\begin{tabular}{c}Наивный\\ байесовский\end{tabular}&0,63&
\tabcolsep=0pt\begin{tabular}{c}Раздел 3 $f_1$\;=\;0,0\\
Раздел 7 $f_1$\;=\;0,18\end{tabular}&
0,46&\tabcolsep=0pt\begin{tabular}{c}Разделы 3, 5, 6, 7\\ имеют 
$f_1$\;=\;0,0\end{tabular}&\textbf{0,76}&\tabcolsep=0pt\begin{tabular}{c}Раздел 6\\ $f_1$\;=\;0,29\end{tabular}\\
\hline
Логит&0,75&Раздел 3 $f_1$\;=\;0,0&0,6\hphantom{9}&
\tabcolsep=0pt\begin{tabular}{c}Разделы 3, 6\\
 имеют $f_1$\;=\;0,0\end{tabular}&\textbf{0,89}&\tabcolsep=0pt\begin{tabular}{c}Раздел 6\\ $f_1$\;=\;0,7\end{tabular}\\
\hline
Перцептрон&0,87&
\tabcolsep=0pt\begin{tabular}{c}Раздел 8 имеет\\ минимальную $f_1$\;=\;0,71\end{tabular}&
0,74&
\tabcolsep=0pt\begin{tabular}{c}Раздел 6 имеет\\ минимальную 
$f_1$\;=\;0,5\end{tabular}&\textbf{0,93}&
\tabcolsep=0pt\begin{tabular}{c}Раздел 6\\ $f_1$\;=\;0,8\end{tabular}\\
\hline
\tabcolsep=0pt\begin{tabular}{c}Многослойная\\ сеть\end{tabular}&\textbf{0,89}&\tabcolsep=0pt\begin{tabular}{c}Раздел 8 имеет\\ минимальную 
$f_1$\;=\;0,71\end{tabular}&\textbf{0,79}&
\tabcolsep=0pt\begin{tabular}{c}Раздел 7 имеет\\ минимальную 
$f_1$\;=\;0,57\end{tabular}&\textbf{0,95}&\tabcolsep=0pt\begin{tabular}{c}Раздел 7\\ $f_1$\;=\;0,89\end{tabular}\\
\hline
     \end{tabular}
     \end{center}
     \end{table*}

\vspace*{-10pt}
      
\section{Результаты практической классификации}

\vspace*{-5pt}

      Сформированный в~предыду\-щем разделе набор описаний задач 
использовался для обучения сле\-ду\-ющих классификаторов.

\begin{enumerate}[1.]
\item Наивный байесовский классификатор~[27, 28]~--- самая прос\-тая модель 
классификации,\linebreak упро\-ща\-ющая ис\-сле\-ду\-емую за\-ви\-си\-мость вход--вы\-ход 
предположением о~не\-за\-ви\-си\-мости входных переменных. Поскольку 
классифицировались векторные данные, то применялся \mbox{вариант} 
классификатора, реализующий метод максимального правдоподобия в~предположении полиномиального распределения входа. Кроме того, меры 
 tf-idf сглаживались по методу Лапласа (описание реализации доступно по 
адресу {\sf https://scikit-learn.org/stable/modules/\linebreak naive\_bayes.html\#multinomial-naive-bayes)}.
\item Логистическая регрессия, точ\-нее мультиномиальная логистическая 
регрессия, или модель логит~[29--32], возможно, самый распространенный 
метод классификации. Детали реализации есть по адресу {\sf  
https://scikit-learn.org/stable/\linebreak modules/linear\_model.html\#logistic-regression}. 
Использовался вариант с~$l_2$-ре\-гу\-ля\-ри\-за\-ци\-ей и~приближенным алгоритмом 
оптимизации Брой\-де\-на--Флет\-че\-ра--Гольд\-фар\-ба--Шанно.
\item Однослойная нейронная сеть прямого распространения~[33, 34] 
с~пороговой функцией активации (перцептрон, {\sf  
https://scikit-learn.org/\linebreak stable/modules/linear\_model.html\#perceptron}).
\item Многослойная нейронная сеть прямого распространения~[33,34] 
с~двумя скрытыми слоями с~чис\-лом нейронов~80 и~20 и~функцией\linebreak 
активации $f(x)\hm= \max(0,x)$ ({\sf  
https://scikit-learn. org/stable/modules/neural\_networks\_supervised.\linebreak html\#neural-networks-supervised}).
\end{enumerate}

     Имеющийся набор описаний задач разбивался случайным образом на 
две равные час\-ти: первые~100~задач использовались для обуче\-ния всех 
четырех классификаторов, остав\-ши\-еся задачи~--- для контроля качества 
классификации. По\-стро\-ен\-ная модель задач дала раз\-мер словаря~167 для 
текс\-то\-во\-го описания и~70~--- для формульного.
     
     Качество классификации оценивается типовой метрикой <<точ\-ность--от\-зыв>> 
     (precision--recall)~\cite{35-bos}, т.\,е.\ гармоническим сред\-ним 
отношений результатов правильных классификаций к~их сумме с~чис\-лом 
ложноправильных результатов (точ\-ность) и~отношений результатов 
правильных классификаций к~их сумме с~чис\-лом ложноотрицательных 
результатов (от\-зыв\-чи\-вость). Эта метрика, известная как $f_1$-score, 
вычисляется для каждого из заданных классов классификации и~общая~--- 
для всех разделов и~всех~100~контрольных примеров. В~приведенной  
таб\-ли\-це результаты расчетов характеризует общая мет\-ри\-ка, а~некоторые 
комментарии к~величине $f_1$-score для отдельных классов даны в~форме 
примечаний. Суммарно выполнены три группы расчетов:
\begin{enumerate}[(1)]
\item классификация 
только по текс\-то\-во\-му описанию задачи (C\_Text);
\item классификация только 
по формульному описанию задачи (C\_Form); 
\item классификация по общему 
описанию задачи (C\_Comm).
\end{enumerate}
     

     
     В дополнение к~этим расчетам выполнялся эксперимент по увеличению 
размера обуча\-ющей выборки, в~котором~200~име\-ющих\-ся задач 
распределялись так: 150~--- для обуче\-ния; 50~--- для контроля. Этот 
эксперимент дал ожи\-да\-емый результат~--- качество всех алгоритмов выросло 
на 10\%--15\%, в~том числе многослойная сеть для модели C\_Comm дала  
$f_1$-score\;=\;1. Но этот результат уже вызывает сомнения с~точ\-ки зрения 
до\-сто\-вер\-ности оценки качества и~эскалирует проб\-ле\-му кардинального 
увеличения объема обуча\-ющей информации, которую в~таких задачах 
решать практически не\-воз\-можно.
     
\section{Выводы}

     Основной полученный в~статье результат~--- это доказательство 
принципиальной воз\-мож\-ности автоматизировать классификацию 
математических задач и~под\-твер\-дить принципиальную воз\-мож\-ность 
прак\-ти\-че\-ской интеграции такой технологии в~дей\-ст\-ву\-ющие ЭОС. В~качестве 
таковой авторам пред\-став\-ля\-ет\-ся сис\-те\-ма дистанционного обуче\-ния 
CLASS.NET~[36]. Анализируя результаты расчетов, мож\-но отметить 
ожи\-да\-емое превосходство многослойной нейронной сети прямого 
рас\-про\-стра\-не\-ния. Но важ\-нее отметить тот факт, что при\-ем\-ле\-мый результат 
дает только модель описания задач, вклю\-ча\-ющая оба набора признаков: 
и~текс\-то\-вый, и~формульный.
     

{\small\frenchspacing
 {%\baselineskip=10.8pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
\bibitem{1-bos}
\Au{Боголепова С.\,В.} Анализ опыта обуче\-ния (в~российском вузе)  
в~он\-лайн-фор\-ма\-те в~период пандемии~// Отечественная и~зарубежная педагогика, 
2021. Т.~1. №\,4(77). С.~107--122.
\bibitem{2-bos}
\Au{Кусаинов~А.\,К.} Оценка качества современной учебной литературы~// Ценности 
и~смыслы, 2019. №\,1(59). С.~8--19.
\bibitem{3-bos}
\Au{Мартюшова~Я.\,Г.} Теоретические основания конструирования электронных 
учебников для студентов технических университетов~// Отечественная и~зарубежная 
педагогика, 2018. Т.~1. №\,5(54). С.~151--165.
\bibitem{4-bos}
\Au{Босов А.\,В., Мартюшова~Я.\,Г., Наумов~А.\,В.} Выбор на\-прав\-ле\-ний оценивания 
качества электронных средств обуче\-ния для организации учебного процесса вуза~// 
Сибирский педагогический ж., 2022. №\,2. С.~54--63.
\bibitem{5-bos}
\Au{Zanibbi R., Blostein~D., Cordy~J.\,R.} Recognizing mathematical expressions using tree 
transformation~// IEEE T.~Pattern Anal., 2002. Vol.~24. No.\,11. P.~1455--1467.
\bibitem{6-bos}
\Au{Blostein D., Grbavec~A.} Recognition of mathematical notation~// Handbook of character 
recognition and document image analysis~/ Eds. P.\,S.\,P.~Wang, H.~Bunke.~--- World 
Scientific Publishing Co., 1997. P.~557--582.
\bibitem{7-bos}
\Au{Chan K.\,F., Yeung D.\,Y.} Mathematical expression recognition: A~survey~// Int. J. Doc. Anal. Recog., 2000. 
Vol.~3. No.\,1. P.~3--15.
\bibitem{8-bos}
\Au{Guidi F., Sacerdoti~Coen~C.} A~survey on retrieval of mathematical knowledge~// Mathematics 
Computer Science, 2016. Vol.~10. No.\,4. P.~409--427.
\bibitem{9-bos}
\Au{Knuth D.\,E.} The \TeX book.~--- Reading, MA, USA: Addison-Wesley, 1984. 483~p.
\bibitem{10-bos}
\Au{Libbrecht P., Melis~E.} Methods to access and retrieve mathematical content in 
ActiveMath~//  Congress (International)  on Mathematical Software.~--- Berlin, Heidelberg: 
Springer, 2006. P.~331--342.
\bibitem{11-bos}
\Au{Libbrecht P., Melis~E.} Semantic search in \mbox{LeActiveMath}~//  1st WebALT Conference and 
Exhibition Proceedings.~---  Eindhoven, Holland, 2006. P.~97--109.
\bibitem{12-bos}
\Au{Miner R., Munavalli~R.} An approach to mathematical search through query formulation 
and data normalization~// Workshop (International) on Mathematical Knowledge 
Management.~--- Heidelberg: Springer, 2007. P.~342--355.
\bibitem{13-bos}
\Au{\mbox{Mi{\!\ptb{\!\v{s}}}utka}~J., \mbox{Galambo{\!\ptb{\!\v{s}}}}~L.} System description: Egomath2 as a tool 
for mathematical searching on wikipedia.org~//  Conference (International) on Intelligent 
Computer Mathematics.~--- Berlin, Heidelberg: Springer, 2011. P.~307--309.
\bibitem{14-bos}
\Au{Miller B.\,R., Youssef A.} Technical aspects of the digital library of mathematical 
functions~// Ann. Math. Artif. Intel., 2003. Vol.~38. No.\,1. P.~121--136.
\bibitem{15-bos}
\Au{Sojka P., \mbox{L$\acute{\iota}$\!{\!\ptb{\v{s}}}ka}~M.} Indexing and searching 
mathematics in digital libraries~// Conference (International) on Intelligent Computer 
Mathematics.~--- Berlin, Heidelberg: Springer, 2011. P.~228--243. 
\bibitem{16-bos}
\Au{Kohlhase M., Anca~S., Jucovschi~C., Palomo~A. G., Sucan~I.\,A.} MathWebSearch~0.4: 
A~semantic search engine for mathematics, 2008. {\sf  
http://mathweb.org/\linebreak projects/mws/pubs/mkm08.pdf}.
\bibitem{17-bos}
\Au{Hu X., Gao~L.\,C., Lin~X.\,Y., Zhi~T., Lin~X.\,F., Baker~J.\,B.} Wikimirs: A~mathematical 
information retrieval system for Wikipedia~// 13th ACM/IEEE-CS Joint Conference on Digital 
Libraries Proceedings, 2013. P.~11--20. 

\bibitem{19-bos} %18
\Au{Liu H., Tian~X., Tian~B., Yang~F., Li~X.} An improved indexing and matching method for 
mathematical expressions based on inter-relevant successive tree~// J.~Computer  
Communications, 2016. Vol.~4. No.\,15. P.~63--78.

\bibitem{18-bos} %19
\Au{Tian X.} A~mathematical indexing method based on the hierarchical features of operators in 
formulae~// 2nd  Conference (International) on Automatic Control and Information 
Engineering.~--- Atlantis Press, 2017. P.~49--52.

\bibitem{20-bos}
\Au{Биряльцев Е.\,В., Гусенков~А.\,М., Жибрик~О.\,Н.} Некоторые подходы к~разметке 
естественнонаучных текс\-тов, содержащих математические выражения~// Ученые записки 
Казанского университета. Сер. Фи\-зи\-ко-ма\-те\-ма\-ти\-че\-ские науки, 2014. T.~156. №\,4. C.~133--148.
\bibitem{21-bos}
\Au{Gusenkov A., Gusenkova~P., Palacheva~Y., Zhibrik~O.} Extended functionality of 
mathematical formulae search service~// 12th Conference (International) on Advances in 
Semantic Processing~/ Eds. M.~Spranger, P.~Lorenz.~--- IARIA XPS Press, 2018. P.~35--41.
\bibitem{22-bos}
\Au{Битюков Ю.\,И., Мартюшова~Я.\,Г.} Решение задач по тео\-рии функций 
комплексного переменного.~--- М.: МАИ, 2022. 87~с.
\bibitem{23-bos}
\Au{Краснов М.\,Л., Киселев~А.\,И., Макаренко~Г.\,И.} Функции комплексного 
переменного: задачи и~примеры с~по\-дроб\-ны\-ми решениями.~--- М.: Либ\-ро\-ком, 2012. 208~с.
\bibitem{24-bos}
\Au{Краснов М.\,Л., Киселев~А.\,И., Макаренко~Г.\,И.} Операционное исчисление. Тео\-рия 
устойчивости: задачи и~примеры с~по\-дроб\-ны\-ми решениями.~--- М.: Либ\-ро\-ком, 2014. 176~с.
\bibitem{25-bos}
\Au{McTear M.\,F., Callejas~Z., Griol~D.} The conversational interface.~--- Cham: Springer, 2016. 422~p.
\bibitem{26-bos}
\Au{Salton G., McGill~M.\,J.} Introduction to modern information retrieval.~--- New York, NY, USA: McGraw-Hill, 1983. 448~p.
\bibitem{27-bos}
\Au{Minsky~M.} Steps toward artificial intelligence~// P.~IRE, 1961. Vol.~49. No.\,1. P.~8--30.
\bibitem{28-bos}
\Au{McCallum A., Nigam~K.} A~comparison of event models for naive Bayes text 
classification~// Workshop on Learning for Text Categorization Proceedings, 1998. Vol.~752. No.\,1. P.~41--48.
\bibitem{29-bos}
\Au{Cox D.\,R.} Some procedures connected with the logistic qualitative response curve~// 
Research papers in probability and statistics~/ Ed. F.\,N.~David.~--- London: Wiley, 1966. P.~55--71.
\bibitem{30-bos}
\Au{Theil H.} A~multinomial extension of the linear logit model~// Int. Econ. 
Rev., 1969. Vol.~10. No.\,3. P.~251--259.

\bibitem{32-bos}
\Au{Hosmer D.\,W., Lemeshow~S.} Applied logistic regression.~--- New York, NY, USA: Wiley, 1989. 307~p.

\bibitem{31-bos} %32
\Au{Hastie~T., Tibshirani~R., Friedman~J.} The elements of statistical learning.~--- 2nd ed.~---  New York, NY, USA: Springer, 2009. 533~p.

\bibitem{33-bos}
\Au{Галушкин А.\,И.} Син\-тез многослойных сис\-тем распознавания образов.~--- М.: Энергия, 1974. 368~c.
\bibitem{34-bos}
\Au{Haykin S.} Neural networks and learning machines.~--- 3rd ed.~--- Upper Saddle River, NJ, USA: Pearson Education, 2009. 906~p.
\bibitem{35-bos}
\Au{Van Rijsbergen C.\,J.} Information retrieval.~--- 2nd ed.~--- Butterworth-Heinemann, 1979. 208~p.
\bibitem{36-bos}
\Au{Наумов А.\,В., Джумурат~А.\,С., Иноземцев А.\,О.} Сис\-те\-ма дистанционного 
обуче\-ния математическим дисциплинам CLASS.NET~// Вестник компьютерных 
и~информационных технологий, 2014. №\,10.\linebreak С.~36--44.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-9pt}

\hfill{\small\textit{Поступила в~редакцию 15.09.22}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{-2pt}

\def\tit{TECHNOLOGY FOR~CLASSIFICATION OF~CONTENT TYPES OF~E-TEXTBOOKS}


\def\titkol{Technology for~classification of~content types of~e-textbooks}


\def\aut{A.\,V.~Bosov and A.\,V.~Ivanov}

\def\autkol{A.\,V.~Bosov and A.\,V.~Ivanov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-8pt}


\noindent
Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, 
44-2~Vavilov Str., Moscow 119333, Russian Federation


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2022\ \ \ volume~16\ \ \ issue\ 4}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2022\ \ \ volume~16\ \ \ issue\ 4
\hfill \textbf{\thepage}}}

\vspace*{3pt} 


\Abste{The problem of automatic classification of the educational content of the e-learning system, 
represented by tasks or practical examples, is being solved. A~promising direction in the development of 
e-learning systems is the assessment of the quality of educational content. Carrying out such an 
assessment is the rationale for the need to create an automated classifier. The main idea is to model the 
content with an object with two properties~--- a textual description in natural language and a~set of 
formulas in the language of scientific computer layout \TeX. Using tasks from the electronic textbook on 
the theory of functions of a~complex variable, a~data set was prepared and labeled in accordance with this 
model. Four text classification algorithms were trained~--- naive Bayes classifier, logistic regression, 
single-layer and multilayer feedforward neural networks. For these classifiers, a number of comparative 
experiments were carried out comparing the classification accuracy using text content only, formula 
content only, and the full model. As a~result of the experiment, not only a formal comparison of the 
algorithms was carried out but also the fundamental advantage of the full model was shown. That is, 
when using both textual description and representation of formulas in the \TeX language, the 
classification accuracy significantly exceeds one-factor algorithms and confirms the readiness of the 
technology for practical application.}

\KWE{e-learning system; training content; classification tasks and algorithms; content quality 
assessment; machine learning}

 \DOI{10.14357/19922264220410} 

\vspace*{-6pt}

 \Ack
    \noindent
 The research was supported by the Russian Science Foundation (project No.\,22-28-00588). 
 The research was carried out using the
  infrastructure of the Shared Research Facilities ``High Performance Computing and Big Data'' (CKP ``Informatics'') of FRC CSC RAS (Moscow).


\vspace*{6pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
 
% \vspace*{-2pt}
 
\bibitem{1-bos-1}
\Aue{Bogolepova, S.\,V.} 2021. Analiz opy\-ta obuche\-niya (v~ros\-siy\-skom vu\-ze) v~on\-layn-for\-ma\-te 
v~pe\-ri\-od pan\-de\-mii [Analysis of students' online learning experience (at university in Russia) at the time 
of the pandemic]. 
\textit{Otechestvennaya i~zarubezhnaya pedagogika} [Domestic and Foreign Pedagogy]  
1(4-77):107--122.
\bibitem{2-bos-1}
\Aue{Kusainov, A.\,K.} 2019. Otsen\-ka ka\-chest\-va sov\-re\-men\-noy ucheb\-noy li\-te\-ra\-tu\-ry 
[Quality assessment of modern educational literature]. \textit{Tsennosti i~smysly} [Values and Meanings] 1(59):8--19.
\bibitem{3-bos-1}
\Aue{Martyushova, Ya.\,G.} 2018. Teo\-re\-ti\-che\-skie osno\-va\-niya kons\-tru\-i\-ro\-va\-niya elekt\-ron\-nykh ucheb\-ni\-kov 
dlya stu\-den\-tov tekh\-ni\-che\-skikh uni\-ver\-si\-te\-tov [Theoretical foundations of designing electronic textbooks 
for students of technical universities]. \textit{Otechestvennaya i~zarubezhnaya pedagogika} [Domestic 
and Foreign Pedagogy] 1(5-54):151--165.
\bibitem{4-bos-1}
\Aue{Bosov, A.\,V., Ya.\,G.~Martyushova, and A.\,V.~Naumov.} 2022. Vy\-bor na\-prav\-le\-niy otse\-ni\-va\-niya 
ka\-chest\-va elekt\-ron\-nykh sredstv obuche\-niya dlya or\-ga\-ni\-za\-tsii ucheb\-no\-go pro\-tses\-sa vu\-za [Directions 
selection for assessing the quality of electronic learning tools for the organization of the educational 
process of the higher educational process]. \textit{Sibirskiy pedagogicheskiy zh.} [Siberian 
Pedagogical~J.] 2:54--63.
\bibitem{5-bos-1}
\Aue{Zanibbi, R., D.~Blostein, and J.\,R.~Cordy.} 2002. Recognizing mathematical expressions using 
tree transformation. \textit{IEEE T. Pattern Anal.} 24(11):1455--1467.
\bibitem{6-bos-1}
\Aue{Blostein, D., and A.~Grbavec.} 1997. Recognition of mathematical notation. \textit{Handbook of 
character recognition and document image analysis}. Eds. P.\,S.\,P.~Wang and H.~Bunke. World 
Scientific Publishing Co. 557--582.
\bibitem{7-bos-1}
\Aue{Chan, K.\,F., and D.\,Y.~Yeung.} 2000. Mathematical expression recognition: A~survey. 
\textit{Int. J.~Doc. Anal. Recog.} 3(1):3--15.
\bibitem{8-bos-1}
\Aue{Guidi, F., and C.~Sacerdoti Coen.} 2016. A~survey on retrieval of mathematical knowledge. 
\textit{Mathematics Computer Science} 10(4):409--427.
\bibitem{9-bos-1}
\Aue{Knuth, D.\,E.} 1984. \textit{The \TeX book}. Reading, MA: Addison-Wesley. 483~p.
\bibitem{10-bos-1}
\Aue{Libbrecht, P., and E.~Melis.} 2006. Methods to access and retrieve mathematical content in 
activemath. \textit{Congress (International) on Mathematical Software Proceedings}.  Berlin, Heidelberg: 
Springer. 331--342.
\bibitem{11-bos-1}
\Aue{Libbrecht, P., and E.~Melis.} 2006. Semantic search in \mbox{LeActiveMath}. \textit{1st WebALT 
Conference and Exhibition Proceedings}.  Eindhoven, Holland. 97--109.
\bibitem{12-bos-1}
\Aue{Miner R., and R.~Munavalli.} 2007. An approach to mathematical search through query 
formulation and data normalization.  \textit{Workshop (International) on Mathematical Knowledge 
Management Proceedings}. Heidelberg: Springer. 342--355.
\bibitem{13-bos-1}
\Aue{\mbox{Mi{\!\ptb{\v{s}}}utka}, J., and L.~\mbox{Galambo{\!\ptb{\v{s}}}}}. 2011. System 
description: Egomath2 as a~tool for mathematical searching on wikipedia.org. \textit{Conference 
(International) on Intelligent Computer Mathematics Proceedings}. Berlin, Heidelberg: Springer. 307--309.
\bibitem{14-bos-1}
\Aue{Miller, B.\,R., and A.~Youssef.} 2003. Technical aspects of the digital library of mathematical 
functions. \textit{Ann. Math. Artif. Intel.} 38(1):121--136.
\bibitem{15-bos-1}
\Aue{Sojka, P., and M.~\mbox{L$\acute{\mbox{{\ptb{\!\i}}}}${\!\ptb{\v{s}}}ka}.} 2011. Indexing and searching 
mathematics in digital libraries. \textit{Conference (International) on Intelligent Computer Mathematics 
Proceedings}. Berlin, Heidelberg: Springer. 228--243. 
\bibitem{16-bos-1}
\Aue{Kohlhase, M., S.~Anca, S.~Jucovschi, A.\,G.~Palomo, and I.\,A.~Sucan.} 2008. 
MathWebSearch~0.4: A~semantic search engine for mathematics. Available at: {\sf  
http://mathweb. org/projects/mws/pubs/mkm08.pdf} (accessed November~17, 2022).
\bibitem{17-bos-1}
\Aue{Hu, X., L.\,C.~Gao, X.\,Y.~Lin, T.~Zhi, X.\,F.~Lin, and J.\,B.~Baker.} 2013. Wiki-mirs: 
A~mathematical information retrieval system for Wikipedia. \textit{13th ACM/IEEE-CS Joint 
Conference on Digital Libraries Proceedings}. 11--20.

\bibitem{19-bos-1}
\Aue{Liu, H., X.~Tian, B.~Tian, F.~Yang, and X.~Li.} 2016. An improved indexing and matching 
method for mathematical expressions based on inter-relevant successive tree. \textit{J.~Computer  
Communications} 4(15):63--78.
\bibitem{18-bos-1}
\Aue{Tian, X.} 2017. A~mathematical indexing method based on the hierarchical features of operators in 
formulae. \textit{2nd  Conference (International) on Automatic Control and Information Engineering 
Proceedings}. Atlantis Press. 49--52.

\bibitem{20-bos-1}
\Aue{Biryaltsev, E.\,V., A.\,M.~Gusenkov, and O.\,N.~Zhibrik.} 2014. Ne\-ko\-to\-rye pod\-kho\-dy k~raz\-met\-ke 
estest\-ven\-no\-na\-uch\-nykh teks\-tov, so\-der\-zha\-shchikh ma\-te\-ma\-ti\-che\-skie vy\-ra\-zhe\-niya [Some approaches to the 
markup of natural science texts containing mathematical expressions]. \textit{Uchenye zapiski 
Kazanskogo universiteta. Ser. Fiziko-matematicheskie nauki} [Proceedings of Kazan University. Physics 
and mathematics ser.] 156(4):133--148.
\bibitem{21-bos-1}
\Aue{Gusenkov, A., P.~Gusenkova, Y.~Palacheva, and O.~Zhibrik.} 2018. Extended functionality of 
mathematical formulae search service. \textit{12th Conference (International) on Advances in Semantic 
Processing}. Eds. M.~Spranger and P.~Lorenz. IARIA XPS Press. 35--41.
\bibitem{22-bos-1}
\Aue{Bityukov, Yu.\,I., and Ya.\,G.~Martyushova.} 2022. \textit{Reshenie zadach po teorii funktsiy 
kompleksnogo peremennogo} [Solving problems on the theory of functions of a~complex variable]. 
Moscow: MAI. 87~p.
\bibitem{23-bos-1}
\Aue{Krasnov, M.\,L., A.\,I.~Kiselev, and G.\,I.~Makarenko.} 2012. \textit{Funk\-tsii komp\-leks\-no\-go 
pe\-re\-men\-no\-go: za\-da\-chi i~pri\-me\-ry s~po\-drob\-ny\-mi re\-she\-ni\-yami} [Functions of 
a~complex variable: Problems and examples with detailed solutions]. Moscow: Librokom. 
208~p.
\bibitem{24-bos-1}
\Aue{Krasnov, M.\,L., A.\,I.~Kiselev, and G.\,I.~Makarenko.} 2012. \textit{Ope\-ra\-tsi\-on\-noe is\-chis\-le\-nie. 
Teo\-riya ustoy\-chi\-vosti: za\-da\-chi i~pri\-me\-ry s~po\-drob\-ny\-mi re\-she\-ni\-yami} [Operational 
calculus. Stability theory: Problems and examples with detailed solutions]. Moscow: 
Librokom. 176~p.
\bibitem{25-bos-1}
\Aue{McTear, M.\,F., Z.~Callejas, and D.~Griol.} 2016. \textit{The conversational interface}. Cham: Springer. 422~p.
\bibitem{26-bos-1}
\Aue{Salton, G., and M.\,J.~McGill.} 1983. \textit{Introduction to modern information retrieval}. New 
York, NY: McGraw-Hill. 448~p.
\bibitem{27-bos-1}
\Aue{Minsky, M.} 1961. Steps toward artificial intelligence. \textit{P.~IRE} 49(1):8--30.
\bibitem{28-bos-1}
\Aue{McCallum, A., and K.~Nigam.} 1998. A~comparison of event models for naive bayes text 
classification. \textit{Workshop on Learning 
for Text Categorization Proceedings}. 752(1):41--48.
\bibitem{29-bos-1}
\Aue{Cox, D.\,R.} 1966. Some procedures connected with the logistic qualitative response curve. 
\textit{Research papers in probability and statistics}. Ed. F.\,N.~David. London: Wiley. 55--71.
\bibitem{30-bos-1}
\Aue{Theil, H.} 1969. A~multinomial extension of the linear logit model. \textit{Int. 
Econ. Rev.} 10(3):251--259.

\bibitem{32-bos-1}
\Aue{Hosmer, D.\,W., and S.~Lemeshow.} 1989. \textit{Applied logistic regression}. New York, NY: 
Wiley. 307~p.

\pagebreak

\bibitem{31-bos-1} %32
\Aue{Hastie, T., R.~Tibshirani, and J.~Friedman. 2009.} \textit{The elements of statistical learning}. 2nd 
ed. New York, NY: Springer. 533~p.

\bibitem{33-bos-1}
\Aue{Galushkin, A.\,I.} 1974. \textit{Sin\-tez mno\-go\-sloy\-nykh sis\-tem ras\-po\-zna\-va\-niya ob\-ra\-zov} [Synthesis 
of multilayer image recognition systems]. Moscow: Energiya. 368~p.
\bibitem{34-bos-1}
\Aue{Haykin, S.} 2009. \textit{Neural networks and learning machines}. 3rd ed. Upper Saddle River, 
NJ: Pearson Education. 906~p.
\bibitem{35-bos-1}
\Aue{Van Rijsbergen, C.\,J.} 1979. \textit{Information retrieval}. 2nd ed. Butterworth-Heinemann. 208~p.
\bibitem{36-bos-1}
\Aue{Naumov, A.\,V., A.\,S.~Dzhumurat, and A.\,O.~Inozemtsev.} 2014. Sis\-te\-ma dis\-tan\-tsi\-on\-no\-go 
obuche\-niya ma\-te\-ma\-ti\-che\-skim dis\-tsip\-li\-nam CLASS.NET [Distance learning system for mathematical 
disciplines CLASS.NET]. \textit{Vestnik komp'yuternykh i~informatsionnykh tekhnologiy} [Herald of 
Computer and Information Technologies] 10:36--44.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received September 15, 2022}}

\Contr

\noindent
\textbf{Bosov Alexey V.} (b.\ 1969)~--- Doctor of Science in technology, principal scientist, Institute of 
Informatics Problems, Federal Research Center ``Computer Science and Control'' of the Russian 
Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, Russian Federation; 
\mbox{AVBosov@ipiran.ru}

\vspace*{3pt}

\noindent
\textbf{Ivanov Alexey V.} (b.\ 1976)~--- Candidate of Science (PhD) in technology, senior scientist, 
Institute of Informatics Problems, Federal Research Center ``Computer Science and Control'' of the 
Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, Russian Federation; 
\mbox{AIvanov@ipiran.ru}


\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература}    