\def\stat{kuzn}

\def\tit{ВЕРОЯТНОСТНО-СТАТИСТИЧЕСКАЯ ОЦЕНКА 
АДЕКВАТНОСТИ ИНФОРМАЦИОННЫХ ОБЪЕКТОВ}

\def\titkol{Вероятностно-статистическая оценка 
адекватности информационных объектов}

\def\autkol{Л.\,А.~Кузнецов}
\def\aut{Л.\,А.~Кузнецов$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

%{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
%{Работа поддержана Российским фондом фундаментальных исследований
%(проекты 11-01-00515а и 11-07-00112а), а также Министерством
%образования и науки РФ в рамках ФЦП <<Научные и
%научно-педагогические кадры инновационной России на 2009--2013~годы>>.}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Липецкий государственный технический университет, kuznetsov@stu.lipetsk.ru}


\Abst{Приведены математические основы и оригинальная методология разработки 
систем оценки семантической близости информационных объектов (ИО), представленных на 
естественном языке. Вводится ве\-ро\-ят\-но\-ст\-но-ста\-ти\-сти\-че\-ское представление 
сопоставляемых ИО. Используется теория информации для 
оценки уровня семантической близости ИО. Методология 
доведена до алгоритмов ее реализации в виде соответствующей автоматизированной 
системы. Представлены результаты практической проверки эффективности методологии. 
}

\vspace*{2pt}

\KW{информационные объекты; естественный язык; семантическая адекватность; 
вероятностная модель; теория информации}

\vspace*{6pt}

 \vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}
      
            \label{st\stat}

\section{Введение. Информация, знания, семантический анализ}
   
   Основным мотивом перехода от индустриальной к постиндустриальной 
модели развития в промышленно развитых странах, начавшегося в конце 
прошлого века, является стремительное увеличение скорости развития науки 
и знания. В~постиндустриальной модели развития, по мнению ведущих 
западных ученых в области социального развития и управления, 
принципиальным является изменение статуса и значения информации, науки 
и знания, которые становятся важнейшими факторами, определяющими 
эволюцию общества. 
   
   Питер Ф.~Друкер, признанный специалист в области организационного 
управления, пишет: <<Изменение значения знания, начавшееся 250~лет тому 
назад, преобразовало общество и экономику. Знание стало сегодня основным 
условием производства. Традиционные <<факторы производства>>~--- земля 
(природные ресурсы), рабочая сила и капитал~--- не исчезли, но приобрели 
второстепенное значение. Эти ресурсы можно получить, причем без особого 
труда, если есть необходимые знания>>~\cite{1-k}. 
   
   Информация и знания становятся главной движущей силой 
экономического развития и перехо-\linebreak дят из категории бесплатного 
общественного бла-\linebreak га в категорию товара. В~промышленно развитых\linebreak \mbox{странах} 
разработка и внедрение технологических инноваций~--- решающий фактор 
социального и экономического развития, залог экономической безопасности. 
В~США, по оценкам американских специалистов, прирост душевого 
национального дохода благодаря этому фактору составляет 90\%. 
   
   Беспрецедентный рост потока информации и знаний, скорости их 
передачи и возможностей доступа на первый план научных проблем 
выдвигает разработку технологий их автоматической обработки. Б$\acute{\mbox{о}}$льшая 
часть существующих и вновь формируемых знаний и информации 
представлена на естественном языке. 

Одной из актуальных, 
фундаментальных проблем в области обработки информации становится 
обеспечение возможности формального семантического сравнения, оценки 
семантической \mbox{бли\-зости} ИО, представленных 
на естественном языке. Разработка формализованных технологий оценки 
семантической близости ИО позволила бы перейти к практической 
реализации важных задач в сфере обработки информации, распространения 
знаний и образования. 
   
   В настоящее время в литературе задача семантического сравнения двух 
текстов, в основном, рас\-смат\-ри\-ва\-ется в контексте дубликатов в 
   веб-докумен\-тах и в системах автоматизированного перевода. При 
поиске дубликатов опираются на число слов, совпавших в двух текстах. 
Алгоритм сравнения на основе шинглов является наиболее простым и 
распространенным. Такой подход используется для нахождения копий 
текстов, полученных копированием и перестановкой слов, но он не позволяет 
оценить семантическую близость текстов.
   
   При более сложном анализе текстов учитывается структура входящих в 
них предложений. В~предложениях выделяются элементы (слова или группы 
слов) и сопоставляются определенные шаблоны для этих элементов. Данный 
подход описан в книге~\cite{2-k} и используется в ряде кандидатских 
диссертаций. 
   
   Однако задача оценки информационной бли\-зости двух текстов в 
обнаруженных автором работах не затрагивается. Используемые там 
концепции не ориентированы на ее решение и не могут быть использованы в 
качестве основы для ее решения.
   
   В данной статье предлагается оригинальная методология оценки 
информационной близости текстов на основании вероятностно-ста\-ти\-сти\-че\-ско\-го 
подхода и теории информации. Реализация методологии 
позволит перейти к практическому решению разнообразных задач, в которых 
требуется определять меру информационной адекватности\linebreak документов, 
представленных на естественном языке. В~част\-ности, разработанная 
концепция будет использована для синтеза автоматизированных сис\-тем 
оценки уровня знаний. 

\section{Формализация анализа текстов}

   Развитие информационных технологий, предо\-став\-ля\-ющих широкие 
возможности ав\-то\-ма\-ти\-зи\-рован\-но\-го анализа и обработки вербально 
пред\-став\-лен\-ной информации, существенно повысило интерес к разработке 
формальных методов исследования и сопоставления текстов. Современные 
компьютерные системы позволяют хранить и обрабатывать практически 
неограниченные объемы текстовой информации. Это стимулирует 
разработку формальных методов для поддержки выполнения постоянно 
расширяющихся и углубляющихся исследований информации, 
представленной на естественном языке. В~настоящее время интенсивно 
разрабатываются формальные методы, позволяющие автоматизировать 
решение задач в области морфологического, синтаксического и 
семантического анализа текстовой информации. 
   
   Из имеющихся публикаций следует, что методологии различных видов 
анализа базируются на сходных концепциях и достаточно близки по своему 
содержанию. Формализация морфологического анализа направлена на 
алгоритмическое пред\-став\-ле\-ние грамматики русского языка. Час\-ти речи 
русского языка определены, однозначно определены формы, в которых они 
могут быть, определены правила, следуя которым должно осуществляться 
изменение слов, принадлежащих к различным час\-тям речи при образовании 
соответствующих форм. Значительная часть правил изменения частей речи 
уже отражена в словарях. Все правила могут быть представлены в виде 
соответствующих процедур, функций, подпрограмм и~т.\,п. В~соответствии 
с имеющимися правилами может быть идентифицировано, какой частью 
речи является конкретное слово, в какой форме оно находится. Поэтому 
может быть написана программа, обеспечивающая автоматизированное 
выполнение морфологического анализа, так что на ее вход будет поступать 
слово предложения, а на выходе она выдаст результат анализа: какой частью 
речи является данное слово и в какой форме оно находится. 
   
   Формализация синтаксического анализа~--- задача также понятная: 
существует синтаксис русского языка, представляющий свод правил, следуя 
которым могут быть достаточно четко определены члены предложения. Раз 
правила существуют, то их можно представить в виде набора процедур, 
обеспечивающих выявление состояния (роли) каждого слова в предложении. 
Правила и процедуры могут быть более или менее сложными, но 
принципиально то, что правила имеются, а следовательно, и процедуры 
могут быть синтезированы по ним. На основании этих процедур может быть 
разработана система синтаксического анализа, которая, получая на свой вход 
предложение, выполнит его разбор и анализ и на выходе, как примерный 
ученик выдаст о каждом слове, входящем в предложение, информацию: 
каким его членом оно является. 
   
   Проблема семантического анализа текстов интенсивно исследуется в 
различных аспектах: разрабатываются правила и алгоритмы анализа 
предложений, выявления их структуры, установления соответствия между 
разноязычными текстами, поиска информации и~т.\,д. При этом, однако, 
формализация семантического анализа ка\-ко\-го-ли\-бо одноязычного текста 
или даже одного предложения представляется задачей весьма малопонятной. 
   
   Под формализацией обычно понимается однозначное математическое 
представление существующих правил, которые, возможно, в текстовом, 
вербальном виде содержат определение способа извлечения нужных 
сведений из начальных, исходно заданных данных. В~контексте 
формализации семантического анализа математическому оформлению 
должны подлежать правила, позволяющие извлечь из слова его смысл. Но, в 
отличие от морфологии и синтаксиса, не существует ка\-ких-ли\-бо 
формальных семантических правил, следуя которым можно было бы 
установить смысл, вложенный в предложение или в каждое отдельное его 
слово. Поэтому невозможно представить систему семантического анализа в 
виде упорядоченного набора правил или предписаний, которая (по аналогии 
с системами морфологического или синтаксического анализа) получала бы 
на входе предложение или слово, а на выходе выдавала бы его смысл. Ибо 
слово и есть его смысл. В~толковом словаре, конечно, разъясняется смысл 
отдельных слов, но, в конечном итоге, это разъяснение представляет 
сопоставление одному слову других слов, близких по смыслу, и следует из 
словаря, а не из каких-либо правил, которые можно было бы формализовать.
   
Следовательно, если морфологический и синтаксический анализ действительно 
представляют анализ в соответствии со смыслом этого слова, т.\,е.\ разбор 
предложения на составляющие его элементы и выяснение их роли и 
состояния, то семантический анализ может пониматься только в смысле 
сравнения и выяснения смысловой близости разных слов и текстов. Только 
при наличии эталона анализируемого предложения, смысл которого 
известен, опираясь на словари, в которых отражена семантическая близость 
отдельных слов и словосочетаний, может быть получен ответ, что 
анализируемое предложение находится в некотором соответствии с эталоном 
и, следовательно, имеет определенный смысл. Например, при переводе 
смысл на язы\-ке-ори\-ги\-на\-ле принимается за известный эталон. С~помощью 
словаря, в котором имеется соответствие между словами и 
словосочетаниями, находится соответствующее выражение на другом языке. 
Важно понимать, что соответствие при этом следует не из слов, а из словаря. 
   
Таким образом, представляется, что при сопоставлении одноязычных текстов 
более правильно говорить не об их семантическом анализе, а об 
уста\-нов\-ле\-нии уровня их информационной адекватности, об определении 
взаимного количества информации, общего для сравниваемых текстов, из 
общего объема информации, содержащегося в одном из них, принимаемом за 
эталонный текст. 
   
   Автоматизированная технология должна обеспечивать реализацию 
функций определения пересечения, общей части дубля и эталона. Для этого в 
автоматизированной технологии должны быть разработаны формально-математические 
инструменты для представления текстов дубля и эталона в 
виде, позволяющем оценить количество информации, содержащейся в них, 
определить долю информации в дубле, отражающую содержание эталона, и 
на этой основе сформировать оценку их семантической близости. 
   
\section{Ограниченность возможностей детерминированного 
подхода}
   
   Имеется принципиальное базовое отличие семантического анализа от 
морфологического и синтак\-си\-че\-ско\-го. Отмеченное кратко выше показывает, 
что объектом морфологического и синтаксического анализа является 
фиксированный, \mbox{полностью} однозначно определенный текстовый фрагмент. 
Определение роли и состояния оборотов или отдельных слов, составляющих 
предложения анализируемого фрагмента, производится по четко 
определенным, детерминированным правилам, которые могут быть 
представлены в виде более или менее сложных алгоритмов, формирующих 
морфологические или синтаксические характеристики предложений, 
оборотов и слов. Процесс и правила формирования морфологических и 
синтаксических характеристик и сами характеристики определенны и 
закономерны. Поэтому эти виды анализа закономерны или 
детерминированы.
   
   На первый взгляд, кажется заманчивой идея представить текст эталона и 
дубля в виде предложений, предложения в виде деревьев или иных 
детерминированных структур и затем сравнить структурированное таким 
образом представление эталона и дубля. Однако русский язык, а здесь 
подразумевается, что именно он используется для вербального 
представления информации, совершенно игнорирует какие-либо 
структурные ограничения по расположению членов предложения, по виду 
предложений, формированию фрагментов предложений из групп слов, 
изобилует бесконечным многообразием форм управления отдельными 
словами и группами слов. По этой причине можно ожидать, что в эталоне и 
дубле не окажется тождественно равных структурных единиц, а чис\-ло 
альтернатив, подлежащих сравнению, может быть бесконечным. В~такой 
ситуации становится принципиальной проблема определения альтернатив и 
логических правил их разрешения. Поэтому представляется, что 
детерминированный семантический анализ не вполне соответствует 
содержательному существу проб\-лемы.
   
   По мнению автора, семантический анализ как термин не вполне удачен. 
Речь может идти об установлении уровня информационного соответствия 
содержания одного, анализируемого текста, который здесь именуется 
дублем, содержанию другого, именуемого эталоном, текста. Представляется, 
что реализация сравнения, выявления уровня соответствия нескольких 
русскоязычных текстов использованием детерминированного 
структурирования и детерминированных правил оценки близости не 
представляется практически возможной. С~учетом интеллектуальной 
специфики одна и та же информация может случайным образом облекаться в 
различную текстовую оболочку. Основная проб\-ле\-ма оценки степени 
близости информационных объектов, представленных на естественном 
языке, следует из семантической многозначности слов и наличия синонимов. 
Эти обстоятельства приводят к неоднозначности лексического представления 
семантического содержания текстов. Проблемы неоднозначности текстовой 
информации известны и активно исследуются специалистами в области 
русского языка. Детерминированный подход сравнения текстов оказывается 
нацеленным фактически на формальное описание тонкостей образования 
синтаксических форм русского языка, многообразие которых представляется 
бесконечным. 
   
   Очевидно, что случай полного совпадения\linebreak текстов, используемый при 
формировании рег\-ла\-мента доступа к информации, здесь не рас\-смат\-ри\-ва\-ет\-ся. 
Должна присутствовать возможность выделения общности 
информационного содержания со\-по\-став\-ля\-емых информационных объектов 
из их случайным образом выбранной формы представления на естественном 
языке. Решение такой задачи может быть получено только при описании 
взаимосвязи семантического (информационного) содержания и лексического 
оформления обоих срав\-ни\-ва\-емых текстов с вероятностно-статистических 
позиций.

\section{Элементы теории информации}

   Более полувека существует в виде научной дисциплины теория 
информации. Ее основоположником является американский специалист в 
об\-ласти передачи информации в технических линиях связи Клод 
   Шен\-нон~\cite{3-k}. Значительный вклад в теорию информации, 
особенно в строгое доказательство ее основных принципов, внесли советские\linebreak 
ученые школы А.\,Н.~Колмогорова~\cite{4-k}. В~теории информа\-ции 
исследуются проблемы передачи и преобразования информации, при этом 
вводится количественная оценка информации. Применительно к проблеме 
сравнения близости ИО, которой посвящена 
данная статья, является важным, что в теории информации разработаны 
теоретические основы исследования бли\-зости сообщений, переданного 
передатчиком и принятого приемником на другом конце линии связи. При 
этом вводится количественная мера информации, которая позволяет 
осуществить сопоставление информационной емкости переданного и 
принятого сообщений и на этой основе оценить искажение (потери) 
информации в линии связи при ее пе\-ре\-даче. 
   
   Теория информации может быть использована для решения проблемы 
оценки близости ИО, представленных на естественном языке. Ничто не 
мешает вместо сообщений, принятого и переданного, рассматривать 
ИО, трактуя один из них~--- аналог переданного 
сообщения~--- как эталонный информационный объект (ЭИО), а другой~--- 
аналог принятого сообщения~--- как дубль ЭИО (ДИО). 
Как будет видно дальше, мера количества информации в 
одном объекте о другом симметрична, поэтому при количественной оценке 
их близости не важно, какой объект считать эталоном, а какой~--- дублем. 
Понятно, что сравнение ЭИО и ДИО на абсолютное их совпадение 
неприемлемо. В~теории информации исследуется количественная, а не 
содержательная сторона информации. В~связи с наличием случайных помех 
в системах формирования и линиях передачи информации сообщения, 
переданное и принятое, интерпретируются случайными величинами~$\xi$. 
Шенноном было предложено использовать энтропию\footnote{Энтропия (от 
греческого \textit{entropia}~--- превращение) введена в 1865~г.\ немецким физиком Р.~Клаузиусом как 
функция состояния термодинамической системы, изменение которой $dS$ в равновесном процессе равно 
отношению количества теплоты $dQ$, подведенного к системе или отведенного от нее, к 
термодинамической температуре системы~$T$: $dS=dQ/T$. Л.~Больцман, один из основателей 
статистической термодинамики, предложил использовать энтропию как меру вероятности пребывания 
системы в данном состоянии. Шеннон ввел энтропию в теорию информации в качестве меры количества 
информации, которое выражается через распределение вероятностей.} как вероятностную меру 
количества информации~\cite{3-k}.
   
   Энтропия исхода определяется в виде логарифма вероятности этого 
исхода:
   \begin{equation}
   H(\xi_i)=- \log p(\xi_i)\,,
   \label{e1-k}
   \end{equation}
а усредненная энтропия случайной величины~$\xi$ выражается через 
функцию распределения ее вероятностей в виде:
\begin{equation}
H_\xi =- \sum\limits_\xi p(\xi)\log p(\xi)\,,
\label{e2-k}
\end{equation}
где $\xi$~--- случайная величина; $p(\xi)\leq 1$~--- распределение ее 
вероятностей. 
   
   В рассматриваемом здесь случае анализа текстов случайными 
величинами могут быть слова или другие конструкции. Под количеством 
информации в теории информации понимается неопределенность, 
устраняемая в результате выяснения исхода, т.\,е.\ значения, принимаемого 
случайной величиной. 
   
   Простейший содержательный пример в контексте статьи может быть 
следующим. Слова: \textit{пример, образец, экспонат} в некотором контексте 
являются синонимами и могут использоваться для обозначения 
объекта~$\xi$ с вероятностями: $p(\xi=\;\mbox{\textit{пример}})\hm=0{,}2$; 
$p(\xi=\;\mbox{\textit{образец}})\hm=0{,}4$; 
$р(\xi=\;\mbox{\textit{экспонат}})\hm=0{,}6$. В~этом случае количество 
информации, получаемое при реализации конкретного исхода, допустим, при 
использовании слова экспонат, т.\,е.\ $\xi\hm=\;\mbox{\textit{экспонат}}$, будет 
в соответствии с~(\ref{e1-k}) равно $\log p(0{,}6)$, а усредненная 
неопределенность объекта~$\xi$ будет по~(\ref{e2-k}) равна: $H_\xi\hm=- 
p(0{,}2)\log p(0{,}2)\hm- p(0{,}4)\log p(0{,}4)\hm- p(0{,}6)\log p(0{,}6)$. 
В~теории информации наиболее часто используются логарифмы по 
основанию~2, в этом случае количество информации определяется в битах.
   
   В реальности чаще интерес представляет сравнение информационной 
емкости сообщений, оценка имеющейся в них совместной информации. Для 
этого по распределениям вероятностей сообщений определяется энтропия 
каждого из них (количество информации в каждом из них), а по совместному 
распределению вероятностей~--- совместная энтропия. По энтропиям 
оценивается количество взаимной информации. 
   
   При использовании теории информации для описания закономерностей 
передачи информации энтропия переданного сообщения определяет 
количество переданной информации, а энтропия принятого сообщения~--- 
количество принятой информации. Общая часть в переданном и принятом 
сообщениях определяет количество взаимной информации. Обозначив через 
$\xi$ переданное сообщение, а через~$\eta$~--- принятое, количество 
взаимной информации $I (\xi\eta)$, или количество информации, 
содержащееся в принятом сообщении~$\eta$ из переданного 
сообщения~$\xi$, можно определить, следуя теории информации~\cite{3-k}, 
в виде: 
   \begin{equation}
   I_{\xi\eta} =\int\limits_X\! \int\limits_Y p_{\xi\eta} (x,y)\log \fr{p_{\xi\eta} 
(x,y)}{p_\xi(x)p_\eta(y)}\,dxdy\,,
   \label{e3-k}
   \end{equation}
где $p_\xi(x)$~--- плотность распределения переданного сообщения;
   $p_\eta(y)$~--- плотность распределения принятого сообщения;
   $p_{\xi\eta}(x,y)$~--- плотность совместного распределения; 
   $X$ и $Y$~--- области определения~$x$ и~$y$ соответственно.
   
   В~(\ref{e3-k}) имеет место равноправное симметричное вхождение~$\xi$ 
и~$\eta$, поэтому взаимная информация симметрична относительно~$\xi$ 
и~$\eta$. Отсюда следует, что при количественной оценке взаимной 
информации не важно, какое сообщение выступает в роли переданного, а 
какое~--- в роли принятого. 
   
   Именно взаимная информация может использоваться в качестве меры 
подобия ИО. Нетрудно видеть, что содержательное существо теории 
информации, направленное на оценку потерь информации при ее передаче, 
адекватно содержательной сущности многих задач в области исследования 
семантической близости ИО на естественном языке. Применение теории 
информации для решения проблемы оценки близости ИО может 
основываться на замене сообщений исследуемыми ИО. 
Один объект (эталон) может интерпретироваться переданным 
сообщением, а второй (дубль)~--- принятым сообщением. Вследствие 
симметрии от перемены ролей количество взаимной информации не 
изменится. Формула~(\ref{e3-k}) отражает количество взаимной информации 
непрерывных сообщений, точнее сообщений, случайный характер которых 
определяется непрерывными функциями распределения вероятностей вида 
$p_\xi(x)$, $x\in X \hm= [x^\prime, x^{\prime\prime}]$, где $x^\prime$ и 
$x^{\prime\prime}$~--- предельные значения~$x$. 
   
   При анализе текстов в качестве случайных величин будут выступать 
синтаксические или морфологические компоненты, которые являются 
дискретными величинами. Их случайными лексическими значениями будут 
выступать слова или словосочетания, характеризуемые дискретными 
ве\-ро\-ят\-но\-стя\-ми, как это показано в приведенном выше кратком примере. 
В~примере под случайным объектом или компонентом~$\xi$ может 
пониматься подлежащее при использовании синтаксической структуризации 
или существительное при использовании морфологической структуризации. 
Компонент~$\xi$ в обоих случаях может принимать случайные значения 
\textit{пример}, \textit{образец}, \textit{экспонат} с вероятностями 
$p(\xi=\;\mbox{\textit{пример}})\hm=0{,}2$; 
$p(\xi=\;\mbox{\textit{образец}})\hm=0{,}4$; 
$p(\xi=\;\mbox{\textit{экспонат}})\hm=0{,}6$. Дискретные значения 
вероятностей могут суммироваться, и поэтому вмес\-то интегралов, 
присутствующих в~(\ref{e3-k}), будут исполь-\linebreak зоваться суммы по всем 
возможным значениям\linebreak случайных величин. Количество взаимной 
информации в дискретном случае будет определяться следующим образом:
   \begin{equation}
   I_{\xi\eta} =\sum\limits_{\xi\in X} \sum\limits_{\eta\in Y} p(\xi,\eta) \log 
\fr{p(\xi,\eta)}{p(\xi)p(\eta)}\,,
   \label{e4-k}
   \end{equation}
где $X = \{x_1, x_2, \ldots , x_n\}$, $Y \hm= \{y_1, y_2, \ldots , y_m\}$~--- 
множества значений случайных величин~$\xi$ и~$\eta$, 
   $p(\xi)$, $p(\eta)$ и $p(\xi,\eta)$~--- распределения их вероятностей. 
   
   Данная статья посвящена изложению общей концепции 
автоматизированной технологии оценки степени близости ИО, 
представленных на естественном языке. Поэтому здесь ограничимся этим 
кратким представлением основного существа теории информации и ее 
дальнейшее использование объясним <<на словах>>. Достаточно полные и 
строгие сведения по энтропии и взаимной информации интересующийся 
читатель сможет найти в оригинальной литературе, например~[3--5], а их 
применение в далекой от передачи информации области управления 
качеством и технологиями~--- в работах автора~\cite{6-k, 7-k} и~др.

\section{Понятие вероятностной модели}

   Структуризация текста с целью извлечения заключенного в нем смысла 
представляется не вполне определенной задачей. Неопределенность следует 
из сложности представления ее содержательного существа, откуда вытекают 
и проблемы с определением методов решения. При оценке степени подобия 
содержания двух ИО смысл каждого из них, вообще 
говоря, интереса не представляет, так как целью является не выяснение 
семантики, а оценка степени их содержательного подобия. Для этого 
необходимо оценить меру совпадения в текстах того, о чем (ком) идет речь, 
что, как, где, когда и~т.\,п.\ с ними происходит или они делают. 
   
   Синтез формального подхода к оценке бли\-зости ИО, представленных на 
естественном языке, тре\-бу\-ет формального пред\-став\-ления самих 
срав\-ни\-ва\-емых объектов, т.\,е.\ разработки модели представления ИО. 
Математические модели объектов\linebreak являются основой для разработки систем 
управления этими объектами, а также решения задач анализа объектов, 
исследования взаимосвязей между компонентами, образующими объект, 
синтеза суж\-дений о состоянии и эволюции объекта. Поэтому структура и 
содержание модели должны разрабатываться с учетом четкого представления 
целей, для достижения которых она будет использоваться. Модель должна 
адекватно отражать все наиболее важные для правильного решения 
поставленной задачи содержательные аспекты объекта и игнорировать те, 
которые, усложняя модель, не способствуют повышению качества решения. 
Модели одного и того же объекта, предназначенные для решения различных 
задач, могут значительно различаться глубиной учета отдельных деталей. 
   
   Применительно к проблеме формального представления 
ИО в задачах оценки их семантической близости 
модель должна обеспечивать возможность сопоставления эквивалентных 
компонентов объектов, отражающих содержание сопоставляемых ИО, и 
игнорировать стилистические тонкости, влия\-ющие на форму представления 
содержания, но не на его смысл. 
   
   Обычно первым шагом при построении модели является структуризация 
объекта, выделение его компонентов, которые в совокупности определяют 
рассматриваемый объект. 

При разработке структуры модели ИО можно было 
бы, следуя имеющимся в литературе примерам, исходить из структуры 
простых предложений, в виде совокупности которых тем или иным способом 
может быть пред\-став\-лен ИО. Простое предложение русская грамматика 
определяет центральной грамматической единицей. <<Это определяется тем, 
что простое предложение представляет собой элементарную 
предназначенную для передачи относительно законченной информации 
единицу\ldots>>~\cite[с.~405]{8-k}. Но далее следуют 154~параграфа, в 
которых излагаются типы и формы простых предложений. Их многообразие 
и присутствие неполной четкости деления по типам и формам делает 
нереальной задачу формального описания даже простых предложений, не 
говоря о более сложных типах предложений. Именно по этой причине 
детерминированный подход, опирающийся на представления русской 
грамматики, как отмечалось выше, представляется малопригодным для 
анализа семантической бли\-зости ИО. 
   
   Вследствие того, что целью разрабатываемой методологии является не 
анализ текстов с позиций грамматики русского языка, а сопоставление их 
семантического содержания, которое может\linebreak случайным образом облекаться в 
лексическую оболочку, к определению структуры модели пред\-став\-ля\-ет\-ся 
целесообразным подойти с вероятностно-ста\-ти\-сти\-че\-ских позиций. 
   
   В теории вероятностей~\cite{9-k} существует вероятностная модель, 
которая позволяет дать формальное, максимально полное описание 
   ве\-ро\-ят\-но\-ст\-но-ста\-ти\-сти\-че\-ско\-го объекта. Она определяется 
на множестве элементарных событий $\{\omega_1, \omega_2, \ldots , 
\omega_n\}$, которое образует пространство элементарных событий, или 
исходов $\Omega =\{\omega_1, \omega_2, \ldots , \omega_n\}$. Известны 
вероятности элементарных событий $p(\omega_i)$, $i=1, 2, \ldots , n$. На 
множестве элементарных событий задается алгебра $\aleph=(A_j \vert 
A_j\subseteq\Omega$) или, иначе, система случайных событий, составленных 
каким-ли\-бо определенным образом из элементарных событий $\omega_i 
\in\Omega$. Для каждого из случайных событий $A_j=\{\omega_i\in \Omega\}$, 
образующих алгебру, по вероятностям элементарных исходов $p(\omega_i)$, 
$\omega_i\in A_j$, определяется его вероятность $P(A_j)$. 
   
   Набор: множество элементарных событий $\Omega \hm=\{\omega_1, \ldots , 
\omega_n\}$, система случайных событий (ал\-геб\-ра) $\aleph=(A_j\vert  
A_j\subseteq\Omega$) и вероятности случайных событий $P(A_j)$~--- образует 
вероятностную модель случайного объекта. Она содержит всю информацию, 
которой может быть охарактеризован случайный объект. Формально 
вероятностная модель (или вероятностное пространство эксперимента с 
конечным пространством исходов~$\Omega$ и алгеброй событий~$\aleph$) 
может быть представлена в виде:
   \begin{equation}
   M_\Omega =\{ \Omega, \aleph, P(A)\}\,,
   \label{e5-k}
   \end{equation}
где $\Omega= \{\omega_1, \omega_2, \ldots , \omega_n\}$, $\aleph= (A_j\vert A_j 
\subseteq \Omega)$, $P(A) \hm= (P(A_j)\vert A_j\in \aleph)$.

\begin{table*}[b]\small
\begin{center}
\Caption{Представление ВСММ ИО (фрагмент)}
\vspace*{2ex}

\tabcolsep=4.5pt
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{Существительные}&\multicolumn{2}{c|}{Прилагательные}&
\multicolumn{2}{c|}{Числительные}&\ldots&\multicolumn{2}{c|}{Глаголы}\\
\hline
Слова&Характеристики&Слова&Характеристики&Слова&Характеристики&\ldots&Слова&Характеристики\\
\hline
1 Дом&$p$(дом)&Серый&$p$(сер.)&Три&$p$ (три)&\ldots&Стоит&$P$(стоит)\\
2 Стол&$p$(стол)&Белый&$p$ (бел.)&Два&$p$ (два)&\ldots&Идет&$P$ (идет)\\
\ldots&\ldots&\ldots&\ldots&\ldots&\ldots&\ldots&\ldots&\ldots\\
\hline
\end{tabular}
\end{center}
\end{table*}
   
   Определить вероятностную модель конкретного случайного объекта 
значит определить все ее элементы~--- множество элементарных исходов, 
сис\-те\-му случайных событий и их вероятности~--- для этого конкретного 
объекта.

\section{Вероятностно-статистическая морфологическая модель 
информационного объекта}
   
   Информационный объект может быть пред\-став\-лен в виде вероятностной 
модели. В нем множество элементарных исходов $\Omega = \{\w_1, \w_2, 
\ldots , \w_n\}$ представляют слова $\w_i$, $i=1, 2, \ldots , n$, со\-став\-ля\-ющие 
текст ИО. Существуют системы структуризации лексического материала. 
Достаточно общими и пригодными для использования при разработке 
ве\-ро\-ят\-но\-ст\-но-ста\-ти\-сти\-че\-ской модели ИО являются синтаксическая и 
морфологическая структуризации русского языка. Морфологическая 
структуризация задается определением частей речи русского языка, которые 
разделяют язык на самые крупные грамматические классы слов~\cite{8-k}. 
Различают десять частей речи, среди которых шесть знаменательных: 
существительные, прилагательные, чис\-ли\-тель\-ные, 
   мес\-то\-име\-ния-су\-ще\-ст\-ви\-тель\-ные, наречия, глаголы и три 
служебные: предлоги, союзы, частицы. Десятой частью являются 
междометия. Части речи, к которым относятся отдельные слова, могут 
трактоваться случайными событиями~$A_j$, $j = 1, 2, \ldots , 10$. Каждое 
отдельное слово (реализация, элементарный исход) $\omega_i$, $i=1, 2, \ldots 
, n$, входит в текст с определенной вероятностью~$p(\omega_i)$. В~тексте 
роль вероятности играет относительная частота $p(\omega_ii)=n_i/n$, где 
$n_i$~--- число употреблений в ИО слова~$i$, $n$~--- общее количество слов 
в ИО. Относительная частота получается экспериментально и называется в 
теории вероятностей эмпирической вероятностью. По вероятностям 
$p(\omega_i)$ отдельных слов вычисляются вероятности событий~$A_j$~--- 
час\-тей речи. Вероятностно-статистическая модель ИО~(\ref{e5-k}), в которой 
алгебра (способ структуризации) слов определяется морфологией, может 
быть названа вероятностно-статистической морфологической моделью 
(ВСММ) ИО, которая может быть по аналогии с~(\ref{e5-k}) записана в виде: 
   \begin{equation}
   M_M =\{\Omega, \aleph_M, P(A)\}\,,
   \label{e6-k}
   \end{equation}
где индекс $M$ подчеркивает морфологический характер модели, который 
отражается через определение алгебры~$\aleph_M$.
   
   Конкретный ИО представляется в виде соответствующего 
   ве\-ро\-ят\-но\-ст\-но-ста\-ти\-сти\-че\-ско\-го морфологического образа 
ИО. Он синтезируется на основа\-нии модели~(\ref{e6-k}) введением 
конкретного множества элементарных исходов $\W_O= (\w_1, \w_2, \ldots$\linebreak $\ldots , 
\w_n)$ -- слов. Обозначение $\W_O$ подчеркивает, что это множество слов 
конкретного ИО. Множество структурируется в соответствии с введенной 
ал\-геб\-рой $\aleph_M=(A_1, A_2, \ldots , A_J)$, где $J$~--- число случайных 
событий (частей речи), используемых в образе, $J\leq  10$, т.\,е.\ некоторые 
части речи, например междометия, предлоги, могут не использоваться при 
формировании образа. В~результате пол\-ностью определяется 
ве\-ро\-ят\-но\-ст\-но-ста\-ти\-сти\-че\-ский морфологический образ (ВСМО) ИО ВСММ~(\ref{e5-k}) 
конкретного ИО, который может быть представлен в виде:
   \begin{equation}
   O_M=\{ \W_O,\aleph_M,P_O(A)\}\,,
   \label{e7-k}
   \end{equation}
где обозначения следуют из~(\ref{e5-k}), (\ref{e6-k}) и текста. 
   
   По множеству элементарных исходов $\W_O$ вычисляются 
количественные характеристики образа: вероятности $p(\w_i)$ и вероятности 
случайных событий $P(A_j)$. По вероятностям может быть в соответствии 
с~(\ref{e2-k}) определена энтропия $H_O$ образа ИО, характеризующая 
количество информации в об\-разе.
   
   Для пояснения, возможно, непривычного для исследований в области 
русского языка подхода и терминологии воспользуемся наглядной 
иллюстрацией. Вероятностно-ста\-ти\-сти\-че\-ская морфологическая
модель ИО может быть представлена в виде табл.~1.
   
   В шапке таблицы для сокращения размеров примера указаны в явном 
виде только 4~части речи из десяти, имеющихся в языке. В~модели будет 
использоваться таблица с полным набором частей речи. Шапка таблицы 
является атрибутом модели. Она отражает структуру ВСММ и является 
общей для представления образов всех ИО. Части речи, указанные в шапке, 
трактуются случайными величинами. В~вероятностном смысле шапка 
таблицы содержит все рассматриваемые при морфологическом подходе 
случайные события или полное поле событий. Смысл полного поля событий 
в данном контексте в том, что любое встреченное в тексте (в ИО) слово 
относится к одному из них (является ка\-кой-либо частью речи). 
   
   Все то, что находится в таблице под шапкой, отражает конкретный ИО, 
т.\,е.\ определяет ВСМО ИО~(\ref{e7-k}). Слова \textit{дом}, \textit{стол} 
являются в примере случайными значениями, которые приняла часть речи 
<<существительное>>, аналогично \textit{серый}, \textit{белый}~--- 
случайные значения <<прилагательного>>, \textit{стоит}, \textit{идет}~--- 
<<глагола>>. Кроме собственно значений, которые принимают части речи в 
ИО, в модели отражаются их случайные характеристики, например 
относительные частоты.
   
   Вероятностно-ста\-ти\-сти\-че\-ский морфологический
образ~(\ref{e7-k}) может быть сформирован для любого произвольного 
ИО, представленного на русском языке, да и не на 
русском тоже. При его формировании могут быть использованы имеющиеся 
достаточно эффективные инструменты морфологического анализа текстов, 
которые позволяют автоматизировать процедуры отнесения слов к частям 
речи. 
   
   При решении задачи оценки семантической близости 
ИО ВСМО синтезируется для обоих сравниваемых объектов. Для 
определенности один из них называется эталоном (ИОЭ), его 
морфологический образ обозначается $O_{\mathrm{МЭ}}$, а второй~--- дублем 
(ИОД), его образ~--- $O_{\mathrm{МД}}$. Ве\-ро\-ят\-но\-ст\-но-ста\-ти\-сти\-че\-ский 
морфологический образ содержит все слова ИО, 
структурированные по частям речи, ве\-ро\-ят\-ности отдельных слов и частей 
речи в ИО. Ве\-ро\-ят\-ности количественно характеризуют ВСМО ИОЭ и ВСМО 
ИОД. На их основе может быть осуществлена оценка количества 
информации в каждом из объектов и оценено количество взаимной 
информации~(\ref{e4-k}) в объектах. Выражение для оценки количества 
взаимной информации~(\ref{e4-k}) может быть приведено к виду:
   \begin{equation}
   I_{\mathrm{МЭД}} = H(O_{\mathrm{МЭ}}) + H(O_{\mathrm{МД}})- 
H(O_{\mathrm{МЭ}}, O_{\mathrm{МД}})\,,
   \label{e8-k}
   \end{equation}
где обозначения совпадают с введенными раньше. 
   
   Можно утверждать, что полное совпадение ВСМО объектов будет иметь 
место при полной идентичности ИОД и ИОЭ. Наличие отклонений ВСМО 
дубля от ВСМО эталона будет указывать на несовпадение содержания ИО, 
количественной оценкой которого является количество совместной 
информации. 
   
   Формирование ВСМО объектов может опираться на имеющиеся 
фундаментальные исследования в области морфологии русского языка и 
разработки\linebreak мощных инструментов морфологической структуризации. 
В~частности, выполнение морфологической структуризации в данном 
исследовании опирает\-ся на электронную версию словаря 
А.\,А.~Зализняка~\cite{10-k}, для практического использования которой 
разработаны оригинальные программные продукты. 

\section{Вероятностно-статистическая синтаксическая модель 
информационного объекта}
   
   С другой стороны, в русском языке классифицированы члены 
предложения. Определение членов предложения задает синтаксическую 
структуру русского языка. Важно подчеркнуть, что части речи обладают 
общностью синтаксических функций, так что эти два способа 
структуризации лексического состава русского языка взаимосвязаны и 
дополняют друг друга. Вероятностно-статистическая модель, синтезируемая 
на синтаксической основе, будет отличаться только системой случайных 
событий, образующих полное поле событий, т.\,е.\ шапкой таблицы, 
отражающей модель. 
   
   Между морфологической и синтаксической структуризацией имеется 
значительное отличие, сле\-ду\-ющее из того, что морфологическая 
структури\-за\-ция является фиксированной, так как имеется всего 10~час\-тей 
речи. Синтаксическая структуризация допускает введение более детальной 
структуры членов предложения. Она определяется разработчиком системы 
сравнения объектов и допускает определенный волюнтаризм в выборе 
системы случайных событий. Для возможности отражения семантических 
оттенков в систему случайных событий могут быть введены разнообразные 
синтаксические конструкции, связанные со спецификой содержания 
сравниваемых ИО. Понятно, что увеличение отражаемого в модели 
разнообразия конструкций, с одной стороны, будет способствовать 
повышению качества сравнения текстов, а с другой~--- усложнению модели. 
Однако если учесть табличное представление модели, стандартное для 
реляционных баз данных, то увеличение таблиц не приведет к 
принципиальным затруднениям при реализации систем оценки близости ИО. 
   
   Вероятностно-статистическая синтаксическая модель (ВССМ) ИО 
аналогична ВСММ ИО и может быть представлена в виде таблицы, подобной 
табл.~1. Шапка таблицы будет отражать принцип 
структурирования по случайным событиям, которые в ней связываются уже с 
членами предложения, т.\,е.\ с синтаксическими конструкциями языка. 
Алгебра вероятностной модели в этом случае будет определяться типами 
членов предложения, которые используются для представления ИО: 
$\aleph_C \hm= \{B_1, B_2, \ldots , B_L)$, где $B_1$~--- подлежащее; $B_2$~--- 
сказуемое; $B_3$~--- определение и~т.\,д.;
   $L$~--- общее число типов членов предложения, используемых в 
синтаксической модели и образующих в ней полное поле событий; 
   $B_l$, $l \hm= 1, 2, \ldots , L$, как и $A_j$, трактуются как случайные 
синтаксические события. Таким образом, ВССМ будет иметь вид: 
\begin{equation}
M_C = \{\Omega, \aleph_C,P(B)\}\,,
\label{e9-k}
\end{equation}
отличающийся от~(\ref{e6-k}) только алгеброй~$\aleph_C$.

Исследуемый ИО посредством какого-либо синтаксического анализатора 
разделяется на члены предложения. На основе этого разделения 
формируются случайные события и синтезируется вероятностно-статистический 
синтаксический образ (ВССО) ИО:
\begin{equation}
O_C=\{\W_O,\aleph_C,P_O(B)\}\,.
\label{e10-k}
\end{equation}
   
   Для оценки семантической близости ИО ВССО 
синтезируется для обоих сравниваемых объектов. На их основе может быть 
оценено количество взаимной информации в сравниваемых 
объектах~(\ref{e4-k}). Выражение для оценки количества взаимной 
информации получается из~(\ref{e8-k}) заменой морфологических образов 
син\-так\-си\-че\-скими:
   \begin{equation}
I_{\mathrm{СЭД}} = H(O_{\mathrm{СЭ}}) + H(O_{\mathrm{СД}})- 
H(O_{\mathrm{СЭ}}, O_{\mathrm{СД}})\,,
\label{e11-k}
\end{equation}
где обозначения совпадают с введенными раньше. 
   
   Синтаксический анализ текста представляет отдельную проблему, 
отличающуюся от рассматриваемой здесь. Поэтому для определения 
инструментов формирования синтаксических образов были 
проанализированы имеющиеся в литературе наработки в этом направлении и 
практически использовался <<Синтаксический анализатор Cognitive 
Dwarf 2.0>>~[11--13].

\vspace*{-0.9pt}

\section{Методология оценки семантической близости информационных объектов}
   
   В морфологической и в синтаксической структуре структурные 
компоненты несут достаточно определенную и близкую семантическую 
нагрузку. Поэтому могут быть установлены отношения эквивалентности 
между компонентами двух структур. Вследствие того, что эти структуры 
охватывают весь лексический состав и грамматический строй русского 
языка, они обеспечивают отражение семантического содержания текстов и, 
следовательно, являются достаточными для сопоставления этого 
семантического содержания. 
   
   Таким образом, ИО может быть представлен в виде 
морфологического\addtolength{\footnotesep}{1.351pt}\footnote{Минимальное количество грамматических терминов, 
используемых в статье, заимствовано из~\cite{8-k} с единственной целью: приблизить 
изложение терминологически к области русского языка, хотя содержание статьи, как 
представляется, достаточно далеко от вопросов собственно языка.}\addtolength{\footnotesep}{-1.351pt} и/или 
синтаксического образа. Формальное представление ИО в виде 
математических объектов~--- ве\-ро\-ят\-но\-ст\-но-ста\-ти\-сти\-че\-ских 
образов~--- позволяет использовать математический аппарат для получения 
количественных оценок их близости. Можно утверждать, что полное 
совпадение как ВСМО, так и ВССО со\-по\-став\-ля\-емых объектов будет 
соответствовать равенству представляемых ими ИО. 

Оценка степени близости ИО, представленных на естественном языке, может 
быть реализована на основе применения вероятностно-статистической 
морфологической и/или синтаксической модели. 
   
   Мерой степени близости служит энтропия и взаимная информация, 
количественные значения которых вычисляются по~(\ref{e2-k}), (\ref{e8-k}) 
и~(\ref{e11-k}). Выше отмечалось, что под количеством информации в теории
информации понимается количество неопределенности случайного объекта, 
которое исчезает при выяснении этой неопределенности. Неопределенность 
объекта характеризуется распределением его вероятностей. 
В~использованном выше примере объекта~$\xi$ с синонимами было задано 
распределение вероятностей: $p(\xi=\;\mbox{\textit{пример}}) \hm= 0{,}2$; 
$p(\xi\hm=\;\mbox{\textit{образец}}) \hm= 0{,}4$; $p(\xi\hm=\;\mbox{\textit{экспонат}}) 
\hm= 0{,}6$. Так что в этом случае энтропия отдельных исходов будет: 
$H(\xi=\;\mbox{\textit{пример}}) \hm=- \log 0{,}2$, 
$H(\xi=\;\mbox{\textit{образец}}) \hm=- \log 0{,}4$, а 
$H(\xi=\;\mbox{\textit{экспонат}}) \hm=- \log 0{,}6$, а\linebreak усредненная энтропия 
$H_\xi \hm=- 0{,}2 \log 0{,}2\hm- 0{,}4 \log 0{,}4\hm - 0{,}6 \log 0{,}6$. Таким образом, 
энтропия будет некоторым числом, зависящим от распределения 
вероятностей случайных событий, но не от их содержания. 
   
   Из выражений~(\ref{e8-k}) и (\ref{e11-k}) для взаимной информации 
можно видеть, что, во-пер\-вых, она тоже является числом, так как 
выражается через числа~--- значения соответствующих энтропий. 
   Во-вто\-рых, выражения~(\ref{e8-k}) и~(\ref{e11-k}) отражают смысл 
взаимной информации как меры неопределенности. 

Пусть используются 
синтаксические образы со\-по\-став\-ля\-емых объектов, а их взаимная информация 
оценивается выражением~(\ref{e11-k}). Рассмотрим два предельных случая. 
   
   В первом пусть ВССО эталона $O_{\mathrm{СЭ}}$ не имеет ничего общего 
с ИССО дубля~$O_{\mathrm{СД}}$. Отсутствие общего означает, что 
вероятность совместного распределения $P(O_{\mathrm{СЭ}},O_{\mathrm{СД}}) 
\hm= 0$. В~теории информации принято считать $0 \log 0=0$, поэтому 
$H(O_{\mathrm{СЭ}}, O_{\mathrm{СД}}) \hm= 0$
 и из~(\ref{e11-k}) следует, что 
количество совместной информации, содержащееся в двух со\-по\-став\-ля\-емых 
объектах, равно их общей неопределенности: $I_{\mathrm{СЭД}} \hm= 
H(O_{\mathrm{СЭ}}) \hm+ H(O_{\mathrm{СД}})$.
   
   Во втором случае пусть дубль полностью совпадает с эталоном, т.\,е.\ 
$O_{\mathrm{СЭ}}\hm=O_{\mathrm{СД}}$. Тогда совпадут энтропии 
$H(O_{\mathrm{СЭ}}) \hm= H(O_{\mathrm{СД}})$, более того, и совместная 
энтропия $H(O_{\mathrm{СЭ}}, O_{\mathrm{СД}})$ будет равна энтропии 
эталона или дубля. Так что количество совместной информации будет равно 
$I_{\mathrm{СЭД}} = H(O_{\mathrm{СЭ}})$, т.\,е.\ неопределенность дубля 
отсутствует, вся неопределенность связана только с неопределенностью 
эталона, только с количеством заключенной в нем информации. Отсюда 
можно заключить, что количество информации~(\ref{e11-k}) изменяется от 
значения\linebreak
$I_{\mathrm{СЭД}} \hm= H(O_{\mathrm{СЭ}})$ до значения 
$I_{\mathrm{СЭД}}\hm = H(O_{\mathrm{СЭ}}) \hm+ H(O_{\mathrm{СД}})$. При 
этом взаимная информация~---\linebreak
 величина положительная. Это следует из 
положительности энтропий: 
$
p(\xi) \leq 1$, $\log p(\xi)\hm\leq  0
$ и, следовательно, 
$$
H(\xi) =- \log p(\xi) \geq 0
$$ 
и факта 
$$
H(O+{\mathrm{СЭ}})  + H(O_{\mathrm{СД}})  \geq H(O_{\mathrm{СЭ}}, O_{\mathrm{СД}})\,.
$$ 

Разумеется, такой же результат может быть получен и для~(\ref{e8-k}). 
Вследствие свойств логарифмической функции количество информации 
изменяется монотонно в определенных выше пределах, что и позволяет 
использовать его в качестве меры семантической близости ИО. 
   
   Для практического применения абстрактные значения энтропии и 
взаимной информации необходимо проградуировать в некоторых понятных и 
связанных с содержательным существом задачи мерах оценки семантической 
близости ИО. 
%
Такая градуировка (тарирование) их значений может 
осуществляться разными способами и, в частности, обеспечивать реализацию 
функций адаптации сис\-те\-мы к различным задачам и типам ИО. Например, в 
простейшем случае может быть взят реальный эталонный ИО такого типа, 
для работы с которым предполагается использовать систему. 
%
Искажением 
эталонного ИО случайным образом и в заданных объемах может быть 
получена серия дублей с известной степенью семантического несовпадения. 
Для каждой пары <<эта\-лон--дубль>> находится значение взаимной 
информации, которое сопоставляется с известной степенью семантического 
несовпадения. На основании сопоставления определяется линейное 
преобразование перевода количества информации в удобную меру оценки 
степени семантического соответствия ИО.
   
   Методология реализуется в виде последовательности следующих этапов: 
   \begin{itemize}
\item выбор вида и формирование вероятностно-ста\-ти\-сти\-че\-ской модели 
конкретизацией ал\-геб\-ры (системы случайных событий) $\aleph_M$ или 
$\aleph_C$;
\item введение содержания (текстов) образов ИО;
\item формирование образа эталонного ИО в виде $O_{\mathrm{МЭ}}$ или 
$O_{\mathrm{СЭ}}$;
\item формирование образа второго ИО (дубля) в виде $O_{\mathrm{МД}}$ или 
$O_{\mathrm{СД}}$; 
\item определение энтропии эталонного ИО в виде $H(O_{\mathrm{МЭ}})$ или 
$H(O_{\mathrm{СЭ}})$;
\item определение энтропии второго ИО (дубля) в виде $H(O_{\mathrm{МД}})$ 
или $H(O_{\mathrm{СД}})$;
\item определение совместной энтропии эталонного ИО и дубля в виде 
$H(O_{\mathrm{МЭ}}, O_{\mathrm{МД}})$ или $H(O_{\mathrm{СЭ}}, 
O_{\mathrm{СД}})$; 
\item определение совместной информации в соответствии с~(\ref{e8-k}) 
или/и в соответствии с~(\ref{e11-k});
\item перевод совместной информации в выбранную меру информационной 
близости ИО.
\end{itemize}

   Разработанная методология оценки семантической близости ИО, 
кажущаяся, на первый взгляд, совершенно от семантики оторванной, имеет 
глубокую содержательную основу. Если следовать более общему 
представлению языка, чем детальное грамматическое, то множества 
элементарных исходов (слов), образующих в вероятностно-ста\-ти\-сти\-че\-ских 
образах случайные события (час\-ти речи в ВСМО и члены предложения в 
ВССО)\linebreak могут трактоваться как соответствующие обобщенные час\-ти речи и 
члены предложения, образующие эти образы. Такое представление позволяет 
выделить главное содержание в сравниваемых ИО.\linebreak Содержательным 
примером, подтверждающим реальность разработанного подхода, является 
достаточно час\-то встречающееся в реальности продуктивное общение людей 
на плохо знакомом им \mbox{языке}. Они не владеют склонениями, спряжениями, 
формами времени и другими элементами грамматики, но, зная две--три сотни 
слов, достаточно успешно общаются, вполне понимая друг друга. 
   
   Здесь излагается ядро методологии и не рассматриваются возможности 
привлечения дополнительных инструментов, повышающих адекватность 
оценки, таких как использование синонимов, введение весовых 
коэффициентов, детализация и комбинация событий и~т.\,п. 
   
   Заметим еще, что такой подход может быть использован и для оценки 
близости ИО, реализованных на других языках и с использованием иных 
алфавитов. Другие языки, например английский или немецкий, отличаются 
от русского в сторону уменьшения свободы в порядке слов и разнообразия 
способов управления, что упрощает задачи их структурирования и 
построения вероятностно-ста\-ти\-сти\-че\-ских моделей ИО, не требуя изменения 
методологии. 
   
   В ряде случаев ИО могут быть представлены с использованием не 
естественного языка, а, например, формального математического языка 
формул. В~этом случае изменяется входной алфавит и, возможно, принцип 
синтеза алгебры случайных событий. Но эти изменения не касаются 
представленной здесь собственно методологии оценки подобия ИО. 

\vspace*{-6pt}
   
\section{Оценка знаний}

\vspace*{-2pt}
   
   Одной из проблем, для решения которой предпринята данная разработка, 
является автоматизированный контроль знаний. Использование для этой 
цели системы тестов представляется автору неприемлемым по множеству 
причин. На кафедре АСУ Липецкого государственного технического 
университета разрабатывается <<Автоматизированная система поддержки 
образовательной программы обучения>> (АСПОП)~\cite{14-k}, одним из 
важнейших компонентов которой является подсистема автоматизированного 
контроля знаний. Концепция подсистемы базируется на изложенной 
методологии. 
   
   Практическая проверка в минимально возможном объеме 
работоспособности принципиальных положений концепции осуществлена 
проверкой знаний студентов. При реализации проверки студентам на экране 
демонстрировался эталонный ответ из АСПОП, который они воспроизводили 
на память и заносили в компьютер. По эталонным ответам из АСПОП 
формировались ВСМО $O_{\mathrm{МЭ}}$ и ВССО $O_{\mathrm{СЭ}}$. По 
ответам студентов формировались соответствующие ВСМО 
$O_{\mathrm{МД}}$ и ВССО $O_{\mathrm{СД}}$. По морфологическим образам 
$O_{\mathrm{МЭ}}$ и $O_{\mathrm{МД}}$ определялись энтропии 
$H(O_{\mathrm{МЭ}})$, $H(O_{\mathrm{МД}})$ и $H(O_{\mathrm{МЭ}}, 
O_{\mathrm{МД}})$, а по ним оценивалось количество взаимной информации. 
Также обрабатывались синтаксические образы эталонных ответов и их 
дублей~--- ответов студентов. 
   
   Распечатанные эталонные ответы и ответы студентов анонимно 
сопоставлялись группой преподавателей, которые выставляли оценки 
студентам по существующей методике по 100-балль\-ной шкале. Оценки 
преподавателей надлежащим образом усреднялись. По оценкам 
преподавателей и количествам взаимной информации, определенным 
автоматизированной системой, определялись параметры масштабного 
преобразования количества информации в принятые в университете 
   100-балль\-ные оценки. После введения коэффициентов масштабного 
преобразования система, как и преподаватели, выдавала 100-балль\-ные 
оценки. 
   
   Оценки, автоматически сформированные сис\-те\-мой, были сопоставлены с 
оценками, вы\-став\-лен\-ны\-ми преподавателями. В~итоге было получено, что 
среднее квадратическое отклонение оценок, вычисленных системой на 
основании сопоставлений вероятностно-статистических образов эталона и 
ответа по изложенной методологии, от оценок, выставленных 
преподавателями, по 100-балль\-ной шкале составило 10\%--15\%. 
Результаты со\-по\-став\-ле\-ния ВСМО и ВССО эталона и ответа оказались 
достаточно близкими. Отметим, что это была пробная проверка, 
предпринятая исключительно для обретения уверенности в практической 
эффективности оригинальной концепции.
   
   Углубление и детализация вероятностно-ста\-ти\-сти\-че\-ских моделей ИО на 
естественном языке, их исследование и применение представляют 
неограниченное, научно новое и практически полезное поле деятельности, в 
освоении которого автор может оказать посильную помощь. 

\vspace*{-6pt}
   
\section{Заключение}

\vspace*{-2pt}

   Разработана оригинальная методология оценки степени семантической 
близости инфор\-ма\-ционных объектов. Методология может служить 
   фор\-маль\-но-ма\-те\-ма\-ти\-че\-ской основой в сфере современных 
информационных технологий для решения разнообразных задач сравнения и 
оценки подобия информационных объектов, представленных на 
естественном языке. Методология вводит ве\-ро\-ят\-но\-ст\-но-ста\-ти\-сти\-че\-скую 
модель представления русскоязычного текста и определяет способы 
представления текстов в виде ве\-ро\-ят\-но\-ст\-но-ста\-ти\-сти\-че\-ских 
морфологических и синтаксических образов, которые позволяют оценить 
количественно и объем информации в информационных объектах, и степень 
их семантического совпадения. Экспериментальная прикидочная проверка 
показала эффективность применения методологии для разработки 
автоматизированных систем оценки знаний. Практическое применение 
методологии только в этой сфере может привести к принципиальным 
изменениям в сфере образования. 

\vspace*{-6pt}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{99}

\bibitem{1-k}
\Au{Друкер П.}
Посткапиталистическое общество. Новая постиндустриальная волна на Западе: 
Антология~/ Под ред. В.\,Л.~Иноземцева.~--- М.: Academia, 1990. 

\bibitem{2-k}
\Au{Мельчук И.\,А.}
Опыт теории лингвистических моделей <<Смысл\;$\leftrightarrow$\;Текст>>.~--- 
2-е изд.~--- М.: Школа <<Языки русской культуры>>, 1999.

\bibitem{3-k}
\Au{Шеннон К.}
Математическая теория связи. 1948~// Работы по теории информации и 
кибернетике~/ Пер. с англ. под ред. Р.\,Л.~Добрушина и О.\,Б.~Лупанова.~--- 
М.: ИЛ, 1963.

\bibitem{4-k}
\Au{Колмогоров А.\,Н.}
Теория информации и теория алгоритмов.~--- М.: Наука, 1987.

\bibitem{5-k}
\Au{Стратонович Р.\,Л.} Теория информации.~--- М.: Сов. радио, 1975.

\bibitem{6-k}
\Au{Кузнецов Л.\,А.}
Введение в САПР производства проката.~--- М.: Металлургия, 1991.

\bibitem{7-k}
\Au{Kuznetsov L.\,A.}
The entropy and information application to identify fuzzy sets~//  ICSC Symposium 
(International) on Fuzzy Logic Proceedings.~---  
Academic Press, 1995. P.~A109--A111.

\bibitem{8-k}
\Au{Белоусов В.\,Н., Ковтунова И.\,И., Кручинина~И.\,Н. и~др.}
Краткая русская грамматика~/ Под ред. Н.\,Ю.~Шведовой и 
В.\,В.~Лопатина~--- М.: Рус. яз., 1989.

\bibitem{9-k}
\Au{Гнеденко Б.\,В.}
Курс теории вероятностей: Учебник.~--- 9-е изд., испр.~--- М.: ЛКИ, 2007.

\bibitem{10-k}
\Au{Зализняк А.\,А.}
Грамматический словарь русского языка: Словоизменение.~--- 3-е изд., 
стер.~--- М.: Рус. яз.,1987. 880~с.
\bibitem{11-k}
Синтаксический анализатор Cognitive Dwarf 2.0. {\sf 
http://cs.isa.ru:10000/dwarf/d2/dw2.html}.

\bibitem{12-k}
\Au{Антонова А.\,А., Мисюрев~А.\,В.}
Реализация синтаксического разбора для русского и английского языков~// 
Системный анализ и информационные технологии (САИТ 2005): Мат-лы 
I~Междунар.\ конф.~--- Пе\-ре\-славль-За\-лес\-ский, 2005.~--- 
Переславль-Залесский, 2005. С.~245--249.

\bibitem{13-k}
\Au{Антонова А.\,А., Мисюрев А.\,В.}
Синтаксический анализатор для русского и английского языков~// Сб. трудов 
ИСА РАН~/ Под ред. В.\,Л.~Арлазарова и Н.\,Е.~Емельянова.~--- М.: УРСС, 
2007.

\label{end\stat}

\bibitem{14-k}
\Au{Кузнецов Л.\,А., Фарафонов А.\,С., Тищенко~А.\,Д., Капнин~А.\,В.}
Автоматизированная система поддержки образовательной программы 
обучения~// Качество. Инновации. Образование, 2010. №\,9. С.~12--20. 
 \end{thebibliography}
}
}


\end{multicols}       