\def\stat{krivenko}

\def\tit{ВЫБОР МОДЕЛИ ДАННЫХ В~ЗАДАЧАХ МЕДИЦИНСКОЙ ДИАГНОСТИКИ}

\def\titkol{Выбор модели данных в~задачах медицинской диагностики}

\def\aut{М.\,П.~Кривенко$^1$}

\def\autkol{М.\,П.~Кривенко}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Кривенко М.\,П.}
\index{Krivenko M.\,P.}



%{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
%{Работа выполнена при  поддержке РФФИ (проект 18-07-00617-A).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Институт проблем информатики Федерального исследовательского центра 
<<Информатика и~управление>> Российской академии наук, 
\mbox{mkrivenko@ipiran.ru}}

\vspace*{-2pt}




\Abst{Эффективное решение задач медицинской диагностики требует применения сложных 
вероятностных моделей, позволяющих адекватно описывать реальные данные 
и~допускающих применение аналитических методов обучаемой классификации. Выбор 
модели смеси нормальных распределений решает поставленные задачи, но приводит 
к~проблеме проклятия размерности. Переход к~модели смеси вероятностных анализаторов 
главных компонент позволяет формально поставить задачу выбора ее структурных 
параметров. Решение предлагается искать, комбинируя применение информационных 
критериев для формирования начальных приближений с~последующим уточнением 
получающихся оценок. На примере экспериментов по диагностированию болезней печени 
и~прогнозированию химического состава мочевых камней демонстрируются возможности 
описанных процедур анализа данных. Предлагаемые решения являются источником 
повышения точности классификации, дают толчок специалистам в~предметной области для 
прояснения сути протекающих процессов.}

\KW{медицинская диагностика; смесь вероятностных анализаторов главных компонент; 
критерий выбора модели; перепроверка} 

\DOI{10.14357/19922264190404} 
  
\vspace*{-4pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}


     
     Применение технологии машинного обучения для медицинской 
диагностики подразумевает принятие модели обрабатываемых данных, 
атрибутами которой должны быть адекватность, аналитическая 
и~вычислительная доступность, прозрачность диагностических решений 
и~возможность их объяснять.
     
     Вариант нормального распределения наиболее распространен и~в~то же 
время чаще всего критикуем (см., например,~[1]). В~том случае, когда модель 
нормального распределения не действует, ее\linebreak развитием является смесь 
нормальных распре\-делений~[2], которая за счет усложнения позволяет лучше 
описывать распределения реальных данных. При этом остается в~силе 
преимущество\linebreak относительно простых аналитических решений типовых 
вероятностных задач в~силу того, что основой остается нормальное 
распределение. Но особенно в~случае анализа многомерных данных 
использование смеси нормальных распределений приводит к~проб\-ле\-мам 
проклятия размерности. 
     
     Эти проблемы, в~свою очередь, актуализируют вопросы выбора варианта 
модели и~порождают необходимость снижения размерности данных. Причин 
здесь несколько: в~медицинской практике сбор данных о пациентах~--- часто 
дорогой, трудоемкий и~иногда вредный для пациентов процесс, и~его 
желательно упростить; из-за большой размерности данных обработка может 
оказаться невозможной; часто присутствует значительный объем избыточной 
или вводящей в~заблуждение информации, удаление которой может не только 
сократить время обработки и~повысить качество классификации, но и~сделать 
полученные решения более понятными. 
     
     Обычно выделяются методы отбора (селекции) признаков и~методы 
преобразования признаков~\cite{3-kri}. К~наиболее простым и~широко 
используемым методам преобразования относятся линейные, а среди них~--- 
анализ главных компонент (PCA~--- principal component
analysis). Но его полезность не проявляется для 
данных, демонстрирующих нелинейность. Понятно, что попытки исправить 
ситуацию были связаны с~расширением имеющихся подходов, в~част\-ности 
путем кластеризации данных и~выполнения PCA внутри кластеров. Подобный 
прогресс стал возможным в~рамках вероятностной модели анализаторов 
главных компонент (PPCA~--- probabilistic PCA) и~ее обобщения до соответствующей смеси 
(PPCAM~--- PPCA mixture).
     
     В~\cite{4-kri} рассматривались возможности разных подходов к~выбору 
структурных параметров (чис\-ло элементов смеси и~размерности этих 
элементов), характеризующих модель PPCAM. Способы \mbox{оценивания} этих 
параметров формируются в~непростых условиях, в~чис\-ле которых 
необходимость привлечения сложных априорных предположений и,~как 
следствие, проб\-ле\-мы полного их задания, отсутствие конкретных наработок 
в~области селекции моделей типа PPCAM, сложность решения сопутствующих 
аналитических и~вычислительных задач. Для реализации выбора размерностей 
предлагалось использовать комбинацию известных методов выбора 
размерностей принятой модели, а~для оценивания качества обучаемой 
классификации данных~--- методы управления выборкой. 
     
     Базовая вероятностная модель анализа главных компонент для 
сниженной размерности основывается на представлении

\vspace*{2pt}

\noindent
     $$
     \mathbf{y}=\mathbf{Wx}+\boldsymbol{\mu} +\boldsymbol{\varepsilon}\,,
     $$
     
     \vspace*{-4pt}
     
     \noindent
где $\mathbf{y}$~--- наблюдаемая $(d\times1)$-пе\-ре\-мен\-ная, $\mathbf{y}\sim$\linebreak
$\sim 
N(\boldsymbol{\mu}, \mathbf{C}(k))$; $\mathbf{W}$~--- ($d\times k$)-мат\-ри\-ца 
преобразования; $\mathbf{x}$~--- латентная ($k\times 1$)-пе\-ре\-мен\-ная, 
$\mathbf{x}\sim N(\mathbf{0}, \mathbf{I})$; $\boldsymbol{\varepsilon}\sim 
N(\mathbf{0},\sigma^2\mathbf{I})$; $\mathbf{C}(k)=\mathbf{WW}^{\mathrm{T}}\hm+ 
\sigma^2\mathbf{I}$. Здесь $d$~--- исходная размерность данных; $k$~--- 
сниженная размерность данных; $\boldsymbol{\mu}$, $\mathbf{W}$ 
и~$\sigma^2$ суть параметры модели. В~случае модели PPCAM каждому  
$j$-му элементу смеси соответствует свой набор па\-ра\-мет\-ров: $\pi_j$~--- вес 
элемента смеси, а~также~$\boldsymbol{\mu}_j$, $\mathbf{W}_j$ и~$\sigma_j^2$.

     Для оценивания параметров PPCAM существует два 
основных варианта~\cite{5-kri}: 
     \begin{enumerate}[(1)]
\item поэтапный, когда сначала находятся оценки параметров смеси 
нормальных распре\-де\-лений, затем осуществляется факторизация 
ковариационных матриц элементов смеси и,~наконец, строятся оценки 
параметров~$\mathbf{W}_j$ и~$\sigma_j^2$;
\item одновременный для оценивания всех па\-ра\-мет\-ров~$\pi_j$, 
$\boldsymbol{\mu}_j$, $\mathbf{W}_j$ и~$\sigma_j^2$, $j\hm= 1,\ldots , m$, 
в~со\-во\-куп\-ности.
\end{enumerate}
     
     Последний вариант из-за специфической организации итерационного 
процесса обладает вычислительными преимуществами, что может стать 
существенным при разовом оценивании. Но снижение размерности на основе 
выбора конкретной модели PPCAM подразумевает многократное оценивание ее 
параметров при различных предположениях. Поэтому поэтапный вариант 
оценивания становится более привлекательным, так как позволяет однократно 
получать представления ковариационных матриц элементов смеси, а затем 
многократно формировать из них нужные оценки. 
     
     Указанный принцип перехода от задачи с~большей размерностью 
к~меньшей можно эффективно использовать и~при переборе различных 
значений числа элементов смеси~$m$. Дело в~том, что одним из сложных 
элементов итерационного алгоритма оценивания параметров смеси оказывается 
формирование начальных приближений. Автор данной статьи для этого 
эффективно комбинирует следующие шаги: однократное оценивание 
параметров смеси для <<заведомо большого>> значения~$\tilde{m}$, а~затем\linebreak\vspace*{-12pt}

\columnbreak

\noindent 
повторное нахождение оценки для меньшего значения $\tilde{m}\hm-1$ путем 
выбора наилучшей оценки из~$\tilde{m}$ оценок, построенных при начальных 
приближениях, полученных исключением одного из элементов смеси в~оценке 
для~$\tilde{m}$.
     
     В~\cite{6-kri} приведен алгоритм выбора размерностей согласно 
информационным критериям AIC (Akaike's information criterion)
и~BIC (Bayesian information criterion) и~алгоритм последовательного выбора 
значений параметров размерности, не ухудшающих точность классификации 
с~точки зрения метода перепроверки (реализуется идея циклического 
покоординатного спуска). 
     
     В качестве иллюстрации предложенных идей анализировались 
результаты реальных обследований с~целью дискриминации данных 
о~ферментах для пациентов с~заболеваниями печени~\cite{7-kri}. Кроме этого 
рассматривалось построение прогноза состава камня по набору показателей как 
задача обуча\-емой классификации типов камней~\cite{6-kri}. Анализ данных 
показал: информационные критерии <<угадывают>> далеко не лучшие 
решения; из них предпочтительным оказывается AIC, что соответствует его 
нацеленности на аппроксимацию участ\-ву\-ющих в~классификации плотностей 
распределения данных; при относительно небольших значениях структурных 
размерностей удается найти решения, приемлемые по сложности 
и~превосходящие по точности известные подходы; полученные оценки в~виде 
смесей не только говорят о непростой структуре данных в~классах, но 
и~позволяют описать возникающие кластеры как через их параметры, так 
и~с~помощью соответствующих наборов наблюденных значений.
     
     Описанные подходы и~алгоритмы не гарантируют наилучшего решения, 
но позволяют выяснить, реально ли упрощение априорных предположений 
и~повышение качества принимаемых решений одновременно. Кроме того, 
появляется новый источник дополнительной информации об объектах 
медицинских исследований.
     
     Предлагаемые решения не просты, требуют дополнительных усилий по 
их развитию и, что более важно, внедрению в~практику медицинской 
диагностики, но создают предпосылки для новых открытий.

\vspace*{-9pt}
     
{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9}
 
 \vspace*{-3pt}
 
\bibitem{1-kri}
\Au{Harris E.\,K., Boyd~J.\,C.} Statistical bases of reference values in laboratory 
medicine.~--- New York, NY, USA: Marcel Dekker, 1995. 361~p.
\bibitem{2-kri}
\Au{Кривенко М.\,П.} Модели для представления и~обработки референсных 
значений~// Информатика и~её применения, 2015. Т.~9. Вып.~2. С.~63--74.
\bibitem{3-kri}
\Au{Jensen R., Shen~Q.} Computational intelligence and feature selection. Rough 
and fuzzy approaches.~--- Hoboken, NJ, USA: John Wiley \& Sons, 2008. 340~p. 
\bibitem{4-kri}
\Au{Кривенко М.\,П.} Выбор размерностей для смеси вероятностных 
анализаторов главных компонент~// Системы и~средства информатики, 2019. 
Т.~29. №\,3. С.~4--15.
\bibitem{5-kri}
\Au{Tipping M.\,E., Bishop~C.\,M.} Mixtures of probabilistic principal component 
analyzers~// Neural Comput., 1999. Vol.~11. Iss.~2. P.~443--482.
\bibitem{6-kri}
\Au{Кривенко М.\,П.} Снижение размерности для смеси вероятностных 
анализаторов главных компонент применительно к~задачам медицинской 
диагностики~// Системы и~средства информатики, 2019. Т.~29. №\,4. С.~4--13.
\bibitem{7-kri}
\Au{Albert A., Harris~E.\,K.} Multivariate interpretation of clinical laboratory 
data.~--- New York, NY, USA: CRC Press, 1987. 328~p.
 \end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 19.08.19}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{-2pt}

\def\tit{DATA MODEL SELECTION IN~MEDICAL DIAGNOSTIC TASKS}


\def\titkol{Data model selection in~medical diagnostic tasks}

\def\aut{M.\,P.~Krivenko}

\def\autkol{M.\,P.~Krivenko}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-11pt}


\noindent
        Institute of Informatics Problems, Federal Research Center ``Computer 
Science and Control'' of the Russian Academy of Sciences, 44-2~Vavilov Str., 
Moscow 119333, Russian Federation
       
\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2019\ \ \ volume~13\ \ \ issue\ 4}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2019\ \ \ volume~13\ \ \ issue\ 4
\hfill \textbf{\thepage}}}

\vspace*{3pt}  


\Abste{Effective solution of medical diagnostics tasks requires the use of complex probabilistic 
models which allow one to adequately describe real data and permit the use of analytical methods 
of the supervised learning classification. Choosing a~model of a~mixture of normal distributions 
solves the posed problems but leads to the curse of dimensionality. The transition to the model of a 
mixture of probabilistic principal component analyzers allows one to formally set the task of 
choosing its structural parameters. The solution is proposed to search by combining the application 
of information criteria for the formation of initial approximations followed by refinement of the 
resulting estimates. Using the example of experiments to diagnose liver diseases and 
to predict the 
chemical composition of urinary stones, the capabilities of the described data analysis procedures 
are demonstrated. The proposed solutions give a source of improving the accuracy of classification, 
impetus to experts in the subject area to clarify the essence of the processes.}

\KWE{medical diagnostics; mixture of probabilistic principal component analyzers; model 
selection criterion; cross validation }

  \DOI{10.14357/19922264190404} 

%\vspace*{-14pt}

%  \Ack
 %   \noindent
  


%\vspace*{-6pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9}
\bibitem{1-kri-1}
\Aue{Harris, E.\,K., and J.\,C.~Boyd.} 1995. \textit{Statistical bases of reference 
values in laboratory medicine}. New York, NY: Marcel Dekker. 361~p.
\bibitem{2-kri-1}
\Aue{Krivenko, M.\,P.} 2015. Modeli dlya predstavleniya i obrabotki referensnykh 
znacheniy [Models for representation and treatment of reference values]. 
\textit{Informatika i~ee Primeneniya~--- Inform. Appl.} 9(2):63--74.
\bibitem{3-kri-1}
\Aue{Jensen, R., and Q.~Shen.} 2008. \textit{Computational intelligence and feature 
selection. Rough and fuzzy approaches}. Hoboken, NJ: John Wiley \& Sons. 340~p.
\bibitem{4-kri-1}
\Aue{Krivenko, M.\,P.} 2019. Vybor razmernostey dlya smesi veroyatnostnykh 
analizatorov glavnykh component [The choice of dimensions for a mixture of 
probabilistic analyzers of the main components]. \textit{Sistemy i~Sredstva 
Informatiki~--- Systems and Means of Informatics} 29(3):4--15.
\bibitem{5-kri-1}
\Aue{Tipping, M.\,E., and C.\,M.~Bishop.} 1999. Mixtures of probabilistic principal 
component analyzers. \textit{Neural Comput.} 11(2):443--482.
\bibitem{6-kri-1}
\Aue{Krivenko, M.\,P.} 2019. Snizhenie razmernosti dlya smesi veroyatnostnykh 
analizatorov glavnykh komponent primenitel'no k~zadacham meditsinskoy 
diagnostiki [Dimension reduction for a~mixture of probabilistic analyzers of the main 
components as applied to medical diagnostic tasks]. \textit{Sistemy i~Sredstva 
Informatiki~--- Systems and Means of Informatics} 29(4):4--13.
\bibitem{7-kri-1}
\Aue{Albert, A., and E.\,K.~Harris}. 1987. \textit{Multivariate interpretation of 
clinical laboratory data}. New York, NY: CRC Press. 328~p.
\end{thebibliography}

 }
 }

\end{multicols}

%\vspace*{-7pt}

\hfill{\small\textit{Received August 19, 2019}}

%\pagebreak

%\vspace*{-22pt}

\Contrl

\noindent
\textbf{Krivenko Michail P.} (b.\ 1946)~--- Doctor of Science in technology, 
professor, leading scientist, Institute of Informatics Problems, Federal Research 
Center ``Computer Science and Control'' of the Russian Academy of Sciences,  
44-2~Vavilov Str., Moscow 119333, Russian Federation; 
\mbox{mkrivenko@ipiran.ru}
\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература}