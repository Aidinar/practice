\newcommand{\mujk}{\mu_{jk}}
\newcommand{\sumk}{\sum\limits_{k=0}^{2^j-1}}

\def\stat{shestakov}

\def\tit{СРЕДНЕКВАДРАТИЧНЫЙ РИСК НЕЛИНЕЙНОЙ РЕГУЛЯРИЗАЦИИ
ЗАДАЧИ ОБРАЩЕНИЯ\\ ЛИНЕЙНЫХ ОДНОРОДНЫХ ОПЕРАТОРОВ\\
ПРИ СЛУЧАЙНОМ ОБЪЕМЕ ВЫБОРКИ$^*$}

\def\titkol{Среднеквадратичный риск нелинейной регуляризации
задачи обращения линейных однородных операторов}
%при случайном объеме выборки}

\def\aut{О.\,В.~Шестаков$^1$}

\def\autkol{О.\,В.~Шестаков}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Шестаков О.\,В.}
\index{Shestakov O.\,V.}


{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Работа выполнена при финансовой поддержке Российского научного фонда 
(проект 18-11-00155).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский государственный университет им.\ М.\,В.~Ломоносова, 
кафедра математической статистики факультета вычислительной математики и~кибернетики; 
Институт проблем информатики Федерального исследовательского центра 
<<Информатика и~управ\-ле\-ние>> Российской академии наук, \mbox{oshestakov@cs.msu.su}}

%\vspace*{-2pt}


\Abst{Задачи построения оценок по наблюдениям, представляющим собой 
некоторое линейное преобразование от исходных данных, возникают во многих 
прикладных областях, таких как вычислительная томография, оптика, физика 
плазмы и~газовая динамика. При наличии шума в~наблюдениях, как правило, 
необходимо применять методы регуляризации. В~последнее время популярными 
стали методы пороговой обработки коэффициентов вейв\-лет-раз\-ло\-же\-ний. Объясняется 
это тем, что такие методы просты, вычислительно эффективны и~имеют 
возможность адаптации к~функциям, имеющим на разных участках разную 
степень регулярности. Анализ погрешностей этих методов представляет собой 
важную практическую задачу, поскольку позволяет оценить качество как самих 
методов, так и~используемого оборудования. При использовании методов пороговой 
обработки обычно предполагается, что число коэффициентов разложения фиксировано, 
а~распределение шума является гауссовым. Эта модель хорошо изучена в~литературе, 
и~для разных классов функций сигналов вычислены оптимальные значения порогов. 
Однако в~некоторых ситуациях объем выборки заранее не известен и~его 
приходится моделировать некоторой случайной величиной. В~данной работе 
рассматривается модель со случайным числом наблюдений, содержащих гауссов 
шум, и~оценивается порядок среднеквадратичного риска при растущем объеме выборки.}

\KW{вейвлеты; пороговая обработка; линейный однородный оператор; 
случайный объем выборки; среднеквадратичный риск}

\DOI{10.14357/19922264190408} 
  
%\vspace*{1pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}


\section{Введение}

При решении обратных статистических задач возникает проблема обращения 
некоторого линейного оператора, и~если в~наблюдаемых данных содержится шум, 
то необходимо применять методы регуляризации. 
В~последнее время значительно возросла популярность нелинейных методов 
подавления шума с~помощью вейв\-лет-раз\-ло\-же\-ния и~процедур пороговой 
обработки~\cite{D94, AS98}. Наиболее распространенными являются мягкая и~жесткая 
пороговые обработки. Такие процедуры позволяют подавить б$\acute{\mbox{о}}$льшую часть шума,
 возникающего из-за дискретизации исходной информации, несовершенства 
 оборудования, случайных помех, наличия фонового излучения и~других причин. 
 Кроме того, таким образом осуществляется сжатие данных с~незначительной потерей
  информации, что позволяет более экономно хранить информацию и~быстрее 
  передавать ее по каналам цифровой связи.

В некоторых случаях объем данных, доступных для анализа (объем выборки), 
заранее не известен. Такие ситуации могут возникать, например, в~случае 
пропуска данных, ограниченности времени сбора данных при случайных временах 
регистрации наблюдений или недостатке информации о характеристиках используемого
 оборудования. В~таком случае предполагается, что объем выборки данных представляет 
 собой случайную величину с~некоторым распределением вероятностей. 
 
 В~моделях с~фиксированным объемом выборки статистические свойства процедур 
 пороговой обработки хорошо изучены и~получены выражения для <<оптимальных>> 
 порогов, ориентированных на различные классы функций сигналов и~различные 
 распределения шума (см., например,~\cite{DJ94, DJ95, DJ98, Jan01, Jan06, SH17}). 
 
 В~данной работе рассматривается модель со случайным числом коэффициентов 
 разложения функции, представляющей собой линейное однородное преобразование 
 искомого сигнала, <<загрязненных>> белым гауссовым шумом, и~оценивается 
 порядок среднеквадратичного риска пороговой обработки при решении задачи 
 обращения этого преобразования. Аналогичные результаты в~модели прямого 
 наблюдения сигнала получены в~работах~\cite{SH18, SH19}.


\section{Обращение линейных однородных операторов}

Линейным однородным оператором называется такое линейное преобразование~$K$ 
искомой функции~$f$, что
$$
K\left[f\left(a\left(x-x_0\right)\right)\right]=a^{-\beta}(Kf)\left[a\left(x-x_0\right)\right]
$$
для любого $x_0$ и~любого $a\hm>0$. Параметр~$\beta$ называется показателем 
однородности. Примерами линейных однородных операторов служат оператор 
интегрирования, преобразование Гильберта и~преобразование Абеля. 
Математические модели с~такими операторами используются при решении 
задач вычислительной томографии, физики плазмы, оптики и~т.\,д.

Рассмотрим методы обращения оператора~$K$, основанные на свойствах 
вейв\-лет-раз\-ло\-же\-ний~\cite{D94, AS98}. Преимуществом этих методов 
является адап\-та\-ция не только к~свойствам оператора~$K$, но и~к~свойствам самой 
искомой функции~$f$.

Вейвлет-разложение функции $f\hm\in L^2(\mathbb{R})$ имеет вид:
\begin{equation}                                                              
\label{waveletdecomp}
f = \sum\limits_{j,k\in Z} \langle f,\psi_{jk}\rangle  \psi_{jk},
\end{equation}
где $\psi_{jk}(t)=2^{j/2}\psi(2^jt-k)$, а $\psi(t)$~-- 
некоторая материнская вейв\-лет-функ\-ция (семейство $\{\psi_{jk}\}_{j,k\in Z}$ 
образует ортонормированный базис в~$L^2(\mathbb{R})$). Индекс~$j$ 
в~\eqref{waveletdecomp} называется масштабом, а индекс~$k$~--- сдвигом. 
В~дальнейшем будут рассматриваться функции на отрезке $[0,1]$,
 равномерно регулярные по Липшицу с~некоторым показателем $\gamma\hm>0$ 
 и~константой Липшица $L\hm>0$. Для таких функций известно~\cite{Mall99}, что если 
 вейв\-лет-функ\-ция~$M$ раз непрерывно дифференцируема ($M\hm\geqslant\gamma$), 
 имеет~$M$ нулевых моментов и~достаточно быстро убывает на бесконечности, т.\,е.\
  существует такая константа $C_A\hm>0$, что
$$
\int\limits_{-\infty}^{\infty}\left(
1+\abs{t}^{\gamma}\right)\abs{\psi(t)}dt\leqslant C_A,$$
то найдется такая константа $A\hm>0$, что 
\begin{equation}                                                                      \label{Coeff_Decay}
\abs{\langle f, \psi_{jk} \rangle} \leqslant 
\fr{A}{2^{j \left( \gamma + 1/2 \right)}}\,.
\end{equation}

Поскольку оператор~$K$ линеен и~однороден, существуют такие функции~$\xi_{jk}$, 
что $\langle K f, \xi_{jk}\rangle\hm = \langle f, \psi_{jk}\rangle$~\cite{D94}. 
Функции~$\xi_{jk}$ называются <<вейглетами>>. По своим свойствам 
они похожи на вейвлеты и~также представляют собой сдвиги 
и~растяжения некоторой материнской функции~$\xi$.

Далее пусть $\xi_{jk} \hm= \lambda_{jk} u_{jk}$, где $\lambda_{jk} \hm= 
\norm{(K^*)^{-1} \psi_{jk}}$. Можно показать, что 
$\lambda_{jk}\hm=2^{\beta j}\lambda_{00}$.
При этом функция~$f$ представляется в~виде ряда
\begin{equation} 
\label{WVD}
f=\sum\limits_{j,k\in Z}\lambda_{jk}\langle Kf,u_{jk}\rangle\psi_{jk}.
\end{equation}
Как видно, в~\eqref{WVD} коэффициенты разложения выражаются через~$Kf$, 
а~не через~$f$. Эта формула лежит 
в~основе метода обращения~$K$, который называется вейв\-лет--вейг\-лет-раз\-ло\-же\-нием.


Аналогично по базису вейв\-лет-функ\-ций можно разложить~$Kf$:
\begin{equation*}
Kf = \sum\limits_{j,k\in Z} \langle Kf,\psi_{jk}\rangle \psi_{jk}.
\end{equation*}
Функции $\psi_{jk}$ не обязаны совпадать с~функциями в~разложении~\eqref{waveletdecomp}, 
но для удобства будем обозначать их так же. Если функции~$Kf$ и~$\psi$ 
удовлетворяют перечисленным выше условиям, то найдется такая константа $C_K\hm>0$, что
\begin{equation}                                                                           \label{VWD_Coeff_Decay}
\abs{\langle Kf,\psi_{jk}\rangle} \leqslant 
\fr{C_K} {2^{j \left(\gamma +{1}/{2} \right)}}.
\end{equation}

Далее через $\mathrm{Lip}(\gamma)$ будем обозначать класс регулярных по 
Липшицу функций, коэффициенты разложения которых удовлетворяют~\eqref{Coeff_Decay} 
или~\eqref{VWD_Coeff_Decay} в~зависимости от используемого метода обращения. 
При этом, поскольку наблюдаемой является функция~$Kf$, 
условия регулярности будут накладываться на нее. 

Пусть теперь $\lambda_{jk}\hm = \norm{K^{-1}\psi_{jk}}$, тогда $\lambda_{jk}\hm =
 2^{\beta j}\lambda_{00}$, а функция~$f$ представляется в~виде ряда~\cite{AS98}
\begin{equation} 
\label{VWD}
f = \sum\limits_{j,k\in Z}\lambda_{jk}\langle Kf,\psi_{jk}\rangle u_{jk},
\end{equation}
где $u_{jk} = K^{-1}\psi_{jk}/\lambda_{jk}$. Функции~$u_{jk}$ не совпадают с~функциями 
в~разложении~\eqref{WVD}, однако по аналогии также называются <<вейглетами>>. 
Формула~\eqref{VWD} лежит в~основе еще одного метода обращения, который 
называется вейг\-лет--вейв\-лет-раз\-ло\-же\-ни\-ем.

Последовательности $\{u_{jk}\}$ в~обоих разложениях не образуют 
ортонормированную систему,
однако если выполнены некоторые условия гладкости, то они образуют
устойчивые базисы~\cite{Lee97, KS11}.



\section{Пороговая обработка коэффициентов}


Рассмотрим следующую модель данных:
\begin{equation*}
X_i = K f(i/n) + z_i, \qquad i = 1, \ldots, 2^J,
\end{equation*}
где $z_{i}$~--- <<шумовые>> коэффициенты, относительно которых
 предполагается, что они независимы и~имеют нормальное распределение 
 с~нулевым средним и~дисперсией~$\sigma^2$. Повторяя рассуждения, описанные 
 в~работах~\cite{ESH14-1, EKS15}, переходим к~моделям дискретных вейглет- или 
 вейв\-лет-ко\-эф\-фи\-ци\-ентов.


Для метода вейв\-лет--вейг\-лет-раз\-ло\-же\-ния имеем
\begin{equation}                                                                         \label{WVD_model}
\begin{split}
Y^{W}_{jk} = \mu^{W}_{jk} +  w_{jk},
\end{split}
\end{equation}
где $\mu^{W}_{jk}\approx 2^{J/2}\langle K f, u_{jk}\rangle$, 
а~шумовые коэффициенты~$w_{jk}$ имеют нормальное распределение с~нулевым средним 
и~не являются независимыми. Дис\-пер\-сии~$\sigma_W^2$ коэффициентов~$w_{jk}$ 
зависят от вида оператора и~выбранного вейв\-лет-ба\-зи\-са, но не зависят от~$j$ 
и~$k$~\cite{JS97, J99}.

Модель вейглет--вейв\-лет-ко\-эф\-фи\-ци\-ен\-тов имеет вид:
\begin{equation}                                              
\label{VWD_model}
Y^{V}_{jk} = \mu^{V}_{jk} +   v_{jk},
\end{equation}
где $\mu^{V}_{jk}\approx 2^{J/2}\langle Kf,\psi_{jk}\rangle$, 
а~шумовые коэффициенты~$v_{jk}$ независимы и~имеют нормальное распределение с~нулевым 
средним и~дисперсией $\sigma_V^2\hm=\sigma^2$.

Популярным методом подавления шума и~построения оценки функции~$f$ 
является пороговая обработка эмпирических коэффициентов. 
К~коэффициентам в~моделях~\eqref{WVD_model} или~\eqref{VWD_model} 
применяется функция жесткой пороговой обработки 
$\rho_{H}(x,T)\hm=y\mathbf{1}(\abs{x}\hm>T)$ или мягкой пороговой 
обработки $\rho_{S}(x,T)\hm=\mathrm{sgn}(x)\left(\abs{x}-T\right)_{+}$ с~порогом~$T$. 
Смысл пороговой обработки заключается в~удалении достаточно маленьких
 коэффициентов, которые считаются шумом.

Далее для сокращения записи будем обозначать через~$Y_{jk}$ <<зашумленные>> 
коэффициенты моделей~\eqref{WVD_model} и~\eqref{VWD_model}, а через~$\mu_{jk}$~--- 
<<чистые>> коэффициенты этих моделей. Через~$\hat{Y}_{jk}$ будем обозначать 
оценки~$\mu_{jk}$, полученные с~помощью пороговой обработки. Также дисперсии 
шумовых коэффициентов~$\sigma_W^2$ и~$\sigma_V^2$ будем обозначать одним 
символом~$\sigma^2$ (хотя эти дисперсии, вообще говоря, различны).

Среднеквадратичный риск пороговой обработки определяется по формуле:
\begin{equation}
\label{Risk_Definition}
r_J(f)=\fr{1}{2^J}\sum\limits_{j=0}^{J-1}\sumk\limits \lambda^2_{jk}
{\sf E}\left(\hat{Y}_{jk}-\mujk\right)^2.
\end{equation}

В ситуации, когда число эмпирических коэффициентов разложения не случайно, в~задачах 
подавления шума и~обратных статистических задачах вычислены оптимальные 
значения порогов и~оценен порядок среднеквадратичного риска для различных 
классов функций сигналов. В~част\-ности,\linebreak повторяя рассуждения, приведенные 
в~работах~\cite{AS98, DJ95, CB99} можно доказать следующее утверждение, 
оценивающее минимаксный порядок риска~\eqref{Risk_Definition}.

\smallskip

\noindent
\textbf{Теорема 1.}\ \textit{Пусть $\gamma>\beta$. При выборе асимптотически оптимального порога для жесткой и~мягкой пороговой обработки справедливо соотношение}:
$$
\sup\limits_{Kf\in \mathrm{Lip}(\gamma)}{r_J(f)}\leqslant 
C\cdot 2^{\frac{2\beta-2\gamma}{2\gamma+1}J}
J^{\frac{2\gamma+2\beta+2}{2\gamma+1}},
$$
\textit{где~$C$~--- некоторая положительная константа}.

\smallskip

Асимптотически оптимальный порог в~теореме~1 при $J\hm\to\infty$ 
удовлетворяет соотношению:
$$
T\simeq\sigma\sqrt{\fr{4\gamma}{2\gamma+1}(1+2\beta)\ln2^J}.
$$


В следующем разделе оценивается порядок среднеквадратичного 
риска пороговой обработки в~модели со случайным числом эмпирических 
коэффициентов разложения.

\vspace*{-6pt}


\section{Случайное число коэффициентов разложения}

Пусть $M$~--- положительная целочисленная случайная величина и~$N\hm=2^M$. 
Тогда среднеквадратичный риск принимает вид:
\begin{multline}
r(f)={}\\
\hspace*{-2mm}{}=\sum\limits_{J=0}^{\infty}{\sf P}\left(N=2^J\right)
\fr{1}{2^J}\sum\limits_{j=0}^{J-1}
\sumk\limits \lambda^2_{jk}{\sf E}\left(\hat{Y}_{jk}-\mujk\right)^2\!\!
\label{Risk_Definition_Rand}
\end{multline}
и его асимптотический порядок в~значительной степени зависит от распределения~$N$. 
Чтобы получить осмысленные оценки порядка риска~\eqref{Risk_Definition_Rand}, 
величина~$N$ должна быть <<большой>>. Рассмотрим последовательность~$N_n$, 
$n\hm=1,\ldots$,  и~предположим, что существует неслучайная возрастающая 
последовательность натуральных чисел~$J_n$, $n\hm=1,\ldots$, такая, что 
$N_n/2^{J_n}$ имеет некоторый предел 
(в~смысле равномерной сходимости по распределению) при $n\hm\to\infty$, т.\,е.
\begin{equation}
\label{converge}
\sup\limits_{x\geqslant0}\abs{H_n(x)-H(x)}<\fr{\varepsilon_n}{2}\to 0\,, \enskip
n\to\infty\,,
\end{equation}
где

\noindent
\begin{equation*}
H_n(x)={\sf P}\left(\fr{N_n}{2^{J_n}}<x\right),
\end{equation*}
а $H(x)$~--- предельная функция распределения. Предположим, что~$H(x)$ не 
имеет атома в~нуле и~исследуем поведение
\begin{multline*}
r_n(f)={}\\
{}=\sum\limits_{J=0}^{\infty}{\sf P}
\left(N_n=2^J\right)\fr{1}{2^J}\sum\limits_{j=0}^{J-1}\sumk\limits \lambda^2_{jk}
{\sf E}\left(\hat{Y}_{jk}-\mujk\right)^2
%\label{Risk_Definition_Rand2}
\end{multline*}
при $n\to\infty$.

Пусть $\delta_n\to0$ и~$\alpha_n\hm\to0$ при $n\hm\to\infty$ так, что 
$J_n\hm+\log_2\delta_n\hm\to\infty$ и~$H(\delta_n)\hm+1\hm-H(\delta^{-1}_n)\hm<\alpha_n$ 
при всех $n\hm=1,\ldots$

Тогда
\begin{multline*}
r_n(f)=\sum\limits_{J=0}^{[J_n+\log_2\delta_n]}\hspace*{-5mm}
{\sf P}\left(N_n=2^J\right)\times{}\\
{}\times\fr{1}{2^J}
\sum\limits_{j=0}^{J-1}\sumk\limits \lambda^2_{jk}
{\sf E}\left(\hat{Y}_{jk}-\mujk\right)^2+{}\\
{}+\sum\limits_{J=[J_n+\log_2\delta_n]+1}^{[J_n-\log_2\delta_n]}
\hspace*{-5mm}
{\sf P}\left(N_n=2^J\right)\times{}\\
{}\times \fr{1}{2^J}
\sum\limits_{j=0}^{J-1}\sumk\limits \lambda^2_{jk}
{\sf E}\left(\hat{Y}_{jk}-\mujk\right)^2+{}\\
{}+\sum\limits_{J=[J_n-\log_2\delta_n]+1}^{\infty}
\hspace*{-5mm}
{\sf P}
\left(N_n=2^J\right)\times{}\\
{}\times\fr{1}{2^J}\sum\limits_{j=0}^{J-1}\sumk\limits \lambda^2_{jk}
{\sf E}\left(\hat{Y}_{jk}-\mujk\right)^2\equiv S_1+S_2+S_3\,.
\end{multline*}
Учитывая~\eqref{converge}, для $S_1\hm+S_3$ имеем:
\begin{multline*}
S_1+S_3\leqslant C_0\left(H_n\left(\delta_n\right)+1-H_n
\left(\delta^{-1}_n\right)\right)\times{}\\
{}\times
\left(J_n+\log_2\delta_n\right)2^{2\beta(J_n+\log_2\delta_n)}
\leqslant{}\\ 
{}\leqslant C_0\left(\alpha_n+\varepsilon_n\right)
\left(J_n+\log_2\delta_n\right)2^{2\beta(J_n+\log_2\delta_n)},
\end{multline*}
где $C_0$~--- некоторая положительная константа.
Для~$S_2$ с~помощью теоремы~1 можно получить \mbox{оценку}:
\begin{equation*}
S_2\leqslant C_1 \cdot
2^{\frac{2\beta-2\gamma}{2\gamma+1}(J_n+\log_2\delta_n)}
\left(J_n+\log_2\delta_n\right)^{\frac{2\gamma+2\beta+2}{2\gamma+1}},
\end{equation*}
где $C_1$~--- некоторая положительная константа. 
Таким образом, справедливо следующее утверждение.

\smallskip


\noindent
\textbf{Теорема~2.}\
\textit{Пусть $\gamma>\beta$. В модели со случайным чис\-лом эмпирических коэффициентов при выборе асимптотически
 оптимального порога начиная с~некоторого~$n$ справедлива оценка}
 
\noindent
\begin{multline*}
\sup\limits_{Kf\in \mathrm{Lip}(\gamma)}
{r_n(f)}\leqslant{}\\
{}\leqslant  C_0\left(\alpha_n+\varepsilon_n\right)
\left(J_n+\log_2\delta_n\right)
2^{2\beta(J_n+\log_2\delta_n)}+{}\\
{}+
C_1\cdot 2^{\frac{2\beta-2\gamma}{2\gamma+1}(J_n+\log_2\delta_n)}
\left(J_n+\log_2\delta_n\right)^{\frac{2\gamma+2\beta+2}{2\gamma+1}}.
\end{multline*}

Сам асимптотически оптимальный порог при $n\hm\to\infty$ удовлетворяет соотношению:

\noindent
$$
T_n\simeq\sigma\sqrt{\fr{4\gamma}{2\gamma+1}(1+2\beta)\ln 2^{J_n+\log_2\delta_n}}.
$$


Вид $\alpha_n$, $\varepsilon_n$ и~$\delta_n$ в~теореме~2 
существенно зависит от поведения последовательности~$N_n/2^{J_n}$ 
и~предельной функции распределения~$H(x)$. Так, $\varepsilon_n$ 
характеризует скорость сходимости~$H_n(x)$ к~$H(x)$, а $\alpha_n$ и~$\delta_n$ 
зависят от поведения~$H(x)$ в~окрестности нуля и~бесконечности.

\smallskip

\noindent
\textbf{Следствие~1.}\
 Если предельное распределение $N_n/2^{J_n}$ вырождено: 
 $N_n/2^{J_n}\xrightarrow{{\sf P}}1$ при $n\hm\to\infty$, тогда начиная 
 с~некоторого~$n$
 
 \noindent
\begin{equation*}
\sup\limits_{f\in \mathrm{Lip}(\gamma)}{r_n(f)}
\leqslant \varepsilon'_n J_n 2^{2\beta J_n}+C_2 \cdot
2^{\frac{2\beta-2\gamma}{2\gamma+1}J_n}
J_n^{\frac{2\gamma+2\beta+2}{2\gamma+1}},
\end{equation*}
где $\varepsilon'_n$ характеризует скорость стремления 
$N_n/2^{J_n}\xrightarrow{{\sf P}}1$, а $C_2$~--- некоторая положительная константа.

Если $\varepsilon'_n$ убывает достаточно быстро, 
то эта оценка совпадает с~оценкой для среднеквадратичного 
риска в~модели с~неслучайным числом эмпирических коэффициентов.

\smallskip

\noindent
\textbf{Следствие~2.}\ 
Пусть $H(x)$ дифференцируема в~окрестности нуля и~для некоторых 
положительных констант~$b$ и~$B$ в~этой окрестности выполнено 
$b\hm\leqslant H'(x)\hm\leqslant B$. Пусть
$\delta_n\simeq 2^{-\frac{4\beta\gamma+2\gamma}{4\beta\gamma+4\gamma+1}J_n}$. 
Тогда начиная с~некоторого~$n$ справедлива оценка:

\noindent
\begin{multline*}
%\label{hard_col1}
\sup\limits_{f\in \mathrm{Lip}(\gamma)}
{r_n(f)}\leqslant C_0\varepsilon_n J_n\cdot
2^{\frac{4\beta\gamma+2\beta}{4\beta\gamma+4\gamma+1}}+{}\\
{}+
C_3 \cdot
2^{-\frac{4\beta\gamma+2\gamma}{4\beta\gamma+4\gamma+1}J_n}
J_n^{\frac{2\gamma+2\beta+2}{2\gamma+1}},
\end{multline*}
где $C_3$~--- некоторая положительная константа.

Таким образом, среднеквадратичный риск для случайного числа эмпирических 
коэффициентов может стремиться к~нулю значительно медленнее, 
чем среднеквадратичный риск для неслучайного числа коэффициентов.

\vspace*{-12pt}


{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
\bibitem{D94}
\Au{Donoho~D.}  Nonlinear solution of linear inverse problems by 
wavelet-vaguelette decomposition~// Appl. Comput. Harmon.~A., 1995. Vol.~2. 
P.~101--126.

\bibitem{AS98}
\Au{Abramovich F., Silverman~B.\,W.} Wavelet 
decomposition approaches to statistical inverse problems~// Biometrika, 1998. 
Vol.~85. No.\,1. P.~115--129.

\bibitem{DJ94}
\Au{Donoho D., Johnstone~I.\,M.} Ideal spatial adaptation via wavelet shrinkage~// 
Biometri\-ka, 1994. Vol.~81. No.\,3. P.~425--455.

\bibitem{DJ95}
\Au{Donoho D., Johnstone~I.\,M., Kerkyacharian~G., Picard~D.} 
Wavelet shrinkage: Asymptopia?~// J.~R. Stat. Soc.~B, 1995. Vol.~57. No.\,2. 
P.~301--369.

\bibitem{DJ98}
\Au{Donoho D., Johnstone~I.\,M.} 
Minimax estimation via wavelet shrinkage~// 
Ann. Stat., 1998. Vol.~26. No.\,3. P.~879--921.

\bibitem{Jan01}
\Au{Jansen M.} Noise reduction by wavelet thresholding.~---  
Lecture notes in statistics ser.~--- New York, NY, USA: 
Springer, 2001. Vol.~161. 217~с.

\bibitem{Jan06}
\Au{Jansen M.} Minimum risk thresholds for data with heavy noise~// 
IEEE Signal Proc. Lett., 2006. Vol.~13. No.\,5. P.~296--299.

\bibitem{SH17}
\Au{Шестаков О.\,В.} Минимаксный среднеквадратичный риск пороговой обработки 
в~моделях с~негауссовым распределением шума~// Вестн. Моск. ун-та. Сер.~15: 
Вычисл. матем. и~киберн., 2017. №\,4. C.~35--40.

\bibitem{SH18}
\Au{Шестаков О.\,В.} Среднеквадратичный риск пороговой обработки при случайном объеме выборки~//
Информатика и~её применения, 2018. Т.~12. Вып.~3. С.~14--17.

\bibitem{SH19}
\Au{Shestakov O.\,V.} Averaged probability of the error in calculating
 wavelet coefficients for the random sample size~// J.~Math. Sci., 2019. Vol.~237. No.\,6. P.~826--830.

\bibitem{Mall99}
\Au{Mallat S.} A~wavelet tour of signal processing.~--- 
New York, NY, USA:~Academic Press, 1999. 857~p.

\bibitem{Lee97}
\Au{Lee N.} Wavelet-vaguelette decompositions and homogenous equations.~-- 
West Lafayette, IN, USA: Purdue University, 1997.  PhD Thesis. 103~p.

\bibitem{KS11}
\Au{Кудрявцев А.\,А., Шестаков~О.\,В.} 
Асимптотика оценки риска при вейг\-лет-вейв\-лет разложении наблюдаемого сигнала~// 
T-Comm~--- Телекоммуникации и~Транспорт, 2011. №\,2. С.~54--57.

\bibitem{ESH14-1}
\Au{Ерошенко А.\,А., Шестаков~О.\,В.} 
Асимптотическая нормальность оценки риска при вейв\-лет--вейг\-лет-раз\-ло\-же\-нии 
функции сигнала в~модели с~коррелированным шумом~// 
Вестн. Моск. ун-та. Сер.~15: Вычисл. матем. и~киберн., 2014. №\,3. C.~110--117.

\bibitem{EKS15}
\Au{Ерошенко А.\,А., Кудрявцев~А.\,А., Шестаков~О.\,В.} 
Предельное распределение оценки риска метода вейг\-лет--вейв\-лет-раз\-ло\-же\-ния 
сигнала в~модели с~коррелированным шумом~// Вестн. Моск. ун-та. Сер.~15: 
Вычисл. матем. и~киберн., 2015. №\,1. C.~12--18.

\bibitem{JS97}
\Au{Johnstone I.\,M., Silverman~B.\,W.} 
Wavelet threshold estimates for data with correlated noise~// J.~R.~Stat.
Soc.~B, 1997. Vol.~59. P.~319--351.

\bibitem{J99}
\Au{Johnstone I.\,M.} 
Wavelet shrinkage for correlated data and inverse problems adaptivity results~// 
Stat. Sinica, 1999. Vol.~9. P.~51--83.

\bibitem{CB99}
\Au{Cai T., Brown~L.} Wavelet estimation for samples with random uniform design~// 
Stat. Probabil. Lett., 1999. Vol.~42. P.~313--321.
 \end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 16.05.19}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{-2pt}

\def\tit{THE MEAN SQUARE RISK OF~NONLINEAR REGULARIZATION IN~THE~PROBLEM OF~INVERSION 
OF~LINEAR HOMOGENEOUS OPERATORS WITH~A~RANDOM SAMPLE SIZE}


\def\titkol{The mean square risk of nonlinear regularization in the problem of inversion 
of linear homogeneous operators} % with a random sample size}

\def\aut{O.\,V.~Shestakov$^{1,2}$}

\def\autkol{O.\,V.~Shestakov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-11pt}


\noindent
$^1$Department of Mathematical Statistics, Faculty of Computational 
Mathematics and Cybernetics, M.\,V.~Lo\-mo-\linebreak
$\hphantom{^1}$no\-sov Moscow State University, 
1-52~Leninskiye Gory, GSP-1, Moscow 119991, Russian Federation

\noindent
$^2$Institute of Informatics Problems, Federal Research Center 
``Computer Science and Control'' of the Russian\linebreak
$\hphantom{^1}$Academy of Sciences, 
44-2~Vavilov Str., Moscow 119333, Russian Federation

\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2019\ \ \ volume~13\ \ \ issue\ 4}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2019\ \ \ volume~13\ \ \ issue\ 4
\hfill \textbf{\thepage}}}

\vspace*{3pt}  

 

\Abste{The problems of constructing estimates from observations, which represent 
a~linear transformation of the initial data, arise in many application areas, 
such as computed tomography, optics, plasma physics, and gas dynamics. 
In the presence of noise in the observations, as a~rule, it is 
necessary to apply regularization methods. Recently, the methods of threshold 
processing of wavelet expansion coefficients have become popular. 
This is explained by the fact that such methods are simple, computationally 
efficient, and have the ability to adapt to functions which have different 
degrees of regularity at different areas. The analysis of errors of these 
methods is an important practical task, since it allows assessing the 
quality of both the methods themselves and the equipment used. When 
using threshold processing methods, it is usually assumed that the 
number of expansion coefficients is fixed and the noise distribution is Gaussian. 
This model is well studied in literature and optimal threshold values are 
calculated for different classes of signal functions. However, in some situations,
 the sample size is not known in advance and has to be modeled by 
 a~random variable. In this paper, the author considers 
 a~model with a~random number of observations containing Gaussian noise and 
 estimates the order of the mean-square risk with an increasing sample size.}

\KWE{wavelets; threshold processing; linear homogeneous operator; 
random sample size; mean square risk}




  \DOI{10.14357/19922264190408} 

%\vspace*{-14pt}

  \Ack
\noindent
This research is supported by the Russian Science Foundation (project No.\,18-11-00155).


%\vspace*{-6pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}

\bibitem{1-sh-1}
\Aue{Donoho, D.} 1995. Nonlinear solution of linear inverse problems 
by wavelet-vaguelette decomposition. \textit{Appl. Comput. Harmon.~A.} 2:101--126.

\bibitem{2-sh-1}
\Aue{Abramovich, F., and B.\,W.~Silverman.}
 1998. Wavelet decomposition approaches to statistical inverse problems.
 \textit{Biometrika} 85(1):115--129.

\bibitem{3-sh-1}
\Aue{Donoho, D., and I.\,M.~Johnstone.}
 1994. Ideal spatial adaptation via wavelet shrinkage. \textit{Biometrika} 81(3):425--455.

\bibitem{4-sh-1}
\Aue{Donoho, D., I.\,M.~Johnstone, G.~Kerkyacharian, and D.~Picard.}
 1995. Wavelet shrinkage: Asymptopia? \textit{J.~R.~Stat. Soc.~B}
 57(2):301--369.

\bibitem{5-sh-1}
\Aue{Donoho, D., and I.\,M.~Johnstone.}
 1998. Minimax estimation via wavelet shrinkage. \textit{Ann. Statist.} 26(3):879--921.

\bibitem{6-sh-1}
\Aue{Jansen, M.}
 2001. \textit{Noise reduction by wavelet thresholding}. 
 Lecture notes in statistics ser.
 New York, NY: Springer. Vol.~161. 217~p.

\bibitem{7-sh-1}
\Aue{Jansen, M.} 2006. Minimum risk thresholds for data with heavy noise. 
\textit{IEEE Signal Proc. Lett.} 13(5):296--299.

\bibitem{8-sh-1}
\Aue{Shestakov, O.\,V.} 2017. Minimax mean-square thresholding risk 
in models with non-Gaussian noise distribution. 
\textit{Moscow Univ. Comput. Math. Cybern.} 41(4):187--192.

\bibitem{9-sh-1}
\Aue{Shestakov, O.\,V.} 2018. Srednekvadratichnyy risk 
po\-ro\-go\-voy obrabotki pri sluchaynom ob''eme vyborki 
[Mean-square thresholding risk with a random sample size].
\textit{Informatika i~ee Primeneniya~--- Inform. Appl.} 12(3):14--17.

\bibitem{10-sh-1}
\Aue{Shestakov, O.\,V.} 2019. Averaged probability 
of the error in calculating wavelet coefficients for the random sample size. 
\textit{J.~Math. Sci.} 237(6):826--830.

\bibitem{11-sh-1}
\Aue{Mallat, S.} 1999. \textit{A~wavelet tour of signal processing}. 
New York, NY: Academic Press. 857~p.

\bibitem{12-sh-1}
\Aue{Lee, N.} 1997. Wavelet-vaguelette decompositions and homogenous equations. 
West Lafayette, IN: Purdue University. PhD Thesis. 103~p.

\bibitem{13-sh-1}
\Aue{Kudryavtsev, A.\,A., and O.\,V.~Shestakov.}
 2011. Asimptotika otsenki riska pri veyglet-veyvlet 
 razlozhenii na\-blyu\-da\-emo\-go signala [The average risk assessment 
 of the wavelet decomposition of the signal]. \textit{T-Comm~--- 
 Telekommunikatsii i~Transport} [T-Comm~--- Telecommunications and Transport] 2:54--57.

\bibitem{14-sh-1}
\Aue{Eroshenko, A.\,A., and O.\,V.~Shestakov.} 2014.
 Asymptotic normality of estimating risk upon the wavelet-vaguelette 
 decomposition of a signal function in a model with correlated noise. 
 \textit{Moscow Univ. Comput. Math. Cybern.} 38(3):110--117.

\bibitem{15-sh-1}
\Aue{Eroshenko, A.\,A., A.\,A.~Kudryavtsev, and O.\,V.~Shestakov.}
 2015. {Limit distribution of a risk estimate using the vaguelette-wavelet
  decomposition of signals in a model with correlated noise}. \textit{Moscow Univ. 
  Comput. Math.  Cybern.} 39(1):6--13.

\bibitem{16-sh-1}
\Aue{Johnstone, I.\,M., and Silverman~B.\,W.}
 1997. Wavelet threshold estimates for data with correlated noise.
 \textit{J.~R.~Stat. Soc.~B} 59:319--351.

\bibitem{17-sh-1}
\Aue{Johnstone, I.\,M.} 1999. Wavelet shrinkage for correlated data and 
inverse problems adaptivity results. \textit{Stat. Sinica} 9:51--83.

\bibitem{18-sh-1}
\Aue{Cai, T., and L.~Brown.} 1999. 
Wavelet estimation for samples with random uniform design. 
\textit{Stat. Probabil. Lett.} 42:313--321.
\end{thebibliography}

 }
 }

\end{multicols}

%\vspace*{-7pt}

\hfill{\small\textit{Received May 16, 2019}}

%\pagebreak

%\vspace*{-22pt}


\Contrl

\noindent
\textbf{Shestakov Oleg V.} (b.\ 1976)~--- 
Doctor of Science in physics and mathematics, professor, Department 
of Mathematical Statistics, Faculty of Computational Mathematics 
and Cybernetics, M.\,V.~Lomonosov Moscow State University, 1-52~Leninskiye Gory,
 GSP-1, Moscow 119991, Russian Federation; 
 senior scientist, Institute of Informatics Problems, Federal Research Center 
 ``Computer Science and Control'' of the Russian Academy of Sciences, 
 44-2~Vavilov Str., Moscow 119333, Russian Federation; \mbox{oshestakov@cs.msu.su}
\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература}  