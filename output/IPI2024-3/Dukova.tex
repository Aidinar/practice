\def\stat{dukova}

\def\tit{КОРРЕКТНАЯ КЛАССИФИКАЦИЯ ПО~ПРЕЦЕДЕНТАМ: ДСМ-МЕТОД НАД~ПРОИЗВЕДЕНИЕМ 
ЧАСТИЧНЫХ ПОРЯДКОВ$^*$}

\def\titkol{Корректная классификация по~прецедентам: ДСМ-метод над~произведением 
частичных порядков}

\def\aut{Е.\,В.~Дюкова$^1$, Г.\,О.~Масляков$^2$, Д.\,С.~Янаков$^3$}

\def\autkol{Е.\,В.~Дюкова, Г.\,О.~Масляков, Д.\,С.~Янаков}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Дюкова Е.\,В.}
\index{Масляков Г.\,О.}
\index{Янаков Д.\,С.} 
\index{Djukova E.\,V.}
\index{Masliakov G.\,O.}
\index{Ianakov D.\,S.}


{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Статья публикуется по представлению программного комитета 21-й Всероссийской конференции 
с~международным участием <<Математические методы распознавания образов>>. Исследование выполнено за 
счет гранта Российского научного фонда №\,24-21-00301, {\sf https://rscf.ru/project/24-21-00301/}.}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{edjukova@mail.ru}}
\footnotetext[2]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{gleb-mas@mail.ru}}
\footnotetext[3]{Национальный исследовательский университет <<Высшая школа экономики>>, \mbox{dmitriyyanakov@gmail.com}}

\vspace*{-6pt}


  

\Abst{Исследуется логический подход к~задаче классификации по прецедентам. Отмечаются 
различие и~связь между двумя известными направлениями логической классификации, 
а~именно направлением, представленным процедурами корректного голосования (Correct 
Voting Procedures, или CVP), и~направлением, базирующимся на идеях ДСМ-ме\-то\-да 
В.\,К.~Финна. Рассматриваются вопросы усовершенствования классификаторов второго 
направления на основе использования менее строгого решающего правила и~обобщения 
схемы работы на случай, когда признаковые описания исследуемых объектов~--- это 
элементы декартова произведения конечных час\-тич\-но упорядоченных множеств. 
В~разработанных новых моделях ДСМ-клас\-си\-фи\-ка\-то\-ров используются идеи, 
предложенные ранее при создании аналогичных алгоритмов направления CVP. Приводятся 
результаты экспериментального исследования на реальных задачах с~применением 
специального линейного упорядочения значений признаков.}

\KW{классификация на основе прецедентов; логический классификатор; процедуры 
корректного голосования; ДСМ-ме\-тод; представительный элементарный классификатор; 
час\-тич\-ный порядок}

\DOI{10.14357/19922264240308}{ZJHDMY}
  
\vspace*{-2pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}


\section{Введение}

\vspace*{-3pt}

  Задача классификации по прецедентам является одной из центральных задач 
машинного обуче\-ния~[1--3] и~имеет важ\-ное прикладное значение~[4--6]. Под 
прецедентной (обуча\-ющей) \mbox{информацией} понимается совокупность примеров 
изуча\-емых объектов, в~которой каждый объект представлен в~виде числового 
вектора, полученного на основе измерения или наблюдения ряда его 
па\-ра\-мет\-ров или характеристик, называемых признаками. Каждый пример 
(обучающий объект или прецедент) приписан к~определенному классу 
объектов. Предполагается, что каждый признак имеет ограниченное множество 
допустимых значений, которые кодируются целыми числами, и~признаковые 
описания любых двух обучающих объектов, принадлежащих разным классам, 
не совпадают. Требуется уметь классифицировать новые, не входящие в~обуча\-ющую выборку объекты. 
  
  Исследуется логический подход к~рассматриваемой задаче, позволяющий 
прогнозировать редкие события. Обучение классификатора сводится к~поиску в~исходных данных информативных фрагментов описаний прецедентов. Такие 
фрагменты позволяют различать объекты из разных классов и, как правило, 
имеют содержательное описание в~терминах той прикладной об\-ласти, 
в~которой решается\linebreak задача. По их наличию в~описании рас\-по\-зна\-ва\-емо\-го 
объекта решается вопрос о~его классификации. Кор\-рект\-ность обуче\-ния 
поз\-во\-ля\-ет без\-оши\-боч\-но распознавать прецеденты. Наиболее \mbox{эффективен} 
логический подход в~случае це\-ло\-чис\-лен\-ной информации низкой знач\-ности, 
особенно бинарной. При большом чис\-ле признаков возникают 
вы\-чис\-ли\-тель\-ные трудности, связанные с~не\-об\-хо\-ди\-мостью решать сложные 
дискретные задачи.
  
  Одно из основных направлений логической классификации представлено 
процедурами корректного голосования (CVP). 
Фундаментальную роль в~создании методов CVP сыграли работы 
С.\,В.~Яблонского, Ю.\,И.~Журавлёва, М.\,М.~Бонгарда и~М.\,Н.~Вайнцвайга. 
В~дальнейшем направление CVP развивалось отечественными и~зарубежными 
учеными и~наиболее существенное развитие получило в~работах 
представителей школы академика РАН Ю.\,И.~Журавлёва. Другое 
рас\-смат\-ри\-ва\-емое на\-прав\-ле\-ние базируется на идеях ДСМ-ме\-то\-да~[7] и~пред\-став\-ле\-но в~России работами В.\,К.~Финна, С.\,О.~Кузнецова, 
М.\,И.~Забежайло, Д.\,И.~Игнатова и~Д.\,В.~Виноградова. В~[8, 9] 
с~использованием понятий CVP приведена общая схема работы логического 
классификатора, включающая оба указанных направления. 
  
  Пусть $X=\{x_1, \ldots , x_n\}$~--- заданное множество признаков; $H$~--- 
набор из~$r$ различных признаков вида $H\hm= \{ x_{j_1},\ldots , x_{j_r}\}$; 
$\sigma\hm= (\sigma_1, \ldots , \sigma_r)$~--- набор, в~котором~$\sigma_i$, 
$i\hm\in \{1, 2, \ldots , r\}$,~--- допустимое значение признака~$x_{j_i}$. Пару 
$(\sigma, H)$ назовем \textit{элементарным классификатором} (ЭК) 
\textit{ранга}~$r$. Элементарному классификатору~$(\sigma, H)$ поставим в~соответствие множество ЭК 
ранга 1~вида ($\sigma_i, \{ x_{j_i}\}$), $i\hm\in \{1,2,\ldots , r\}$, обозначаемое~$Q_{(\sigma, H)}$. 
  
  Пусть $S=(a_1, \ldots , a_n)$~--- изучаемый объект (здесь~$a_j$, $j\hm\in 
\{1,2,\ldots , n\}$,~--- значение признака~$x_j$ для объекта~$S$). Будем 
говорить, что ЭК $(\sigma, H)$ содержится в~$S$, если $a_{j_i}\hm=\sigma_i$ 
при $i\hm= 1,2,\ldots , r$. Элементарный классификатор~$(\sigma, H)$ называется представительным для 
класса~$K$, если $(\sigma, H)$ содержится хотя бы в~одном прецеденте из~$K$ и~не содержится ни в~каком прецеденте не из~$K$. 
  
  Понятие представительного ЭК введено в~направлении CVP~[10, 11]. 
Согласно схеме работы логического классификатора, описанной в~[8, 9], 
каждый такой классификатор на этапе обучения задает некоторый час\-тич\-ный 
порядок на множестве представительных ЭК класса и~ищет максимальные 
относительно заданного порядка элементы этого множества. 
  
  В направлении CVP наиболее информативными считаются тупиковые 
представительные ЭК $(\sigma, H)$  класса~$K$, обладающие свойством: 
любой ЭК $(\sigma^\prime, H^\prime)$ класса~$K$, такой что $Q_{(\sigma^\prime, 
H^\prime)} \hm\subset Q_{(\sigma, H)}$, не является представительным ЭК 
класса~$K$. Решающее правило основано на процедуре <<голосования>>, 
в~которой участ\-ву\-ют найденные тупиковые представительные ЭК 
классов~\cite{11-duk}. Если тупиковый представительный ЭК $(\sigma, H)$  
класса~$K$ содержится в~распознаваемом объекте~$S$, то $(\sigma, H)$ дает 
положительную оценку $\Gamma_K(S,\sigma, H)$ за принадлежность~$S$ 
к~классу~$K$, которая равна числу прецедентов, в~которых содержится 
$(\sigma, H)$. В~противном случае $\Gamma_K(S,\sigma, H)\hm=0$. Оценки, 
поданные тупиковыми представительными ЭК класса~$K$ за 
принадлежность~$S$  к~этому классу, суммируются, и~суммарная оценка 
делится на число прецедентов класса~$K$. Объект~$S$ относится к~классу, 
получившему наибольшую оценку. Если таких классов несколько, то 
происходит отказ от распознавания объекта~$S$.
  
  В ДСМ-методе искомое подмножество представительных ЭК класса~$K$ 
состоит из ДСМ-пред\-ста\-ви\-тель\-ных ЭК этого класса. Представительный 
для класса~$K$ ЭК $(\sigma, H)$ называется ДСМ-пред\-ста\-ви\-тель\-ным, 
если не существует представительного ЭК $(\sigma^\prime, H^\prime)$ 
класса~$K$ такого, что $Q_{(\sigma, H)} \hm\subset Q_{(\sigma^\prime, 
H^\prime)}$ и~$(\sigma^\prime, H^\prime)$ содержится в~каждом из тех 
прецедентов, в~которых содержится $(\sigma, H)$. Распознаваемый объект~$S$ 
относится к~классу~$K$, если в~$S$ содержится хотя бы один  
ДСМ-пред\-ста\-ви\-тель\-ный ЭК этого класса и~не содержится ни одного  
ДСМ-пред\-ста\-ви\-тель\-но\-го ЭК из других классов. В~противном случае 
происходит отказ от классификации. Основная цель представляемой работы~--- 
улучшение качества работы рассматриваемого классификатора за счет 
изменения слишком строгого решающего правила и~модификация 
усовершенствованной версии ДСМ-ме\-то\-да на случай час\-тич\-но 
упорядоченных данных. 
  
  На базе ДСМ-ме\-то\-да разработан классификатор ДСМ-Г с~использованием 
решающего правила, применяемого в~CVP. Новый классификатор 
модифицирован для работы с~описаниями объектов, представляющими собой 
элементы декартова произведения конечных час\-тич\-но упорядоченных 
множеств (в~этом случае на множествах значений признаков задаются конечные 
час\-тич\-ные порядки). В~предлагаемой модификации ДСМ-ме\-то\-да, названной 
в~работе классификатором \mbox{ДСМ-Г+}, используются идеи, предложенные ранее 
в~[12] при создании аналогичных алгоритмов направления CVP. Актуальность 
рассматриваемого обобщения обусловлена существованием прикладных задач 
машинного обуче\-ния, качественное решение которых невозможно в~рамках 
классической постановки логического анализа данных. В~классическом случае 
описания объектов это элементы декартова произведения конечных антицепей. 
  
  Авторами проведено экспериментальное исследование построенных 
классификаторов на реальных задачах со специальными линейными по\-рядками 
на множествах значений признаков. В~тестирова\-нии также участ\-во\-ва\-ли 
алгоритмы из CVP и~ряд наиболее известных алгоритмов машинного обуче\-ния. 
Результаты счета описаны в~разд.~3.

\vspace*{-6pt}

\section{ДСМ-метод над~произведением частичных порядков}

\vspace*{-3pt}

  Как уже было отмечено во введении, решение прикладных задач 
классификации не всегда возможно в~рамках классических постановок 
логической классификации, не учитывающих наличие сложных отношений на 
множествах допустимых значений признаков. В~работе~[12] предложена более 
общая постановка логической классификации, нацеленная на решение задач, 
в~которых каждый признак принимает значения из некоторого конечного 
час\-тич\-но упорядоченного множества чисел и~описания объектов~--- это 
элементы декартова произведения конечных час\-тич\-но упорядоченных 
множеств. В~такой новой постановке дано более общее понятие ЭК 
и~приведено описание основных моделей классификаторов направления CVP, 
в~част\-ности алгоритма, основанного на нахождении тупиковых 
представительных ЭК. В~данном разделе аналогичные построения проведены 
для ДСМ-клас\-си\-фи\-ка\-тора.
  
  Пусть исследуемое множество объектов~$M$ представимо в~виде $M\hm= 
N_1 \cdots N_n$, где~$N_j$, $j\hm=\overline{1, n}$,~--- конечное 
множество допустимых значений признака~$x_j$, на котором задан час\-тич\-ный 
порядок. \mbox{Считается}, что элемент $S_1\hm=(a_1, \ldots , a_n)$ множества~$M$ 
\textit{предшествует} элементу $S_2\hm= (b_1, \ldots , b_n)$ множества~$M$, 
если~$a_j$ предшествует~$b_j$ при $j\hm=\overline{1, n}$. Далее запись 
$S_1\prec S_2$ означает, что~$S_1$ предшествует~$S_2$ и~$S_1\not= S_2$.
  
  Будем считать, что каждое множество~$N_j$, $j\hm\in \{1,2,\ldots , n\}$, имеет 
наибольший элемент, т.\,е.\linebreak такой элемент, которому предшествует любой 
элемент из~$N_j$. Если наибольший элемент в~$N_j$ отсутствует, то~$N_j$ 
дополним таким элементом.
  
  Пару $(\sigma, H)$, где $H$~--- набор из~$r$ различных признаков вида 
$H\hm= \{x_{j_1}, \ldots , x_{j_r}\}$, $\sigma\hm= (\sigma_1, \ldots ,  
\sigma_r)$~--- набор, в~котором~$\sigma_i$, $i\hm\in \{1,2,\ldots , r\}$,~--- 
допустимое значение признака~$x_{j_i}$, назовем 
ЭК, если при любом $i\hm\in \{1,2,\ldots , r\}$ 
значение~$\sigma_i$ не является наибольшим элементом в~$N_{j_i}$.
  
  Будем говорить, что ЭК $(\sigma, H)$, $H\hm= \{ x_{j_1}, \ldots , x_{j_r}\}$, 
$\sigma\hm= (\sigma_1, \ldots , \sigma_r)$, $\sigma_i\hm\in N_{j_i}$, 
$i\hm=\overline{1,r}$, содержится в~объекте $S\hm= (a_1, \ldots , a_n)$ из~$M$, 
если~$a_{j_i}$ предшествует~$\sigma_i$ в~$N_{j_i}$ при $i\hm=\overline{1, r}$. 
Понятие представительного ЭК, приведенное во введении, полностью 
переносится на рассматриваемый общий случай.
  
  Пусть $(\sigma, H)$~--- ЭК, в~котором $H\hm= \{ x_{j_1}, \ldots , x_{j_r}\}$, 
$\sigma\hm= (\sigma_1, \ldots , \sigma_r)$,  $\sigma_i\hm\in N_{j_i}$, 
$i\hm=\overline{1, r}$. Элементарному классификатору~$(\sigma, H)$ сопоставим набор $S_{(\sigma, H)} \hm= 
(\gamma_1, \ldots , \gamma_n)$ из~$M$, в~котором  $\gamma_t\hm=\sigma_i$ при 
$t\hm= j_i$, $i\hm=\overline{1, r}$, и~$\gamma_t$~--- наибольший элемент в~$N_t$ 
при $t\notin \{j_1,\ldots , j_r\}$. 
  
  Представительный для класса~$K$ ЭК $(\sigma, H)$ назовем тупиковым, если 
любой ЭК $(\sigma^\prime, H^\prime)$ такой, что $S_{(\sigma, H)}\prec 
S_{(\sigma^\prime, H^\prime)}$, не является представительным для класса~$K$. 
Поиск ЭК данного вида относится к~сложным в~вычислительном плане задачам 
и~может быть осуществлен на основе перечисления упорядоченных тупиковых 
покрытий целочисленной матрицы~[12]. Бинаризация данных (см.\ ниже) 
позволяет осуществлять поиск тупиковых представительных ЭК класса~$K$ на 
основе перечисления неприводимых покрытий булевой матрицы, т.\,е.\ путем 
решения хорошо известной дискретной задачи, называемой монотонной 
дуализацией~[13]. 
  
  Элементарный классификатор~$(\sigma, H)$ назовем ДСМ-пред\-ста\-ви\-тель\-ным для класса~$K$, 
если $(\sigma, H)$~--- представительный ЭК для~$K$ и~не существует 
представительного ЭК $(\sigma^\prime, H^\prime)$ класса~$K$ такого, что 
$S_{(\sigma^\prime, H^\prime)} \prec S_{(\sigma, H)}$ и~$(\sigma^\prime, 
H^\prime)$ содержится в~каждом из тех прецедентов, в~которых содержится 
$(\sigma, H)$. Через $\mathcal{P}(K)$ обозначим множество всех  
ДСМ-пред\-ста\-ви\-тель\-ных ЭК класса~$K$. Опишем процедуру поиска ЭК из 
$\mathcal{P}(K)$ в~случае, когда множество значений каждого признака 
представляет собой либо цепь (на этом множестве задан линейный порядок), 
либо антицепь. 
  
  Рассмотрим признак~$x_j$, $j\hm\in \{1,2,\ldots , n\}$, и~множество $N_j\hm= 
\{a_{j1},\ldots , a_{jk_j}\}$ значений этого признака. Пусть $a,b\hm\in N_j$. 
Положим $\delta(a,b)\hm=1$, если~$a$ предшествует~$b$ в~$N_j$, иначе 
$\delta(a,b)\hm=0$. Тогда полученное из исходного новое описание объекта 
$S\hm= (a_1, \ldots , a_n)$, $a_j\hm\in N_j$, $j\hm= \overline{1, n}$, будет иметь 
вид:
  \begin{multline}
  \left(\delta(a_1, a_{11}),\ldots,\delta(a_1,a_{1k_1}),\ldots , \delta(a_n,a_{n1}),\ldots\right.\\
\left.  \ldots  , 
\delta(a_n,a_{nk_n})\right).
  \label{e1-duk}
  \end{multline}
  
  Таким образом, объект~$S$ из множества~$M$ может быть описан при 
помощи $k_1+\cdots + k_n$ бинарных признаков. Заметим, что признаку~$x_j$, 
$j\hm= \overline{1, n}$, и~допустимому значению $a_{ji}\hm\in N_j$, 
$i\hm=\overline{1, k_j}$, признака~$x_j$ соответствует бинарный 
признак~$\tilde{x}_t$, где $t\hm= i$ при $j\hm=1$ и~$t\hm= k_1+\cdots + k_{j-
1}+i$ при $j\hm>1$, причем $\tilde{x}_t$ имеет значение~1 в~описании 
объекта~$S$ тогда и~только тогда, когда~$a_j$ предшествует~$a_{ji}$ в~$N_j$. 
Признак~$\tilde{x}_t$ и~пару $(x_j, a_{ji})$ назовем \textit{родственными}. 
Будем говорить, что признак~$x_j$ \textit{порождает} признак~$\tilde{x}_t$. 
Признак~$\tilde{x}_t$ считается \textit{граничным для}~$S$, если $a_j\hm= 
a_{ji}$. Признак~$\tilde{x}_t$ считается \textit{вырожденным}, если~$a_{ji}$~--- наибольший элемент в~$N_j$.
  
  Отметим, что в~классическом варианте каждое множество~$N_j$, 
$j\hm=\overline{1,n}$,~--- антицепь и~преобразование~(\ref{e1-duk}) известно как 
\textit{one-hot} кодирование. В~этом случае согласно~(\ref{e1-duk}) бинарный 
признак~$\tilde{x}_t$ имеет значение~1 в~описании объекта~$S$ тогда и~только 
тогда, когда $a_j\hm= a_{ji}$. При выполнении указанного 
равенства~$\tilde{x}_t$ будет граничным для~$S$. 
  
  Пусть $\tilde{X}$~--- множество бинарных признаков, полученное 
в~результате применения к~исходным данным преобразования~(\ref{e1-duk}). 
Два признака из~$\tilde{X}$ назовем \textit{сходными}, если они порождены 
одним признаком из~$X$. Набору признаков $\tilde{H}$, $\tilde{H}\hm\subseteq 
\tilde{X}$, $\tilde{H}\hm= \{\tilde{x}_{t_1},\ldots , \tilde{x}_{t_r}\}$, не 
содержащему сходных и~вы\-рож\-ден\-ных признаков, поставим в~соответствие ЭК 
$(\sigma, H)$, $H\hm\subseteq X$, $H\hm= \{ x_{j_1}, \ldots , x_{j_r}\}$, 
$\sigma\hm= (\sigma_1, \ldots , \sigma_r)$ такой, что при любом $i\hm\in 
\{1,2,\ldots , r\}$ признак~$\tilde{x}_{t_i}$ и~пара $(x_{j_i}, \sigma_i)$ 
оказываются родственными. 

\begin{table*}[b]\small %tabl1
\vspace*{-15pt}
\begin{center}
\Caption{Описание задач}
\vspace*{2ex}

\begin{tabular}{|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Датасет}}&\multicolumn{2}{c|}{Число признаков}&\multicolumn{2}{c|}{Число объектов}\\
\cline{2-5}
&До 
преобразования~(\ref{e1-duk})&После преобразования~(\ref{e1-duk})&Обучающая
выборка&Тестовая 
выборка\\
\hline
М&\hphantom{9}6&\hphantom{9}21&1382\hphantom{9}&346\hphantom{9}\\
КН&\hphantom{9}9&\hphantom{9}27&766&192\hphantom{9}\\
И&81&162&\hphantom{9}63&16\\
НС&35&379&116&29\\
ОС&19&566&213&54\\
\hline
\end{tabular}
\end{center}
\end{table*}

    
    Рассмотрим булеву матрицу~$L_K$, строки которой представляют собой 
описания прецедентов из класса~$K$ посредством признаков из~$\tilde{X}$. 
Под\-мат\-ри\-цу мат\-ри\-цы~$L_K$, образованную описаниями некоторого 
подмножества прецедентов~$R$ и~набором признаков $\{ \tilde{x}_{t_1},\ldots , 
\tilde{x}_{t_r}\}$, не содержащим сходных и~вырожденных признаков, назовем 
правильной, если все ее элементы равны~1, среди признаков $ 
\tilde{x}_{t_1},\ldots , \tilde{x}_{t_r}$ есть граничный для некоторого 
прецедента из~$R$ признак и~для любого класса~$K^\prime$, $K^\prime\not= 
K$, любая подматрица матрицы~$L_{K^\prime}$, расположенная в~столбцах 
с~номерами $t_1,\ldots , t_r$, содержит элементы, равные~0. 
  
  Правильную подматрицу $L^*$ матрицы~$L_K$ назовем 
\textit{максимальной}, если любая другая под\-мат\-рица мат\-ри\-цы~$L_K$, 
содержащая~$L^*$, не является правильной. Нетрудно видеть, что существует 
взаимно \mbox{однозначное} соответствие между множеством 
 ДСМ-пред\-ста\-ви\-тель\-ных ЭК класса~$K$ и~множеством максимальных 
правильных под\-мат\-риц в~мат\-ри\-це~$L_K$. 
  
  Таким образом, перечисление ЭК из $\mathcal{P}(K)$, так же как 
и~в~рассмотренном ранее в~[14] случае, когда каждое множество~$N_j$, 
$j\hm= \overline{1, n}$,~--- антицепь, может быть осуществлено на основе 
перечисления специальных подматриц матрицы~$L_K$. Отметим, что эта 
дискретная перечислительная задача алгоритмически менее сложна, чем задача 
монотонной дуализации, решаемая при нахождении тупиковых 
представительных ЭК класса~$K$. 
  
  На этапе распознавания базовый вариант ДСМ-ме\-то\-да действует более 
строго по сравнению с~классификаторами из CVP~[14], что приводит 
к~большому числу отказов от классификации. На первом\linebreak этапе для каждого 
класса~$K$ строится множество $\mathcal{P}(K)$. Объект~$S$ относится 
к~классу~$K$, если~$S$ содержит хотя бы один ЭК из $\mathcal{P}(K)$ и~не 
содержит ни одного ЭК из $\mathcal{P}(K^\prime)$, $K^\prime\not= K$. 
В~противном случае происходит отказ от классификации. В~разд.~3 настоящей 
работы приведены результаты экспериментального исследования, показавшие, 
что использование решающего правила, применяемого в~CVP, гарантированно 
позволяет повысить точность ДСМ-ме\-то\-да. Кроме того, показано, что\linebreak 
точ\-ность усовершенствованного ДСМ-ме\-то\-да, названного классификатором 
\mbox{ДСМ-Г}, мож\-но дополнительно повысить за счет задания \mbox{линейных}\linebreak порядков на 
множествах значений признаков, полученных на основе анализа встре\-ча\-емости 
отдельного значения каждого признака в~описаниях \mbox{прецедентов}. 
Со\-от\-вет\-ст\-ву\-ющая \mbox{модификация} алгоритма \mbox{ДСМ-Г} названа классификатором 
\mbox{ДСМ-Г+}. Приведем описание используемой в~\mbox{ДСМ-Г+} процедуры линейного 
упорядочения значений при\-зна\-ков. 
{ %\looseness=1

}
  
  Пусть $R_1(K)$ и~$R_2(K)$~--- множества прецедентов из класса~$K$ и~не 
из~$K$ соответственно; $S\hm= (a_1,\ldots , a_n)$~--- объект из~$M$; $a\hm\in 
N_j$, $j\hm\in \{1, \ldots,n\}$. Положим 
$$
B_j(S,a)=
\begin{cases}
1, &\mbox{если}\  a_j=a;\\
0 &\mbox{иначе};
\end{cases}
$$
 $W_t\hm= 1/\vert R_t(K)\vert$, $t\hm\in \{1,2\}$; 
$\mu_j^{(t)}(a)\hm= W_t\sum\nolimits_{S\in R_t(K)} B_j(S,a)$, $t\hm\in \{1,2\}$; 
$\mu_j(a)\hm= \mu_j^{(1)}(a)\hm- \mu_j^{(2)}(a)$. Величина $\mu_j(a)$ служит 
оценкой информативности значения~$a$ признака~$x_j$ в~классе~$K$\linebreak 
и~позволяет установить на множестве значений признака~$x_j$, 
встречающихся в~описаниях прецедентов из~$K$, линейный порядок, согласно 
которому $a\hm\in N_j$ предшествует $b\hm\in N_j$, если $\mu_j(a)\hm\leq 
\mu_j(b)$.
  
  Задание порядка описанным способом эффективно по времени вычислений, 
но делает классификатор менее чувствительным к~выбросам и~не гарантирует 
корректность классификации. Другой очевидный недостаток описанной 
процедуры линейного упорядочения значений заключается в~том, что порядок 
на множестве значений каждого признака выбирается независимо от выбора 
порядков для других признаков. Однако проведенные в~работе~[15] 
и~в~настоящей работе экспериментальные исследования свидетельствуют 
о~целесообразности введения указанного порядка.

\begin{table*}\small %tabl2
\begin{center}
\Caption{Точность классификации и~время работы алгоритмов (в секундах)}
\vspace*{2ex}

\begin{tabular}{|c|l|l|l|l|l|}
\hline
Датасет&\multicolumn{1}{c|}{М}&\multicolumn{1}{c|}{КН}&\multicolumn{1}{c|}{И}&\multicolumn{1}{c|}{НС}&\multicolumn{1}{c|}{ОC}\\
\hline
ДСМ&0,885 / 0,12&0,830 / 0,55&0,440 / 65,88&0,699 / 0,69&0,492 / 0,42\\
ДСМ-Г&0,919 / 0,12&\textbf{0,999} / 0,55&0,576 / 65,88&0,862 / 0,69&0,566 / 0,42\\
ДСМ-Г+&0,995 / 0,07&0,845 / 0,74&0,684 / 13,60&\textbf{0,945} / 283,57&\textbf{0,977} / 2969,18\\
ТЭК&0,947 / 0,02&0,995 / 0,06&0,657 / 140,13&0,883 / 0,10&0,644 / 0,04\\
ТЭК+&0,976 / 0,44&0,992 / 1,43&0,607 / 175,92&0,935 / 203,38&0,864 / 325,28\\
ЛГ&0,791 / $<$0,01&0,627 / $<$0,01&\textbf{0,792} / $<$0,01&0,909 / $<$0,01&0,690 / 0,01\\
СЛ&0,998 / 0,12&0,996 / 0,12&0,750 / 0,09&0,916 / 0,09&0,697 / 0,10\\
ГБ&\textbf{0,999} / 0,1&0,989 / 0,08&0,701 / 0,05&0,902 / 0,06&0,670 / 0,07\\
\hline
\end{tabular}
\end{center}
\vspace*{-6pt}
\end{table*}

\vspace*{-6pt}

\section{Результаты экспериментов}

\vspace*{-3pt}

  Экспериментальное исследование проводилось на реальных задачах. 
Рассматривались следующие наборы данных: <<Машины>> (М); <<Крес\-ти\-ки-но\-ли\-ки>> (КН); <<Инсульт>> (И); <<Неорганические соединения>> (НС); 
<<Остеогенная саркома>> (ОС). Первые два набора были взяты из репозитория 
UCI ({\sf https://archive.ics.uci.edu}), а~остальные~--- из репозитория ФИЦ ИУ РАН. 
В~табл.~1 приведены размерности входных данных, включая число признаков 
до и~после бинаризации. 
  


  В тестировании участ\-во\-ва\-ли базовый ДСМ-клас\-си\-фи\-ка\-тор (ДСМ), его 
модификации \mbox{ДСМ-Г} и~ДСМ-Г+, алгоритмы голосования по тупиковым 
представительным ЭК, именуемые ТЭК и~ТЭК+ в~случаях антицепей и~цепей 
соответственно, и~классические алгоритмы машинного обучения, такие как 
логистическая регрессия (ЛГ), случайный лес (СЛ) и~градиентный бустинг над 
ре\-ша\-ющи\-ми деревьями (ГБ). Для тестирования логических классификаторов 
использовались авторские реализации, написанные на языке программирования 
C++. Тестирование ДСМ-Г+ и~ТЭК+ проводилось с~линейными порядками на 
множествах значений признаков, полученными на основе анализа 
встречаемости отдельного значения признака в~описаниях прецедентов 
(процедура линейного упорядочения описана в~разд.~2). Для перечисления 
ДСМ-пред\-ста\-ви\-тель\-ных ЭК применялся алгоритм Close By One~[16]. 

  Результаты счета (средняя точность классификации по показателю ROC AUC (receiver operating characteristic
  area under the curve) и~среднее время работы алгоритмов, полученные на основе случайного  
10-крат\-но\-го разбиения исходной выборки на базовую и~тестируемую 
подвыборки в~отношении $4:1$) приведены в~табл.~2. Функционал качества 
ROC AUC был выбран из-за его устойчивости к~несбалансированности 
выборки.
  
  Нетрудно видеть, что на рассмотренных задачах новый классификатор ДСМ-Г+ 
показал более высокое качество по сравнению с~базовым вариантом  
ДСМ-ме\-то\-да и~на задачах <<Остеогенная саркома>> и~<<Неорганические 
соединения>> превзошел все тестируемые алгоритмы. Однако в~случае задач 
большой размерности из-за большого числа по\-рож\-да\-емых  
ДСМ-пред\-ста\-ви\-тель\-ных ЭК алгоритмы ДСМ-Г и~ДСМ-Г+ работают 
существенно дольше, чем другие методы. 
  

  
  
  Таким образом, экспериментальные данные не позволяют сделать 
однозначный вывод о выборе конкретного алгоритма классификации при 
решении практических задач, поскольку ни один из тес\-ти\-ру\-емых алгоритмов 
классификации не оказался лучшим одновременно и~по качеству 
классификации, и~по времени работы. Если прирост в~качестве существен, то 
стоит жертвовать скоростью, и~наоборот. В~первом случае примером служит 
задача <<Остеогенная саркома>>, на которой алгоритм ДСМ-Г+ показал 
качество почти в~98\% со временем работы примерно 50~мин. Тестирование 
алгоритма ДСМ-Г+ на задаче <<Неорганические соединения>> иллюстрирует 
второй случай (качество алгоритма ДСМ-Г+ всего на~3\% выше, чем 
у~случайного леса, однако время работы гораздо больше).
  
  \smallskip
  

  
  \noindent
  \textbf{Замечание~1.}\ Алгоритмы ДСМ-Г и~ДСМ-Г+ осуществляют поиск 
ДСМ-представительных ЭК класса~$K$ на основе построения максимальных 
правильных подматриц булевой матрицы~$L_K$, строками\linebreak которой служат 
описания прецедентов класса~$K$ посредством признаков из~$\tilde{X}$ (см.\ 
разд.~2). Для пе\-ре\-чис\-ле\-ния искомых под\-мат\-риц применялся алгоритм Close By 
One~[13]. Этот алгоритм на очередном шаге строит под\-мат\-ри\-цу~$L^*$ 
матрицы~$L_K$, обладающую следующим свойством: в~$L^*$ все элементы 
равны~1 и~любая другая подматрица матрицы~$L_K$, содержащая~$L^*$, 
имеет нулевые элементы. Алгоритм Close By One имеет полиномиальную от 
размера входа (размера мат\-ри\-цы~$L_K$) слож\-ность шага. Поскольку 
по\-стро\-ен\-ная на очередном шаге алгоритма Close By One под\-мат\-ри\-ца не всегда 
оказывается правильной, на каждом шаге этого алгоритма требуется 
дополнительная проверка, осуществляемая также за полиномиальное время. 
  
  На скорость работы алгоритма Close By One существенно влияет число его 
шагов, которое, как правило, растет экспоненциально с~ростом размера задачи. 
Общее число шагов этого алгоритма зависит от степени разреженности 
матрицы~$L_K$ относительно числа единичных элементов. Алгоритм Close By 
One работает дольше на менее разреженных булевых матрицах, о~чем 
свидетельствуют результаты счета на задачах <<И>> и~<<НС>>. Видно, что 
время работы алгоритма ДСМ-Г на первой задаче больше, хотя ее размер 
меньше размера второй задачи. Число ДСМ-пред\-ста\-ви\-тель\-ныx ЭК 
в~задаче <<И>> значительно превышает число ДСМ-пред\-ста\-ви\-тель\-ныx 
ЭК в~задаче <<НС>>. 
  
  В случае антицепей, в~отличие от цепей, чем больше в~данных 
целочисленных признаков с~высокой значностью, тем более разрежена 
матрица~$L_K$. Это объясняет разницу во времени работы алгоритмов ДСМ-Г и~ДСМ-Г+ на задачах НС и~ОС (обе задачи содержат признаки высокой 
значности).
  
  Время счета ДСМ-Г+ на задаче ОС, имеющей после  
преобразования~(\ref{e1-duk}) размер $213\times 566$, не превысило 1~ч (это 
наибольшее зафиксированное время счета).
  
  Авторами дополнительно проведены эксперименты на случайных булевых 
матрицах с~равновероятным появлением~0 и~1. Если матрица имеет размеры 
$100\times100$, то среднее время работы алгоритма Close By One примерно 
2~мин. Счет проводился с~использованием авторской реализация этого 
алгоритма на С++. 
  
  \smallskip
  
  \noindent
  \textbf{Замечание~2.}\ Коды программ для классификаторов ДСМ, ДСМ-Г 
и~ДСМ-Г+, а~также данные, на которых проводились исследования, выложены 
в~открытый доступ (ссылка: {\sf 
https://gitflic.ru/project/ yanakidis/jsm\_partially\_ordered}).

\vspace*{-6pt}

\section{Заключение }

\vspace*{-3pt}

  На основе ДСМ-метода построены новые классификаторы: ДСМ-Г (модель 
c~решающим правилом из CVP) и~ДСМ-Г+ (модель c решающим\linebreak правилом из 
CVP, ориентированная на работу с~час\-тич\-но упорядоченными данными). 
Проведено эксперимен\-таль\-ное исследование на реальных задачах, показавшее, 
что предложенные классификаторы имеют достаточно хорошее качество, 
однако при больших размерностях данных могут работать дольше других 
тестируемых алгоритмов.
   
{\small\frenchspacing
 { %\baselineskip=11.5pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99} 
\bibitem{1-duk}
\Au{Вапник В.\,Н., Червоненкис~А.\,Я.} Теория распознавания образов. Статистические 
проблемы обучения.~--- М.: Наука, 1974. 416~с.
\bibitem{2-duk}
\Au{Bishop С.\,M.} Pattern recognition and machine learning.~--- Information science and statistics 
ser.~--- New York, NY, USA: Springer, 2006. 778~p.
\bibitem{3-duk}
\Au{Theodoridis S.} Pattern recognition.~--- 4th ed.~--- Burlington, MA, USA: Academic Press, 2009. 961~p.

\bibitem{5-duk} %4
\Au{Босов А.\,В., Иванов~А.\,В.} Технология классификации типов контента электронного 
учебника~// Информатика и~её применения, 2022. Т.~16. Вып.~4. С.~63--72. doi: 
10.14357/19922264220410. EDN: YERCNH.

\bibitem{4-duk} %5
\Au{Архипов П.\,О., Филиппских~С.\,Л., Цуканов~М.\,В.} Разработка новой модели 
ступенчатой сверточной нейронной сети для классификации аномалий на 
панорамах~// Информатика и~её применения, 2023. Т.~17. Вып.~1. С.~50--56.  doi: 
10.14357/19922264230107. EDN: FHNUPW.

\bibitem{6-duk}
\Au{Тубольцев В.\,П., Лапко~А.\,В., Лапко~В.\,А.} Не\-па\-ра\-мет\-ри\-че\-ский алгоритм 
автоматической классификации данных дистанционного зондирования~// Информатика и~её применения, 2023. Т.~17. Вып.~4. С.~23--31. doi: 10.14357/19922264230404. EDN: 
MPEWAW.
\bibitem{7-duk}
\Au{Финн В.\,К.} О возможности формализации правдоподобных рассуждений средствами 
многозначных логик~// Всесоюзн. симпозиум по логике и~методологии науки.~--- Киев: 
Наукова думка, 1976. С.~82--83. 
\bibitem{8-duk}
\Au{Djukova E., Masliakov~G., Djukova~A.} On the logical classification of integer data~// 9th  
Conference (International) on Information Technology and Nanotechnology Proceedings.~--- 
Piscataway, NJ, USA: IEEE, 2023. Art.~10139273. 4~p. doi: 
10.1109/ITNT57377.2023. 10139273. 
\bibitem{9-duk}
\Au{Дюкова Е.\,В., Масляков~Г.\,О., Дюкова~А.\,П.} Логические методы корректной 
классификации данных~// Информатика и~её применения, 2023. Т.~17. Вып.~3. С.~64--70. 
doi: 10.14357/19922264230309. EDN: \mbox{OZHXOX}.
\bibitem{10-duk}
\Au{Баскакова Л.\,В., Журавлёв~Ю.\,И.} Модель распознающих алгоритмов с~представительными наборами 
и~сис\-те\-ма\-ми опорных множеств~// Ж.~вычисл. матем. и~матем. физ., 1981. Т.~21. №\,5. С.~1264--1275. 
\bibitem{11-duk}
\Au{Дюкова Е.\,В., Песков~Н.\,В.} Поиск информативных фрагментов описаний объектов 
в~дискретных процедурах распознавания~// Ж.~вычисл. матем. и~матем. физ., 2002. Т.~42. 
№\,5. С.~741--753. 
\bibitem{12-duk}
\Au{Дюкова Е.\,В., Масляков~Г.\,О., Прокофьев~П.\,А.} О логическом анализе данных 
с~час\-тич\-ны\-ми порядками в~задаче классификации по прецедентам~// Ж.~вычисл. матем. 
и~матем. физ., 2019. Т.~59. №\,9. С.~1605--1616.
\bibitem{13-duk}
\Au{Дюкова Е.\,В., Журавлёв~Ю.\,И.} Задача монотонной дуализации и~ее обобщения: 
асимптотические оценки числа решений~// Ж.~вычисл. матем. и~матем. физ., 2018. Т.~58. 
№\,12. С.~2153--2168.
\bibitem{14-duk}
\Au{Gnatyshak D.\,V., Ignatov~D.\,V., Kuznetsov~S.\,O., Mir\-kin~B.\,G.} Triadic formal concept 
analysis and triclustering: Searching for optimal patterns~// Mach. Learn., 2015. Vol.~101. 
P.~271--302.  doi: 10.1007/s10994-015-5487-y.
\bibitem{15-duk}
\Au{Дюкова Е.\,В., Масляков~Г.\,О.} О выборе частичных порядков на множествах значений 
признаков в~задаче классификации~// Информатика и~её применения, 2021. Т.~15. Вып.~4. 
С.~72--78.  doi: 10.14357/ 19922264210410. EDN: UVJFGF.

\bibitem{16-duk}
\Au{Кузнецов С.\,О.} Быстрый алгоритм построения всех пересечений объектов из конечной 
полурешетки~// На\-уч\-но-тех\-ни\-че\-ская информация. Сер.~2. Информационные 
процессы и~системы, 1993. №\,1. С.~17--20. 
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 31.03.24}}

%\vspace*{10pt}

%\pagebreak

\newpage

\vspace*{-28pt}

%\hrule

%\vspace*{2pt}

%\hrule


\def\tit{CORRECT SUPERVISED CLASSIFICATION:\\ JSM-METHOD OVER~PRODUCT 
OF~PARTIAL ORDERS}


\def\titkol{Correct supervised classification: JSM-method over~product 
of~partial orders}


\def\aut{E.\,V.~Djukova$^1$, G.\,O.~Masliakov$^1$, and~D.\,S.~Ianakov$^2$}

\def\autkol{E.\,V.~Djukova, G.\,O.~Masliakov, and~D.\,S.~Ianakov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-8pt}


\noindent
$^1$Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, 
44-2~Vavilov\linebreak
$\hphantom{^1}$Str., Moscow 119333, Russian Federation

\noindent
$^2$National Research University Higher School of Economics, 20~Myasnitskaya Str., Moscow 
101000, Russian\linebreak
$\hphantom{^1}$Federation


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2024\ \ \ volume~18\ \ \ issue\ 3}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2024\ \ \ volume~18\ \ \ issue\ 3
\hfill \textbf{\thepage}}}

\vspace*{4pt}



\Abste{The authors consider a logical approach to the supervised classification problem. 
A~difference and a~connection between two well-known directions of logical classification are noted: 
the direction represented by Correct Voting Procedures (CVP) and the direction based on the ideas of the JSM-method. 
The issues of improving the classifiers of the second direction are considered on the basis of using 
a~less strict decisive rule and generalizing a~scheme of work in the case when the featured descriptions of the objects under 
study are the elements of the Cartesian product of finite partially ordered sets. The developed new models of the JSM-classifiers 
use the ideas proposed earlier when creating similar algorithms for the CVP direction. 
The results of an experimental study on real-world tasks using a~special linear ordering of feature values are presented.}

\KWE{supervised classification; logical classifier; Correct Voting Procedures; JSM-method; 
representative elementary classifier; partial order} 




\DOI{10.14357/19922264240308}{ZJHDMY}

\vspace*{-12pt}


    
      \Ack

\vspace*{-3pt}

\noindent
The paper is published on the proposal of the Program Committee of the 21st All-Russian 
Conference with International Participation ``Mathematical Methods for Pattern Recognition.'' 
The research was supported by the Russian Science Foundation (grant  
No.\,24-21-00301, {\sf https://rscf.ru/project/24-21-00301/}). 


  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}

\bibitem{1-duk-1}
\Aue{Vapnik, V.\,N., and A.\,Ya.~Chervonenkis.} 1974. \textit{Teo\-riya raspoznavaniya obrazov. 
Statisticheskie problemy obuche\-niya} [Pattern recognition theory (statistical learning 
problems)]. Moscow: Nauka. 416~p.
\bibitem{2-duk-1}
\Aue{Bishop, C.\,M.} 2006. \textit{Pattern recognition and machine learning}. Information science and statistics 
ser. New York, NY: 
Springer-Verlag. 778~p.
\bibitem{3-duk-1}
\Aue{Theodoridis, S.} 2009. \textit{Pattern recognition}. 4th ed. Burlington, MA: Academic Press. 
961~p.
  
\bibitem{5-duk-1}
\Aue{Bosov, A.\,V., and A.\,V.~Ivanov.} 2022. Tekhnologiya klassifikatsii tipov kontenta 
elektronnogo uchebnika [Technology for classification of content types of e-textbooks]. 
\textit{Informatika i~ee Primeneniya~--- Inform. Appl.} 16(4):63--72. doi: 
10.14357/19922264220410. EDN: YERCNH.

\bibitem{4-duk-1}
\Aue{Arkhipov, P.\,O., S.\,L.~Filippskikh, and M.\,V.~Tsukanov.} 2023. Razrabotka novoy modeli 
stupenchatoy svertochnoy neyronnoy seti dlya klassifikatsii anomaliy na panoramakh 
[Development of a~new model of step convolutional neural network for classification of 
anomalies on panoramas]. \textit{Informatika i~ee Primeneniya~--- Inform. Appl.}   
17(1):50--56. doi: 10.14357/19922264230107. EDN: FHNUPW.  

\bibitem{6-duk-1}
\Aue{Tuboltsev, V.\,P., A.\,V.~Lapko, and V.\,A.~Lapko.} 2023. Neparametricheskiy algoritm 
avtomaticheskoy klassifikatsii dannykh distantsionnogo zondirovaniya [Nonparametric 
algorithm for automatic classification of\linebreak remote sensing data]. \textit{Informatika i~ee 
Primeneniya~--- Inform. Appl.} 17(4):23--31. doi: 10.14357/19922264230404. EDN: 
MPEWAW.
\bibitem{7-duk-1}
\Aue{Finn, V.\,K.} 1976. O~vozmozhnosti formalizatsii pravdopodobnykh rassuzhdeniy 
sredstvami mnogoznachnykh logic [On the possibility of formalizing plausible reasoning by 
means of multivalued logics]. \textit{Vsesoyuzn. simpozium po logike i~metodologii nauki}  
[All-Union Symposium on the Logic and Methodology of Science]. Kiev: Naukova dumka.  
82--83.
\bibitem{8-duk-1}
\Aue{Djukova, E., G.~Masliakov, and A.~Djukova.} 2023. On the logical classification of integer 
data. \textit{9th Conference (International)  on Information Technology and Nanotechnology 
Proceedings}. Piscataway, NJ: IEEE. Art.~10139273. 4~p. doi: 
10.1109/ITNT57377.2023.10139273. 
\bibitem{9-duk-1}
\Aue{Djukova, E.\,V., G.\,O.~Maslyakov, and A.\,P.~Djukova.} 2023. Logicheskie metody 
korrektnoy klassifikatsii dannykh [Logical methods of correct data classification]. 
\textit{Informatika i~ee Primeneniya~--- Inform. Appl.} 17(3):64--70. doi: 
10.14357/19922264230309. EDN: OZHXOX.
\bibitem{10-duk-1}
\Aue{Baskalova, L.\,V., and Yu.\,I.~Zhuravlev.} 1981. A~model of recognition algorithms with 
representative samples and systems of supporting sets. \textit{USSR Comp. Math. Math.} 
21(5):189--199. doi: 10.1016/0041-5553(81)90109-9.
\bibitem{11-duk-1}
\Aue{Dyukova, E.\,V., and N.\,V.~Peskov.} 2002. Search for informative fragments in descriptions 
of objects in discrete recognition procedures. \textit{Comp. Math. Math. Phys.} 42(5):711--723. 
EDN: LHJOVR.
\bibitem{12-duk-1}
\Aue{Djukova, E.\,V., G.\,O.~Masliakov, and P.\,A.~Prokofyev.} 2019. On the logical analysis of 
partially ordered data in the supervised classification problem. \textit{Comp. Math. Math. Phys.} 
59(9):1542--1552. doi: 10.1134/S0965542519090082.\linebreak EDN:  KMZRFX.
\bibitem{13-duk-1}
\Aue{Djukova, E.\,V., and Y.\,I.~Zhuravlev.} 2018. Monotone dualization problem and its 
generalizations: Asymptotic estimates of the number of solutions. \textit{Comp. Math.  Math. 
Phys.} 58(12):2064--2077. doi: 10.1134/S0965542518120102. EDN: YUPYKW.
\bibitem{14-duk-1}
\Aue{Gnatyshak, D.\,V., D.\,V.~Ignatov, S.\,O.~Kuznetsov, and B.\,G.~Mirkin.} 2015. Triadic 
formal concept analysis and triclustering: Searching for optimal patterns. \textit{Mach. Learn.} 
101:271--302. doi: 10.1007/s10994-015-5487-y.
\bibitem{15-duk-1}
\Aue{Djukova, E.\,V., and G.\,O.~Maslyakov.} 2021. O~vybore chastichnykh poryadkov na 
mnozhestvakh znacheniy pri\-zna\-kov v~zadache klassifikatsii [On the choice of partial orders on 
feature values sets in the supervised classification problem]. \textit{Informatika i~ee 
Primeneniya~--- Inform. Appl.} 15(4):72--78. doi: 10.14357/19922264210410. EDN: UVJFGF.
\bibitem{16-duk-1}
\Aue{Kuznetsov, S.\,O.} 1993. Fast algorithm for construction of all intersections of objects from 
a~finite semilattice.  \textit{Automatic Documentation Mathematical Linguistics} 27(5):\linebreak 23--28.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received March 31, 2024}} 

\vspace*{-18pt}

\Contr

\vspace*{-3pt}

\noindent
\textbf{Djukova Elena V.} (b.\ 1945)~--- Doctor of Science in physics and mathematics, principal 
scientist, Federal Research Center ``Computer Science and Control'' of the Russian Academy of 
Sciences, 44-2 Vavilov Str., Moscow 119333, Russian Federation; \mbox{edjukova@mail.ru}

\vspace*{3pt}


\noindent
\textbf{Masliakov Gleb O.} (b.\ 1996)~--- Candidate of Science (PhD) in physics and mathematics, 
junior scientist, Federal Research Center ``Computer Science and Control'' of the Russian 
Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, Russian Federation; 
\mbox{gleb-mas@mail.ru}

\vspace*{3pt}

\noindent
\textbf{Ianakov Dmitrii S.} (b.\ 2002)~--- master student, National Research University Higher 
School of Economics, 20~Myasnitskaya Str., Moscow 101000, Russian Federation; 
\mbox{dmitriyyanakov@gmail.com}



\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 