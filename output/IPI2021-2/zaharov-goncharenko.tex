

\def\stat{zah-gonch}

\def\tit{НЕКОТОРЫЕ СВОЙСТВА СМЕСЕЙ НОРМАЛЬНЫХ
РАСПРЕДЕЛЕНИЙ И~ИХ~ПРИЛОЖЕНИЯ К ЗАДАЧАМ МАГНИТОЭНЦЕФАЛОГРАФИИ$^*$}

\def\titkol{Некоторые свойства смесей нормальных
распределений и~их~приложения к~задачам магнитоэнцефалографии}

\def\aut{М.\,Б.~Гончаренко$^1$, Т.\,В.~Захарова$^2$}

\def\autkol{М.\,Б.~Гончаренко, Т.\,В.~Захарова}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Гончаренко М.\,Б.}
\index{Захарова Т.\,В.}
\index{Goncharenko M.\,B.}
\index{Zakharova T.\,V.}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Работа выполнена при частичной поддержке РФФИ (проект 19-07-00352) 
и~в~соответствии с~программой Московского центра фундаментальной и~прикладной математики.}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{АО Интел,  goncharenko.mir@yandex.ru}
\footnotetext[2]{Московский государственный университет имени М.\,В.~Ломоносова,
    факультет вычислительной математики и~кибернетики; 
    Институт проб\-лем информатики Федерального исследовательского центра <<Информатика и~управ\-ле\-ние>> 
    Российской академии наук, \mbox{tvzaharova@mail.ru}}


\vspace*{-12pt}



\Abst{Рассматриваются различные свойства общих смесей вероятностных распределений. 
Особое внимание уделено случаю, когда смешиваемое распределение является нормальным. 
Установлены сходства в~поведении нормальных смесей и~нормальных распределений при трансформациях. 
Рассмотрено приложение к~задачам исследования головного мозга методом магнитоэнцефалографии (МЭГ). 
Определены условия, при которых применима оценка Эйткена (обобщенного метода наименьших квадратов) 
для поиска источников нейрофизиологической активности в~случае, когда распределение шума 
является нормальной смесью общего вида.}

\KW{смеси распределений; смеси нормальных распределений; смеси распределений Стьюдента; 
смеси логнормальных распределений; смеси гам\-ма-рас\-пре\-де\-ле\-ний; магнитоэнцефалография; 
МЭГ; обратная задача МЭГ; оценка Эйткена}

\DOI{10.14357/19922264210207}

\vspace*{-2pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}

\section{Введение}

\vspace*{-1pt}

Смеси вероятностных распределений общего вида (compound probability distribution) 
возникают в~широком классе математических моделей, где параметры вероятностных распределений 
сами являются случайными величинами. Например, такая ситуация естественным образом возникает в~процедуре 
байесовского вывода при подсчете апостериорного распределения. Другое распространенное приложение смесей~--- 
моделирование распределений с~тяжелыми хвостами. Оно оказывается полезным для описания данных
 эксперимента с~более высокой наблюдаемой дисперсией, чем предполагала оригинальная модель. 
 Стоит отметить, что распределение случайных сумм также имеет вид смеси, а~важный частный случай~--- 
 конечной смеси распределений~--- широко используется при обработке неоднородных данных и,~в~част\-ности, 
 в~задачах классификации наблюдений.


Данная статья посвящена исследованию свойств смесей нормальных законов. Повышенное 
внимание к~нормальному распределению вызвано его широкой распространенностью в~прикладных моделях 
анализа данных. Подробнее о~нормальных смесях и~их различных применениях можно 
прочесть в~книгах~\cite{mac, tit}. Знание рассмотренных в~статье свойств поможет понять, 
как изменяются свойства модели при замене предположения о~нормальности распределения ка\-ко\-го-ли\-бо 
параметра (например, аддитивного шума) на смесь нормальных распределений. 
В~рамках данной работы были обобщены результаты, полученные для конечных нормальных 
смесей в~статье~\cite{simple_mix}, на случай нормальных смесей общего вида. 
Отдельно рассматривается применение нормальных смесей в~обратной задаче нейровизуализации 
(исследования распределения источников активности внутри головного мозга) методом МЭГ.

\vspace*{-3pt}

\section{Базовые понятия}

Чтобы исследовать свойства смесей нормальных распределений, сначала надо ввести 
строгое определение смеси вероятностных распределений. По этой теме имеется обширная 
литература (см.\ например~\cite{teicher_60, teicher_63}), но в~более современном виде 
понятие смеси дается в~книге В.\,Ю.~Королева~\cite{korolev}, которое и~будет процитировано ниже.

Рассмотрим функцию $F (x, \textbf{y})$, определенную на множестве $\mathbb{R} \times \mathbb{Y}.$

Пусть $\mathbb{Y}$~--- это некоторое подмножество $m$-мер\-но\-го 
евклидова пространства, $\mathbb{Y}\hm\subseteq\mathbb{R}^m$ при некотором $m \hm\geqslant 1$, 
причем множество~$\mathbb{Y}$ снабжено борелевской $\sigma$-ал\-геб\-рой $\mathcal{B}$. 
Более того, при каждом фиксированном~$\textbf{y}$ функция $F (x, \mathbf{y})$ 
является функцией распределения по~$x$, а~при каждом фиксированном~$x$ функция~$F (x, \mathbf{y})$ 
измерима по $\mathbf{y}$, т.\,е.\ для любых $x \hm\in \mathbb{R}$ и~$c \hm\in \mathbb{R}$ 
выполнено условие $\{\mathbf{y} : F (x, \mathbf{y}) \hm< c\} \hm\in \mathcal{B}$. Пусть 
${\sf Q}$~--- вероятностная мера, определенная на измеримом пространстве~$(\mathbb{Y}, \mathcal{B})$.

Функция распределения
$$
        H(x) = \int\limits_ \mathbb{Y} F (x, \mathbf{y}) {\sf Q} (d\mathbf{y}), \enskip  x \in \mathbb{R},
$$
{\bfseries\textit{называется смесью функции распределения $F (x, \textbf{y})$ по~$\textbf{y}$
 относительно $\sf Q$}}. Распределение $F (x, \mathbf{y})$ называется смешиваемым, в~то время как мера~$\sf Q$ 
 задает смешивающее распределение.

Введем $m$-мерную случайную величину~$\mathbf{Y}$: $\mathbf{Y}(y) \hm\equiv y$, $y \hm\in \mathbb{Y}$,  
определенную на вероятностном пространстве $(\mathbb{Y}, \mathcal{B},{\sf Q})$. Тогда
функция распределения $H(x)$ может быть записана в~виде:
$$
        H(x) = {\sf E} F (x, \mathbf{Y}), \quad  x \in \mathbb{R}.
$$

Если $f(x, \mathbf{y})$~--- плотность распределения, соответствующая функции 
распределения $F (x, \mathbf{y})$,
$$
f(x, \mathbf{y}) = \fr{d}{dx} \, F (x,\mathbf{y}),
$$
то смеси $H(x)$ соответствует плотность
$$
        h(x) = {\sf E} f(x, \mathbf{Y}) = \int\limits_ \mathbb{Y} f(x, \textbf{y}) 
        {\sf Q} (d\mathbf{y}), \quad  x \in \mathbb{R}.
$$

Далее будет рассмотрен важный частный случай вероятностных смесей: 
так называемая сдвиг/мас\-штаб\-ная смесь. Введем определение согласно~\cite{korolev}.

Пусть в~определении, сформулированном выше, $m \hm= 2$. Предположим, что вектор~$\mathbf{y}$ имеет вид:
$$
\mathbf{y} = (u, v),
$$
где $u > 0$ и~$v \hm\in \mathbb{R}$, так что функция распределения $F (x,\textbf{y})$ 
допускает представление
$$
        F (x,\textbf{y}) = F \left(\fr{x-v}{u}\right), \quad  x \in \mathbb{R}.
$$

Тогда $\mathbb{Y}$~--- это положительная полуплоскость, т.\,е.\ $\mathbb{Y = R^+ \times R}$, 
и~функция распределения
$$
        H(x) = \int\limits_ \mathbb{Y} F\left(\fr{x-v}{u}\right) {\sf Q} (du, dv), \quad  x \in \mathbb{R},
$$
{\bfseries\textit{называется сдвиг/масштабной смесью функции распределения~$F$ относительно меры~$Q$}} 
с~параметром масштаба~$u$ и~параметром сдвига (положения)~$v$.

Если функция распределения~$F$ имеет плотность~$f$, то смеси~$H(x)$ соответствует плотность
$$
        h(x) = \int\limits_ \mathbb{Y} \fr{1}{u} f\left(\fr{x-v}{u}\right) {\sf Q} (du, dv), \quad  x \in \mathbb{R}.
$$

\vspace*{-12pt}


\section{Основные результаты}

\subsection{Свойства нормальных смесей}

\noindent
\textbf{Определение~1.}
Распределение случайной величины~$\xi$ является масштабной смесью нормальных 
распределений, если плотность~$\mathit{p}_\xi(x)$ представима в~виде:
$$
\mathit{p}_\xi(x) = \il 0 \infty \fr{1}{\sigma} \, \varphi\left(\fr{x}{\sigma}\right) {\sf Q} (d\sigma), 
\quad x \in \mathbb{R},
$$
где $\varphi(x)$~--- плотность стандартного нормального распределения.

\smallskip

Далее исследуем свойства этих смесей и~покажем, какие из свойств 
нормального распределения остаются справедливыми, а~какие~--- нет.


Для полноты изложения приведем доказательство известного утверждения.

\smallskip

\noindent
\textbf{Утверждение~1.}
\textit{Если плотность случайной величины~$\xi$ является масштабной смесью нормальных распределений, 
случайная величина~$X^2$ имеет распределение~$\chi^2(n)$~--- хи-квад\-рат с~$n$~степенями свободы, 
$X^2$ и~$\xi$ независимы, то случайная величина $t \hm= {\xi}/{\sqrt{X^2/n}}$ 
имеет плотность распределения, являющуюся смесью распределений Стьюдента с~$n$~степенями свободы}.


\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \
Рассмотрим плот\-ность~$\xi$, она имеет вид:
$$
\mathit{p}_\xi(x) =  \il 0 \infty \fr{1}{\sigma} \, \varphi\left(\fr{x}{\sigma}\right) {\sf Q} (d\sigma),
$$
где $\varphi(x)$~--- плотность стандартного нормального распределения.

Введем вспомогательную величину $\eta \hm= \sqrt{{X^2}/{n}}$ с~плот\-ностью
$$
\mathit{p}_\eta(y) = \fr{2ny({1}/{2})^{{n}/{2}}(ny^2)^{n/{2}-1}}
{\Gamma\left({n}/{2}\right)e^{{ny^2}/{2}}},\mbox{ где } y\ge0.$$

Тогда плотность частного ${\xi}/{\eta}$ имеет вид:
\begin{multline*}
\mathit{p}_{{\xi}/{\eta}}(z) = \mathit{p}_t(z) = {}\\
{}=
\int\limits_0^\infty y p_\eta(y) \, \left(\il 0 \infty \fr{1}{\sigma} \, 
\varphi\left(\fr{z\, y}{\sigma}\right) {\sf Q} (d\sigma) \right) {d}y={}
\\
{}= \int\limits_0^\infty \fr{ n^{n/2} \, y^n \, e^{-{ny^2}/{2}} } {2^{{n}/{2}-1} 
 \Gamma\left({n}/{2}\right) } 
  \left(\il 0 \infty \fr{1}{\sigma}\, \varphi\left(\fr{z\, y}{\sigma}\right) {\sf Q} 
  (d\sigma) \right) {d}y.
\end{multline*}
В силу теоремы Фубини изменив порядок интегрирования,  проведем следующие преобразования:
\begin{multline*}
\mathit{p}_t(z) = \int\limits_0^\infty \fr{1}{\sqrt{2\pi} \, \sigma} \,
\fr{n^{{n}/{2}}}{2^{{n}/{2}-1}  \Gamma\left({n}/{2}\right)}\times{}\\
{}\times 
\il 0 \infty y^n  e^{-({1}/{2}) \left({z^2}/{\sigma^2}+n\right) y^2} {d}y \, {\sf Q} (d\sigma) = {}\\
{}=
\int\limits_0^\infty \fr{1}{\sqrt{2\pi} \, \sigma} \,
\fr{n^{{n}/{2}}}{2^{{n}/{2}-1} \Gamma\left({n}/{2}\right)} \times{}\\
{}\times
\il 0 \infty (y^2)^{({n+1})/{2}-1}  e^{-({1}/{2}) \left({z^2}/{\sigma^2}+n\right) y^2} \,
{d}\left(\fr{y^2}{2}\right)  {\sf Q} (d\sigma) = {}\\
{}= \int\limits_0^\infty \fr{1}{\sqrt{2\pi} \, \sigma} \,
\fr{n^{{n}/{2}}}{2^{{n}/{2}-1}  \Gamma\left({n}/{2}\right)} \, 
\fr{1}{2^{({1-n})/{2}}} \times{}\\
{}\times \left(\fr{z^2}{\sigma^2}+n\right)^{-({n+1})/{2}} 
 \Gamma\left(\fr{n+1}{2}\right) {\sf Q} (d\sigma).
\end{multline*}


После упрощения подынтегрального выражения плотность~$\mathit{p}_t(z)$ примет вид:
\begin{multline*}
\mathit{p}_t(z) = \int\limits_0^\infty \fr{1}{\sqrt{\pi} \, \sigma} \,
\fr{\Gamma\left(({n+1})/{2}\right)} {\Gamma\left({n}/{2}\right)} \, 
 \fr{1}{\sqrt{n}}\times{}\\
 {}\times \left(\fr{n}{{z^2}/{\sigma^2}+n}\right)^{({n+1})/{2}}  {\sf Q} (d\sigma) ={}  \\
{}= \int\limits_0^\infty \fr{1}{\sigma} \, \fr{1}{\sqrt{\pi \, n}} \,
\fr{\Gamma\left(({n+1})/{2}\right)} {\Gamma\left({n}/{2}\right)}\times{}\\
{}\times
 \left(\fr{1}{1+{z^2}/({\sigma^2 n}})\right)^{({n+1})/{2}}  {\sf Q} (d\sigma).
\end{multline*}

Используя обозначение $\mathit{s}_n(x)$ для плотности распределения Стьюдента с~$n$~степенями свободы
$$
\mathit{s}_n(x) = \fr{\Gamma\left(({n+1})/{2}\right)}
{\Gamma({n}/{2})\sqrt{\pi n}}\left(1 + \fr{x^2}{n}\right)^{-({n+1})/{2}}, \enskip x \in \mathbb{R},
$$
получим следующее выражение для плотности~$\mathit{p}_t$:
$$
\mathit{p}_t(x) = \il 0 \infty \fr{1}{\sigma} \, s_n\left(\fr{x}{\sigma}\right) {\sf Q} (d\sigma).
$$


Таким образом, плотность~$\mathit{p}_t$ является масштабной смесью распределений Стьюдента 
относительно~${\sf Q}$.

Утверждение доказано.~\hfill$\square$


\smallskip

\noindent
\textbf{Теорема~1.}
\textit{Если случайная величина~$\xi$ имеет смешанное нормальное распределение 
относительно вероятностной меры~$Q$, то случайная величина 
$\eta\hm=\exp(\xi)$ имеет смешанное логнормальное распределение относительно~$Q$. 
И~наоборот, если~$\eta$ имеет смешанное логнормальное распределение, то $\xi\hm=\ln 
\eta$ имеет смешанное нормальное распределение относительно одной и~той же меры~$Q$}.


\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \
Докажем сначала первое утверждение теоремы.

Получим выражение для плотности~$\eta$ в~явном виде. По условию теоремы
$$
{\sf P} (\xi \le x) = \il 0 \infty  \il {-\infty} \infty \Phi \left(\fr{ x-a}{\sigma} \right) {\sf Q}
 (d\sigma, da),
$$
поэтому
\begin{multline*}
\mathit{F}_\eta(x) = {\sf P} (\eta \le x)) = {\sf P} (\exp(\xi) \le x)) = {}\\
{}={\sf P} (\xi \le \ln x))
=\il 0 \infty  \il {-\infty} \infty \Phi \left(\fr{\ln x-a}{\sigma} \right) {\sf Q} (d\sigma, da),
\end{multline*}
где $\Phi(x)$~--- функция распределения стандартного нормального закона, $x\hm>0$.

Следовательно,
$$
\mathit{p}_\eta(x) = \il 0 \infty  \il {-\infty} \infty \fr{1}{x \sigma} \,
\varphi\left(\fr{\ln x-a}{\sigma} \right) {\sf Q} (d\sigma, da).
$$

Таким образом, плотность $\mathit{p}(x)$ смешиваемого распределения имеет вид
$$
\mathit{p}(x) = \fr{1}{x\sigma\sqrt{2\pi}}\,e^{-{(\ln x - a)^2}/({2\sigma^2})}, \enskip x>0.
$$
А значит, $\eta$ имеет смешанное логнормальное распределение.

Для доказательства обратного утверждения теоремы воспользуемся следующей известной леммой.

\noindent
\textbf{Лемма~1.}
\textit{Если функция $y\hm=g(x)$ возрастает и~дифференцируема, случайная величина~$\xi$ имеет 
плотность $p_\xi$, тогда плотность~$p_\eta$ случайной 
величины $\eta\hm=g(\xi)$ определяется формулой}:
$$
p_\eta(y)=p_\xi(g^{-1}(y))\, \fr{1}{g'(g^{-1}(y))}\,.
$$



Итак, пусть плотность случайной величины~$\xi$ является смесью логнормальных распределений относительно~$Q$.
Тогда плотность случайной величины $\eta\hm=\ln\xi$, с~учетом леммы, равна

\noindent
\begin{multline*}
p_\eta(y)=p_\xi(\exp(y)) \fr{1}{1/\exp(y)}=
\exp(y)\times{}\\
{}\times \il 0 \infty  \il {-\infty} \infty \fr{1}{\exp(y)\, \sigma} \,
\varphi \left(\fr{\ln \exp(y)-a}{\sigma} \right) {\sf Q} (d\sigma, da)={}\\
\\
{}=\il 0 \infty  \il {-\infty} \infty \fr{1}{\sigma} \,
\varphi \left(\fr{y-a}{\sigma} \right) 
{\sf Q} (d\sigma, da).
\end{multline*}

Таким образом, плотность случайной величины~$\eta$ является смесью 
нормальных распределений относительно той же смешивающей меры~$Q$.


Теорема доказана.~\hfill$\square$

\smallskip

\noindent
\textbf{Замечание~1.}\ 
Связь между нормальным и~логнормальным распределениями сохраняется и~для соответствующих 
смесей нормальных и~логнормальных распределений. Данная теорема обобщает результаты, 
полученные авторами в~статье~\cite{simple_mix}.


\smallskip

\noindent
\textbf{Теорема~2.}\
\textit{Если плотность случайной величины~$\xi$ является масштабной смесью нормальных распределений,
то случайная величина~$\xi^2$ будет распределена с~плотностью, являющейся масштабной смесью 
гам\-ма-рас\-пре\-де\-ле\-ний, т.\,е.}
\begin{multline*}
{p}_{\xi^2}(x) =  \il 0 \infty  \fr{1}{\sigma \, \sqrt{x}} \, 
\varphi\left(\fr{\sqrt{x}}{\sigma}\right) {\sf Q} (d\sigma)= {}\\
{}=\il 0 \infty  \fr{1}{\sigma  \sqrt{2 \pi x }} \,   e^{-{x}/({2 \, \sigma^2})} {\sf Q} (d\sigma).
\end{multline*}


\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \
Выпишем функцию распределения для~$\xi^2$ и~проведем 
необходимые преобразования с~использованием теоремы Фубини:
\begin{multline*}
\mathrm{F}_{\xi^2}(x) = {\sf P} (\xi^2 \leq x) =  {\sf P} \left( -\sqrt{x} \leq \xi \leq \sqrt{x}\right) = {}\\
{}=
\int\limits_{-\sqrt{x}}^{\sqrt{x}} \il 0 \infty \fr{1}{\sigma}\, 
\varphi\left(\fr{x}{\sigma}\right) {\sf Q} (d\sigma)\, {d}x ={} \\
{}= \il 0 \infty \int\limits_{-\sqrt{x}}^{\sqrt{x}} \fr{1}{\sigma} \,
\varphi\left(\fr{x}{\sigma}\right)  {d}x {\sf Q} (d\sigma) = {}\\
{}=
\il 0 \infty \left(\Phi\left(\fr{\sqrt{x}}{\sigma}\right) - \Phi\left(\fr{-\sqrt{x}}{\sigma}\right)\right) 
{\sf Q} (d\sigma) = {}\\
{}= \il 0 \infty \left( 2 \Phi\left(\fr{\sqrt{x}}{\sigma}\right) - 1\right) {\sf Q} (d\sigma) ={}\\
{}=
 2 \il 0 \infty \Phi\left(\fr{\sqrt{x}}{\sigma}\right) {\sf Q} (d\sigma) - 1.
\end{multline*}

Далее для нахождения плотности распределения~$\xi^2$ продифференцируем функцию распределения, полученную выше:
\begin{multline*}
{p}_{\xi^2}(x) = \fr{{d}}{{d}x}\,\mathrm{F}_{\xi^2}(x) = 
\il 0 \infty \fr{1}{\sigma \sqrt{x}} \,\varphi\left(\fr{\sqrt{x}}{\sigma}\right)
 {\sf Q} (d\sigma) ={}\\
 {}=
  \il 0 \infty \fr{1}{\sigma \sqrt{2\pi \, x}}\, e^{-{x}/({2\sigma^2})} {\sf Q} (d\sigma).
\end{multline*}

Таким образом, плотность распределения случайной величины~$\xi^2$ является масштабной 
смесью гам\-ма-рас\-пре\-де\-ле\-ний.


Теорема доказана.~\hfill$\square$

\smallskip

\noindent
\textbf{Замечание 2.} Эти три теоремы наглядно демонстрируют схожесть в~поведении 
нормальных смесей и~нормального распределения. Аналоги данных теорем для дискретных 
смесей можно найти в~\cite{simple_mix}. Но смеси нормальных распределений обладают 
особенностями поведения, отличающими их от нормального распределения.
В~част\-ности, широко известный факт об эквивалентности свойств некоррелированности 
и~независимости для компонент многомерного нормального распределения~\cite{borovkov}
уже не выполняется для конечной нормальной смеси, как показано в~\cite{simple_mix}.

\subsection{Обратная задача магнитоэнцефалографии}

В статье \cite{simple_mix} рассматривалось приложение конечных нормальных смесей для 
моделирования \mbox{шума} измерений активности головного мозга методом МЭГ. 
Магнитоэнцефалография~--- неинвазивная технология нейровизуализации, позволяющая исследовать 
электромагнитную активность человеческого мозга путем измерения магнитного поля непосредственно 
вблизи поверхности головы испытуемого (подробнее о~МЭГ см.~\cite{hama_main, our}).


С помощью МЭГ можно исследовать различные аспекты функционирования головного мозга 
с~высоким временн$\acute{\mbox{ы}}$м разрешением, сопоставимым со скоростью передачи 
нервного импульса\linebreak (это качественно отличает МЭГ от другого популярного метода функциональной 
нейровизуализации~--- функциональной маг\-нит\-но-ре\-зо\-нанс\-ной\linebreak томографии, фМРТ). 
Запись МЭГ представляет собой многоканальный сигнал, регистрируемый массивом сенсоров внут\-ри 
специального шлема, под который помещается голова испытуемого. Отдельный интерес представляет 
локализация (указание точных координат и~интенсивностей) источников активности 
внут\-ри головного мозга испытуемого. Для ее установления необходимо решить обратную задачу МЭГ.


Рассмотрим обратную задачу МЭГ:
\begin{equation}
\label{MEG_inv}
Y = L\Theta + \mathcal{E},
\end{equation}
где $Y \in \mathbb{R}^n$~--- измеряемые данные; $L\hm \in \mathbb{R}^{n \times k}$~--- оператор 
Био--Са\-ва\-ра--Лап\-ла\-са; $\Theta\hm \in \mathbb{R}^k$~--- 
неизвестные амплитуды источников; $\mathcal{E} \hm\in \mathbb{R}^n$~--- шум; $k$~--- 
количество источников активности; $n$~--- чис\-ло МЭГ-сен\-со\-ров, $k \hm\ge n$.
Классический подход к~решению подобных задач предполагает минимизацию нормы ошибки:
$$
||\mathcal{E}||^2 = ||Y - L\Theta||^2 \rightarrow \min\limits_\Theta.
$$
О других подходах можно прочесть в~статье~\cite{bayes_inverse}. 
Физические и~математические свойства модели обратной задачи МЭГ рассматриваются 
в~\cite{MEG_source_loc}.

В теории линейной регрессии доказано, что у~задачи~\eqref{MEG_inv} существует решение 
наименьших квадратов~\cite{app_regr} при выполнении следующих условий:
\begin{itemize}
    \item ${\sf E}\mathcal{E} = 0$~--- математическое ожидание шума равно нулю;
    \item $\Sigma > 0$~--- матрица ковариации ошибок положительно определена;
    \item $\mathrm{rank}\,L = n$, т.\,е.~$L$~--- мат\-ри\-ца полного строкового ранга.
\end{itemize}

Решение $\hat{\Theta}$, полученное методом взвешенных наименьших квадратов при 
выполнении обозначенных выше условий, называют оценкой Эйткена~\cite{app_regr}:
\begin{equation}
\label{Aitken_WLS}
\hat{\Theta} = \left(L^{\top}\Sigma^{-1}L\right)^{-1}L^{\top}\Sigma^{-1}Y\,.
\end{equation}

Оценка~\eqref{Aitken_WLS} является несмещенной, состоятельной и~оптимальной в~классе всех 
линейных оценок~\cite{app_regr}.


Анализ реальных записей <<пустой комнаты>> (собственного шума сенсоров и~окружающей среды, 
без испытуемого) показал, что зачастую распределение шума имеет сложную структуру с~такими 
особенностями, как тяжелые хвосты, мультимодальность, несимметричность. Таким образом, 
для более адекватного описания реальных данных требуется более сложная модель шума.


В данном разделе будет рассматриваться модель шума, имеющего распределение в~виде 
многомерной нормальной смеси общего вида с~плотностью
\begin{equation}
\label{eq:general_gaussian_mixture}
h(\vec{x}) = \int \limits_{\mathbb{Y}} f_y\left(\vec{x}; \vec{\mu_y}, \Sigma_y\right) {\sf Q}({d}y),
\end{equation}
где $f_y(\vec{x}; \vec{\mu_y}, \Sigma_y)$~--- плотность $k$-мер\-но\-го 
нормального распределения с~вектором средних~$\vec{\mu_y}$ и~ковариационной матрицей~$\Sigma_y$  
(для упрощения выкладок будем считать, что $\Sigma_y$ невырождена $\forall y \hm\in \mathbb{Y}$), 
$\vec{x}\hm \in \mathbb{R}^k$. Далее будем использовать сокращенную запись~$f_y(\vec{x})$.


В статье~\cite{simple_mix} была доказана теорема о~том, что матрица ковариации 
конечной нормальной смеси положительно определена (в~случае если в~смеси есть компоненты с~положительно 
определенными ковариационными матрицами).


Для доказательства соответствующей теоремы в~случае общей нормальной смеси сначала докажем 
следующую лемму.

\smallskip

\noindent
\textbf{Лемма~2.}
\textit{Матрица ковариации нормальной смеси}~\eqref{eq:general_gaussian_mixture} \textit{имеет вид}:
$$
\Sigma = {\sf E}_y \Sigma_y + {\sf E}_y \left(\vec{\mu_y} - {\sf E}_y\vec{\mu_y}\right)\left(\vec{\mu_y} - 
{\sf E}_y\vec{\mu_y}\right)^\top,
$$
\textit{где $\vec{\mu_y}$ и~$\Sigma_y$~--- 
вектор средних и~ковариационная мат\-ри\-ца смешиваемого нормального распределения}.


\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \
Пусть случайная величина $\vec{X}$ имеет смешанное $k$-мер\-ное нормальное 
распределение с~плотностью~\eqref{eq:general_gaussian_mixture}. 
Тогда ее матрица ковариации по определению равна 
$$
\Sigma = 
{\sf E}\vec{X}\vec{X}^\top - {\sf E}\vec{X}{\sf E}\vec{X}^\top\,.
$$
 Рассмотрим каждое из слагаемых подробнее:
\begin{multline}
{\sf E}\vec{X}\vec{X}^\top =
\int\limits_{\mathbb{R}^k} \vec{x}\vec{x}^\top 
\int\limits_\mathbb{Y} f_y(\vec{x}) {\sf Q}\,(dy) \,{d}\vec{x} = {}\\
{}=
\!\!\!\int\limits_\mathbb{Y} \int\limits_{\mathbb{R}^k} \!\vec{x}\vec{x}^\top f_y(\vec{x})\,d\vec{x} 
{\sf Q}(dy) = 
\!\!\!\int\limits_\mathbb{Y}\!\! \left( \Sigma_y + \vec{\mu_y}\vec{\mu_y}^\top \right)
\! {\sf Q}(dy) = {} \\
 {} = 
{\sf E}_y \left( \Sigma_y + \vec{\mu_y}\vec{\mu_y}^\top \right);
\label{eq:first_summand}
\end{multline}

\vspace*{-12pt}

\noindent
\begin{multline}
\label{eq:second_summand}
{\sf E}\vec{X} =\int\limits_{\mathbb{R}^k} \vec{x} 
\int\limits_\mathbb{Y} f_y(\vec{x}) {\sf Q}(dy)\, d\vec{x} ={}\\
{}=
 \int\limits_\mathbb{Y} \int\limits_{\mathbb{R}^k} \vec{x} f_y(\vec{x}) 
 \,{d}\vec{x} {\sf Q}(dy) =
  \int\limits_\mathbb{Y} \vec{\mu_y} {\sf Q}(dy) = 
{\sf E}_y \vec{\mu_y}.
\end{multline}
    
Объединяя результаты~\eqref{eq:first_summand} и~\eqref{eq:second_summand} и~перегруппировывая 
слагаемые, получим итоговое выражение для ковариационной матрицы в~виде:
\begin{equation}
\label{eq:covar_matrix}
\Sigma = {\sf E}_y \Sigma_y + {\sf E}_y
 (\vec{\mu_y} - {\sf E}_y\vec{\mu_y})(\vec{\mu_y} - {\sf E}_y\vec{\mu_y})^\top.
\end{equation}
Лемма доказана.~\hfill$\square$


\smallskip

\noindent
\textbf{Теорема~3.}
\textit{Ковариационная матрица нормальной смеси}~\eqref{eq:general_gaussian_mixture} 
\textit{положительно определена}.


\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \
Рассмотрим случайную величину $\vec{X}$, имеющую смешанное нормальное распределение 
с~плот\-ностью~$\eqref{eq:general_gaussian_mixture}$. Ее ковариационная матрица имеет 
вид~\eqref{eq:covar_matrix}. По определению матрица~$\Sigma$ является положительно определенной, 
если выполнено
$$
u^\top\Sigma u > 0,\quad \forall\  u \in \mathbb{R}^k.
$$

Распишем более подробно с~учетом предыдущей леммы
\begin{multline*}
u^\top\Sigma u =ХЪ\\
ХЪ= u^\top{\sf E}_y \Sigma_y u +  
u^\top {\sf E}_y (\vec{\mu_y} - {\sf E}_y\vec{\mu_y})(\vec{\mu_y} - 
{\sf E}_y\vec{\mu_y})^\top u ={} \\ 
{}= {\sf E}_y u^\top \Sigma_y u +  u^\top {\sf E}_y (\vec{\mu_y} - {\sf E}_y\vec{\mu_y})(\vec{\mu_y} - 
{\sf E}_y\vec{\mu_y})^\top u = {}\\ 
{}= {\sf E}_y \underbrace{u^\top \Sigma_y u}_{> 0} + 
 \underbrace{u^\top {\sf E}_y (\vec{\mu_y} - {\sf E}_y\vec{\mu_y})(\vec{\mu_y} - 
 {\sf E}_y\vec{\mu_y})^\top u}_{\geqslant 0}.
\end{multline*}
Первое слагаемое строго положительно из-за положительной определенности матриц 
$\Sigma_y \forall y \hm \in \mathbb{Y}$. 
Второе слагаемое есть ковариационная мат\-ри\-ца~$\vec{\mu_y}$; следовательно, 
она неотрицательно определена. В~итоге получим, что
$$
u^\top\Sigma u > 0.
$$

Теорема доказана.~\hfill$\square$


\noindent
\textbf{Замечание~3.}\ Теорема остается справедливой, даже если матрицы~$\Sigma_y$ 
вырождены при некотором $y\hm \in A \hm\subset \mathbb{Y}$. Это следует из того, что
\begin{multline*}
u^\top{\sf E}_y \Sigma_y u = u^\top\int\limits_\mathbb{Y} \Sigma_y {\sf Q}(dy) u 
= {}\\
{}=u^\top\int\limits_{\mathbb{Y} \setminus A} \Sigma_y {\sf Q}(dy) u + 
u^\top\int\limits_A \Sigma_y {\sf Q}(dy) u \geqslant {}\\ 
{}\geqslant
u^\top\int\limits_{\mathbb{Y} \setminus A} \Sigma_y {\sf Q}(dy) u > 0,\ \forall
 u \in \mathbb{R}^k.
\end{multline*}

Также из доказательства видно, что для справедливости теоремы достаточно, 
чтобы у~смешиваемого распределения была положительно определенная матрица 
ковариации, а~непосредственный вид смешиваемого распределения значения не имеет.


Таким образом, при использовании модели шума в~виде нормальной смеси общего вида 
оценка интенсивностей источников с~помощью обобщенного метода наименьших 
квадратов остается справедливой. Стоит отметить, что решение обратной задачи 
таким методом пользуется большой популярностью в~прикладных нейрофизиологических исследованиях.

%\vspace*{-10pt}

\section{Заключение}

В~статье представлены базовые понятия непрерывных смесей вероятностных
 распределений и~подробно рассмотрен частный случай нормальных смесей общего вида, 
 определены законы распределения случайных величин, являющихся функциональным 
 преобразованием случайных величин с~плотностью в~виде нормальной смеси общего \mbox{вида}.

Смеси распределений общего вида возникают в~множестве прикладных задач, а~также 
они используются как средство представления не-нормальных распределений. Для важного частного 
случая, где смешиваемое распределение является нормальным, были рассмотрены распределения 
трансформации смеси и~установлены сходства в~поведении нормальных смесей и~нормального 
распределения. Также было доказано, что обобщенный метод наименьших квадратов поиска 
псевдообратного оператора остается применимым и~в~случае шума, имеющего распределение в~виде 
смеси общего вида. Этот результат говорит о~применимости широко распространенных методов решения 
обратной задачи МЭГ и~в~случае не-нор\-маль\-но\-го шума, который может быть представлен в~виде 
нормальной смеси. Такая ситуация часто встречается при обработке данных реальных экспериментов.


\vspace*{-12pt}

{\small\frenchspacing
{%\baselineskip=10.8pt
%\addcontentsline{toc}{section}{References}
\begin{thebibliography}{99}

\vspace*{-4pt}

\bibitem{tit}        
\Au{Titterington D.\,M., Smith~A.\,F.\,M., Makov~U.\,E.} 
Statistical analysis of finite mixture distributions.~--- New York, NY, USA: Wiley, 1985. 243~p.

\bibitem{mac}       
\Au{McLachlan G.\,J., Peel D.} Finite mixture models.~--- New York, NY, USA: Wiley \& Sons, 2000. 419~p.

\bibitem{simple_mix}     %3
\Au{Гончаренко М.\,Б., Захарова~Т.\,В.} 
Особенности поведения конечных смесей нормальных распределений~// 
Вестник Московского университета. Сер.~15: Вы\-чис\-ли\-тель\-ная математика и~кибернетика, 2018.  
№\,3. С.~30--36.
\bibitem{teicher_60}     
\Au{Teicher H.} On the mixture of distributions~// Ann. Math. Stat., 1960. Vol.~31. No.\,1. P.~55--73.
\bibitem{teicher_63}     
\Au{Teicher H.} Identifiability of finite mixtures~// 
Ann. Math. Stat., 1963. Vol.~34. No.\,4. P.~1265--1269.
\bibitem{korolev}       
\Au{Королев В.\,Ю.} EM-ал\-го\-ритм, его модификации и~их применение к~задаче 
разделения смесей вероятностных распределений: Теоретический обзор.~--- М.: ИПИ РАН, 2007. 94~с.
\bibitem{borovkov}      
\Au{Боровков А.\,А.} Математическая статистика.~--- 
4-е изд.~--- М.: Лань, 2010. 704~с.
\bibitem{hama_main}     
\Au{Hamalainen M., Hari~R., Ilmoniemi~R.\,J., Knuutila~J., Lounasmaa~O.\,V.} 
Magnetoencephalography~--- theory, instrumentation, and applications to noninvasive studies of 
the working human brain~// Rev. Mod. Phys., 1993. Vol.~65. No.\,2. P.~413--497.
\bibitem{our}          
\Au{Захарова Т.\,В., Никифоров~С.\,Ю., Гончаренко~М.\,Б., Драницына~М.\,А., Климов~Г.\,А., 
Хазиахметов~М.\,Ш., Чаянов~Н.\,В.} 
Методы обработки сигналов для лока-\linebreak\vspace*{-12pt}

\pagebreak

\noindent
лизации невосполнимых областей головного мозга~// 
Системы и~средства информатики, 2012. Т.~22. №\,2. С.~157--175.
\bibitem{bayes_inverse} 
\Au{Гончаренко~М.\,Б., Захарова~Т.\,В.} 
Вероятностный подход к~решению обратной задачи МЭГ~// Системы и~средства информатики, 2018. Т.~28. 
№\,1. С.~35--52.
\bibitem{MEG_source_loc} 
\Au{Zakharova T.\,V., Karpov~P.\,I., Bugaevskii~V.\,M.} 
Localization of the activity source in the inverse problem of magnetoencephalography~// 
Comput. Math. Model., 2017. Vol.~28. No.\,2. P.~148--157.
\bibitem{app_regr} 
\Au{Дрейпер Н.\,Р., Смит~Г.} Прикладной регрессионный анализ~/
Пер. с~англ.~--- 3-е изд.~--- М.: Диалектика, 2016. 912~с.
(\Au{Draper~N., Smith~H.} {Applied regression analysis}.~--- 3rd ed.~---
 New York, NY, USA: John Wiley \& Sons, Inc., 1998. 736~p.)
 \end{thebibliography}

}
}

\end{multicols}

\vspace*{-3pt}

\hfill{\small\textit{Поступила в~редакцию 27.09.2020}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{-2pt}

\def\tit{SOME PROPERTIES OF GAUSSIAN MIXTURES AND~APPLICATIONS TO~MAGNETOENCEPHALOGRAPHY PROBLEMS}


\def\titkol{Some properties of gaussian mixtures and~applications to~magnetoencephalography problems}

\def\aut{M.\,B.~Goncharenko$^1$ and T.\,V.~Zakharova$^{2,3}$}

\def\autkol{M.\,B.~Goncharenko and T.\,V.~Zakharova}


\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-10pt}


\noindent
$^1$INTEL A/O, 17-4 Krylatskaya Str., Moscow 121614, Russian Federation

\noindent
$^2$Department of Mathematical Statistics, Faculty of Computational Mathematics and Cybernetics,
M.\,V.~Lomo-\linebreak 
$\hphantom{^1}$nosov Moscow State University, 1-52~Leninskie Gory, GSP-1, Moscow 119991, Russian
Federation

\noindent
$^3$Institute of Informatics Problems, Federal Research Center ``Computer Science and Control'' 
of the Russian\linebreak
$\hphantom{^1}$Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, Russian Federation

 
\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2021\ \ \ volume~15\ \ \ issue\ 2}
}%
\def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2021\ \ \ volume~15\ \ \ issue\ 2
\hfill \textbf{\thepage}}}

\vspace*{5pt}




\Abste{The article is dedicated to research of various properties of compound probability 
distributions (mixture distributions). Special attention is paid to the case when the mixed 
distribution is Gaussian. The authors establish the similarities in the behavior of Gaussian 
mixtures and Gaussian distributions during transformations. The authors study applications 
to magnetoencephalographic brain research. The authors determine the conditions under which 
the Aitken estimator (generalized least squares) is applicable for localization of sources 
of neurophysiologic activity in the case of noise having compound Gaussian distribution.}

\KWE{compound distributions; compound Gaussian distribution; compound Student 
distribution; compound lognormal distribution; compound gamma distributions; 
magnetoencephalography; MEG; inverse MEG problem; Aitken's estimator}



\DOI{10.14357/19922264210207}

\vspace*{-3pt}

 \Ack
\noindent
The work was partly supported by the Russian Foundation for Basic Research (project 19-07-00352). 
The research was conducted in accordance with the program of the Moscow Center for 
Fundamental and Applied Mathematics.

\vspace*{6pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}

\bibitem{2-zg}
\Aue{Titterington, D.\,M., A.\,F.~M. Smith, and U.\,E.~Makov.}
 1985. \textit{Statistical analysis of finite mixture distributions}. New York, NY: Wiley. 243~p.
 
 \bibitem{1-zg}
\Aue{McLachlan, G., and D.~Peel.} 2000. 
\textit{Finite mixture models}. New York, NY: Wiley \& Sons. 419~p.

\bibitem{3-zg}
\Aue{Goncharenko, M.\,B., and T.\,V.~Zakharova.}
 2018. Oso\-ben\-nosti povedeniya konechnykh smesey normal'nykh raspredeleniy 
 [Features of behavior of finite mixtures of normal distributions].  
 \textit{Vestnik Moskovskogo Universiteta. Ser.~15: Vychislitel'naya matematika i~kibernetika} 
 [Bull. Moscow State University. Ser.~15: Comput. Math., Cybern.] 3:30--36.
\bibitem{4-zg}
\Aue{Teicher, H.} 1960. On the mixture of distributions.
 \textit{Ann. Math. Stat.} 31(1):55--73.
\bibitem{5-zg}
\Aue{Teicher, H.} 1963. Identifiability of finite mixtures. 
 \textit{Ann. Math. Stat.} 34(4):1265--1269.
\bibitem{6-zg}
\Aue{Korolev, V.\,Yu.} 2007.  \textit{EM-algoritm, ego modifikatsii i~ikh primenenie 
k~zadache razdeleniya smesey veroyatnostnykh raspredeleniy. Teoreticheskiy obzor} 
[EM algorithm modifications and their application to the separation of mixtures of probability 
distributions. Theoretical review]. Moscow: IPI RAN. 94~p.
\bibitem{7-zg}
\Aue{Borovkov, A.\,A.}
 2010.  \textit{Matematicheskaya statistika} [Mathematical statistics]. 4th ed. Moscow: Lan. 704~p.
\bibitem{8-zg}
\Aue{Hamalainen, M., R.~Hari, R.\,J.~Ilmoniemi, J.~Knuutila, and O.\,V.~Lounasmaa.}
 1993. Magnetoencephalography~--- theory, instrumentation, and applications to noninvasive studies 
 of the working human brain.  \textit{Rev. Mod. Phys.} 65(2):413--497. 
\bibitem{9-zg}
\Aue{Zakharova, T.\,V., S.\,Yu.~Nikiforov, M.\,B.~Goncharenko, M.\,A.~Dranitsyna, G.\,A.~Klimov, 
M.\,Sh.~Khaziakhmetov, and N.\,V.~Chayanov.}
 2012. Metody obrabotki signalov dlya lokalizatsii nevospolnimykh oblastey golovnogo mozga 
 [Signal processing methods for localization of nonrenewable brain regions]. 
  \textit{Sistemy i~Sredstva Informatiki~--- Systems and Means of Informatics} 22(2):157--175.
\bibitem{10-zg}
\Aue{Goncharenko, M.\,B., and T.\,V.~Zakharova.}
 2018. Ve\-ro\-yat\-nost\-nyy podkhod k~resheniyu obratnoy za\-da\-chi mag\-ni\-to\-en\-tse\-lo\-gra\-fii 
 [Probabilistic approach to solving the magnetoencephalography inverse problem].
  \textit{Sistemy i~Sredstva Informatiki~--- Systems and Means of Informatics} 28(1):35--52.
\bibitem{11-zg}
\Aue{Zakharova, T.\,V., P.\,I.~Karpov, and V.\,M.~Bugaevskii.}
 2017. Localization of the activity source in the inverse problem of magnetoencephalography. 
  \textit{Comput. Math. Model.} 28(2):148--157.
\bibitem{12-zg}
\Aue{Draper, N., and H.~Smith.} 1998. 
 \textit{Applied regression analysis}. 3rd ed. New York, NY: John Wiley \& Sons, Inc. 736~p.
 \end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-3pt}

  \hfill{\small\textit{Received September~27, 2020}}


%\pagebreak

%\vspace*{-8pt}  

\Contr

\noindent
\textbf{Goncharenko Miroslav B.} (b.\ 1991)~--- 
software development engineer for graphics, INTEL A/O, 17-4~Krylatskaya Str., 
Moscow 121614, Russian Federation; \mbox{goncharenko.mir@yandex.ru}

\vspace*{3pt}

\noindent
\textbf{Zakharova Tatiana V.} (b.\ 1962)~--- 
Candidate of Science (PhD) in physics and mathematics, associate professor, Department
 of Mathematical Statistics, Faculty of Computational Mathematics and Cybernetics, M.\,V.~Lomonosov 
 Moscow State University, 1-52~Leninskie Gory, GSP-1, Moscow 119991, Russian Federation; 
 senior scientist, Institute of Informatics Problems, Federal Research Center 
 ``Computer Science and Control'' of the Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, 
 Russian Federation; \mbox{lsa@cs.msu.ru}
\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература}