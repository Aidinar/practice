
\newcommand{\Radon}{\textit{R}}
\newcommand{\Variance}{{\sf D}}

\def\stat{eroshenko}



\def\tit{АСИМПТОТИЧЕСКИЕ СВОЙСТВА ОЦЕНКИ РИСКА В ЗАДАЧЕ
ВОССТАНОВЛЕНИЯ ИЗОБРАЖЕНИЯ С КОРРЕЛИРОВАННЫМ
 ШУМОМ ПРИ ОБРАЩЕНИИ ПРЕОБРАЗОВАНИЯ РАДОНА$^*$}



\def\titkol{Асимптотические свойства оценки риска в задаче
восстановления изображения с коррелированным  шумом}
% при обращении преобразования Радона}

\def\aut{А.\,А.~Ерошенко$^1$,  О.\,В.~Шестаков$^2$}

\def\autkol{А.\,А.~Ерошенко,  О.\,В.~Шестаков}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Работа выполнена при финансовой поддержке РНФ (проект 14-11-00364).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский государственный университет им.\ М.\,В.~Ломоносова,
факультет вычислительной математики и кибернетики,
кафедра математической статистики,
aeroshik@gmail.com}
\footnotetext[2]{Московский государственный университет им.\ М.\,В.~Ломоносова, факультет вычислительной математики и кибернетики,
кафедра математической статистики; Институт проблем
информатики Российской академии наук, oshestakov@cs.msu.su}

\vspace*{-6pt}

\Abste{В последние годы вейвлет-методы, основанные на разложении проекций
по специальному базису и~последующей процедуре пороговой обработки,
широко используются при решении задач реконструкции томографических
 изображений. Их привлекательность заключается, во-пер\-вых, в~быстроте алгоритмов,
 а~во-вто\-рых, в~возможности реконструкции локальных участков изображения
 по неполным проекционным данным, что имеет ключевое значение, например,
 для медицинских приложений, где пациента нежелательно подвергать
 лишней дозе облучения. Анализ погрешностей этих методов представляет собой
 важную практическую задачу, поскольку позволяет оценить качество как
 самих методов, так и~используемого оборудования. В~работе рассматривается
 задача оценки функции при обращении оператора Радона в~модели
 с~коррелированным шумом. Исследуются асимптотические свойства оценки риска
 при пороговой обработке коэффициентов вейв\-лет-вейг\-лет-раз\-ло\-же\-ния
 функции изображения. Приводятся условия, при которых имеет место
 асимптотическая нормальность несмещенной оценки риска.}

\KW{вейвлеты; линейный однородный оператор; преобразование Радона;
пороговая обработка; несмещенная оценка риска; коррелированный шум;
асимптотическая нормальность}

\vspace*{-6pt}

\DOI{10.14357/19922264140404}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}

\section{Введение}

Методы статистического анализа часто применяются для решения задач,
в~которых данные наблюдаются не напрямую, в~частности для
задач компьютерной томографии, связанных с~обращением преобразования Радона.
Томографические методы революционизировали медицинскую диагностику,
поскольку позволили
<<увидеть>> внутренние органы человека, не подвергая пациента опасности.
Эти методы применяются также в~геологии, астрономии, сейсмологии, электронной
микроскопии, диагностике плазмы, химии и~во многих других областях.
Рассматривается следующая модель:
\begin{equation*}
X = R f + z\,,
\end{equation*}
где $R$~--- оператор Радона; $f$~--- искомая функция изображения; $z$~---
коррелированный шум с~нулевым математическим ожиданием.

Для того чтобы <<очистить>> целевую функцию (изображение) от шума,
используется пороговая обработка коэффициентов вейв\-лет-вейг\-лет-раз\-ло\-же\-ния
наблюдаемых данных. Наличие шума приводит к~погрешностям. Оценки этих погрешностей
(риска) и~их свойства в~моделях компьютерной томографии с~независимым шумом
исследовались в~работе~[1]. Показано, что при определенных условиях оценка
риска обладает свойствами состоятельности и~асимптотической нормальности.
В~данной работе исследуется асимптотическое поведение оценки риска в~модели
со стационарным коррелированным шумом.

\section{Преобразование Радона: вейвлет-вейглет-разложение функции}

Определим оператор Радона $\Radon$ как набор интегралов от функции~$f$
по всевозможным прямым плос\-кости:
\begin{equation*}
(\Radon f)(s,\theta) = \int\limits_{L_{s,\theta}} f(x,y)\, d l\,,
\end{equation*}
где
\begin{equation*}
{L_{s,\theta}} = \left\{(x,y)\colon x\cos\theta + y\sin\theta - s = 0 \right\}\,.
\end{equation*}

Задача томографии~--- восстановить функцию по наборам ее линейных интегралов,
 т.\,е.\ восстановить~$f$ по $\Radon f$. Для решения этой
 задачи воспользуемся методом вейв\-лет-вейг\-лет-раз\-ло\-же\-ния~[2].

Пусть заданы $\phi(x)$ и~$\psi(x)$~--- отцовский и~материнский вейвлеты.
Тогда можно определить:

\vspace*{2pt}

\noindent
\begin{equation}
\left.
\begin{array}{rl}
\psi_{j,k_1,k_2}^{[1]} (x,y) &= 2^j \phi(2^j x - k_1) \psi(2^j y - k_2)\,;\\[9pt]
\psi_{j,k_1,k_2}^{[2]} (x,y) &= 2^j \psi(2^j x - k_1) \phi(2^j y - k_2)\,;\\[9pt]
\psi_{j,k_1,k_2}^{[3]} (x,y) &= 2^j \psi(2^j x - k_1) \psi(2^j y - k_2),
\end{array}
\right\}
\label{vaguelette_2d}
\end{equation}

\vspace*{-2pt}

\noindent
семейство $\left\{\psi^{[\lambda]}_{j,k_1,k_2}\right\}_{\lambda,j,k_1,k_2}$
образует ортонормированный базис в~$L^2(\mathbb{R}^2)$. Индекс~$j$
в~(\ref{vaguelette_2d}) называется масштабом, а~индексы $k_1$ и~$k_2$~---
сдвигами. Функция~$\psi$ должна удовлетворять определенным
требованиям, однако ее можно выбрать таким образом, чтобы она
обладала некоторыми полезными свойствами, например была
дифференцируемой нужное число раз и~имела заданное число~$M_0$
нулевых моментов~[3], т.\,е.

\vspace*{4pt}

\noindent
$$
\int\limits_{-\infty}^{\infty}t^k\psi(t)\,dt=0\,,\quad k=0,\ldots,M_0-1\,.
$$

\vspace*{-2pt}

\noindent
В данной работе предполагается, что используются вейвлеты Мейера~[4]
с~достаточным количеством непрерывных производных.

Вейвлет-разложение функции~$f$ имеет вид:

\vspace*{4pt}

\noindent
\begin{equation}
\label{waveletdecomp}
f = \sum\limits_{\lambda,j,k_1,k_2} \left\langle f\,,\
\psi^{[\lambda]}_{j,k_1,k_2}\right\rangle \psi^{[\lambda]}_{j,k_1,k_2}\,.
\end{equation}


\vspace*{-2pt}

На практике в~задаче томографии функция~$f$ обычно задана в~дискретных отсчетах
на круге. Без ограничения общности будем считать, что это круг
единичного радиуса с~центром в~начале координат.
Будем рассматривать <<растянутую>> версию функции
$ \overline{f} (Nx,Ny) \hm= f(x,y)$.
Для дискретных вейв\-лет-ко\-эф\-фи\-ци\-ен\-тов справедливо
$f_{j,k_1,k_2}^{W^{[\lambda]}} \approx 2^{J} \left\langle f,
\psi^{[\lambda]}_{j,k_1,k_2} \right\rangle$.
Также потребуем, чтобы функция~$f$ была равномерно регулярной по
Липшицу с~некоторым параметром $0\hm<\gamma\hm<1$:

\noindent
\begin{equation*}
\left\vert f(x_1,y_1) - f(x_2,y_2)\right\vert
\leq C\!\left(\!\left\vert x_1 - x_2\right\vert^2\! + \!
\left\vert y_1 - y_2\right\vert^2\right)^{\!\gamma/2}\!\!,
\end{equation*}
где $C$~--- некоторая константа. Тогда существует константа~$A$ такая, что~[4]:

\noindent
\begin{align}
\label{Coeff_Decay}
\abs{f_{j,k_1,k_2}^{W^{[\lambda]}}} \leq \fr{A \cdot 2^{J}}{2^{j(\gamma+1)}}\,.
\end{align}

Для обращения оператора Радона определим вейглеты~[2]:
\begin{equation}
\xi_{j,k_1,k_2}^{[\lambda]} = I^{-1}\Radon\psi_{j,k_1,k_2}^{[\lambda]}\,,
\label{Radon_vaguelette}
\end{equation}
где $I$~--- потенциал Рисса:
$\hat{I}^{p} g(w) \hm= |w|^{-p} \hat{g}(w)$. Для вейглетов справедливо соотношение:
\begin{equation*}
\left[R f, \xi_{j,k_1,k_2}^{[\lambda]}\right] = \left\langle
f,\psi_{j,k_1,k_2}^{[\lambda]}\right\rangle\,,
\end{equation*}
которое позволяет использовать в~разложении~(\ref{waveletdecomp})
только проекционные данные и~тем самым предлагает метод обращения преобразования
Радона.


\section{Модель данных}

Предположим, что проекционные данные измеряются при $(s,\theta)\hm\in [-1,1]\times[0,\pi]$.
Пусть $\{e_{i,j}$, $i,j \hm \in \mathbb{Z}\}$~--- стационарный гауссовский
процесс с~ковариационной последовательностью $r_{k,p} \hm= \cov (e_{i,j},
e_{i+k,j+p})$.
Для выборки с~размерами $n \hm= m$ модель проекционных данных
с~шумом выглядит следующим образом:
\begin{multline*}
Y_{i,j} = R f\left(-1+\fr{2i}{n},\fr{j\pi}{n}\right) + e_{i,j}\,, \\
i = 1, \dots, n\,, \enskip j = 1, \dots, n\,, \enskip n=2^J\,.
\end{multline*}
%

Структура ковариации шума для преобразования Радона должна
отражать типичную ситуацию: на практике проекции для разных углов
регистрируются независимо друг от друга.
В~рассматриваемой модели ошибок получаются независимые наблюдения
в~случае разных углов и~стационарный гауссовский шум
с~нулевым математическим ожиданием, конечной дисперсией
и~ковариационной последовательностью $r_\delta \hm\sim A \delta^{-\alpha}$
($0\hm<\alpha\hm<1$) для одинаковых углов.

Как и~в одномерном случае~[5], создаем для равномерных отсчетов наблюдаемое
поле при $(s,\theta)\hm\in [-1,1]\times[0,\pi]$:
\begin{multline*}
Y_n(s,\theta) = \fr{1}{n^2} \sum\limits_{i=1}^{[n(s+1)/2]}\,
\sum\limits_{j=1}^{[n\theta/\pi]} Y_{i,j}=
RF_n(s,\theta) + {}\\
{}+\fr{1}{n^2} \sum\limits_{i=1}^{[n(s+1)/2]}\,
\sum\limits_{j=1}^{[n\theta/\pi]} e_{i,j}\,,
\end{multline*}
где
\begin{equation*}
RF_n(s,\theta)= \fr{1}{n^2}
\sum\limits_{i=1}^{[n(s+1)/2]}\sum\limits_{j=1}^{[n\theta/\pi]}
R f\left(-1+\fr{2i}{n},\fr{j\pi}{n}\right)
\end{equation*}
представляет собой суммарный <<сигнал>> поля.

Положим $H = 1- \alpha/2$, $H \hm\in (1/2,1)$
и~определим дробное броуновское движение $\mathbf{B}_H(s)$~---
гауссовский процесс на $\mathbb{R}$ с~нулевым средним  и~ковариационной функцией
\begin{equation*}
r(s,t) = \fr{V_H}{2}(|s|^{2H} + |s|^{2H} - |s-t|^{2H})\,, \enskip s,t \in \mathbb{R}\,,
\end{equation*}
где
$$
V_H = \Variance (\mathbf{B}_H(1)) =
\fr{-\Gamma(2-2H)\cos(\pi H)}{\pi H(2H-1)}\,.
$$

Далее по аналогии с~моделью, описанной в~[5],
рассматриваем непрерывную аппроксимацию:
\begin{equation}
Y(s,\theta) = R F(s,\theta) + n^{-(1+\alpha)/2} \tau \mathbf{B'}_H(s,\theta)\,,
\label{model_sum2}
\end{equation}
где $\tau = \sqrt{{2A}/({(1-\alpha)(2-\alpha)})}$~--- нормировочный множитель,
который без ограничения общности далее будем считать равным единице,
$R F(s,\theta)\hm=\int\limits_{-1}^{s}\int\limits_{0}^{\theta}Rf(t,q)\,dtdq$,
а~$\mathbf{B'}_H(s,\theta)$~--- случайная функция, которая для каждого
фиксированного угла~$\theta$ представляет собой дробное броуновское
движение $\mathbf{B}_H(s)$ и~имеет некоррелированные приращения по~$\theta$.

Применяя к~\eqref{model_sum2} вейглет-раз\-ло\-же\-ние, получаем:
\begin{align*}
\left[Y, \xi_{j,k_1,k_2}^{[\lambda]}\right] &\!\!= \!
\left[R f, \xi_{j,k_1,k_2}^{[\lambda]}\right]\! \!+\! n^{-(1+\alpha)/2}
\left[ \mathbf{B'}_H, \xi_{j,k_1,k_2}^{[\lambda]}\right]\!;\\
\left[Y, \xi_{j,k_1,k_2}^{[\lambda]}\right] &\!\!= \!
\left\langle f, \psi_{j,k_1,k_2}^{[\lambda]}\right\rangle \!+\! n^{-(1+\alpha)/2}
\left[ \mathbf{B'}_H, \xi_{j,k_1,k_2}^{[\lambda]}\right]\!.
\end{align*}
%

Переходя к~дискретному вейглет-пре\-обра\-зо\-ва\-нию и~вспоминая, что $n\hm=2^J$,
по аналогии с~дискретным вейв\-лет-пре\-обра\-зо\-ва\-ни\-ем
получаем модель дискретных вейг\-лет-ко\-эф\-фи\-ци\-ентов:
\begin{equation*}
X_{j,k_1,k_2}^{[\lambda]} = \mu_{j,k_1,k_2}^{[\lambda]} +
2^{(1-\alpha)J/2} e_{j,k_1,k_2}^{[\lambda]}\,,
\end{equation*}
где
\begin{align*}
\mu_{j,k_1,k_2}^{[\lambda]} &=  2^J\left[Rf, \xi_{j,k_1,k_2}^{[\lambda]}\right]\,;
\\
e_{j,k_1,k_2}^{[\lambda]}&=\left[ \mathbf{B'}_H, \xi_{j,k_1,k_2}^{[\lambda]}\right]
=\int\xi_{j,k_1,k_2}^{[\lambda]}\,d\mathbf{B'}_H\,.
\end{align*}

Из~\eqref{vaguelette_2d} и~\eqref{Radon_vaguelette} получаем
выражения для преобразований Фурье вейг\-лет-функ\-ций по первому аргументу:
\begin{align*}
\widehat{\xi}_{j,k_1,k_2}^{[1]}(w,\theta) &= |w|\cdot 2^{-j}e^{i(k_1\cos\theta+k_2
\sin\theta) 2^{-j} w}\times{}\\
&\hspace*{9mm}{}\times \widehat{\phi}(2^{-j}w\cos\theta) \widehat{\psi}(2^{-j}w\sin\theta)\,;\\
\widehat{\xi}_{j,k_1,k_2}^{[2]}(w,\theta) &=
|w|\cdot 2^{-j}e^{i(k_1\cos\theta+k_2\sin\theta) 2^{-j} w}{}\times{}\\
&\hspace*{9mm}{}\times \widehat{\psi}(2^{-j}w\cos\theta) \widehat{\phi}(2^{-j}w\sin\theta)\,;\\
\widehat{\xi}_{j,k_1,k_2}^{[3]}(w,\theta) &=
|w|\cdot 2^{-j}e^{i(k_1\cos\theta+k_2\sin\theta) 2^{-j} w} \times{}\\
&\hspace*{9mm}{}\times\widehat{\psi}(2^{-j}w\cos\theta) \widehat{\psi}(2^{-j}w\sin\theta).
\end{align*}
Рассмотрим ковариацию коэффициентов модели, например для $(\lambda_1 ,\lambda_2)
\hm=(3,3)$. Проведем интегрирование по углу и~воспользуемся свойствами
$\mathbf{B}_H(s)$~[5]. Без ограничения общности считаем, что  $j \hm\geq i$.
Обозначим $\Delta \hm= j \hm- i$. Имеем

\columnbreak

\noindent
\begin{multline*}
\left\vert \,\cov\left(X_{j,k_1,k_2}^{[3]},X_{i,l_1,l_2}^{[3]}\right)\right\vert
={}\\[3pt]
{}= \left\vert \fr{1}{2\pi}\,2^{(1-\alpha)J}\int \!\!\int
\widehat{\xi}_{j,k_1,k_2}^{[3]}(w,\theta) \overline{\widehat{\xi}_{i,l_1,l_2}^{[3]}
(w,\theta)} \times{}\right.\\[3pt]
\left.{}\times |w|^{-(1-\alpha)}\, dw d\theta \vphantom{\fr{1}{2\pi}}
\right\vert=
\left\vert \fr{1}{2\pi}\,2^{(1-\alpha)J}\int \!\!\int
 2^{-j-i} w^2\times{}\right.\\[3pt]
\left. {}\times e^{i((k_1\cos\theta+k_2\sin\theta) 2^{-j} -
 (l_1\cos\theta+l_2\sin\theta) 2^{-i}) w} \times{}\right.
\\[3pt]
{}\times \widehat{\psi}(2^{-j}w\cos\theta)
\widehat{\psi}(2^{-j}w\sin\theta) \times{}\\
\left.{}\times \overline{ \widehat{\psi}(2^{-i}w\cos\theta)
\widehat{\psi}(2^{-i}w\sin\theta)} |w|^{-(1-\alpha)} \,d w d\theta
\vphantom{\fr{1}{2\pi}}\right\vert={}
\end{multline*}

\vspace*{-2pt}

\noindent
(сделаем замену $w' = 2^{-i} w$ и~перейдем от полярных координат к~декартовым:
$w_1 \hm= w \cos\theta$, $w_2 \hm= w\sin\theta$)
%
\begin{multline*}
=\left\vert \fr{1}{2\pi}\, 2^{(1-\alpha)J}\cdot 2^{i\alpha-\Delta}\times{}\right.\\
{}\times \int\!\! \int
e^{i((k_1 2^{-\Delta} - l_1) w_1+(k_2 2^{-\Delta} - l_2) w_2 )} \times{}
\\
{}\times \left\vert w_1^2 +w_2^2\right\vert^{(1+\alpha)/2} \widehat{\psi}(2^{-\Delta}w_1)
 \widehat{\psi}(2^{-\Delta}w_2) \times{}\\
\left. {}\times\overline{ \widehat{\psi}(w_1) \widehat{\psi}(w_2)}\,  d w_1 d w_2
\vphantom{\fr{1}{2\pi}}\right\vert \leq{}
\end{multline*}


\vspace*{-2pt}

\noindent
(воспользуемся следующим свойством вейвлетов Мейера~[5]: при любом натуральном~$M_0$
существует константа $C_{M_0}\hm>0$ такая, что  $|\widehat{\psi}(w)|\hm\leq
C_{M_0}|w|^{M_0}\textbf{1}_{w\in \mathrm{supp}\left(\widehat{\psi}\right)}$)

\noindent
\begin{multline*}
\leq\left\vert \fr{C^2_{M_0}}{2\pi}\,
2^{(1-\alpha)J}\cdot 2^{i\alpha-\Delta}\times{}\right.\\
{}\times \int\limits_{\mathrm{supp}\left(\widehat{\psi}\right)}
\int\limits_{\mathrm{supp}\left(\widehat{\psi}\right)}
e^{i((k_1 2^{-\Delta} - l_1) w_1+(k_2 2^{-\Delta} - l_2) w_2 )} \times{}\\
{}\times |w_1^2 +w_2^2|^{(1+\alpha)/{2}}\cdot
2^{-2\Delta M_0}(w_1 w_2)^{M_0} \times{}\\
\left.{}\times\overline{ \widehat{\psi}(w_1)
\widehat{\psi}(w_2)} \, d w_1 d w_2
\vphantom{\fr{C^2_{M_0}}{2\pi}}\right\vert\leq{}\\
\end{multline*}

\vspace*{-14pt}

\noindent
(предположим, что выбранный вейвлет Мейера имеет достаточное число
непрерывных производных, чтобы функция $g(w_1,w_2) \hm=
|w_1^2\hm +w_2^2|^{({1+\alpha})/2} \times$\linebreak
$\times 2^{-2\Delta M_0}(w_1 w_2)^{M_0}
\overline{ \widehat{\psi}(w_1) \widehat{\psi}(w_2)}$ имела $M_1$
непрерывных производных по~$w_1$ и~$w_2$, и~воспользуемся свойствами
обратного преобразования Фурье)

\noindent
\begin{multline*}
\leq 2^{(1-\alpha)J} \cdot 2^{i\alpha}\cdot 2^{-(1+2M_0)\Delta}\times{}\\
{}\times
\fr{C''}{\left\vert k_1\cdot 2^{-\Delta} - l_1\right\vert^{M_1}
\left\vert k_2\cdot 2^{-\Delta} - l_2\right\vert^{M_1}}
\end{multline*}
с некоторой константой $C''\hm>0$.


Отдельно выделим случай $k_1 \cdot2^{-\Delta}\hm=l_1$ и~$k_2 \times$\linebreak
$\times 2^{-\Delta}\hm=l_2$.
Можно показать, что в~этом случае
\begin{equation*}
\left\vert\cov\left(X_{j,k_1,k_2}^{[\lambda]},X_{i,l_1,l_2}^{[\lambda]}\right)\right\vert
\leq C_e\cdot 2^{J(1-\alpha) + i\alpha -(2M_0+1)\Delta}
\end{equation*}



\noindent
с некоторой константой $C_e\hm>0$. Аналогично рассматриваются случаи, когда
$k_1 \cdot2^{-\Delta}\hm=l_1$ и~$k_2 \cdot2^{-\Delta}\hm=l_2$ 
выполнены не одновременно.
Варианты других комбинаций $(\lambda_1 ,\lambda_2)$ рассматриваются аналогично.


Обозначим $M' = -(2M_1-2M_0-1)$ и~выберем~$M_0$ так, что $M'\hm>0$.

Тогда

\noindent
\begin{multline}
\left\vert \cov\left(X_{j,k_1,k_2}^{[\lambda]},X_{i,l_1,l_2}^{[\lambda]}\right)\right\vert
\leq{}\\
\hspace*{-1mm}{}\leq
\begin{cases}
        C'\cdot 2^{J(1-\alpha) + i\alpha -(2M_0+1)\Delta} &
        \hspace*{-13mm}\mbox{ при }k_1\cdot 2^{-\Delta}=l_1, \\
        &\hspace*{-5.3mm} k_2\cdot 2^{-\Delta}=l_2\,;\\
        C' \fr{2^{(1-\alpha)J+i\alpha-M'\Delta}}
        {\left\vert k_2 - 2^{\Delta} l_2\right\vert^{M_1}} & \hspace*{-13mm}\mbox{ при } k_1 \cdot2^{-\Delta}=l_1\,;\\[11pt]
        C' \fr{2^{(1-\alpha)J+i\alpha-M'\Delta}}
        {\left\vert k_1 - 2^{\Delta} l_1\right\vert^{M_1}} & \hspace*{-13mm}\mbox{ при } k_2 \cdot2^{-\Delta}=l_2\,;\\[11pt]
        C' \fr{2^{(1-\alpha)J+i\alpha-M'\Delta}}
        {\left\vert k_1 - 2^{\Delta} l_1\right\vert^{M_1}
        \left\vert k_2 - 2^{\Delta} l_2\right\vert^{M_1}} & \mbox{ иначе}
    \end{cases}\!\!\!\!
    \label{Cov_Decay11}
\end{multline}

\vspace*{-3pt}

\noindent
с некоторой константой $C'\hm>0$.

Дисперсия для коэффициентов модели имеет вид:
\begin{equation}
\label{Var_Model}
\sigma_{\lambda,j}^2=C_{\lambda,\alpha} \cdot 2^{(1-\alpha)J}\cdot 2^{j\alpha}\,,
\end{equation}
где константа $C_{\lambda,\alpha}$ зависит от параметра~$\alpha$
и~выбранного вейв\-лет-ба\-зиса.

\vspace*{-6pt}

\section{Пороговая обработка и~оценка риска}

\vspace*{-1pt}

Смысл пороговой обработки коэффициентов вейв\-лет-вейг\-лет-раз\-ло\-же\-ния
заключается в~удалении достаточно маленьких коэффициентов, которые считаются шумом.
Будем рассматривать так называемую мягкую пороговую обработку с~порогом
$T_{\lambda,j}$, зависящим от уровня~$j$. К~каждому
коэффи\-ци\-енту применяется функция
$\rho_{T_{\lambda,j}}(x)\hm=\mathrm{sgn}\left(x\right)\left(\abs{x}\hm -
T_{\lambda,j}\right)_{+}$, т.\,е.\ при такой пороговой обработ\-ке
коэффициенты, которые по модулю меньше порога $T_{\lambda,j}$,
обнуляются, а~абсолютные величины остальных коэффициентов
уменьшаются на величину порога. Погрешность (или риск) мягкой
пороговой обработки определяется следующим образом:

\vspace*{-2pt}

\noindent
\begin{multline}
\label{Risk_def}
R_J(f) = \sum\limits_{j = 0}^{J - 1}\sum_{k_1=0}^{2^j-1}\sum\limits_{k_2=0}^{2^j-1}
\sum\limits_{\lambda=1}^3 \Expect\left(\mu_{j,k_1,k_2}^{[\lambda]} -{}\right.\\
\left.{}-
\rho_{T_{\lambda,j}}\left(X_{j,k_1,k_2}^{[\lambda]}\right)\right)^2.
\end{multline}

В~[6] предложено использовать порог $T_{\lambda,j} \hm= \sqrt{2\ln 2^{2j}}
\sigma_{\lambda,j}$, названный универсальным.
В~дальнейшем будет использоваться именно такой вид\linebreak\vspace*{-12pt}

\columnbreak

\noindent
 порога.
В~выражении~(\ref{Risk_def}) присутствуют неизвестные величины
$\mu_{j,k_1,k_2}^{[\lambda]}$, поэтому вычислить значение $R_J(f)$ нельзя.
Однако его можно оценить. В~качестве оценки риска используется следующая величина~[4]:
\begin{multline}
\label{risk_Est}
\widehat{R}_J (f) = {}\\
{}=\sum\limits_{j=0}^{J-1} \sum\limits_{k_1=0}^{2^j-1}
\sum\limits_{k_2=0}^{2^j-1} \sum\limits_{\lambda=1}^3 F\left[
\left(X_{j,k_1,k_2}^{[\lambda]}
\right)^2,T_{\lambda,j},\sigma_{\lambda,j}\right]\,,
\end{multline}
где
$F(x,T,\sigma) = (x - \sigma^2)\mathbf{1}_{|x|\leq T} \hm+
\left(\sigma^2\hm + T^2\right)\mathbf{1}_{|x|>T}.
$
Величина $\widehat{R}_J(f)$ является несмещенной оценкой для $R_J(f)$~[4].
В~работе~[1] исследовались асимптотические свойства оценки~(\ref{risk_Est})
в~модели с~независимым шумом.
Было показано, что при определенных условиях гладкости эта
оценка является состоятельной и~асимптотически нормальной.
Далее будет исследовано асимптотическое поведение оценки~(\ref{risk_Est})
в~модели данных с~долгосрочной зависимостью, рассматриваемой в~данной работе.

\vspace*{-5pt}

\section{Вспомогательные результаты}

\vspace*{-2pt}

Введем следующее обозначение для последовательностей: $a_J\hm\simeq b_J$,
если $\lim\limits_{J\rightarrow \infty} ({a_J}/{b_J})\hm = 1$.

\vspace*{3pt}

\noindent
\textbf{Лемма~1.}
\textit{Для любых $0<\alpha<1$ и~$\gamma>(1+\alpha)^{-1}$ выполняется
$D_J^2 \hm= \Variance \widehat{R}_J(f)\hm \simeq  \tilde{C}\cdot2^{4J}$,
где константа~$\tilde{C}$ зависит от~$\alpha$ и~выбранного вейвлет-базиса,
но не зависит от функции сигнала}~$f$.

\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \ Поскольку
$\gamma > {1}/(1+\alpha)$, то ${1}/(1+\gamma)\hm<(1\hm+\alpha)/(2\hm+\alpha)$.
Выберем~$p''$ так, что ${1}/(1+\gamma)\hm < p'' \hm<
(1\hm+\alpha)/(2\hm+\alpha)$ и~$p''J$~--- целое число.
Тогда в~силу~\eqref{Coeff_Decay} $\mu_{j,k_1,k_2}^{[\lambda]}\hm\to 0$
для всех~$j$: $p''J\hm\leq j\hm< J$ при $J\hm\to \infty$.
Разобьем выражение~\eqref{risk_Est} на две суммы:

\noindent
\begin{multline*}
\widehat{R}_J (f) ={}\\
{}= \sum\limits_{j=0}^{p''J} \sum\limits_{k_1=0}^{2^j-1}
\sum\limits_{k_2=0}^{2^j-1}
\sum\limits_{\lambda=1}^3 F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},
\sigma_{\lambda,j}\right] +{}\\
{}+
 \sum\limits_{j=p''J+1}^{J-1} \sum\limits_{k_1=0}^{2^j-1}
 \sum\limits_{k_2=0}^{2^j-1} \sum\limits_{\lambda=1}^3
 F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},\sigma_{\lambda,j}\right].
\end{multline*}
%
Поскольку существует константа $C_F \hm> 0$ такая, что
$F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},\sigma_{\lambda,j}\right] \hm
\leq C_F  j \cdot2^{(1-\alpha)J}\cdot2^{j\alpha}$, то для первой суммы имеем:

\noindent
\begin{multline*}
\abs{\sum_{j=0}^{p''J} \sum_{k_1=0}^{2^j-1}\sum_{k_2=0}^{2^j-1}
\sum_{\lambda=1}^3 F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},
\sigma_{\lambda,j}\right]}
\leq {}\\
{}\leq C_F\sum_{j=0}^{p''J}
\sum_{k_1=0}^{2^j-1}
\sum_{k_2=0}^{2^j-1}
\sum_{\lambda=1}^3 j \cdot2^{(1-\alpha)J}\cdot2^{j\alpha} \leq{}
\end{multline*}

\end{multicols}



\noindent
\begin{equation}
\label{Large_Coeff_Order}
\hspace*{10mm}{}\leq C_F\cdot 2^{(1-\alpha)J}
\sum_{j=0}^{p''J}
\sum_{\lambda=1}^3 j\cdot 2^{j(2+\alpha)}
\leq C'_F  J\cdot 2^{J(1 - \alpha + (\alpha + 2) p'')}
\end{equation}
с некоторой константой $C'_F\hm > 0$. Далее,
\begin{multline}                                                                        \label{Var_Struct}
\Variance \widehat{R}_J(f)
= \sum\limits_{j = 0}^{J - 1} \sum\limits_{k_1 = 0}^{2^j - 1}
\sum\limits_{k_2 = 0}^{2^j - 1} \sum\limits_{\lambda=1}^3
\Variance F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},\sigma_{\lambda,j}\right]+{}\\
{}+ \sum\limits_{i = 0}^{J - 1} \sum\limits_{l_1 = 0}^{2^i - 1}
\sum\limits_{l_2 = 0}^{2^i - 1} \sum\limits_{\lambda_1=1}^3
\sum\limits_{j = 0}^{J - 1}\sum\limits_{k_1 = 0}^{2^j - 1}
\sum\limits_{k_2 = 0}^{2^j - 1}\sum\limits_{\lambda_2=1}^3\!
\cov\left(F\left[\left(X_{i,l_1,l_2}^{[\lambda_1]}\right)^2,
T_{\lambda_1,i},
\sigma_{\lambda_1,i}\right], F\left[\left(X_{j,k_1,k_2}^{[\lambda_2]}\right)^2,
T_{\lambda_2,j},\sigma_{\lambda_2,j}\right]\right)\,,
\end{multline}
где во второй сумме предполагается, что $(\lambda_1,i,l_1,l_2)\hm\neq(\lambda_2,j,k_1,k_2)$.

Сумму дисперсий разобьем на две суммы:
\begin{equation*}
\sum\limits_{j = 0}^{p''J} \sum\limits_{k_1 = 0}^{2^j - 1}
\sum\limits_{k_2 = 0}^{2^j - 1}
\sum\limits_{\lambda=1}^3 \Variance F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},\sigma_{\lambda,j}\right]+
\sum\limits_{j = p''J + 1}^{J-1} \sum\limits_{k_1 = 0}^{2^j - 1}
\sum\limits_{k_2 = 0}^{2^j - 1}
\sum\limits_{\lambda=1}^3 \Variance F
\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},\sigma_{\lambda,j}\right].
\end{equation*}
Поскольку $p''<(1+\alpha)/(2+\alpha)$, из~\eqref{Large_Coeff_Order}
следует, что первая сумма имеет меньший порядок, чем вторая. Для второй
в~силу выбора порога и~(\ref{Var_Model}) справедливо
\noindent
\begin{multline*}
\sum\limits_{j = p''J + 1}^{J - 1} \sum\limits_{k_1 = 0}^{2^j - 1}
\sum\limits_{k_2 = 0}^{2^j - 1} \sum_{\lambda=1}^3 \Variance
F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_j,\sigma_j\right]
\simeq \sum\limits_{j = p''J + 1}^{J - 1} \sum\limits_{k_1 = 0}^{2^j - 1}
\sum\limits_{k_2 = 0}^{2^j - 1}
\sum\limits_{\lambda=1}^3 \Variance \left(X_{j,k_1,k_2}^{[\lambda]}\right)^2={}
\\
{}=
\sum_{j = p''J + 1}^{J - 1} \sum_{k_1 = 0}^{2^j - 1}
\sum_{k_2 = 0}^{2^j - 1} C_1 \cdot2\sigma_j^2\left(\sigma_j^2 +\mu^2_{j,k_1,k_2}\right)
\simeq\sum\limits_{j = p''J + 1}^{J - 1} \sum\limits_{k_1 = 0}^{2^j - 1}
\sum\limits_{k_2 = 0}^{2^j - 1} 2C_1 \sigma_j^4
\simeq C'_\alpha \cdot2^{4J}\,,
\end{multline*}
где $C_1$ и~$C'_\alpha$~--- некоторые положительные константы.
%
Далее перейдем к~сумме ковариаций в~(\ref{Var_Struct}).
Аналогично сумме дисперсий имеем:
\begin{multline*}
\hspace*{-2.5mm}\sum\limits_{i = 0}^{J - 1} \sum\limits_{l_1 = 0}^{2^i - 1}
\sum\limits_{l_2 = 0}^{2^i - 1} \sum\limits_{\lambda_1=1}^3
\sum\limits_{j = 0}^{J - 1}\sum\limits_{k_1 = 0}^{2^j - 1}
\sum\limits_{k_2 = 0}^{2^j - 1}\sum\limits_{\lambda_2=1}^3\!\!
\cov\!\left(\!F\!\left[\left(X_{i,l_1,l_2}^{[\lambda_1]}\right)^2,
T_{\lambda_1,i},\sigma_{\lambda_1,i}
\vphantom{(X_{i,l_1,l_2}^{[\lambda_1]})^2}\right],
F\left[\left(X_{j,k_1,k_2}^{[\lambda_2]}\right)^2,T_{\lambda_2,j},\sigma_{\lambda_2,j}\right]\right)
\simeq {}\\
{}\simeq \sum\limits_{i = p''J + 1}^{J - 1} \sum\limits_{l_1 = 0}^{2^i - 1} \sum_{l_2 = 0}^{2^i - 1} \sum_{\lambda_1=1}^3\sum_{j = p''J + 1}^{J - 1}\sum_{k_1 = 0}^{2^j - 1} \sum_{k_2 = 0}^{2^j - 1}\sum_{\lambda_2=1}^3
\cov\left(\left(X_{i,l_1,l_2}^{[\lambda_1]}\right)^2,
\left(X_{j,k_1,k_2}^{[\lambda_2]}\right)^2\right)\,.
\end{multline*}
Известно, что $\cov\left(X^2,Y^2\right) \hm= 4\Expect X\Expect Y \cov\left(X, Y\right) + 2
\cov^2 \left(X, Y\right)$, если вектор $(X,Y)$ имеет двумерное нормальное распределение.
Так же, как в~работе~[7], можно показать, что асимптотика первого
слагаемого меньше второго, а для второго в~силу~(\ref{Cov_Decay11}) справедливо
\begin{multline*}
\fr{1}{2} \sum\limits_{i = p''J + 1}^{J - 1}
\sum\limits_{l_1 = 0}^{2^i - 1} \sum\limits_{l_2 = 0}^{2^i - 1}
\sum\limits_{\lambda_1=1}^3 \sum\limits_{j = p''J + 1}^{J - 1}
\sum\limits_{k_1 = 0}^{2^j - 1} \sum\limits_{k_2 = 0}^{2^j - 1}
\sum\limits_{\lambda_2=1}^3
\cov^2\left(X_{i,l_1,l_2}^{[\lambda_1]}, X_{j,k_1,k_2}^{[\lambda_2]}\right)=
{}\\
{}=\sum\limits_{\lambda_1=1}^3\sum\limits_{\lambda_2=1}^3
\sum\limits_{i = p''J + 1}^{J - 1} \sum\limits_{l_1 = 0}^{2^i - 1}
\sum\limits_{l_2 = 0}^{2^i - 1} \sum\limits_{\Delta = 0}^{J - 1 - i}
{\sum\limits^{2^{i+\Delta} - 1}_{k_1 = %\protect\tiny
\left\{
\begin{array}{ll} %\begin{cases}
{\scriptstyle l_1 + 1}, & {\scriptstyle \Delta = 0;} \\
{\scriptstyle 0,} & {\scriptstyle \Delta > 0.}
\end{array}\right.
%\end{cases}
}}
{\sum\limits^{2^{i+\Delta} - 1}_{k_2 =  %{ %\protect\tiny
\left\{  %\begin{cases}
\begin{array}{ll}
{\scriptstyle l_2 + 1,} & {\scriptstyle \Delta = 0;} \\
{\scriptstyle 0,} & {\scriptstyle \Delta > 0.}
\end{array}
\right.
%\end{cases}
} }
\cov^2\left(X_{i,l_1,l_2}^{[\lambda_1]},
X_{j,k_1,k_2}^{[\lambda_2]}\right) \leq{}\\
{}\leq \sum\limits_{i = p''J + 1}^{J - 1} \sum\limits_{l_1 = 0}^{2^i - 1}
\sum\limits_{l_2 = 0}^{2^i - 1}
\left(\sum\limits_{\delta_1 = 1}^{2^i - l_1} \sum\limits_{\delta_2 = 1}^{2^i - l_2}
\fr{ C'^2 \cdot2^{2J(1-\alpha)}2^{2i\alpha}}{\delta_1^{2M_1}\, \delta_2^{2M_1}} +{}
\right.\\
\left.{}+ \sum\limits_{\Delta = 1}^{J-i-1}\sum\limits_{k_1 = 0}^{2^{i+\Delta} - 1}
\sum\limits_{k_2 = 0}^{2^{i+\Delta} - 1}
2^{2J(1-\alpha)}\cdot 2^{2i\alpha}\cdot 2^{-2M'\Delta}
\fr{C'^2\mathbf{1}(k_1 \neq 2^{\Delta} l_1,k_2 \neq 2^{\Delta} l_2)}
{\left\vert k_1 - 2^{\Delta} l_1\right\vert^{2M_1}\left\vert k_2 - 2^{\Delta} l_2\right\vert^{2M_1}} \right) ={}
\end{multline*}

\noindent
\begin{multline*}
{}= C'^2 \cdot2^{2J(1-\alpha)} \sum\limits_{i = p''J + 1}^{J - 1}
2^{2i\alpha}\sum\limits_{l_1 = 0}^{2^i - 1} \sum\limits_{l_2 = 0}^{2^i - 1}
\left( \sum\limits_{\delta_1 = 1}^{2^i - l_1}
\fr{1}{\delta_1^{2M_1}}\sum\limits_{\delta_2 = 1}^{2^i - l_2} \fr{1}
{\delta_2^{2M_1}} +{}\right.\\
\left.{}+ \sum\limits_{\Delta = 1}^{J-i-1}\sum\limits_{k_1 = 0}^{2^{i+\Delta} - 1}
\sum\limits_{k_2 = 0}^{2^{i+\Delta} - 1} 2^{-2M'\Delta}
\fr{\mathbf{1}(k_1 \neq 2^{\Delta} l_1,k_2 \neq 2^{\Delta} l_2)}
{\left\vert k_1 - 2^{\Delta} l_1\right\vert^{2M_1} \left\vert k_2 - 2^{\Delta} l_2
\right\vert^{2M_1}} \right) \simeq{}
\\
{}\simeq C'^2 \cdot2^{2J(1-\alpha)} \!\sum\limits_{i = p''J + 1}^{J - 1} 2^{2i\alpha}
\sum\limits_{l_1 = 0}^{2^i - 1} \sum\limits_{l_2 = 0}^{2^i - 1} \left( H^2_0
+ \sum\limits_{\Delta = 1}^{J-i-1}2^{-2M'\Delta}
\sum\limits_{k_1 = 0}^{2^{i+\Delta} - 1}
\fr{\mathbf{1}\left(k_1 \neq 2^{\Delta} l_1\right)}
{\left\vert k_1 -2^{\Delta}l_1\right\vert^{2M_1}}
\sum\limits_{k_2 = 0}^{2^{i+\Delta} - 1} \fr{\mathbf{1}\left(k_2 \neq 2^{\Delta} l_2\right)}
{\left\vert k_2 -2^{\Delta}l_2\right\vert^{2M_1}} \right)\simeq{}\\
{}\simeq  C'^2 \cdot 2^{2J(1-\alpha)} \sum\limits_{i = p''J + 1}^{J - 1}
2^{2i(\alpha+1)} \left( H_0
+ \sum\limits_{\Delta = 1}^{J-i-1}2^{-2M'\Delta} H_1 \right)
\simeq C'^2\cdot 2^{2J(1-\alpha)}
\sum\limits_{i = p''J + 1}^{J - 1} 2^{2i(\alpha+1)} H_2
\simeq C''_\alpha \cdot 2^{4J},
\end{multline*}

\hrule
\begin{multicols}{2}

\noindent
где $H_0$, $H_1$, $H_2$ и~$C''_\alpha$~--- положительные константы
(в~случае $k_1 2^{-\Delta}\hm=l_1$ или $k_2 2^{-\Delta}\hm=l_2$
в~приведенных выкладках вместо соответствующих слагаемых используется первая,
вторая или третья оценки из~\eqref{Cov_Decay11}).

Объединяя результаты, получаем, что $\Variance \widehat{R}_J(f)\hm\simeq
\tilde{C} 2^{4J}$.
Лемма доказана.

\smallskip

Докажем еще одно свойство эмпирических вейг\-лет-ко\-эф\-фи\-ци\-ен\-тов.
Говорят, что последовательность случайных величин $\{Y_i\}_{i = 1}^\infty$
обладает свойством $\rho$-пе\-ре\-ме\-ши\-ва\-ния, если для функции
%
\begin{equation*}
\rho(m) = \sup\limits_{i,j:|i - j| > m} \abs{\corr\left(Y_i,Y_j\right)}
\end{equation*}
%
справедливо $\rho(m) \hm \to 0$ при $m \hm\to \infty$.

\smallskip

\noindent
\textbf{Лемма~2.}\
\textit{Последовательность
$\left\{F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,\right.\right.$\linebreak
$\left.\left.T_{\lambda,j},
\sigma_{\lambda,j}
\vphantom{\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2}\right]\right\}$, $\lambda\hm=1,2,3, j = 0,\dots, J \hm- 1, k_1 \hm= 1,\dots, 2^j,
k_2 \hm= 1,\dots, 2^j$,
обладает свойством $\rho$-пе\-ре\-ме\-шивания,
причем для некоторой положительной константы~$C_\rho$}
$$
\rho(m) \leq
\begin{cases}
       \fr{C_\rho}{(m+1)^{2M_1}}  \,  & \mbox{ \textit{для элементов}}\\
       &\mbox{\textit{на одном уровне }} (i = j);  \\
      \fr{C_\rho}{2^{(m+1)(2M' +\alpha)}}   \,  & \mbox{ \textit{для элементов}}\\
      &\mbox{\textit{на разных уровнях}}.  \\
\end{cases}
$$

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \  Сначала рассмотрим функцию
$\rho(m)$ для разных коэффициентов $X_{i,l_1,l_2}^{[\lambda]}$ на одном уровне~$i$.

Для некоторой константы $C_\rho \hm> 0$ при $k_1\hm\neq l_1$ и~$k_2\hm\neq l_2$
имеем:
%

\end{multicols}

\hrule

\begin{align}
\rho(m)
&=\sup\limits_{{\begin{smallmatrix}0\leq i\leq J-1,\\
\lambda_1, \lambda_2= 1,2,3, \\
k_1,k_2,l_1,l_2:\left[ \begin{gathered}{\scriptstyle |k_1-l_1|>m,}\\
  {\scriptstyle |k_2-l_2|>m.}\end{gathered} \right.\end{smallmatrix}}}
   \fr{\abs{\cov\left(F\left[\left(X_{i,l_1,l_2}^{[\lambda_1]}\right)^2,
   T_{\lambda_1,i},\sigma_{\lambda_1,i}\right],F\left[\left(X_{i,k_1,k_2}^{[\lambda_2]}\right)^2,
   T_{\lambda_2,i},\sigma_{\lambda_2,i}\right]\right)}}
   {\sqrt{\Variance F\left[\left(X_{i,l_1,l_2}^{[\lambda_1]}\right)^2,
   T_{\lambda_1,i},\sigma_{\lambda_1,i}\right]
   \Variance F\left[\left(X_{i,k_1,k_2}^{[\lambda_2]}\right)^2,T_{\lambda_2,i},
   \sigma_{\lambda_2,i}\right]}}\leq{}\notag\\
&\leq \sup\limits_{{\begin{smallmatrix}0\leq i\leq
J-1,\\k_1,k_2,l_1,l_2:\left[ \begin{gathered}
{\scriptstyle |k_1-l_1|>m,}\\
{\scriptstyle |k_2-l_2|>m.}
\end{gathered} \right.\end{smallmatrix}}}
C_\rho\fr{2^{2J(1-\alpha)}\cdot2^{2i\alpha}\left\vert k_1-l_1\right\vert^{-2M_1}
\left\vert k_2-l_2\right\vert^{-2M_1}}
{\sqrt{\sigma^4_i\sigma^4_i}}\leq{}\notag\\
&{}\leq \sup\limits_{{\begin{smallmatrix}0\leq i\leq J-1,\\
k_1,k_2,l_1,l_2:\left[ \begin{gathered}
{\scriptstyle |k_1-l_1|>m,}\\ {\scriptstyle  |k_2-l_2|>m.}\end{gathered}
\right.\end{smallmatrix}}}
C_\rho \fr{2^{2J(1-\alpha)}\cdot 2^{2i\alpha}\left\vert k_1-l_1\right\vert^{-2M_1}
\left\vert k_2-l_2\right\vert^{-2M_1}}
{2^{2J(1-\alpha)}\cdot 2^{2i\alpha}}\leq{}\notag\\
&{}\leq \sup\limits_{{\begin{smallmatrix}0\leq
i\leq J-1,\\k_1,k_2,l_1,l_2:\left[
\begin{gathered}
{\scriptstyle |k_1-l_1|>m,}\\ {\scriptstyle  |k_2-l_2|>m.}\end{gathered}
\right.\end{smallmatrix}}}
C_\rho\fr{1}{\left\vert k_1-l_1\right\vert^{2M_1}\left\vert k_2-l_2\right\vert^{2M_1}}
\leq \fr{C_\rho}{(m+1)^{2M_1}} \,.
\label{rho_1}
\end{align}
%
Случаи $k_1 = l_1$ или $k_2 = l_2$ рассматриваются аналогично.

\pagebreak

Далее рассмотрим функцию перемешивания для элементов
$$
F\left[\left(X_{i,l_1,l_2}^{[\lambda_1]}\right)^2,T_{\lambda_1,i},
\sigma_{\lambda_1,i}\right],\enskip
F\left[\left(X_{j,k_1,k_2}^{[\lambda_2]}\right)^2,T_{\lambda_2,j},\sigma_{\lambda_2,j}\right]
$$
на разных уровнях $i,j: j\hm>i, j\hm-i\hm=\Delta\hm>0$.
Рассмотрим случай $\left\vert k_{1}2^{-\Delta} \hm\neq l_{1}\right\vert$,
$\left\vert k_{2}2^{-\Delta} \hm\neq l_{2}\right\vert$:

\noindent
\begin{align}
\rho(m)
&=\sup\limits_{{\begin{smallmatrix}j-i=\Delta>m,\\
\lambda_1, \lambda_2= 1,2,3,\\ 0\leq l_1,l_2\leq2^i-1,
0\leq k_1,k_2\leq2^j-1,\\|k_{1}\cdot2^{-\Delta}\neq
l_{1}|,|k_{2}\cdot2^{-\Delta}\neq l_{2}|.\end{smallmatrix}}}
\fr{\abs{\cov\left(F\left[\left(X_{i,l_1,l_2}^{[\lambda_1]}\right)^2,T_{\lambda_1,i},
\sigma_{\lambda_1,i}\right],
F\left[\left(X_{j,k_1,k_2}^{[\lambda_2]}\right)^2,T_{\lambda_2,j},
\sigma_{\lambda_2,j}\right]\right)}}
{\sqrt{\Variance F\left[\left(X_{i,l_1,l_2}^{[\lambda_1]}\right)^2,T_{\lambda_1,i},
\sigma_{\lambda_1,i}\right] \Variance F
\left[\left(X_{j,k_1,k_2}^{[\lambda_2]}\right)^2,
T_{\lambda_2,j},\sigma_{\lambda_2,j}\right]}}\leq{}\notag\\
&{}\leq \sup\limits_{{\begin{smallmatrix}j-i=\Delta>m,\\
0\leq l_1,l_2\leq2^i-1, 0\leq k_1,k_2\leq2^j-1,\\
|k_{1}\cdot2^{-\Delta}\neq l_{1}|,|k_{2}\cdot2^{-\Delta}\neq l_{2}|.
\end{smallmatrix}}} C_\rho\fr{2^{2J(1-\alpha)}\cdot2^{2i\alpha}\cdot2^{-2 M' \Delta}
\left\vert \left(k_1 - 2^{\Delta}l_1\right)^{-2M_1} \left(k_2-
2^{\Delta}l_2\right)^{-2M_2}\right\vert}
{2^{J(1-\alpha)}\cdot 2^{i\alpha}\cdot 2^{J(1-\alpha)}\cdot2^{(i+\Delta)\alpha}}\leq{}\notag\\
&\hspace*{-10mm}{}\leq \sup\limits_{{\begin{smallmatrix}j-i=\Delta>m,\\
0\leq l_1,l_2\leq2^i-1, 0\leq k_1,k_2\leq2^j-1,\\
|k_{1}\cdot2^{-\Delta}\neq l_{1}|,|k_{2}\cdot2^{-\Delta}\neq l_{2}|.
\end{smallmatrix}}} \fr{C_\rho\cdot 2^{-2M'\Delta}}{2^{\Delta\alpha}}
\leq \sup\limits_{{\begin{smallmatrix}
j-i=\Delta>m,\\ 0\leq l_1,l_2\leq2^i-1, 0\leq k_1,k_2\leq2^j-1,\\
|k_{1}\cdot2^{-\Delta}\neq l_{1}|,|k_{2}\cdot2^{-\Delta}\neq l_{2}|.
\end{smallmatrix}}}\fr{C_\rho}{2^{\Delta(2M' +\alpha)}}
=\fr{C_\rho}{2^{(m+1)(2M' +\alpha)}}\,.
\label{rho_2}
\end{align}

\hrule

\vspace*{2pt}

\begin{multicols}{2}

\noindent
Аналогично рассматриваются случаи, когда выполнено хотя бы одно из равенств
 $\left\vert k_{1}\cdot2^{-\Delta} \hm= l_{1}\right\vert$,
 $\left\vert k_{2}\cdot 2^{-\Delta} \hm= l_{2}\right\vert$.

Из~\eqref{rho_1} и~\eqref{rho_2} следует утверждение леммы.

\vspace*{-6pt}


\section{Основная теорема}

Докажем асимптотическую нормальность оценки риска.

\smallskip

\noindent
\textbf{Теорема.}
\textit{Пусть $0\hm<\alpha<1$ и~функция~$f$ равномерно регулярна по Липшицу
с~параметром $\gamma\hm>(1\hm+\alpha)^{-1}$. Тогда при пороговой обработке
с~универсальным порогом $T_{\lambda,j}$ имеет место сходимость по распределению}:
\begin{equation}
\label{asnorm}
\fr{\widehat{R}_J(f) - R_J(f)}{ D_J } \Rightarrow \textbf{N}(0,1)\,, \enskip
J \rightarrow \infty\,,
\end{equation}
\textit{где $D_J^2 = \tilde{C} 2^{4J}$, а~константа $\tilde{C}$
зависит от~$\alpha$ и~выбранного вейв\-лет-ба\-зиса}.

\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \
Из леммы~1 следует, что $\Variance \widehat{R}_J(f)\hm\simeq D_J^2
\hm = \tilde{C}\cdot 2^{4J}$.
Разобьем выражение в~(\ref{asnorm}) на две суммы, как и~в лемме~1:


\noindent
\begin{multline*}
\fr{\widehat{R}_J(f) - R_J(f)}{ D_J } ={}\\
{}=\fr{1}{D_j}\left(
\sum\limits_{j = 0}^{p''J}\sum\limits_{k_1 = 0}^{2^j - 1}
\sum\limits_{k_2 = 0}^{2^j - 1}\sum\limits_{\lambda = 1}^{3}
\left(F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,\right.\right.\right.
\\
\left.\left.\left.T_{\lambda,j},
\sigma_{\lambda,j}
\vphantom{\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2}
\right] -
\Expect F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},\sigma_{\lambda,j}
\right]
\right)\!
\vphantom{\sum\limits_{j = 0}^{p''J}\sum\limits_{k_1 = 0}^{2^j - 1}}
\right) +{}
\end{multline*}

\noindent
\begin{multline*}
{}+\fr{1}{D_j}\left( \sum\limits_{j = p''J+1}^{J-1}\sum\limits_{k_1 = 0}^{2^j - 1}
\sum\limits_{k_2 = 0}^{2^j - 1}\sum\limits_{\lambda = 1}^{3}
\left(F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,\right.\right.\right.\\[1pt]
\left.\left.\left.T_{\lambda,j},\sigma_{\lambda,j}
\vphantom{\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2}
\right] -
 \Expect
F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},\sigma_{\lambda,j}
\right]\right)\!
\vphantom{\sum\limits_{j = 0}^{p''J}\sum\limits_{k_1 = 0}^{2^j - 1}}
\right)\,,
\end{multline*}
где ${1}/(1+\gamma) < p'' <(1+\alpha)/(2+\alpha)$. Тогда
вследствие~(\ref{Large_Coeff_Order}) первая сумма стремится к~нулю
п.~в.

Из леммы~2 следует, что последовательность
$\left\{F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},\sigma_{\lambda,j}\right]\right\}$,
$\lambda\hm=1,2,3$, $j \hm= 0,\dots, J \hm- 1$, $k_1 \hm= 1,\dots, 2^j$, $k_1 \hm=
1,\dots, 2^j$, обладает свойством $\rho$-пе\-ре\-ме\-ши\-ва\-ния
и,~следовательно, обладает свойством
$\alpha$-пе\-ре\-ме\-ши\-ва\-ния~[8].

Далее, действуя, как в~лемме~1, можно показать, что

\noindent
\begin{multline*}
\sup\limits_{J > 0} \fr{1}{D^2_J}
\sum\limits_{j = p''J + 1}^{J - 1}
\sum\limits_{k_1 = 0}^{2^j - 1} \sum\limits_{k_2 = 0}^{2^j - 1}
\sum\limits_{\lambda = 1}^{3} \Expect
\left( F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,\right.\right.\\[1pt]
\left.\left.T_{\lambda,j},\sigma_{\lambda,j}
\vphantom{\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2}\right]
-
\Expect  F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},
\sigma_{\lambda,j}\right]\right)^2
= {}
\\[1pt]
{}=\sup\limits_{J > 0} \fr{1}{D^2_J}\sum\limits_{j = p''J + 1}^{J - 1}
\sum\limits_{k_1 = 0}^{2^j - 1} \sum\limits_{k_2 = 0}^{2^j - 1}
\sum\limits_{\lambda = 1}^{3} \Variance
F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,\right.\\[1pt]
\left.T_{\lambda,j},\sigma_{\lambda,j}
\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2\right]
\leq \sup\limits_{J > 0} \fr{\tilde{C}'_\alpha \cdot2^{4J}}{\hat{C}\cdot 2^{4J}}
\leq \infty\,.
\end{multline*}
%

Также можно показать, что выполнено условие Линдеберга:
для любого $\epsilon \hm> 0$

\noindent
\begin{multline}
\label{Norm_Cond2}
\fr{1}{D^2_J} \sum\limits_{j = p''J + 1}^{J - 1}
\sum\limits_{k_1=0}^{2^j - 1}\sum\limits_{k_2=0}^{2^j - 1}
\sum\limits_{\lambda = 1}^{3} \Expect
\left( \!F\!\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2\!\!,\right.\right.\\
\left.\left.T_{\lambda,j},\sigma_{\lambda,j}
\vphantom{\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2}
\right] -\Expect F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,
T_{\lambda,j},\sigma_{\lambda,j}\right]\right)^2\;\times\\
{}\times\mathbf{1}
\left( \left\vert F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,
T_{\lambda,j},\sigma_{\lambda,j}\right] -{}\right.\right.\\
\left.\left.{}-
\Expect  F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,T_{\lambda,j},\sigma_{\lambda,j}\right]\right\vert
> \epsilon D_J\right) \rightarrow 0\,,\\ J\rightarrow\infty.
\end{multline}


Действительно, поскольку
\begin{multline*}
\hspace*{-6pt}\left\vert F\left[\left(X_{j,k_1,k_2}^{[\lambda]}\right)^2,
T_{\lambda,j},\sigma_{\lambda,j}\right]\right\vert
\leq T_{\lambda,j}^2 =2\ln2^{2j}\sigma^2_{\lambda,j}
= {}\\
{}=\tilde{C}_{\lambda,\alpha} j\cdot 2^{J(1-\alpha)}\cdot 2^{j\alpha}
\end{multline*}
с~некоторой константой $\tilde{C}_{\lambda,\alpha}\hm>0$
и~$D_J^2 \hm\simeq \hat{C} \cdot2^{4J}$, то начиная с~некоторого~$J$ все
индикаторы в~(\ref{Norm_Cond2}) обращаются в~ноль.

Таким образом, выполнены все условия теоремы~2.1 из работы~[9]
и~справедлива сходимость по распределению~(\ref{asnorm}). Теорема доказана.



{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9}


\bibitem{1-ero}
\Au{Маркин А.\,В., Шестаков О.\,В.} Асимптотики оценки риска
при пороговой обработке вейв\-лет-вейг\-лет коэффициентов в~задаче
томографии~// Информатика и~её применения, 2010. Т.~4. Вып.~2.
С.~36--45.

\bibitem{2-ero}
\Au{Donoho D.} Nonlinear solution of linear inverse problems
by wavelet-vaguelette decomposition~// Appl. Comput.
Harmon. Anal., 1995. Vol.~2. P.~101--126.

\bibitem{3-ero}
\Au{Добеши И.} Десять лекций по вейвлетам~/
Пер. с англ.~--- Ижевск: НИЦ
Регулярная и~хаотическая динамика, 2001. 357~с.
(\Au{Daubechies~I.} Ten lectures on wavelets.
CBMF-NSF regional
conference ser. in applied mathematics. SIAM, 1992. 369~p.)

\bibitem{4-ero}
\Au{Mallat S.} A~wavelet tour of signal processing.~---
Academic Press, 1999. 662~p.

\bibitem{5-ero}
\Au{Johnstone I.\,M., Silverman~B.\,W.} Wavelet threshold
estimates for data with correlated noise~// J.~Roy. Stat. Soc.
 B, 1997. Vol.~59. P.~319--351.

\bibitem{6-ero}
\Au{Kolaczyk E.\,D.} Wavelet methods for the inversion of
certain homogeneous linear operators in the presence of noisy data.~---
Stanford: Stanford University, 1994. Ph.D. Dissertation. 163~p.

\bibitem{7-ero}
\Au{Ерошенко А.\,А., Шестаков~О.\,В.} Асимптотические свойства
оценки риска при пороговой обработке вейв\-лет-ко\-эф\-фи\-ци\-ен\-тов в~модели
с~коррелированным шумом~// Информатика и~её применения, 2014. Т.~8.
Вып.~1. С.~36--44.

\bibitem{8-ero}
\Au{Bradley R.\,C.} Basic properties of strong mixing
conditions. A~survey and some open questions~// Probab. Surveys,
2005. Vol.~2. P.~107--144.

\bibitem{9-ero}
\Au{Peligrad M.} On the asymptotic normality of sequences of
weak dependent random variables~// J.~Theor. Probab., 1996. Vol.~9.
No.~3. P.~703--715.
 \end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-9pt}

\hfill{\small\textit{Поступила в редакцию 29.09.14}}

%\newpage

\vspace*{12pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{12pt}

\def\tit{ASYMPTOTIC PROPERTIES OF~RISK ESTIMATE IN~THE~PROBLEM
OF~RECONSTRUCTING IMAGES WITH CORRELATED NOISE BY~INVERTING THE~RADON TRANSFORM}

\def\titkol{Asymptotic properties of risk estimate in~the~problem
of~reconstructing images} % with correlated noise by~inverting the Radon transform}

\def\aut{A.\,A.~Eroshenko$^1$ and~O.\,V.~Shestakov$^{1,2}$}

\def\autkol{A.\,A.~Eroshenko and~O.\,V.~Shestakov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-9pt}

\noindent
$^1$Faculty of Computational Mathematics and Cybernetics,
M.\,V.~Lomonosov Moscow State University,
1-52~Lenin-\linebreak
$\hphantom{^1}$skiye Gory, GSP-1, Moscow 119991, Russian Federation

\noindent
$^2$Institute of Informatics Problems, Russian Academy of Sciences,
44-2~Vavilov Str., Moscow 119333, Russian\linebreak
$\hphantom{^1}$Federation


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2014\ \ \ volume~8\ \ \ issue\ 4}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2014\ \ \ volume~8\ \ \ issue\ 4
\hfill \textbf{\thepage}}}

\vspace*{3pt}


\Abste{In recent years, wavelet methods based on the decomposition
of projections in a special basis and the following thresholding
procedure became widely used for solving the problems of tomographic
image reconstruction. These methods are easily implemented through
fast algorithms; so, they are very appealing in practical situations.
Besides, they allow the reconstruction of local parts of the images using
incomplete projection data, which is essential, for example, for medical
applications, where it is not desirable to expose the patient to the redundant
radiation dose. Wavelet thresholding risk analysis is an important practical
task, because it allows determining the quality of techniques themselves and
the equipment which is used. The present paper considers\linebreak\vspace*{-12pt}}

\Abstend{the problem of
estimating the function by inverting the Radon transform in the model of
data with correlated noise. The asymptotic properties of mean-square risk
estimate of wavelet-vaguelette thresholding technique are studied. The conditions
under which the unbiased risk estimate is asymptotically normal are given.}

\KWE{wavelets; linear homogeneous operator; Radon transform;
thresholding; unbiased risk estimate;
correlated noise; asymptotic normality}


\DOI{10.14357/19922264140404}

\vspace*{-3pt}

\Ack
\noindent
The research was financially supported by the Russian Science Foundation (project
14-11-00364).

%\vspace*{3pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}



{\small\frenchspacing
 { %\baselineskip=10pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9}



\bibitem{1-ero-1}
\Aue{Markin, A.\,V., and O.\,V.~Shestakov}. 2010.
Asimptotiki otsen\-ki riska pri porogovoy obrabotke veyvlet-veyglet
koeffitsientov v~zadache tomografii
[Asymptotic properties of risk estimate for wavelet-vaguelette coefficients
thresholding in  tomographic reconstruction problem].
\textit{Informatika i ee Primeneniya}~--- \textit{Inform. Appl.} 4(2):36--45.

%\vspace*{-3pt}

\bibitem{2-ero-1}
\Aue{Donoho, D.} 1995. Nonlinear solution of linear inverse problems
by wavelet-vaguelette decomposition.
\textit{Appl. Comput. Harmon. Anal.}  2:101--126.

%\vspace*{-3pt}

\bibitem{3-ero-1}
\Aue{Daubechies, I.} 1992.\textit{Ten lectures on wavelets.}
CBMF-NSF regional
conference ser. in applied mathematics.
SIAM. 369~p.

%\vspace*{-3pt}

\bibitem{4-ero-1}
\Aue{Mallat, S.}  1999.
\textit{A~wavelet tour of signal processing.} Academic Press. 662~p.

\bibitem{5-ero-1}
\Aue{Johnstone, I.\,M., and B.\,W.~Silverman}. 1997.
Wavelet threshold estimates for data with correlated noise.
\textit{J.~Roy. Stat. Soc. B}  59:319--351.

\bibitem{6-ero-1}
\Aue{Kolaczyk, E.\,D.} 1994. Wavelet
methods for the inversion of certain homogeneous linear operators in
the presence of noisy data.  Stanford: Stanford University. Ph.D. Thesis. 163~p.

\smallskip

\bibitem{7-ero-1}
\Aue{Eroshenko, A.\,A., and O.\,V.~Shestakov}. 2014.
Asimptoticheskie svoystva otsenki riska pri porogovoy obra-\linebreak botke
veyvlet-koeffitsientov v~modeli s~korrelirovannym\linebreak shumom
[Asymptotic properties of wavelet thresholding risk estimate in
the model of data with correlated noise].
\textit{Informatika i ee Primeneniya}~--- \textit{Inform. Appl.} 8(1):\linebreak 36--44.

\smallskip

\bibitem{8-ero-1}
\Aue{Bradley, R.\,C.} 2005.
Basic properties of strong mixing conditions.
A~survey and some open questions. \textit{Probab. Surveys}  2:107--144.

\smallskip

\bibitem{9-ero-1}
\Aue{Peligrad, M.} 1996.
On the asymptotic normality of sequences of weak dependent random variables.
\textit{J.~Theor. Probab.} 9(3):703--715.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received September 29, 2014}}

\vspace*{-18pt}

\Contr

\noindent
\textbf{Eroshenko Alexander A.} (b.\ 1989)~---
PhD student, Department of Mathematical Statistics,
Faculty of Computational Mathematics and Cybernetics,
M.\,V.~Lomonosov Moscow State University,
1-52  Leninskiye Gory, GSP-1, Moscow 119991, Russian Federation;
aeroshik@gmail.com

\vspace*{3pt}

\noindent
\textbf{Shestakov Oleg V.} (b.\ 1976)~---
Doctor of Science in physics and mathematics, associate professor,
%Department of Mathematical Statistics,
Faculty of Computational Mathematics and Cybernetics,
M.\,V.~Lomonosov Moscow State University,
1-52  Leninskiye Gory, GSP-1, Moscow 119991, Russian Federation;
senior scientist, Institute of Informatics Problems, Russian Academy of Sciences,
44-2 Vavilov Str., Moscow 119333, Russian Federation;
oshestakov@cs.msu.su

\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература}