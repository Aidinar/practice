\def\stat{chubich}

\def\tit{ИНФОРМАЦИОННАЯ ТЕХНОЛОГИЯ АКТИВНОЙ  ПАРАМЕТРИЧЕСКОЙ ИДЕНТИФИКАЦИИ
СТОХАСТИЧЕСКИХ КВАЗИЛИНЕЙНЫХ ДИСКРЕТНЫХ  СИСТЕМ$^*$}

\def\titkol{Информационная технология активной  параметрической идентификации
%стохастических квазилинейных дискретных  систем
}

\def\autkol{В.\,М.~Чубич}
\def\aut{В.\,М.~Чубич$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
{Работа выполнена  при поддержке Федерального агентства по образованию в рамках ФЦП
<<Научные и на\-уч\-но-пе\-да\-го\-ги\-че\-ские кадры инновационной России>> на
  2009--2013~гг.\ (гос. контракт №\,П2365 от 18.11.2009~г.).}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Новосибирский государственный технический университет, chubich\_62@ngs.ru}


\vspace*{6pt}

  \Abst{Впервые рассмотрены теоретические и прикладные аспекты проблемы активной
па\-ра\-мет\-ри\-че\-ской идентификации гауссовских нелинейных дискретных сис\-тем. Рассмотрен
случай вхождения подлежащих оцениванию параметров в уравнения состояния и
наблюдения, начальные условия и ковариационные матрицы помех динамики и ошибок
измерений. Приведены оригинальные результаты. Рассмотрен пример оптимального
оценивания параметров одной модельной структуры.}

\vspace*{2pt}

  \KW{оценивание параметров; метод максимального правдоподобия; планирование
оптимальных входных сигналов; информационная матрица Фишера; критерий
оптимальности}

      \vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}

\section{Введение}

  Проблема идентификации~--- одна из основных проблем теории и практики
автоматического управ\-ле\-ния. Результаты решения задачи идентификации могут
использоваться при проектировании различных систем управления
подвижными и технологическими объектами, при построении прогнозирующих
моделей, при конструировании следящих и измерительных систем.

  По способу проведения эксперимента существующие методы идентификации
можно разделить на пассивные и активные. При пассивной идентификации для
построения математической модели используются реально действующие в
системе сигналы и тем самым нормальный режим эксплуатации не нарушается.
Методы пассивной идентификации достаточно полно описаны, например,
  в~[1--3]. Активная идентификация, напротив, предполагает нарушение
технологического режима и подачу на вход изучаемой системы специальным
образом синтезированного сигнала. Его находят в результате решения
экстремальной задачи для некоторого предварительно выбранного
функционала от информационной (или дисперсионной) матрицы вектора
оцениваемых параметров. Трудности, связанные с необходимостью нарушения
технологического режима, окупаются повышением эффективности и
корректности проводимых исследований. Это обусловлено самой идеологией
активной идентификации, базирующейся на сочетании традиционных приемов
параметрического оценивания с концепцией планирования эксперимента [4--7].

  Более определенно процедура активной параметрической идентификации
систем с предварительно выбранной модельной структурой предполагает
выполнение следующих этапов:
  \begin{enumerate}[1.]
\item Вычисление оценок параметров по измерительным данным,
соответствующим выбранному пробному сигналу.
\item Синтез с учетом полученных на первом этапе оценок оптимального в
соответствии с некоторым критерием сигнала.
\item Пересчет оценок неизвестных параметров по измерительным данным,
соответствующим полученному на втором этапе сигналу.
\end{enumerate}

  Целесообразность применения концепции активной идентификации при
построении ма\-те\-ма\-тических моделей стохастических стационарных линейных
дискретных и непрерывно-дискретных\linebreak сис\-тем показана в~[8--10]. Рецензия на
монографию~\cite{10-c} помещена в~\cite{11-c}. В~данной статье приведены
результаты дальнейших исследований автора в рамках указанной проблемы
применительно к стохастическим нелинейным дискретным системам.

\section{Постановка задачи}

  Рассмотрим следующую модель управляемой, наблюдаемой,
идентифицируемой динамической системы в пространстве состояний:

\noindent
  \begin{align}
  x(k+1)&=f[x(k),u(k),k]+\Gamma(k) w(k)\,,
  \label{e1-c}\\
  y(k+1) & =h[x(k+1),k+1]+v(k+1)\,,\notag\\
  &\hspace*{13mm} k=0, 1, \ldots , N-1\,,
  \label{e2-c}
  \end{align}
где $x(k)$~--- $n$-век\-тор состояния; $u(k)$~--- детерминированный
$r$-век\-тор управления (входа); $w(k)$~--- $p$-век\-тор возмущения;
$y(k+1)$~--- $m$-век\-тор измерения (выхода); $v(k+1)$~--- $m$-век\-тор
ошибки измерения.

  Предположим, что век\-тор-функ\-ции $f[x(k),u(k),k]$ и $h[x(k+1),k+1]$
непрерывны и дифференцируемы по~$x(k)$, $u(k)$ и $x(k+1)$ соответственно;
случайные векторы~$w(k)$ и~$v(k+1)$ образуют стационарные белые
гауссовские последовательности, для которых $E[w(k)]=0$,
$E[w(k)w^{\mathrm{T}}(i)]\hm =Q\delta_{ki}$, $E[v(k+1)]=0$, $E[v(k+1)v^{\mathrm{T}} (i+1)] R\delta_{ki}$,
$E[v(k+1) w^{\mathrm{T}}(i)=0$, $k,i=0, 1, \ldots , N-1$ (здесь и далее $E[\cdot]$~--- оператор
математического ожидания, $\delta_{ki}$~--- символ Кронекера); начальное
состояние~$x(0)$ имеет нормальное распределение с параметрами
$E[x(0)]=\overline{x}(0)$, $E\{[x(0)-\overline{x}(0)][x(0)-
\overline{x}(0)]^{\mathrm{T}}\}=P(0)$ и не коррелирует с~$w(k)$ и~$v(k+1)$ при любых
значениях переменной~$k$; неизвестные параметры сведены в вектор $\Theta =
(\theta_1,\theta_2,\ldots , \theta_s)$, включающий в себя элементы
  век\-тор-функ\-ций $f[x(k), u(k),k]$, $h[x(k+1), k+1]$, мат\-риц $\Gamma(k)$,
$Q$, $R$, $P(0)$ и вектора~$\overline{x}(0)$ в различных комбинациях.

  Необходимо для математической модели~(1), (2) с учетом высказанных
априорных предположений разработать процедуру активной параметрической
идентификации и исследовать ее эффективность. В~такой математической
постановке задача рассматривается и решается впервые.

\vspace*{-4pt}

\section{Линеаризация модели}

\vspace*{-2pt}

  Считая значение вектора неизвестных параметров~$\Theta$ фиксированным,
выполним линеаризацию во временной области нелинейной модели~(1), (2)
относительно номинальной траектории $\{x_H(k+1),\ k=0, 1, \ldots , N-1\}$, для
которой
  \begin{equation}
  \left.
  \begin{array}{rl}
  x_H(k+1) & =f[x_H(k), u_H(k),k]\,,\\[3pt]
  &\hspace*{7mm} k=0,1, \ldots , N-1\,;\\[3pt]
  x_H(0) & =\overline{x}(0)\,.
  \end{array}
  \right \}
  \label{e3-c}
  \end{equation}

  Разложив для каждого~$k$ век\-тор-функ\-ции $f[x(k), u(k), k]$ и $h[x(k+1),
k+1]$ в ряды Тейлора в окрестностях точек $[x_H(k), u_H(k)]$ и $x_H(k+1)$
соответственно и отбросив члены второго и более высоких порядков, запишем
уравнения линеаризованной модели

\noindent
  \begin{multline*}
  x(k+1)=f\left[x_H(k),u_H(k),k\right]+{}\\
  {}+\fr{\partial f[x_H(k),u_H(k)k]}{\partial
x(k)}\left[x(k)-x_H(k)\right]+{}\hspace*{5mm}
\end{multline*}
  \begin{multline}
  {}+\fr{\partial f[x_H(k),u_H(k)k]}{\partial u(k)}\left[ u(k)-
u_H(k)\right]+{}\\
{}+\Gamma(k) w(k)\,;
\label{e4-c}
  \end{multline}
  
  \vspace*{-12pt}

  \noindent
  \begin{multline}
  y(k+1) =h\left[x_H(k+1),k+1\right]+{}\\
  {}+
  \fr{\partial h[x_H(k+1),k+1]}{\partial x(k+1)}\left[ x(k+1)-
x_H(k+1)\right]+{}\\
{}+v(k+1)\,,\label{e5-c}
  \end{multline}
для которой и будем решать поставленную задачу. С~учетом обозначений
\begin{multline}
a(k)=f\left[ x_H(k),u_H(k),k\right] -{}\\
{}-\fr{\partial f [x_H(k),u_H(k),k]}{\partial
x(k)}\,x_H(k)+{}\\
{}+\fr{\partial f[x_H(k),u_H(k),k]}{\partial u(k)}\left [ u(k)-u_H(k)\right]\,;
\label{e6-c}
\end{multline}

\vspace*{-8pt}

\noindent
\begin{equation}
\Phi(k)=\fr{\partial f[x_H(k),u_H(k),k]}{\partial x(k)}\,;
\label{e7-c}
\end{equation}

\vspace*{-14pt}

\noindent
\begin{multline}
A(k+1)=h\left[ x_H(k+1),k+1\right]-{}\\
{}-\fr{\partial h [x_H(k+1),k+1]}{\partial
x(k+1)}\,x_H(k+1)\,;
\label{e8-c}
\end{multline}

\vspace*{-8pt}

\noindent
\begin{equation}
H(k+1)=\fr{\partial h[x_H(k+1),k+1]}{\partial x(k+1)}
\label{e9-c}
\end{equation}
соотношения~(4), (5) определяют модель гауссовской линейной
нестационарной системы, описывающейся уравнениями:
\begin{align}
x(k+1) &= a(k)+\Phi(k)x(k)+\Gamma(k) w(k)\,;\label{e10-c}\\[4pt]
y(k+1) &=A(k+1) +H(k+1) x(k+1)+v(k+1)\,,\notag\\
&\hspace*{20mm} k=0, 1, \ldots , N-1\,.\label{e11-c}
\end{align}

  Заметим, что для нелинейностей, имеющих характеристики с угловыми
точками и разрывами, можно воспользоваться методом статистической
линеаризации~\cite{12-c, 13-c}.

\section{Оценивание неизвестных параметров}

  Оценивание неизвестных параметров математической модели
осуществляется по данным наблюдений $\Xi$ в соответствии с критерием
идентификации~$\chi$. Сбор числовых данных происходит в процессе
проведения идентификационных экспериментов, которые выполняются по
некоторому плану~$\xi_v$.

  Предположим, что экспериментатор может произвести $v$ запусков
системы, причем сигнал~$U_1$ он
 подает на вход системы $k_1$~раз, сигнал
$U_2$~--- $k_2$~раз\linebreak\vspace*{-12pt}

\pagebreak

\noindent
 и~т.\,д., наконец, сигнал $U_q$~--- $k_q$~раз. В~этом
случае дискретный (точный) нормированный план эксперимента~$\xi_v$
представляет собой совокупность точек $U_1, U_2, \ldots , U_q$, называемых
спектром плана, и соответствующих им долей повторных запусков:
  $$
  \xi_v=\left \{
  \begin{matrix}
  U_1, U_2, \ldots , U_q\\
  \fr{k_1}{v}, \fr{k_2}{v}, \ldots ,\fr{k_q}{v}
  \end{matrix}
  \right \}\,,
  \enskip U_i\in \Omega_U,\ i=1, 2, \ldots ,q\,.
  $$
Здесь $U_i^{\mathrm{T}}=\{[u^i(0)]^{\mathrm{T}}, [u^i(1)]^{\mathrm{T}}, \ldots , [u^i(N-1)]^{\mathrm{T}}\}$, $i=1, 2, \ldots , q$;
$\Omega_U\subset R^{Nr}$ задает ограничения на условия проведения
эксперимента.

  Обозначим через $Y_{i,j}$ $j$-ю реализацию выходного сигнала ($j=1, 2,
\ldots , k_i$), соответствующую $i$-му\linebreak входному сигналу~$U_i$
  ($i=1, 2, \ldots ,q$). Тогда в результате проведения по плану
$\xi_v$~идентификационных экспериментов будет сформировано множество:
  \begin{multline*}
  \Xi = \left\{ (U_i, Y_{i,j}),\ j=1, 2, \ldots ,
  k_i, \ i=1, 2, \ldots , q\right \}\,,\\
\sum\limits_{i=1}^q k_i=v\,.
  \end{multline*}
Уточним структуру $Y_{i,j}$:
\begin{multline*}
Y_{i,j}^{\mathrm{T}} =\left \{ \left[y^{i,j}(1)\right]^{\mathrm{T}}, \left [y^{i,j}(2)\right]^{\mathrm{T}}, \ldots , \left[
y^{i,j}(N)\right ]^{\mathrm{T}}\right \}\,,\\
j=1, 2,\ldots , k_i\,,\ i=1, 2, \ldots , q\,,
\end{multline*}
и заметим, что в случае пассивной параметрической идентификации, как
правило, $q=v=1$.

  Априорные предположения, высказанные при постановке задачи, и
выполненная линеаризация моделей состояния и наблюдения относительно
опорной траектории~(3) позволяют воспользоваться для оценивания
неизвестных параметров методом максимального правдоподобия (ММП).
В~соответствии с этим методом необходимо найти такие значения параметров
$\hat\Theta $, для которых
  $$
  \hat\Theta  =\mathrm{arg}\,\min_{\Theta\in \Omega_\Theta}\left[ \chi(\Theta,
\Xi)\right] =\mathrm{arg}\,\min_{\Theta\in\Omega_\Theta} \left[-\ln L(\Theta,
\Xi)\right]\,,
  $$
где $\ln L(\Theta, \Xi)$~--- логарифмическая функция правдоподобия.

  Согласно~\cite{14-c, 15-c} в нашем случае критерий идентификации имеет
следующий вид:
  \begin{multline*}
  \chi(\Theta, \Xi) =\fr{Nmv}{2}\,\ln 2\pi+{}\\
  {}+\fr{1}{2}\sum\limits_{i=1}^q
\sum\limits_{j=1}^{k_i}\sum\limits_{k=1}^{N-1}\left [
\varepsilon^{i,j}(k+1)\right]^{\mathrm{T}} \left[B^i(k+1)\right]^{-1}\times{}\\
{}\times \left[
\varepsilon^{i,j}(k+1)\right] +\fr{1}{2}\,\sum\limits_{i=1}^q
k_i\sum\limits_{k=0}^{N-1}\ln \mathrm{det}\, B^i(k+1)\,,
  \end{multline*}
где
$\varepsilon^{i,j}(k+1) =y^{i,j}(k+1)+\hat{y}^{i,j}(k+1\vert k)$,
а $\hat{y}^{i,j}(k+1\vert k)$ и $B^i(k+1)$ определяются по соответствующим
ре-\linebreak\vspace*{-12pt}
\columnbreak

\noindent
куррентным уравнениям дискретного фильтра Калмана (см.,
например,~\cite{16-c}):
\begin{align}
\hat{x}^{i,j}(k+1\vert k) &=\Phi^i(k) \hat{x}^{i,j}(k\vert k)+a^i(k)\,;\notag\\
P^i (k+1\vert k)&={}\notag\\
&\hspace*{-16mm}{}=\Phi^i (k) P^i (k\vert k)[\Phi^i (k) ]^{\mathrm{T}}+
\Gamma(k) Q \Gamma^{\mathrm{T}}(k)\,;\label{e12-c}\\
\hat{y}^{i,j}(k+1\vert k) &={}\notag\\
&\hspace*{-5mm}{}=H^i(k+1) \hat{x}^{i,j}(k+1\vert k)+A^i(k+1)\,;\notag\\
B^i(k+1) &={}\notag\\
&\hspace*{-22mm}{}=H^i(k+1)P^i(k+1\vert k)\left[H^i(k+1)\right]^{\mathrm{T}}+R\,;\label{e13-c}\\
K^i(k+1) & ={}\notag\\
&\hspace*{-22mm}{}= P^i(k+1\vert k) \left[ H^i(k+1)\right]^{\mathrm{T}}\left[B^i(k+1)\right]^{-1}\,;\label{e14-c}\\
\hat{x}^{i,j}(k+1\vert k+1) & ={}\notag\\
&\hspace*{-10mm}{}=\hat{x}^{i,j}(k+1\vert  k)+K^i(k+1)\varepsilon^{i,j}(k+1)\,;\notag\\
P^i(k+1 \vert k+1) &={}\notag\\
&\hspace*{-16mm}{}=\left[ I-K^i(k+1)H^i(k+1)\right] P^i(k+1\vert k)\label{e15-c}
\end{align}
для $k=0, 1, \ldots , N-1$, $j=1, 2, \ldots , k_i$, $i=1, 2, \ldots , q$ с начальными
условиями $\hat{x}^{i,j}(0\vert 0)=\overline{x}(0)$, $P(0\vert 0)\hm=P(0)$.

  Для нахождения условного минимума $\chi(\Theta, \Xi)$ воспользуемся
методом проекции градиента~\cite{17-c, 18-c}, учитывая, что
  \begin{multline*}
  \fr{\partial \chi(\theta)}{\partial \theta_l} = \sum\limits_{i=1}^q
\sum\limits_{j=1}^{k_i}\sum\limits_{k=0}^{N-1} \left[ \fr{\partial
\varepsilon^{i,j}(k+1)}{\partial\theta_l}\right]^{\mathrm{T}} \times{}\\
{}\times \left[ B^i(k+1)\right ]^{-
1}\left[\varepsilon^{i,j}(k+1)\right]-{}\\
  {}- \fr{1}{2}\sum\limits_{i=1}^q
\sum\limits_{j=1}^{k_i}\sum\limits_{k=0}^{N-1} \left[
\varepsilon^{i,j}(k+1)\right]^{\mathrm{T}} \left[B^i(k+1)\right]^{-1}\times{}\\
{}\times
\fr{\partial
B^i(k+1)}{\partial\theta_l}\left[ B^i(k+1)\right]^{-1}\varepsilon^{i,j}(k+1)+{}\\
  {}+\fr{1}{2}\,\sum\limits_{i=1}^q k_i \sum\limits_{k=0}^{N-1} Sp \left[\left[
B^i(k+1)\right]^{-1}\fr{\partial B^i(k+1)}{\partial\theta_l}\right]\,,\\
 l=1, 2, \ldots ,s\,.
  \end{multline*}
  
\vspace*{-8pt}

\section{Планирование оптимальных входных сигналов}

\vspace*{-2pt}

     Оптимальный выбор входных сигналов позволяет экспериментатору при
заданном чис\-ле запусков системы подготовить наиболее информативные
данные наблюдений, использующиеся для на\-хож\-де\-ния оценок неизвестных
параметров. Отметим, что свобода в выборе входных характеристик
суще-\linebreak\vspace*{-12pt}
\pagebreak

\noindent
ственно различается в зависимости от приложений. В~экономических и
экологических системах у экспериментатора нет возможности воздействовать
на систему с целью проведения идентификационных экспериментов, в то время
как в лабораторных условиях и на стадиях разработки нового оборудования
выбор входных величин имеет лишь амплитудные и мощностные ограничения.

  Предварим рассмотрение алгоритмов синтеза оптимальных входных
сигналов изложением некоторых основополагающих понятий и результатов
теории планирования эксперимента для нашего случая.

  Под непрерывным нормированным планом~$\xi$ условимся понимать
совокупность величин:
  \begin{multline}
  \xi =
    \left \{
  \begin{matrix}
  U_1, U_2, \ldots , U_q\\[3pt]
  p_1, p_2, \ldots , p_q
  \end{matrix}
  \right \}\,, \enskip p_i\geq 0\,,\enskip
  \sum\limits_{i=1}^q p_i=1\,,\\
  U_i\in \Omega_U\,,\enskip   i=1, 2, \ldots , q\,.
    \label{e16-c}
\end{multline}
Здесь $U_i^{\mathrm{T}}=\{[u^i(0)]^{\mathrm{T}}, [u^i(1)]^{\mathrm{T}}, \ldots , [u^i(N-1)]^{\mathrm{T}}\}$, $i=1, 2, \ldots ,q$,
по аналогии с дискретным планом~$\xi_v$, но веса~$p_i$ могут принимать
любые значения в диапазоне от~0 до~1, в том числе и иррациональные.
Множество планирования~$\Omega_U$ определяется ограничениями на
условия проведения эксперимента.

  Для плана~(\ref{e16-c}) нормированная информационная матрица~$M(\xi)$
определяется соотношением:
  \begin{equation}
  M(\xi)=\sum\limits_{i=1}^q p_i M(U_i;\theta)\,,\label{e17-c}
  \end{equation}
в котором информационные матрицы Фишера (ИМФ) одноточечных планов
$$
M(U;\theta)=- \underset{Y}{E} \left [ \fr{\partial^2\ln L(\Theta,
\Xi)}{\partial\theta\partial\theta^{\mathrm{T}}}\right]
$$
зависят от неизвестных параметров~$\Theta$, что позволяет в дальнейшем
говорить только о локально-оп\-ти\-маль\-ном планировании. В~\cite{19-c}
приводятся выражение и алгоритм вычисления информационных матриц
Фишера $M(U;\Theta)$ для модели~(\ref{e10-c}), (\ref{e11-c}).

  В~разд.~4 были рассмотрены вопросы, связанные с оцениванием
неизвестных параметров мо\-делей стохастических нелинейных дискретных
сис\-тем. Качество оценивания параметров можно\linebreak повысить за счет построения
плана эксперимента, оптимизирующего некоторый выпуклый функционал~$X$
от информационной матрицы $M(\xi)$, решив экстремальную задачу
  \begin{equation}
  \xi^* =\mathrm{arg}\,\min_{\xi\in\Omega_\xi} X[M(\xi)]\,.
  \label{e18-c}
  \end{equation}
Для критерия $D$-оп\-ти\-маль\-ности $X[M(\xi)] =$\linebreak
$=-\ln\,\mathrm{det}\,M(\xi)$,
для критерия $A$-оп\-ти\-маль\-ности $X[M(\xi)]\hm =-Sp M^{-1}(\xi)$.

  Планирование эксперимента определенным образом воздействует на
нижнюю границу неравенства Рао--Кра\-ме\-ра~\cite{20-c}: для
  $D$-оп\-ти\-маль\-но\-го плана минимизируется объем, для
  $A$-оп\-ти\-маль\-ного плана~--- сумма квадратов длин осей эллипсоида
рассеяния оценок параметров.

\vspace*{-6pt}

\section{Алгоритмы численного построения оптимальных планов}

\vspace*{-3pt}

  В соответствии с~\cite{21-c} экстремальная задача поиска минимума
$X[M(\xi)]$ может быть сведена к конечномерной задаче с размерностью
пространства варьируемых переменных не более чем $(Nr+1)(s(s+1)/2+1)$. Ее
решение можно осуществить с помощью общих методов численного поиска
экстремума. При этом возможны два подхода. 
Первый из них (прямой)
предполагает поиск минимума функционала $X[M(\xi)]$ в про\-стран\-ст\-ве
элементов информационной матрицы при ограни-\linebreak чениях $M\in\Omega_M$, где
$\Omega_M=\{M(\xi)\vert \xi\in\Omega_\xi\}$~--- мно-\linebreak жество информационных
матриц. Характерной осо\-бен\-ностью этого подхода является большая
размерность экстремальной задачи. Поскольку $X[M(\xi)]$~--- выпуклый
функционал, здесь имеет мес\-то задача выпуклого программирования, для
решения которой предлагается следующий алгоритм.

\vspace*{-4pt}

\subsection{Прямая градиентная процедура построения непрерывных
оптимальных планов}

\smallskip

\textbf{Шаг~1.} Зададим начальный невырожденный план:

\noindent
\begin{multline*}
\xi_0=\left \{
\begin{matrix}
U_1^0, U_2^0, \ldots , U_q^0,\\[3pt]
p_1^0, p_2^0, \ldots , p_q^0
\end{matrix}
\right \}\,,\ U_i^0\in \Omega_U\,,\
p_i^0=\fr{1}{q}\,,\\ i=1, 2, \ldots ,q\,,
\end{multline*}
в котором $q=s(s+1)/2+1$. Вычислим информационные матрицы $M(U_i^0)$
одноточечных планов для $i=1, 2, \ldots , q$ и по формуле~(\ref{e17-c})
информационную матрицу всего плана~$\xi_0$. Положим $l=0$.

\smallskip

\textbf{Шаг~2.} Считая веса $p_1^l, p_2^l, \ldots , p_q^l$ фиксированными, решим
задачу
$$
X[M(\xi_1)]\rightarrow \min_{U_1^l, \ldots , U_q^l}\,, U_i^l\in \Omega_U\,,\
i=1, 2, \ldots , q\,,
$$
методом проекции градиента:
$$
\tilde{U}^{l+1}=\pi_{\Omega_{\tilde{U}}}\left\{ \tilde{U}^l-\rho_l^\prime
\nabla_{\tilde{U}} X[M(\xi_l)]\right \}\,,
$$


\noindent
где $\tilde{U^{\mathrm{T}}}=(U_1^{\mathrm{T}}, U_2^{\mathrm{T}}, \ldots , U_q^{\mathrm{T}})$;
$\pi_{\Omega_{\tilde{U}}}\{\cdot\}$~--- проекция точ\-ки\footnote{Для сигналов,
ограниченных по мощности или по амплитуде, когда $\Omega_{\tilde{U}}$~---
соответственно координатный шар или параллелепипед, известны явные выражения для
проекции~\cite{18-c}.} на множество $\Omega_{\tilde{U}}$; $\rho_l^\prime \geq
0$~--- длина шага.

  Далее составим план:
  $$
  \tilde{\xi}_l=\left \{
  \begin{matrix}
  U_1^{l+1}, U_2^{l+1}, \ldots , U_q^{l+1}\\[3pt]
  p_1^l, p_2^l, \ldots , p_q^l
  \end{matrix}
  \right \}\,,
  $$
где $U_i^{l+1}$~--- точки, найденные на шаге~2. 

Вычислим $M(U_i^{l+1})$, $i=1, 2, \ldots ,q$.

  \smallskip

\textbf{Шаг~3.} Зафиксировав точки спектра полученного плана, решим задачу
\begin{multline*}
  X[M(\tilde{\xi}_l)] \rightarrow \min_{p_1^l, p_2^l, \ldots , p_q^l}\,\enskip
\sum\limits_{i=1}^q p_i^l=1\,,\ p_i^l\geq 0\,,\\ i=1, 2, \ldots ,q\,,
\end{multline*}
методом проекции градиента Розена~\cite{17-c}:
$$
\tilde{p}^{l+1} =\tilde{p}^l-\rho_l^{\prime\prime} P\nabla_{\tilde{p}}
X[M(\tilde{\xi}_l)]\,,
$$
где $\tilde{p}=(p_1, p_2, \ldots , p_q)$, $\rho_l^{\prime\prime}\geq 0$~--- длина
шага, $P$~--- мат\-ри\-ца оператора проектирования. Составим план:
$$
\xi_{l+1}=\left \{
\begin{matrix}
U_1^{l+1}, U_2^{l+1}, \ldots , U_q^{l+1}\\[3pt]
p_1^{l+1}, p_2^{l+1}, \ldots ,  p_q^{l+1}
\end{matrix}
\right \}\,.
$$

  \smallskip

\textbf{Шаг~4.} Если выполняется неравенство
  $$
  \sum\limits^q_{i=1}\left[ \Vert U_i^{l+1}-U_i^l\Vert^2+\left( p_i^{l+1}-
p_i^l\right)^2\right]\leq \delta\,,
  $$
где $\delta$~--- малое положительное число, перейдем к шагу~5. В~противном
случае для $l=l+1$ повторим шаги~2 и~3.

  \smallskip

\textbf{Шаг~5.} Проверим необходимое условие оптимальности плана:
  $$
  \left\vert \mu \left( U_i^{l+1},\xi_{l+1}\right) -\eta\right\vert \leq \delta\,,\enskip
i=1,2, \ldots , q\,.
  $$
Если оно выполняется, закончим процесс. В~противном случае повторим все
сначала, скорректировав начальное приближение~$\xi_0$.

  Значения параметров $X[M(\xi)]$, $\mu(U,\xi)$, $\eta$ прямой градиентной
процедуры для критериев $D$- и $A$-оп\-ти\-маль\-ности определяем по
табл.~1.

  \noindent
\begin{center} %tabl1
\parbox{80mm}{{\tablename~1}\ \ \small{Соответствие значений параметров $X[M(\xi)]$, $\mu(U,\xi)$ и $\eta$
  критериям оптимальности}}
%\begin{center} %fig1

\vspace*{2ex}
\tabcolsep=4.3pt
{\small
\begin{tabular}{|c|c|c|c|}
  \hline
\tabcolsep=0pt\begin{tabular}{c}Кри-\\ терий\end{tabular}&$X[M(\xi)]$ &$\mu(U,\xi)$ &$\eta$\\
\hline
&&&\\[-8pt]
$D$ &$-\ln\,\mathrm{det}\,M(\xi)$ &$Sp[M^{-1}(\xi)M(U)]$&$s$\\
$A$ &$SpM^{-1}(\xi)$ &$Sp[M^{-2}(\xi)M(U)]$ &$SpM^{-1}(\xi)$ \\
\hline
\end{tabular}
}
\end{center}
%\vspace*{12pt}
%\begin{center}
%\end{center}
\vspace*{9pt}

\smallskip
\addtocounter{table}{1}


Приведенный алгоритм требует вычисления градиентов
\begin{align*}
\nabla_{\tilde{U}} X[M(\xi)]&=\left\Vert \fr{\partial X[M(\xi)]}{\partial
u_j^{(i)}(t)}\right\Vert\,,\enskip i=1, \ldots ,q\,,\\
&\hspace*{12mm}t=0, \ldots , N-1\,,\enskip j=1, \ldots ,r\,;\\
\nabla_{\tilde{p}} X[M(\xi)] &=\left\Vert \fr{\partial X [M(\xi)]}{\partial
p_i}\right\Vert\,,\enskip i=1, \ldots ,q\,.
\end{align*}

  Начнем с критерия $D$-оп\-ти\-маль\-ности. Для него получаем
  \begin{multline*}
  \fr{\partial X[M(\xi)]}{\partial u_j^{(i)}(t)}=\fr{\partial [-
\ln\,\mathrm{det}\,M(\xi)]}{\partial u_j^{(i)}(t)}={}\\
{}=
  -Sp\left[ M^{-1}(\xi)\fr{\partial M(\xi)}{\partial u_j^{(i)}(t)}\right] ={}\\
  {}=-p_i
Sp\left[M^{-1}(\xi)\fr{\partial M(U_i;\theta)}{\partial u_j^{(i)}(t)}\right]\,,\\
  i=1, \ldots ,q\,,\ t=0, \ldots , N-1\,,\ j=1, \ldots ,r\,.
  \end{multline*}
Для вычисления производных
$$
\fr{\partial M(U;\theta)}{\partial u_j(t)}=
\left\Vert \fr{\partial M_{\alpha\beta}(U;\theta)}{\partial u_j(t)}\right\Vert\,,\enskip
\alpha, \beta=1, \ldots , s\,,
$$
воспользуемся тем, что ИМФ можно представить в виде суммы двух слагаемых,
одно из которых зависит от входного сигнала, а другое~--- нет (данный факт
вытекает из материалов~\cite{19-c}):
$$
M_{\alpha\beta}(U;\Theta)=W_{\alpha\beta}(U;\Theta)+V_{\alpha\beta}(\Theta)\,.
$$

\noindent
Здесь

\end{multicols}

\hrule


\begin{multline*}
W_{\alpha\beta}(U;\Theta)=
\sum\limits_{k=0}^{N-1}\left \{
Sp\left [
\fr{\partial H(k+1)}{\partial
\theta_\alpha}\,C_0\overline{x}_A(k+1)\overline{x}_A^{\mathrm{T}}(k+1)C_0^{\mathrm{T}}\fr{\partial
H^{\mathrm{T}}(k+1)}{\partial \theta_\beta}\,B^{-1}(k+1)\right ]+{}\right.\\
{}+Sp\left[\fr{\partial H(k+1)}{\partial\theta_\alpha}\,C_0\overline{x}_A(k+1)
\overline{x}_A^{\mathrm{T}}(k+1)C_{\beta}^{\mathrm{T}} H^{\mathrm{T}}(k+1) B^{-1}(k+1)\right]+{}
\end{multline*}

\noindent
\begin{multline*}
{}+ Sp\left[\fr{\partial
H(k+1)}{\partial\theta_\alpha}\,C_0\overline{x}_A(k+1)\fr{\partial
A^{\mathrm{T}}(k+1)}{\partial\theta_\beta} B^{-1}(k+1)\right]+{}\\
{}+
Sp\left[H(k+1)C_\alpha\overline{x}_A(k+1)\overline{x}_A^{\mathrm{T}}(k+1)C_0^{\mathrm{T}}\fr{\partial
H^{\mathrm{T}}(k+1)}{\partial\theta_\beta} B^{-1}(k+1)\right]+{}\\
{}+Sp\left[ H(k+1)C_\alpha\overline{x}_A(k+1)\overline{x}_A^{\mathrm{T}}(k+1) C_\beta^{\mathrm{T}}
H^{\mathrm{T}}(k+1) B^{-1}(k+1)\right]+{}\\
{}+Sp\left[ H(k+1)C_\alpha \overline{x}_A(k+1)\fr{\partial
A^{\mathrm{T}}(k+1)}{\partial\theta_\beta}\,B^{-1}(k+1)\right]+{}\\
{}+Sp\left[ \fr{\partial
A(k+1)}{\partial\theta_\alpha}\,\overline{x}_A^{\mathrm{T}}(k+1)C_0^{\mathrm{T}}\fr{\partial
H^{\mathrm{T}}(k+1)}{\partial \theta_\beta}\,B^{-1}(k+1)\right]+{}\\
\left.{}+ Sp\left[ \fr{\partial
A(k+1)}{\partial\theta_\alpha}\,\overline{x}_A^{\mathrm{T}}(k+1)C_\beta^{\mathrm{T}} H^{\mathrm{T}} (k+1) B^{-1}(k+1)
\right]\right\}\,,\ \alpha,\beta=1, 2, \ldots , s\,.
\end{multline*}
 В соответствии с указанным разложением получаем, что
  \begin{multline}
  \fr{\partial M_{\alpha\beta}(U;\Theta)}{\partial u_j(t)}=\fr{\partial
W_{\alpha\beta}(U;\Theta)}{\partial u_j(t)}={}\\
  {}=\sum\limits_{k=0}^{N-1}\!\left \{\!Sp\left[\fr{\partial
H(k+1)}{\partial\theta_\alpha}\,C_0\left(\fr{\partial\overline{x}_A(k+1)}{\partial
u_j(t)}\,\overline{x}_A^{\mathrm{T}}(k+1)+\overline{x}_A(k+1)\fr{\partial\overline{x}_A^{\mathrm{T}}(k
+1)}{\partial u_j(t)}\right) C_0^{\mathrm{T}}\fr{\partial H^{\mathrm{T}}(k+1)}{\partial\theta_\beta}\,B^{-
1}(k+1)\right]+{}\right.\\
  {}+Sp\left[\fr{\partial
H(k+1)}{\partial\theta_\alpha}\,C_0\left(\fr{\partial\overline{x}_A(k+1)}{\partial
u_j(t)}\,\overline{x}_A^{\mathrm{T}}(k+1)+\overline{x}_A(k+1\vert
k)\fr{\partial\overline{x}_A^{\mathrm{T}}(k+1)}{\partial u_j(t)}\right)C_\beta^{\mathrm{T}} H^{\mathrm{T}}(k+1)B^{-
1}(k+1)\right]+{}\\
  {}+Sp\left[\fr{\partial
H(k+1)}{\partial\theta_\alpha}\,C_0\fr{\partial\overline{x}_A(k+1)}{\partial
u_j(t)}\,\fr{\partial A^{\mathrm{T}}(k+1)}{\partial\theta_\beta}\,B^{-1}(k+1)\right]+{}\\
  {}+ Sp\left[ H(k+1) C_\alpha\left( \fr{\partial\overline{x}_A(k+1)}{\partial
u_j(t)}\,\overline{x}_A^{\mathrm{T}}(k+1)+\overline{x}_A(k+1)\fr{\partial
\overline{x}^{\mathrm{T}}_A(k+1)}{\partial u_j(t)}\right) C_0^{\mathrm{T}}\fr{\partial
H^{\mathrm{T}}(k+1)}{\partial\theta_\beta}\,B^{-1}(k+1)\right]+{}\\
  {}+ Sp\left[ H(k+1)C_\alpha \left( \fr{\partial \overline{x}_A(k+1)}{\partial
u_j(t)}\,\overline{x}_A^{\mathrm{T}}(k+1)+\overline{x}_A(k+1)\fr{\partial\overline{x}_A^{\mathrm{T}}(k
+1)}{\partial u_j(t)}\right)C_\beta^{\mathrm{T}} H^{\mathrm{T}}(k+1) B^{-1}(k+1)\right]+{}\\
  {}+ Sp\left[ H(k+1) C_\alpha \fr{\partial\overline{x}_A(k+1)}{\partial
u_j(t)}\,\fr{\partial A^{\mathrm{T}}(k+1)}{\partial\theta_\beta}\,B^{-1}(k+1)\right]+{}\\
  {}+ Sp\left[ \fr{\partial
A(k+1)}{\partial\theta_\alpha}\,\fr{\partial\overline{x}_A^{\mathrm{T}}(k+1)}{\partial
u_j(t)}\,C_0^{\mathrm{T}}\fr{\partial H^{\mathrm{T}}(k+1)}{\partial\theta_\beta}\,B^{-1}(k+1)\right]+{}\\
  \left.{}+Sp\left[ \fr{\partial
A(k+1)}{\partial\theta_\alpha}\,\fr{\partial\overline{x}_A^{\mathrm{T}}(k+1)}{\partial
u_j(t)}\,C_\beta^{\mathrm{T}} H^{\mathrm{T}}(k+1)B^{-1}(k+1)\right]\right\}\,.
  \label{e19-c}
  \end{multline}
  

  Алгоритм вычисления производных от ИМФ по компонентам входного
сигнала $\partial M(U;\Theta)/\partial u_j(t)$ для заданных значений $U,\Theta$
при фиксированных $j,t$ может быть следующим\footnote{Приводится здесь
впервые. Разработан на основе материалов~\cite{19-c}.}:

\textbf{Шаг~1.} Задать $Q$, $R$, $\overline{x}(0)$, $P(0)$,
$\{\partial\overline{x}(0)/\partial\theta_i$, $i\hm=1, 2, \ldots , s\}$.

\textbf{Шаг~2.} Положить $\partial M(U;\Theta)/\partial u_j(t)=0$; $k=0$;
$x_H(k)=\overline{x}(0)$; $\partial
x_H(k)/\partial\theta_i=\partial\overline{x}(0)/\partial\theta_i$, $i=1, 2, \ldots , s$;
$P(k\vert k)=P(0)$.

%\columnbreak

\textbf{Шаг~3.} Определив $u_H(k)$, найти $a(k)$ по формуле~(\ref{e6-c}) и
$\{\partial a(k)/\partial\theta_i, \ i=1, 2, \ldots ,s\}$ по формуле:
  \begin{multline*}
  \fr{\partial a(k)}{\partial\theta_i}=\fr{\partial
f[x_H(k),u_H(k),k]}{\partial\theta_i}-
\fr{\partial^2 f[x_H(k),
u_H(k),k]}{\partial\theta_i\partial x(k)}\,x_H(k)
-\fr{\partial f[x_H(k), u_H(k),k]}{\partial x(k)}\,\fr{\partial
x_H(k)}{\partial\theta_i}+{}\\
{}+\fr{\partial^2 f[x_H(k), u_H(k), k]}{\partial\theta_i \partial
u(k)}\left[ u(k)-u_H(k)\right]\,.
  \end{multline*}
  
 % \pagebreak
При помощи выражения~(\ref{e7-c}) получить $\Phi(k)$ и
$\{\partial\Phi(k)/\partial\theta_i,\ i=1, 2, \ldots ,s\}$.

\textbf{Шаг~4.} Если $k=0$, вычислить:
  $$
  \overline{x}_A(k+1)=
  \begin{bmatrix}
  \Phi(0)\overline{x}(0)+a(0)\\[3pt]
  \fr{\partial\Phi(0)}{\partial\theta_1}\,\overline{x}(0)+\Phi(0)\fr{\partial\overline{x}(
0)}{\partial\theta_1}+\fr{\partial a(0)}{\partial\theta_1}\\[3pt]
  \ldots\\[3pt]
  \fr{\partial\Phi(0)}{\partial\theta_s}\,\overline{x}(0)+\Phi(0)\fr{\partial\overline{x
}(0)}{\partial\theta_s}+\fr{\partial a(0)}{\partial\theta_s}
  \end{bmatrix}
  $$
и перейти к шагу~8.

\textbf{Шаг~5.} Найти $\tilde{K}(k)$ по формуле:
  $$
  \tilde{K}(k)=\Phi(k) K(k)\,.
  $$

\textbf{Шаг~6.} Сформировать матрицы $\Phi_A(k)$, $a_A(k)$ в соответствии с
равенствами:
  $$
  \Phi_A(k) =
  \begin{bmatrix}
  \Phi(k) & 0 & \ldots & 0\\[3pt]
  \fr{\partial\Phi(k)}{\partial\theta_1} -\tilde{K}(k)\fr{\partial
H(k)}{\partial\theta_1} & \Phi(k)-\tilde{K}(k)H(k) &\ldots & 0\\[3pt]
  \ldots &\ldots &\ldots &\ldots\\[3pt]
  \fr{\partial\Phi(k)}{\partial\theta_s}-\tilde{K}(k)\fr{\partial H(k)}{\partial
\theta_s} & 0 &\ldots & \Phi(k)-\tilde{K}(k)H(k)
  \end{bmatrix}\,;
  $$
  $$
  a_A(k)=
  \begin{bmatrix}
  a(k)\\[3pt]
  \fr{\partial a(k)}{\partial\theta_1}-\tilde{K}(k)\fr{\partial A(k)}{\partial\theta_1}\\[3pt]
  \ldots\\[3pt]
  \fr{\partial a(k)}{\partial\theta_s}-\tilde{K}(k)\fr{\partial A(k)}{\partial\theta_s}
  \end{bmatrix}\,.
  $$
  
  \vspace*{6pt}
  
    \hrule
  
  \smallskip

  \begin{multicols}{2}
  
 

  \textbf{Шаг~7.} Вычислить $\overline{x}_A(k+1)$ по формуле:
  $$
  \overline{x}_A(k+1)=\Phi_A(k)\overline{x}_A(k)+a_A(k)\,.
  $$

\textbf{Шаг 8.} Найти $x_H(k+1)$ и $\{\partial x_H(k+1)/\partial\theta_i$,\ $i=1, 2, \ldots ,
s\}$ при помощи выражения~(\ref{e3-c}).
Вы\-чис\-лить $\{\partial A(k+1)/\partial\theta_i, \ i=1, 2, \ldots ,s\}$,
воспользовавшись равенством~(\ref{e8-c}). Определить $H(k+1)$ по
формуле~(\ref{e9-c}) и $\{\partial H(k+1)/\partial\theta_i,\ i=1, 2, \ldots , s\}$.

\smallskip
\textbf{Шаг~9.} Сформировать матрицу~$\Gamma(k)$ и найти $P(k+1\vert k)$,
$B(k+1)$, $K(k+1)$, $P(k+1\vert k+1)$, используя
  выражения~(\ref{e12-c})--(\ref{e15-c}).

\smallskip
\textbf{Шаг~10.} Определить $\partial a(k)/\partial u_j(t)$ и $\{\partial^2
a(k)/(\partial\theta_i \partial u_j(t))$, $i=1, 2, \ldots ,s\}$ по формулам:
  \begin{align*}
  \fr{\partial a(k)}{\partial u_j(t)} &=\fr{\partial f [x_H(k),u_H(k),k]}{\partial
u(k)}\,\fr{\partial u(k)}{\partial u_j(t)}\,;\\[6pt]
  \fr{\partial^2 a(k)}{\partial\theta_i\partial u_j(t)} &=\fr{\partial^2 f[x_H(k),
u_H(k),k]}{\partial\theta_i \partial u(k)}\,\fr{\partial u(k)}{\partial u_j(t)}\,.
  \end{align*}
  \columnbreak

\textbf{Шаг 11.} Если $k=0$, вычислить $\partial\overline{x}_A(k+1)/\partial u_j(t)$ по
  формуле:
    $$
  \fr{\partial\overline{x}_A(k+1)}{\partial u_j(t)} =
  \begin{cases}
    \begin{bmatrix}
  \fr{\partial a(0)}{\partial u_j(t)}\\[3pt]
  \fr{\partial^2 a(0)}{\partial\theta_1 \partial u_j(t)}\\[3pt]
  \ldots\\[3pt]
  \fr{\partial^2 a(0)}{\partial\theta_s\partial u_j(t)}
  \end{bmatrix}\,, & \mbox{если}\ t=0\,;\\[6pt]
  0\,, & \mbox{если}\ t\not=0
  \end{cases}
  $$
и перейти к шагу~14.

\textbf{Шаг~12.} Сформировать вектор $\partial a_A(k)/\partial u_j(t)$ в соответствии с
равенством:
  $$
  \fr{\partial a_A(k)}{\partial u_j(t)}=
  \begin{bmatrix}
  \fr{\partial a(k)}{\partial u_j(t)}\\[3pt]
  \fr{\partial^2 a(k)}{\partial\theta_1 \partial u_j(t)}
  \\[3pt]
  \ldots\\[3pt]
  \fr{\partial^2 a(k)}{\partial\theta_s \partial u_j(t)}
  \end{bmatrix}\,.
  $$
  
  \pagebreak

\textbf{Шаг~13.} Вычислить $\partial\overline{x}_A(k+1)/\partial u_j(t)$ по формуле:
  $$
  \fr{\partial\overline{x}_A(k+1)}{\partial u_j(t)}=
  \begin{cases}
  \Phi_A(k)\fr{\partial\overline{x}_A(k)}{\partial u_j(t)}+\fr{\partial
a_A(k)}{\partial u_j(t)}\,, & t\leq k\,;\\
  0\,, &\hspace*{-30mm} \mbox{в противном случае}\,.
  \end{cases}
  $$

\smallskip
\textbf{Шаг~14.} Используя выражение~(\ref{e19-c}), получить приращение $\Delta
(\partial M(U;\Theta)/\partial u_j(t))$, отвечающее текущему значению~$k$.

\smallskip
\textbf{Шаг 15.} Положить
  $$
  \fr{\partial M(U;\Theta)}{\partial u_j(t)} =\fr{\partial M(U;\Theta)}{\partial
u_j(t)}+\Delta\fr{\partial M(U;\Theta)}{\partial u_j(t)}\,.
  $$

\smallskip
\textbf{Шаг~16.} Увеличить $k$ на единицу. Если $k\leq N-1$, перейти к шагу~3.
В~противном случае закончить процесс.

  \bigskip

  Получить выражение для градиента по весам не составляет особого труда,
поскольку
  \begin{multline*}
  \fr{\partial X[M(\xi)]}{\partial p_i}=\fr{\partial [-\ln\,\mathrm{det}\,M(\xi)]}{\partial p_i}={}\\
{}= -Sp\left[ M^{-1}(\xi)\fr{\partial
M(\xi)}{\partial p_i}\right]={}\\
  {}=-Sp\left[ M^{-1}(\xi) M(U_i;\theta)\right]\,,\ i=1,\ldots ,q\,.
  \end{multline*}

  Перейдем к критерию $A$-оп\-ти\-маль\-ности. В~этом случае
  \begin{multline*}
  \fr{\partial X[M(\xi)]}{\partial u_j^{(i)}(t)}=\fr{\partial [Sp M^{-1}(\xi)]}{\partial
u_j^{(i)}(t)}=
Sp\left[\fr{\partial M^{-1}(\xi)}{\partial u_j^{(i)}(t)}\right]={}\\
  {}=-Sp \left [ M^{-1}(\xi)\fr{\partial M(\xi)}{\partial u_j^{(i)}(t)}\,M^{-1}(\xi)\right]={}\\
  {}= -p_i Sp\left[ M^{-1}(\xi)\fr{\partial M(U_i;\theta)}{\partial
u_j^{(i)}(t)}\, M^{-1}(\xi)\right]={}\\
  {}= -p_i Sp \left [ M^{-2}(\xi)\fr{\partial M(U_i;\theta)}{\partial
u_j^{(i)}(t)}\right ]\,,\\
  i=1, \ldots , q\,, \ t=0, \ldots , N-1\,,\ j=1, \ldots ,r\,;
  \end{multline*}
  
  \vspace*{-6pt}

\noindent
\begin{multline*}
  \fr{\partial X[M(\xi)]}{\partial p_i}=\fr{\partial Sp M^{-1}(\xi)]}{\partial
p_i}=Sp\left[\fr{\partial M^{-1}(\xi)}{\partial p_i}\right]={}\\
{}=-Sp \left [ M^{-1}(\xi)\fr{\partial M(\xi)}{\partial p_i}\,M^{-1}(\xi)\right]={}\\
{}= -Sp\left[ M^{-1}(\xi) M(U_i;\theta) M^{-1}(\xi)\right]={}\\
{}=
-Sp\left[ M^{-2}(\xi) M(U_i;\theta)\right]\,, \enskip i=1, 2, \ldots , q\,.
\end{multline*}

  Другой подход (его называют двойственным) к решению оптимизационной
задачи~(\ref{e18-c}) основан на теореме эквивалентности из~\cite{21-c} и
заключается в минимизации $X[M(\xi)]$ по набору аргументов
$\{U_i,p_i\}_{i=1}^q$ при ограничениях $U_i\in\Omega_U$, $p_i\geq 0$,
$\sum\limits_{i=1}^q p_i=1$. В~этом случае рассматриваемая задача уже не
является задачей выпуклого программирования, но размерность вектора
варьируемых параметров может оказаться значительно меньше, чем при
прямом подходе.

\subsection{Двойственная градиентная процедура построения
непрерывных оптимальных планов$^1$}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Соответствие значений параметров $X[M(\xi)]$, $\mu(U,\xi)$, $\eta$
двойственной процедуры критериям $A$- и $D$-оп\-ти\-маль\-ности также см.\ по табл.~1.}

\smallskip\textbf{Шаг~1.} Зададим начальный невырожденный план~$\xi_0$ и по
формуле~(\ref{e17-c}) вычислим нормированную матрицу $M(\xi_0)$ плана.
Положим $l=0$.

\smallskip\textbf{Шаг~2.} Найдем локальный максимум
  $$
  U^l=\mathrm{arg}\,\max_{U\in \Omega_U} \mu\left ( U,\xi_l\right)
  $$
методом проекции градиента. Если окажется, что
$\left\vert \mu\left( U^l,\xi_l\right)-\eta\right\vert \leq\delta$,
закончим процесс.
  Если
$
  \mu\left( U^l,\xi_l\right)>\eta$, перейдем к шагу~3. В~противном случае будем искать новый локальный
максимум.

\smallskip\textbf{Шаг~3.} Вычислим $\tau_l$ по формуле
  \begin{equation*}
  \tau_l =\mathrm{arg}\,\min_{0\leq \tau\leq 1} X\left[
M\left(\xi^\tau_{l+1}\right)\right]\,.
\end{equation*}
Здесь
\begin{equation*}
  \xi^\tau_{l+1} =\left(1-\tau\right)\xi_l+\tau\xi\left(U^l\right)\,,
  \end{equation*}
где $\xi(U^l)$~--- одноточечный план, размещенный в точке~$U^l$.

\smallskip\textbf{Шаг~4.} Составим план
  $$
  \xi_{l+1}=\left (1-\tau_l\right)\xi_l+\tau_l\xi\left(U^l\right)\,,
  $$
произведем его <<очистку>> в соответствии с рекомендациями из~\cite{4-c},
положим $l=l+1$ и перейдем к шагу~2.

  Приведенный алгоритм требует вычисления градиента
  \begin{multline*}
  \nabla_U \mu\left(U,\xi\right) =\left\Vert \fr{\partial\mu(U,\xi)}{\partial
u_j(t)}\right\Vert\,,\enskip t=0,1, \ldots ,N-1\,,\\  j=1,2, \ldots ,r\,.
  \end{multline*}

  Для критерия $D$-опти\-маль\-ности получаем:
  \begin{multline*}
  \fr{\partial\mu(U,\xi)}{\partial u_j(t)} =\fr{\partial
  Sp[M^{-1}(\xi)M(U)]}{\partial u_j(t)}= {}\\[6pt]
  {}=Sp\left[ M^{-1}(\xi)\fr{\partial
M(U)}{\partial u_j(t)}\right]\,, \enskip t=0,1, \ldots ,N-1\,, \\[6pt]
j=1, \ldots ,r\,.
  \end{multline*}

  В случае критерия $A$-опти\-маль\-ности
    \begin{multline*}
  \fr{\partial\mu(U,\xi)}{\partial u_j(t)} =\fr{\partial
  Sp[M^{-2}(\xi)M(U)]}{\partial u_j(t)}={}\\[6pt]
  {}=Sp\left[ M^{-2}(\xi)\fr{\partial
M(U)}{\partial u_j(t)}\right]\,, \enskip t=0,1, \ldots ,N-1\,, \\ j=1, \ldots ,r\,.
    \end{multline*}

   Итак, рассмотрены две принципиально разные градиентные процедуры
построения непрерыв-\linebreak ных оптимальных планов. До решения конкретной задачи
не представляется возможным судить, эффективность какой из них окажется
выше. Проведенный анализ позволил организовать вычисление градиентов
функционалов $X[M(\xi)]$ и $\mu[U,\xi]$ по рекуррентным аналитическим
формулам. Основу алгоритмов вычисления указанных градиентов составили
алгоритмы нахождения информационной матрицы одноточечного плана
$M(U;\Theta)$ из~\cite{19-c} и ее производных $\partial M(U;\Theta)/\partial
u_j(t)$.

  Практическое применение построенного непрерывного оптимального плана
\begin{multline*}
  \xi^*=\left\{
  \begin{matrix}
  U_1^*, U_2^*, \ldots , U_q^*\\[6pt]
  p_1^*, p_2^*, \ldots , p_q^*
  \end{matrix}
  \right \}\,,\enskip \sum\limits_{i=1}^q p_i^*=1\,,\ p_i^*\geq 0\,,\\ U_i^*\in
\Omega_U\,,\ i=1, 2, \ldots , q\,,
  \end{multline*}
затруднено тем обстоятельством, что веса~$p_i^*$ представляют собой, вообще
говоря, произвольные вещественные числа, заключенные в интервале от нуля
до единицы. Возможный алгоритм <<округления>> непрерывного плана до
дискретного изложен в~\cite{6-c}.

     Разработанный в рамках системы MATLAB программный комплекс
включает в себя модули, отвечающие за вычисление информационной матрицы
и ее производных по компонентам входного сигнала, нахождение
     ММП-оце\-нок неизвестных параметров моделей гауссовских
нелинейных дискретных систем, синтез $A$- и $D$-оп\-ти\-маль\-ных входных
сигналов (реализованы прямая и двойственная градиентные процедуры).

\section{Пример активной идентификации динамической~системы}

  Рассмотрим следующую модель стохастической нелинейной дискретной
системы:
  \begin{align}
  x(k+1) &=\left(1-\fr{\theta_2}{\theta_1}\right) x(k)+{}\notag\\
&\hspace*{-15mm}  {}+\fr{0{,}01}{\theta_1}\left[
u(k)-x(k)\right] e^{0{,}25[u(k)-x(k)]}+\fr{0{,}1}{\theta_1}\,w(k)\,;\label{e20-c}\\
  y(k+1) &= x(k+1)+v(k+1)\,, \notag\\
  &\hspace*{18mm}k=0,1,\ldots , N-1\,,
  \label{e21-c}
  \end{align}
где $\theta_1$, $\theta_2$~--- неизвестные параметры системы, причем $2\leq
\theta_1\leq 10$, $0{,}05\leq \theta_2\leq 2$.

  Будем считать, что выполнены все априорные предположения из разд.~2,
причем
  \begin{align*}
  E\left[ w(k) w(i)\right] & = 0{,}6\delta_{ki}=Q\delta_{ki}\,;\\
  E\left[ v(k+1) v(i+1)\right] &=0{,}3\delta_{ki}=R\delta_{ki}\,;\\
  E\left[x(0)\right] &=0=\overline{x}(0)\,;\\
  E\left\{\left[ x(0)-\overline{x}(0)\right]\left[ x(0)-
\overline{x}(0)\right]\right\}&=0{,}01=P(0)\,.
  \end{align*}

  Выполнив временную линеаризацию модели~(\ref{e20-c}), (\ref{e21-c})
относительно номинальной траектории
\begin{equation}
\left.
\begin{array}{rl}
x_H(k+1)  &=\left(1-\fr{\theta_2}{\theta_1}\right) x_H(k)+{}\\[6pt]
&\hspace*{-15mm}{}+\fr{0{,}01}{\theta_1}\left[
u_H(k)-x_H(k)\right] e^{0{,}25[u_H(k)-x_H(k)]}\,,\\[6pt] 
&\hspace*{15mm}k=0,1, \ldots ,N-1\,;\\[9pt]
x_H(0)&=0\,,
\end{array}
\right \}
\label{e22-c}
\end{equation}
получим линеаризованную модель вида~(\ref{e10-c}), (\ref{e11-c}), в которой
\begin{multline*}
a(k)=\fr{0{,}01}{\theta_1}\left \{
\vphantom{\left[ u_H(k)-x_H(k)\right]^2}
\vphantom{[x_H(k)]^2}
 \left[ 1+0{,}25(u_H(k)-x_H(k))\right] u(k)-
{}\right.\\
\left.{}-0{,}25\left[ u_H(k)-x_H(k)\right]^2\right \} e^{0{,}25 [u_H(k)-x_H(k)]}\,;
\end{multline*}

\vspace*{-12pt}

\noindent
\begin{multline*}
\Phi(k)=1-\fr{\theta_2}{\theta_1}-\fr{0{,}01}{\theta_1}\left\{1+0{,}25\left[u_H(k)-{}\right.\right.\\
\left.\left.{}-x_H(k)\right]\right\} e^{0{,}25[u_H(k)-x_H(k)]}\,;
\end{multline*}

\vspace*{-6pt}

\noindent
\begin{equation*}
\Gamma(k) = \fr{0{,}1}{\theta_1}\,; \enskip A(k+1)= 0\,;\enskip
H(k+1)=1\,.
\end{equation*}

  Таким образом, необходимо оценить па\-ра\-мет\-ры~$\theta_1$, $\theta_2$,
входящие в~$a(k)$, $\Phi(k)$ и~$\Gamma(k)$.

  Считаем, что для номинальной траектории~(\ref{e22-c}) $u_H(k)=u(k)$, $k=0,
1, \ldots ,N-1$, обеспечивается наилучшее приближение построенной
линеаризованной модели к своему нелинейному аналогу.

  Выберем область планирования
  $
  \Omega_U=\{U\hm \in R^N\vert 10\leq u(k)\leq 15\,, k=0,1, \ldots ,N-1\}$ и критерий
$A$-оп\-ти\-маль\-ности.

  Для того чтобы ослабить зависимость результатов оценивания от
выборочных данных, произведем пять независимых запусков системы и
усредним полученные оценки неизвестных параметров. Реализации выходных
сигналов получим компьютерным моделированием при истинных значениях
параметров $\theta_1^*=4$, $\theta_2^*=0{,}5$ и $N=31$.

  О качестве идентификации в пространстве параметров и в пространстве
откликов будем судить соответственно по значениям
коэффициентов~$k_\theta$ и~$k_Y$, вычисляющихся по следующим
формулам:

\noindent
  \begin{align*}
  k_\theta &= \fr{\Vert \theta^* -\hat{\theta}_{\mathrm{ср}}\Vert}{\Vert \theta^* -
\hat{\theta}^*_{\mathrm{ср}}\Vert } ={}\\[3pt]
&\hspace*{12mm}{}=\sqrt{\fr{(\theta_1^*-
\hat{\theta}_{1\mathrm{ср}})^2+(\theta_2^*-
\hat{\theta}_{2\mathrm{ср}})^2}{(\theta_1^*-
\hat{\theta}_{1\mathrm{ср}}^*)^2+(\theta_2^*-\hat{\theta}_{2\mathrm{ср}}^*)^2}}\,;\\[6pt]
  k_Y &=\fr{\Vert Y_{\mathrm{ср}}-\hat{Y}_{\mathrm{ср}}\Vert}{\Vert
Y_{\mathrm{ср}}-\hat{Y}^*_{\mathrm{ср}}\Vert }={}\\[3pt]
&\hspace*{-1mm}{}=\sqrt{\fr{\sum_{k=0}^{N-1}
(y_{\mathrm{ср}}(k+1)-\hat{y}_{\mathrm{ср}}(k+1\vert k+1))^2}{\sum_{k=0}^{N-1}
(y_{\mathrm{ср}}(k+1)-\hat{y}^*_{\mathrm{ср}}(k+1\vert k+1))^2}}\,,
  \end{align*}
  
  \end{multicols}
  
    \begin{table}[b]\small %tabl2
    \vspace*{-24pt}
  \begin{center}
  \Caption{Результат выполнения процедуры активной идентификации
  \label{t2-c}}
  \vspace*{2ex}

  \begin{tabular}{|p{90mm}|c|c|c|}
  \hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Входной сигнал}}& 
\raisebox{-6pt}[0pt][0pt]{\tabcolsep=0pt\begin{tabular}{c}Номер запуска\\ системы\end{tabular}}&
\multicolumn{2}{c|}{\tabcolsep=0pt\begin{tabular}{c}Значения оценок\\ параметров\end{tabular}}\\
\cline{3-4}
&&&\\[-8pt]
&&$\hat{\theta}_1$&$\hat{\theta}_2$\\
\hline
\multicolumn{1}{|c|}{Исходный }& &&\\
%&&&\\[-9pt]
\hspace*{0pt}{\raisebox{-52mm}{
\epsfxsize=77.97mm
\epsfbox{cht-1.eps}
}}
&1&\,6,6782\,&0,4520\\[-135pt]
\cline{2-4}
&&&\\[-2pt]
&2&6,1915&0,4014\\[7pt]
\cline{2-4}
&&&\\[-2pt]
&3&3,2376&0,5220\\[7pt]
\cline{2-4}
&&&\\[-2pt]
&4&3,8666&0,5807\\[7pt]
\cline{2-4}
&&&\\[-2pt]
&5&4,7786&0,5493\\[7pt]
\cline{2-4}
&\tabcolsep=0pt\begin{tabular}{c}Средние\\ значения\\ по запускам\end{tabular}&4,9505&0,5011\\
\hline
\multicolumn{1}{|c|}{Синтезированный }& &&\\
%&&&\\[-9pt]
\hspace*{0pt}{\raisebox{-52mm}{
\epsfxsize=77.97mm
\epsfbox{cht-2.eps}
}}&1&4,7958&0,4888\\[-135pt]
\cline{2-4}
&&&\\[-2pt]
&2&4,5351&0,4962\\[7pt]
\cline{2-4}
&&&\\[-2pt]
&3&3,6677&0,4967\\[7pt]
\cline{2-4}
&&&\\[-2pt]
&4&3,2482&0,4975\\[7pt]
\cline{2-4}
&&&\\[-2pt]
&5&4,8276&0,5340\\[7pt]
\cline{2-4}
&\tabcolsep=0pt\begin{tabular}{c}Средние\\ значения\\ по запускам\end{tabular}&4,2151&0,5026\\
\hline
\end{tabular}
\end{center}
\end{table}

\addtocounter{figure}{1}
\begin{figure}[b] %fig2
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=163.409mm
\epsfbox{chu-2.eps}
}
\end{center}
\vspace*{-6pt}
\begin{minipage}[t]{79mm}
\Caption{Графическое представление $Y_{\mathrm{ср}}(k+1)$~(\textit{1}) и
$\hat{Y}_{\mathrm{ср}}(k+1|k+1)$~(\textit{2}) при $U$, изображенном на рис.~1
\label{f2-c}}
%\end{figure*}
\end{minipage}
\hfill
%\begin{figure*} %fig3
\vspace*{-6pt}
\begin{minipage}[t]{79mm}
  \Caption{Графическое представление  $Y_{\mathrm{ср}}(k+1)$~(\textit{1}) и  
  $\hat{Y}^*_{\mathrm{ср}}(k+1\vert k+1)$~(\textit{2})
при $U$, изображенном на рис.~1
  \label{f3-c}}
  \end{minipage}
  \end{figure}



\begin{multicols}{2}


\begin{center} %fig1
\vspace*{3pt}
\mbox{%
\epsfxsize=77.97mm
\epsfbox{chu-1.eps}
}
\end{center}
\vspace*{6pt}
%\begin{center}
{{\figurename~1}\ \ \small{Тестовый сигнал~$U$ для анализа
 качества прогнозирования на основе результатов из табл.~2}}
%\end{center}
%\vspace*{9pt}

\bigskip
\addtocounter{figure}{1}


\noindent
где $\theta^*$~--- вектор истинных значений параметров;
$\hat{\theta}_{\mathrm{ср}}$~--- вектор усредненных оценок неизвестных
зна-чений параметров по исходному входному сигналу;
$\hat{\theta}_{\mathrm{ср}}^*$~--- вектор усредненных оценок неизвестных
значений параметров по синтезированному входному сигналу;
$Y_{\mathrm{ср}}=\{y_{\mathrm{ср}}(k+1),\ k=0,1, \ldots , N-1\}$,
$\hat{Y}_{\mathrm{ср}} =\{y_{\mathrm{ср}}(k+1\vert k+1),\ k=0,1,\ldots , N-1\}$,
$\hat{Y}^*_{\mathrm{ср}}=\{\hat{y}_{\mathrm{ср}}^*(k+1|k+1),\ k=0,1, \ldots , N-1\}$~---
усредненные по всем запускам последовательности измерений для
вектора~$\theta$, равного~$\theta^*$, $\hat{\theta}_{\mathrm{ср}}$,
$\hat{\theta}_{\mathrm{ср}}^*$ соответственно, при некотором выбранном
допустимом входном сигнале $U\in \Omega_U$.

  Результаты выполнения процедуры активной параметрической
идентификации представлены в табл.~2 (оптимальный план получился
одноточечным).


  Данные, приведенные в табл.~2, показывают, что коэффициент
$k_\theta\approx 4{,}4$. В~пространстве откликов при псевдослучайном
входном сигнале~$U$, приведенном на рис.~1, $k_Y\approx 1{,}3$.
Последовательности $Y_{\mathrm{ср}}$,  $\hat{Y}_{\mathrm{ср}}$,
$\hat{Y}^*_{\mathrm{ср}}$ изображены на рис.~2 и~3.




\section{Заключение}

  Дано систематическое изложение наиболее существенных для практики
вопросов теории и техники активной параметрической идентификации
гауссовских нелинейных дискретных систем. Рассмотрен случай вхождения
неизвестных параметров в уравнения состояния и наблюдения, начальные
условия и ковариационные матрицы помех динамики и ошибок измерений.
Приведен разработанный алгоритм для вычисления производных от
информационной матрицы по компонентам входного сигнала, позволяющий
использовать при синтезе входного сигнала метод проектирования градиента и
в результате сократить время поиска оптимального плана эксперимента.
Приведены оригинальные градиентные алгоритмы активной идентификации,
позволяющие решать задачи оптимального оценивания параметров методом
максимального правдоподобия с привлечением прямой и двойственной
процедур синтеза $A$- и $D$-оп\-ти\-маль\-ных входных\linebreak сигналов. На примере
одной модельной струк\-ту\-ры продемонстрирована эффективность и
це\-ле\-со\-образ\-ность применения концепции активной па\-ра\-мет\-ри\-че\-ской
идентификации при построении\linebreak моделей нелинейных систем.

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{99}

\bibitem{1-c}
\Au{Сейдж Э.\,П., Мелса Дж.\,Л.}
Идентификация систем управления.~--- М.: Наука, 1974.

\bibitem{2-c}
\Au{Эйкхофф П.}
Основы идентификации систем управ\-ле\-ния. Оценивание параметров и
состояния.~--- М.: Мир, 1975.

\bibitem{3-c}
\Au{Гроп Д.} Методы идентификации систем.~--- М.: Мир, 1979.

\bibitem{4-c}
\Au{Федоров В.\,В.}
Теория оптимального эксперимента (планирование регрессионных
экспериментов).~--- М.: Наука, 1971.

\bibitem{5-c}
\Au{Денисов В.\,И.}
Математическое обеспечение системы ЭВМ~--- экспериментатор.~--- М.:
Наука, 1977.

\bibitem{7-c}
\Au{Горский В.\,Г., Адлер Ю.\,П., Талалай~А.\,М.}
Планирование промышленных экспериментов (модели динамики).~--- М.:
Металлургия, 1978.

\bibitem{6-c}
\Au{Ермаков С.\,М., Жиглявский А.\,А.}
Математическая теория оптимального эксперимента.~--- М.: Наука, 1987.


\bibitem{8-c}
\Au{Денисов В.\,И., Чубич В.\,М., Черникова~О.\,С.}
Активная идентификация стохастических линейных дискретных систем во
временной области~// Сиб. журн. индустр. матем., 2003. Т.~6. №\,3(15).
С.~70--87.

\bibitem{9-c}
\Au{Денисов В.\,И., Чубич В.\,М., Черникова~О.\,С.}
Активная параметрическая идентификация стохастических линейных
дискретных систем в частотной области~// Сиб. журн. индустр. матем., 2007.
Т.~10. №\,1(29). С.~70--89.

\bibitem{10-c}
\Au{Денисов В.\,И., Чубич В.\,М., Черникова~О.\,С., Бобылева~Д.\,И.}
Активная параметрическая идентификация стохастических линейных
сис\-тем.~--- Новосибирск: НГТУ, 2009.

\bibitem{11-c}
\Au{Синицын И.\,Н.}
Рецензия на книгу В.\,И.~Денисова, В.\,М.~Чубича, О.\,С.~Черниковой,
Д.\,И.~Бобылевой <<Активная параметрическая идентификация
стохастических линейных систем>>~// Системы высокой доступности, 2009.
№\,3. С.~56.

\bibitem{12-c}
\Au{Казаков И.\,Е.}
Статистические методы проектирования систем управления.~--- М.:
Машиностроение, 1969.

\bibitem{13-c}
\Au{Пугачев В.\,С., Казаков И.\,Е., Евланов Л.\,Г.}
Основы статистической теории автоматических систем.~--- М.:
Машиностроение, 1974.

\bibitem{14-c}
\Au{Gupta N.\,K., Mehra R.\,K.}
Computational aspects of maximum likelihood estimation and reduction in sensitivity
function calculations~// IEEE Trans. Automat. Control, 1974. Vol.~19. No.\,6.
P.~774--783.

\bibitem{15-c}
\Au{$\acute{\mbox{А}}$str$\Ddot{\mbox{o}}$m K.\,J.}
Maximum likelihood and prediction errors methods~// Automatica, 1980,
Vol.~16. Р.~551--574.

\bibitem{16-c}
\Au{Огарков М.\,А.} Методы статистического оценивания параметров
случайных процессов.~--- М.: Энергоатомиздат, 1980.

\bibitem{17-c}
\Au{Базара М., Шетти К.}
Нелинейное программирование.~--- М.: Мир, 1982.

\bibitem{18-c}
\Au{Сухарев А.\,Г., Тимохов~В.\,В., Федоров~В.\,В.}
Курс методов оптимизации.~--- М.: Наука, 1986.

\bibitem{19-c}
\Au{Чубич В.\,М.}
Вычисление информационной матрицы Фишера в задаче активной
параметрической идентификации стохастических нелинейных дискретных
систем~// Науч. вест. НГТУ, 2009. №\,1(34). С.~23--40.

\bibitem{20-c}
\Au{Льюнг Л.}
Идентификация систем: Теория для пользователя.~--- М.: Наука, 1991.

 \label{end\stat}

\bibitem{21-c}
\Au{Mehra R.\,K.}
Optimal input signals for parameter estimation in dynamic systems~--- survey and
new results~// IEEE Trans. Automat. Control, 1974. Vol.~19. No.\,6.
P.~753--768.
 \end{thebibliography}
}
}


\end{multicols}