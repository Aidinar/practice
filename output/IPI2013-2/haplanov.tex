\def\stat{haplanov}

\def\tit{АСИМПТОТИЧЕСКАЯ НОРМАЛЬНОСТЬ ОЦЕНКИ ПАРАМЕТРОВ МНОГОМЕРНОЙ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ}

\def\titkol{Асимптотическая нормальность оценки параметров многомерной логистической регрессии}

\def\autkol{А.\,Ю. Хапланов}

\def\aut{А.\,Ю. Хапланов$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

%{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
%{Работа
%поддержана Российским фондом фундаментальных исследований (проекты
%11-01-00515а, 11-07-00112а, 11-01-12026-офи-м), Министерством
%образования и науки РФ (госконтракт 16.740.11.0133).}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский государственный университет им. М.\,В. Ломоносова, Khaplanova@gmail.com}


\Abst{Построена оценка вектора коэффициентов многомерной логистической регрессии, 
когда размерность этого вектора растет с увеличением объема выборки. Установлена 
оценка скорости сходимости предложенной оценки, а также ее асимптотическая нормальность.}

\KW{логистическая регрессия; скорость сходимости; асимптотическая нормальность; предикторы 
высокой размерности}

\vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}


\section{Введение}



В современной информатике методы машинного обучения (см., например,~\cite{ML}) широко 
используются для решения многих типов вероятностных задач. Достаточно упомянуть 
кластеризацию и понижение размерности наблюдений. В~представленной работе исследуется 
проб\-ле\-ма классификации данных. Распространенным подходом к ее решению является 
применение метода логистической регрессии (см., например,~\cite{Francis,LONG}). Этот 
метод час\-то используется для распознавания образов, анализа текстов и решения многих 
других прикладных задач (см., например,~\cite{text, tensor}). В~модели логистической 
регрессии предполагается, что бинарная случайная величина~$Y$ определенным образом 
зависит от вектора факторов $X\hm=(X_1,\ldots,X_p)$, принимающего значения в пространстве~$\R^p$. 
В~статьях~\cite{Anderson,hossain} изучался случай, когда $Y$ принимает значения в 
множестве $\{0,1,\ldots,k\}$. В~данной работе исследуется обобщение этой модели. Пусть 
для каждого $n\hm\in\mathbb{N}$ величина $Y\hm=Y(n)$ отображает пространство элементарных 
исходов~$\Omega$ в множество $\{0,1,\ldots,k\}$, а $X\hm=X(n)$~--- случайный вектор со 
значениями в $\mathbb{R}^{p_n}$. Предположим, что существует параметр $\alpha^{0,n}\hm\in\R^{kp_n}$ 
логистической зависимости~$Y(n)$ от~$X(n)$ (см., например,~\cite{gee}). Необходимые 
определения даются в разд.~2. По независимым наблюдениям векторов 
$(X_q(n)^{\mathrm{T}},Y_q(n))^{\mathrm{T}}$, $q\hm=1,\ldots,n$, имеющих такое же 
распределение, как $(X(n)^{\mathrm{T}},Y(n))^{\mathrm{T}}$, 
строится оценка $\widehat{\alpha}_n$ вектора $\alpha^{0,n}$. Символ~T обозначает 
транспонирование. Основным результатом данной работы является доказательство асимптотической 
нормальности величины $\widehat{\alpha}_n\hm-\alpha^{0,n}$ при 
$n\hm\rightarrow\infty$. Тем самым обобщаются работы~\cite{gee, MLELR}, 
в которых рас\-смат\-ри\-вал\-ся случай $k\hm=1$. Кроме того, устанавливается оценка скорости 
сходимости $\widehat{\alpha}_n$ к $\alpha^{0,n}$ при $n\hm\rightarrow\infty$.


\section{Основные результаты}


Пусть для каждого $n\hm\in\mathbb{N}$ дан случайный вектор $(X(n)^{\mathrm{T}},Y(n))^{\mathrm{T}}$ такой, что 
$X(n)$ принимает значения в $\R^{p_n}$, а $Y(n)$~--- в множестве $\{0,\ldots,k\}$, где $k$ 
и~$p_n$ являются натуральными числами. Для удобства записи введем $K\hm=\{1,\ldots,k\}$. 
В~работе исследуется многомерная логистическая зависимость изучаемой переменной от факторов 
(см., например,~\cite{Anderson}). А~именно: пусть для $n\hm\in\N$, $j\hm\in K$ и $x\hm\in\R^{p_n}$ 
справедливы соотношения
\begin{gather*}
\p\left(Y(n)=j\left|X(n)=x\right.\right)\!=\!\fr{\exp\{-(\alpha^{0,n}_j)^{\mathrm{T}}x\}}
{1+\sum\nolimits_{t=1}^k\!\!\!\hspace*{-0.5pt}\exp\{-(\alpha^{0,n}_t)^{\mathrm{T}}x\}};\\
\p\left(Y(n)=0\left|X(n)=x\right.\right)\!=\!\fr{1}{1+\sum\nolimits_{t=1}^k
\hspace*{-0.5pt}\!\!\!\exp\{-(\alpha^{0,n}_t)^{\mathrm{T}}x\}},
\end{gather*}
где $\alpha^{0,n}_j$~--- неслучайные векторы в пространстве $\R^{p_n}$. 
Обозначим $\alpha^{0,n}\hm=\{(\alpha^{0,n}_1)^{\mathrm{T}},\ldots,(\alpha^{0,n}_k)^{\mathrm{T}}\}^{\mathrm{T}}$. 
В~дальнейшем для любого вектора $\alpha\hm\in\R^{kp_n}$ будет удобно использовать 
двойную нумерацию компонент, т.\,е.\ $\alpha^{(r,l)}\hm=\alpha^{l+(r-1)p_n}$, 
$r\hm\in K$, $l\hm\in\{1,\ldots,p_n\}$. Тогда $(\alpha^{0,n})^{(r,l)}\hm=(\alpha^{0,n}_r)^l$. 
Положим $\alpha^{(r,\cdot)}:=\left\{\alpha^{(r,1)},\ldots,\alpha^{(r,p_n)}\right\}^{\mathrm{T}}$. 
Определим функции $\{\pi^n_j(\alpha,x)\}_{j=0}^k$ такие, что для 
$j\hm\in K$, $\alpha\hm\in\R^{kp_n}$ и $x\hm\in\R^{p_n}$
\begin{gather*}
\pi^n_j(\alpha,x)=\fr{\exp\left\{-\left(\alpha^{(j,\cdot)}\right)^{\mathrm{T}}x\right\}}
{1+\sum\nolimits_{t=1}^k\exp\left\{-\left(\alpha^{(t,\cdot)}\right)^{\mathrm{T}}x\right\}}\,;\\
\pi^n_0(\alpha,x)=\fr{1}{1+\sum\nolimits_{t=1}^k\exp\left\{-\left(\alpha^{(t,\cdot)}\right)^{\mathrm{T}}x\right\}}\,.
\end{gather*}

Предполагая, что случайный вектор $X(n)$ имеет плотность распределения $g_n(x)$, 
запишем функцию правдоподобия для наблюдений 
$(X_q(n)^{\mathrm{T}},Y_q(n))^{\mathrm{T}}$, $q\hm=1,\ldots,n$. Имеем:
\begin{multline*}
L_n(\alpha)=\prod\limits_{q=1}^{n}\left(\pi^n_{Y_q(n)}(\alpha,X_q(n))g_n(X_q(n))\right)={}\\
\hspace*{-2pt}{}=
\prod\limits_{q=1}^n\!\left\{\prod\limits_{j=0}^k\left[\pi^n_{j}(\alpha ,X_q(n))\right]^{I\{Y_q(n)=
j\}}\!\right\}\!\prod\limits_{i=1}^ng_n(X_i(n)),\hspace*{-4.07253pt}
\end{multline*}
где $I\{A\}$~--- индикатор множества~$A$. Будем считать, что последний множитель отличен 
от нуля. Тогда он никак не повлияет на исследование поведения функции $L_n(\alpha)$ по 
аргументу~$\alpha$. Поэтому функция плотности $g_n(x)$ не учитывается, когда исследуется 
модель логистической регрессии (см., например,~\cite{Gramacy}). Введем
\begin{multline*}
\widetilde{L}_n(\alpha)=\prod\limits_{q=1}^{n}
\left(\pi^n_{Y_q(n)}(\alpha, X_q(n))\right)={}\\
{}=
\prod\limits_{q=1}^n\left\{\prod\limits_{j=0}^k\left[\pi^n_{j}(\alpha, X_q(n))\right]^{I\{Y_q(n)
=j\}}\right\}\,.
\end{multline*}
Положим $\mathcal{L}_n(\alpha)=\ln \widetilde{L}_n(\alpha)$. Справедливо равенство:
\begin{equation*}
\mathcal{L}_n(\alpha)=\sum\limits_{q=1}^n\left[\sum\limits_{j=0}^k I\left\{Y_q(n)=j\right\}
\ln\pi^n_j(\alpha, X_q(n))\right]\,.
\label{Ln}
\end{equation*}
Рассмотрим функцию:
\begin{multline*}
R_n(\alpha)=-\triangledown\mathcal{L}_n(\alpha)=
\left\{R_n^{(1,1)}(\alpha),\ldots\right.\\
\left.\ldots , R_n^{(1,p_n)}(\alpha),R_n^{(2,1)}(\alpha),\ldots,
R_n^{(k,p_n)}(\alpha)\right\}^{\mathrm{T}}\,, \\ \alpha\in\R^{kp_n}\,,
\end{multline*}
где 
$$
R_n^{(r,l)}(\alpha)\hm=\sum\limits_{q=1}^n\left[
I\left\{Y_q(n)=r\right\}-\pi^n_r(\alpha, X_q(n))\right]X_q^l(n).
$$ 
Пусть 
$\widehat{\alpha}_n$~--- вектор с минимальной евклидовой нормой, для 
которого $R_n(\widehat{\alpha}_n)\hm=\overline{0}$, здесь $\overline{0}$~--- 
нулевой вектор в пространстве $\R^{kp_n}$. Если решение этого уравнения определяется 
неоднозначно, то в качестве оценки используется корень, минимальный в лексикографическом 
смысле. В~случае когда корней не существует, полагаем $\widehat{\alpha}_n\hm=\overline{0}$. 
Далее будет доказано, что с вероятностью, стремящейся к единице при $n\hm\rightarrow\infty$, 
у функции $R_n(\alpha)$ существует как минимум один корень, а построенный вектор 
$\widehat{\alpha}_n$ является асимптотически нормальной оценкой $\alpha^{0,n}$. 
Для того чтобы сформулировать основные результаты данной работы, понадобятся новые 
обозначения. Заметим, что для 
исследуемой модели $\E\left(I\left\{ Y(n)\hm=r\right\}|X(n)\right)\hm=
\pi^n_r(\alpha^{0,n}, X(n))$. Значит, $\E R_n(\alpha^{0,n})\hm=\overline{0}.$ 
Введем матрицу вторых производных функции $-\mathcal{L}_n(\alpha)$:
\begin{equation*}
Q_n(\alpha)= \triangledown R_n(\alpha)^{\mathrm{T}}= \left(u_{(m,s)}^{(r,l)}(\alpha)\right)\,,
\end{equation*}
где $(r,l)$ и $(m,s)$ обозначают номера строки и столбца элементов матрицы $Q_n(\alpha)$ в 
двойной нумерации. Функции $u_{(m,s)}^{(r,l)}(\alpha)$ для $r,m\hm\in K$, 
$l,s\hm\in\left\{1,\ldots,p_n\right\}$ и $\alpha\hm\in\R^{kp_n}$ удовлетворяют соотношению
\begin{equation*}
u_{(m,s)}^{(r,l)}(\alpha)=\sum\limits_{q=1}^nH^n_{r,m}(\alpha, X_q(n))X_q^l(n)X_q^s(n)\,,
\end{equation*}
где $H^n_{r,m}(\alpha,x)$ для $n\hm\in\N$, $\alpha\hm\in\R^{kp_n}$ и $x\hm\in\R^{p_n}$ 
определяются следующим образом:
\begin{multline}
H^n_{r,m}(\alpha,x)={}\\
{}=
\begin{cases}
-\pi^n_r(\alpha,x)\pi^n_m(\alpha,x)\,,&\mbox{ если}\  r\neq m\,,\\
\pi^n_r(\alpha,x)(1-\pi^n_r(\alpha,x))\,,&\mbox{ если}\   r=m\,.
\end{cases}
\label{eq7}
\end{multline}

Введем также квадратную матрицу $B_n\hm=\left(b_{(m,s)}^{(r,l)}(\alpha^{0,n})\right)$ 
порядка $kp_n$, для которой $b_{(m,s)}^{(r,l)}(\alpha)\hm=H^n_{r,m}(\alpha, X(n))X^l(n)X^s(n)$. 
Положим $G_n(\alpha)\hm=\E Q_n(\alpha)$. Важно отметить, что $G_n(\alpha^{0,n})$ совпадает 
с ковариационной матрицей вектора $R_n(\alpha^{0,n})$. Для упрощения записи далее пишем $G_n$ 
вместо $G_n(\alpha^{0,n})$. Легко заметить, что $G_n\hm=nB_n$. Далее понадобятся следующие условия.

\medskip

\noindent
\textbf{1.}\ \textit{Существует константа $C\hm>0$ такая, что для всех $n\hm\in\N$ 
неравенство $\|X(n)\|\leq C$ выполняется почти наверное}.

\medskip

\noindent
\textbf{2.}\  \textit{Существует число $c\hm>0$, для которого неравенство 
$m^{\mathrm{T}}_nB_nm_n\hm\geq c\|m_n\|^2$ выполняется при всех $n\hm\in\N$ и $m_n\hm\in\R^{kp_n}$, 
где $\|\cdot\|$~--- евклидова норма}.


\medskip

\noindent
\textbf{Замечание 1.}
Из определения матрицы $B_n$ следует, что условие~2 будет иметь место, 
например, когда вектор $X(n)$ нормально распределен с единичной ковариационной матрицей 
и существует натуральное чис\-ло~$s$ такое, что $(\alpha^{0,n})^{(r,l)}\hm=0$ 
при всех $n\hm\in\mathbb{N}$, $r\hm\in K$ и $l\hm\geq s$.

\medskip

Чтобы сформулировать основной результат, введем неслучайную матрицу $U_n$ 
размера $[k\times kp_n]$:

\noindent
{\footnotesize
\begin{multline*}
U_n={}\\
{}=\left(\begin{array}{ccccc}\overbrace{\fr{1}{\sqrt{p_n}}\;\;\cdots\;\;
\fr{1}{\sqrt{p_n}}}^{p_n}&\overbrace{0\;\;\;\;\!\cdots\!\;\;\;\;0\vphantom{\fr{1}{p_n}}}^{p_n}&
\cdots&\overbrace{0\;\;\;\;\!\cdots\!\;\;\;0\vphantom{\fr{1}{p_n}}}^{p_n}\\
0\;\;\;\;\cdots\;\;\;\;0&\displaystyle{\fr{1}{\sqrt{p_n}}}\;\;\!\cdots\!\;\;
\fr{1}{\sqrt{p_n}}&\cdots&0\;\;\;\!\cdots\!\;\;\;\;0\\
\vdots\;\;\;\;\;\;\;\;\;\;\;\;\;\;\!\vdots\!&\vdots\;\;\;\;\;\;\;\;\;\;\;\;\;\;\vdots&\!\ddots\!&\!\vdots\!\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\!\vdots\\
0\;\;\;\;\;\!\cdots\!\;\;\;\;\;0&0\;\;\;\;\;\!\cdots\!\;\;\;\;\;0&\!\cdots\!&\displaystyle{\fr{1}{\sqrt{p_n}}}\;\!\cdots\!\;\frac1{\sqrt{p_n}}
\end{array}\right)\!.
\end{multline*}}

\noindent
\textbf{Теорема 1.}\
\textit{Предположим, что выполняются условия~$1$ и~$2$. Тогда для любой 
последовательности $\delta_n\hm>0$, для которой $\delta_np_n/\sqrt{n}\hm\rightarrow0$ и 
$\sqrt{p_n}/\delta_n\hm\rightarrow0$ при $n\hm\rightarrow\infty$, имеет место соотношение:}
\begin{gather*}
\mathbb{P}\left(\|\alpha^{0,n}-~\widehat{\alpha}_n\|\geq \fr{\delta_n}{\sqrt{n}}\right)\rightarrow0,\,\,\,\;\;n\rightarrow\infty.
\end{gather*}


\medskip

\noindent
\textbf{Теорема 2.}\
\textit{Пусть выполняются условия~$1$, $2$ и $p_{n}\hm=o(n^{1/3})$ при 
$n\hm\rightarrow\infty$. Тогда}
\begin{equation*}
U_{n}G^{1/2}_{n}\left(\widehat{\alpha}_{n}-\alpha^{0,n}\right)\stackrel{d}{\rightarrow}Z\,,\ 
Z\sim N(0, E_k)\,,\ n\rightarrow\infty\,,
\end{equation*}
где $E_k$~--- единичная матрица порядка~$k$.

\medskip

\noindent
\textbf{Следствие 1.}
\textit{Если выполняются условия теоремы~$2$, то при $n\hm\rightarrow\infty$ 
справедливы соотношения:}
\begin{equation*}
\left\|\fr{Q_n(\widehat{\alpha}_n)}{n}-\fr{G_n}{n}\right\|_2\stackrel{\p}{\rightarrow}0\,;
\end{equation*}
\begin{equation*}
U_nQ_n(\widehat{\alpha}_n)^{1/2}(\widehat{\alpha}_n-\alpha^{0,n})\stackrel{d}{\rightarrow}Z\,,\ 
Z\sim N(0, E_k)\,,\label{equation3}
\end{equation*}
где $\|M\|_2$~--- операторная норма матрицы~$M$.


\medskip

Для доказательства этих теорем понадобится несколько элементарных вспомогательных утверждений.

\medskip

\noindent
\textbf{Лемма 1.}
\textit{Пусть дано отображение $F:\R^u\hm\rightarrow\R^v$ с непрерывными частными производными. 
Тогда для $x_1,x_2\hm\in\R^u$ выполняется тождество:}
\begin{multline*}
F(x_1)-F(x_2)={}\\
{}=\left[\int\limits_{0}^{1}\left(\triangledown_{x} 
(F(x)^{\mathrm{T}})|_{x=x_2+u(x_1-x_2)}\right)
\,{du}\right]^{\mathrm{T}}(x_1-x_2)\,,
\end{multline*}
где интеграл от матрицы берется поэлементно.


\medskip

Если записать определение первообразной функции для $F(x)$, утверждение этой леммы станет очевидным.\\

\medskip

\noindent
\textbf{Лемма 2} (см., например,~\cite{rudin}).
\textit{Пусть дано непрерывное инъективное отображение $\Gamma:\ \R^p\hm\rightarrow \R^p$. 
Фиксируем точку $x_0\hm\in\R^p$. Предположим, что $\inf_{||x-x_0||\hm=\delta}\left\|\Gamma(x)\hm-
\Gamma(x_0)\right\|\hm\geq R$ для некоторых констант $\delta,R\hm>0$. Тогда для любого 
$y\hm\in\{u\in\R^p\,:\,\|u-\Gamma(x_0)\|\hm\leq R\}$ существует такая точка $x(y)$, 
что $\Gamma(x(y))\hm=y$ и $\|x(y)-x_0\|\hm\leq\delta$}.

\medskip

\noindent
\textbf{Лемма 3.}
\textit{Если выполняются условия теоремы~$1$, то при $n\hm\rightarrow\infty$ 
имеет место предельное соотношение}
\begin{gather}
\sup_{\alpha\in N_n(\delta_n)}\|G^{-1/2}_nQ_n(\alpha)G^{-1/2}_n-E_{kp_n}\|_2
\stackrel{\p}{\rightarrow}0\,,\label{supremum}
\end{gather}
где 
$$
N_n(\delta_n)\hm=\{\alpha\in\R^{kp_n}:\,||G^{1/2}_n(\alpha-\alpha^{0,n})||\hm\leq 
\delta_n\}\,;
$$
$E_{kp_n}$~--- единичная матрица порядка~$kp_n$.


\section{Доказательства}

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\ леммы~3.
Оценим норму, фигурирующую в~(\ref{supremum}). Имеем:
\begin{multline}
\left\|G^{-1/2}_nQ_n(\alpha_n)G^{-1/2}_n-E_n\right\|_2={}\\
{}=\left\|G^{-1/2}_n\left[Q_n(\alpha_n)-G_n(\alpha^{0,n})\right]G^{-1/2}_n\right\|_2={}\\
{}=\left\|G^{-1/2}_n\left[Q_n(\alpha_n)-Q_n(\alpha^{0,n})+
Q_n(\alpha^{0,n})-{}\right.\right.\\
\left.\left.{}-G_n(\alpha^{0,n})\right]G^{-1/2}_n\right\|_2\leq
\left\|G^{-1/2}_n\sqrt{n}\right\|_2\times{}\\
{}\times\left\|\fr{Q_n(\alpha_n)-Q_n(\alpha^{0,n})}{n}\right\|_2 
\left\|G^{-1/2}_n\sqrt{n}\right\|_2+{}\\
{}+\left\|G^{-1/2}_n\sqrt{n}\right\|_2 \left\|\fr{Q_n(\alpha^{0,n})-
G_n(\alpha^{0,n})}{n}\right\|_2\times{}\\
{}\times\left\|G^{-1/2}_n\sqrt{n}\right\|_2\,.\label{eq14}
\end{multline}

Величина $\left\|G^{-1/2}_n\sqrt{n}\right\|_2$ ограничена константой, которая по 
условию~2 не зависит от~$n$. Используя неравенство $\|A\|_2\leq v\|A\|_{\infty}$, где 
$A$~--- квадратная матрица порядка $v$ и $\|A\|_{\infty}\hm= \max\limits_{i,j}\{|a_{i,j}|\}$, 
получаем, что
\begin{multline}
\left\|\fr{Q_n(\alpha_n)-Q_n(\alpha^{0,n})}{n}\right\|_2\leq{}\\
{}\leq kp_n\left\|
\fr{Q_n(\alpha_n)-Q_n(\alpha^{0,n})}{n}\right\|_{\infty}={}\\
{}=\fr{kp_n}{n}\max\limits_{r,m,l,s}\left\{\left|\sum\limits_{q=1}^n
\left[H^n_{r,m}(\alpha_n, X_q(n))-{}\right.\right.\right.\\
\left.\left.\left.{}-H^n_{r,m}(\alpha^{0,n}, X_q(n)) \right] 
X_q^l(n)X_q^s(n)\vphantom{\sum\limits_{q=1}^n}\right|\right\}\leq{}\\
{}\leq kp_n\max\limits_{r,m,l,s,q}\left\{\left|H^n_{r,m}(\alpha_n, X_q(n))-{}\right.\right.\\
\left.\left.{}-H^n_{r,m} (\alpha^{0,n}, X_q(n))\right|C^2\right\}\,,
\label{eq13}
\end{multline}
где $C$~--- константа, для которой $\p\left(\|X(n)\|\hm\leq C\right)=1$ при $n\hm\in\N$. 
Из определения функции $H^n_{r,m}(\alpha,x)$ и равенства~(\ref{eq7}) 
следует существование числа $L\hm\in\R_+$ такого, что для $n\hm\in\N$ выполняется неравенство:
\begin{multline}
\left|H^n_{r,m}(\alpha_n, X_q(n))-H^n_{r,m}(\alpha^{0,n}, X_q(n))\right|\leq{}\\
{}\leq
\left\|\alpha_n-\alpha^{0,n}\right\|L\,.\label{eq12}
\end{multline}

Пользуясь определением множества $N_n(\delta_n)$, оценим правую часть неравенства~(\ref{eq12}):
\begin{multline*}
\left\|\alpha_n-\alpha^{0,n}\right\|=\left\|G_n^{-1/2}G_n^{1/2}(\alpha_n-\alpha^{0,n})\right\|\leq{}\\
\!{}\leq\left\|G_n^{-1/2}\right\|_2\left\|G_n^{1/2}(\alpha_n-\alpha^{0,n})\right\|\leq \left\|G_n^{-1/2}\sqrt{n}\right\|_2\frac{\delta_n}{\sqrt{n}}.\hspace*{-7.18407pt}
\end{multline*}

Цепочка неравенств~(\ref{eq13}) может быть продолжена следующим образом:
\begin{multline}
kp_n \max\limits_{r,m,l,s,q}\left\{\left|H^n_{r,m}(\alpha_n, X_q(n))-{}\right.\right.\\
\left.\left.{}-
H^n_{r,m}(\alpha^{0,n}, X_q(n))\right|C^2\right\}\leq{}\\
{}\leq\fr{kp_n\delta_n}{\sqrt{n}} \,C^2L\left\|G_n^{-1/2}\sqrt{n}\right\|_2\,.
\label{eq161}
\end{multline}

Заметим, что при выполнении условий леммы~3 первое слагаемое в~\eqref{eq14} 
стремится к нулю, когда $n\hm\rightarrow\infty$. Далее
\begin{multline*}
\left\|\fr{Q_n(\alpha^{0,n})-G_n(\alpha^{0,n})}{n}\right\|_2\leq{}\\
{}\leq
\left\|\fr{Q_n(\alpha^{0,n})-G_n(\alpha^{0,n})}{n}\right\|_{F}=\fr{1}{n}\times{}\\
{}\times\!\left(\sum\limits_{j_1,j_2,i_1,i_2}^{k,k,p,p}\!\left\{
\sum\limits_{q=1}^n\!X_q^{j_1}(n)X_q^{j_2}(n)H^n_{i_1,i_2}(\alpha^{0,n}, X_q(n))-{}\right.\right.\\
\left.\left.{}-\E\left[X_q^{j_1}(n)X_q^{j_2}(n)H_{i_1,i_2}^n(\alpha^{0,n}, X_q(n))\right]
\vphantom{\sum\limits_{q=1}^n}
\right\}^2
\vphantom{\sum\limits_{j_1,j_2,i_1,i_2}^{k,k,p,p}}\right)^{1/2}\,,
\end{multline*}
где $\|A\|_F=\sqrt{\sum\limits_{i,j}(a_{i,j})^2}$ является нормой Фробениуса матрицы 
$A\hm=(a_{i,j})$. В~силу неравенства Чебышёва для векторов (см., например,~\cite{vectors}) 
имеем:
\begin{multline*}
\p\left\{\left\|\fr{Q_n(\alpha^{0,n})-G_n(\alpha^{0,n})}{n}\right\|_2\geq
\varepsilon\right\}\leq{}\\
{}\leq\!
\p\!\left(\sum\limits_{j_1,j_2,i_1,i_2}\!\!\left\{
\!\sum\limits_{q=1}^n\!X_q^{j_1}(n)\!X_q^{j_2}(n)\!H^n_{i_1,i_2}
(\alpha^{0,n}, X_q(n))\!-{}\right.\right.\hspace*{-12.14558pt}
\end{multline*}

\noindent
\begin{multline}
\hspace*{-3pt}\!\!\!\left.\left.{}-\E\left[X_q^{j_1}(n)\!X_q^{j_2}(n)\!H^n_{i_1,i_2}(\alpha^{0,n},\! X_q(n))
\right]\! \vphantom{\sum\limits_{q=1}^n}\right\}^2\!\!\!
\geq n^2 \varepsilon^2\!\right)\!\leq{}\hspace*{-0.7565pt}\\
{}\leq \left( \sum\limits_{j_1,j_2,i_1,i_2}^{k,k,p,p}\left\{
\sum\limits_{q=1}^n\mathbb{D}\left(X_q^{j_1}(n)X_q^{j_2}(n)\times{}\right.\right.\right.\\
\left.\left.\left.{}\times
H^n_{i_1,i_2}(\alpha^{0,n}, X_q(n))
\right) 
\vphantom{\sum\limits_{q=1}^n}\right\}
\vphantom{\sum\limits_{j_1,j_2,i_1,i_2}^{k,k,p,p}}\right)\Bigg / (\varepsilon^2n^2)
\leq{}\\
{}\leq\fr{k^2p_n^2nB}{\varepsilon^2n^2}=\fr{p_n^2k^2B}{n\varepsilon^2}\,.
\label{eq171}
\end{multline}

Существование такой константы~$B$, для которой $\mathbb{D}\left(X_q^{j_1}X_q^{j_2}H_{i_1,i_2}
(\alpha_{n} X_q)\right)\hm\leq B$ при всех $n\hm\in \N$, $i_1,i_2\hm\in K$, 
$j_1,j_2\hm\in\{1,\ldots,p_n\}$ и $q\hm\in\{1,\ldots,n\}$, следует из ограниченности 
функций $H^n_{i_1,i_2}(\alpha,x)$ и  условия~2. 
Подставляя~\eqref{eq161} и~\eqref{eq171} в~\eqref{eq14}, получаем утверждение леммы.

\medskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\ теоремы~1.
Напомним, что $N_n(\delta_n)\hm=\{\alpha\in\R^{kp_n}:\ \|G^{1/2}_n~(\alpha\hm-\alpha^{0,n})\|\hm\leq \delta_n\}$. 
Основная идея доказательства теоремы состоит том, что уравнение $R_n(\alpha)\hm=\overline{0}$ имеет решения 
$\alpha(n)\hm\in N_n(\delta_n)$  с вероятностью, стремящейся к единице при $n\hm\rightarrow\infty$. 
Для проверки этого рассмотрим функцию $F_n(\alpha)\hm=G_n^{-1/2}\left[R_n(\alpha)\hm-
R_n(\alpha^{0,n})\right]$. Легко заметить, что с вероятностью, стремящейся к единице при 
$n\hm\rightarrow\infty$, эта функция является непрерывным автоморфизмом некоторой окрестности 
точки $\alpha^{0,n}$ в пространстве $\R^{kp_n}$. Нетрудно видеть, что $F(\alpha^{0,n})\hm=
\overline{0}$. Рассмотрим цепочку неравенств, в которой будет использоваться неравенство 
Чебышёва для векторов и тот факт, что $G_n$~--- ковариационная матрица вектора 
$R_n(\alpha^{0,n})$.
\begin{multline*}
\p\left(\|G_n^{-1/2}R_n(\alpha^{0,n})\|\leq c_0\delta_n\right)\geq{}\\
{}\geq 1-\fr{\E\|G_n^{-1/2}R_n(\alpha^{0,n})\|^2}{(c_0\delta_n)^2}=
1-\fr{kp_n}{(c_0\delta_n)^2}\,. %\label{eq5}
\end{multline*}
Таким образом, $\p\left(\|G^{-1/2}R_n(\alpha^{0,n})\|\hm\leq c_0\delta_n\right)\hm\rightarrow1$ 
при $n\hm\rightarrow\infty$. Теперь покажем, что $\p\left(\inf\limits_{\alpha\in\partial 
N_n(\delta_n)}\|F_n(\alpha)\|\hm\geq c_0\delta_n\right)\hm\rightarrow1$, где 
$\partial N_n(\delta_n)\hm=\{\alpha\in\R^{kp_n}:\|G^{1/2}_n(\alpha\hm-\alpha^{0,n})\|\hm= 
\delta_n\}$.  Применим лемму~1 к функции $R_n(е\alpha)$. Тогда
\begin{multline*}
R_n(\alpha)-R_n(\alpha^{0,n})={}\\
{}=\left[\int\limits_{0}^{1}\triangledown_{x} 
(R_n(x)^{\mathrm{T}})|_{x=\alpha^{0,n}+u(\alpha-\alpha^{0,n})}\,{du}\right]^{\mathrm{T}}
\!\!\!(\alpha-\alpha^{0,n}).\hspace*{-2.51587pt}
\end{multline*}

Обозначая через $\widetilde{Q}_n(\alpha)$ последний интеграл, получаем 
$R_n(\alpha)\hm-R_n(\alpha^{0,n})\hm=\widetilde{Q}_n(\alpha)(\alpha\hm-\alpha^{0,n}).$ Отсюда
\begin{multline*}
\inf\limits_{\alpha\in\partial N_n(\delta_n)}\|G_n^{-1/2}(R_n(\alpha)-R_n(\alpha^{0,n}))\|^2={}\\
{}=\inf\limits_{\alpha\in\partial N_n(\delta_n)}\|G_n^{-1/2}\widetilde{Q}_n(\alpha)(\alpha-\alpha^{0,n})\|^2={}\\
{}=\inf\limits_{\alpha\in\partial N_n(\delta_n)}
\left[(\alpha-\alpha^{0,n})^{\mathrm{T}}\widetilde{Q}_n(\alpha)^{\mathrm{T}}G_n^{-1}\times{}\right.\\
\left.{}\times\widetilde{Q}_n(\alpha)
(\alpha-\alpha^{0,n})\delta_n^2\right]\Big /\delta_n^2\,.
\end{multline*}
В этих переходах применялось равенство $\|m\|^2\hm=m^{\mathrm{T}}m$, где $m$~--- произвольный вектор. 
Воспользуемся неравенством Ко\-ши--Бу\-ня\-ков\-ско\-го--Швар\-ца для 
векторов $(\alpha\hm-\alpha^{0,n})^{\mathrm{T}}\widetilde{Q}_n(\alpha)G_n^{-1/2}$ и 
$G_n^{1/2}(\alpha\hm-\alpha^{0,n})$. В~конце следующей цепочки неравенств 
$(\alpha\hm-\alpha^{0,n})^{\mathrm{T}}G_n^{1/2}/\delta_n$ заменяется произвольным вектором~$e$ 
единичной длины. Имеем
\begin{multline*}
\!\!\!\!\!\!\p\!\left(\inf\limits_{\alpha\in\partial N_n(\delta_n)}||G_n^{-1/2}\{R_n(\alpha)-
R_n(\alpha^{0,n})\}||\geq c_0\delta_n\!\right)\!\geq{}\hspace*{-1.26547pt}\\
{}\geq\p\left(\inf\limits_{\alpha\in\partial N_n(\delta_n)}\fr{
(\alpha-\alpha^{0,n})^{\mathrm{T}}\widetilde{Q}_n(\alpha)^{\mathrm{T}}(\alpha-\alpha^{0,n})}
{\delta_n}\geq{}\right.\\
\left.{}\geq c_0\delta_n
\vphantom{\fr{(\alpha-\alpha^{0,n})^{\mathrm{T}}\widetilde{Q}_n(\alpha)^{\mathrm{T}}(\alpha-\alpha^{0,n})}
{\delta_n}}
\right)\geq{}\\
{}\geq\p\left( \inf\limits_{\substack{{\alpha\in\partial N_n(\delta_n),}\\{||e||=1}}}
\left[e^{\mathrm{T}}G_n^{-1/2}\widetilde{Q}_n(\alpha)^{\mathrm{T}}G_n^{-1/2}e\right]\geq c_0\right).\hspace*{-1.757pt}
%\label{eq17}
\end{multline*}

Из леммы~3 следует, что
\begin{multline}
\p\left(\inf\limits_{\alpha\in\partial N_n(\delta_n)}||G_n^{-1/2}\{R_n(\alpha)-
R_n(\alpha^{0,n})\}||\geq{}\right.\\
\left.{}\geq c_0\delta_n \vphantom{\inf\limits_{\alpha\in\partial N_n(\delta_n)}}
\right)\rightarrow 1\,,\ n\rightarrow\infty\,.
\label{eq111}
\end{multline}
Значит, для любого $c_0\in(0,1)$ при $n\hm\rightarrow\infty$ будет верно
\begin{multline*}
\p\left(\inf\limits_{\alpha\in\partial N_n(\delta_n)}||G_n^{-1/2}\{R_n(\alpha)-
R_n(\alpha^{0,n})\}||\geq{}\right.\\
\left.{}\geq ||G_n^{-1/2}R_n(\alpha^{0,n})||
\vphantom{\inf\limits_{\alpha\in\partial N_n(\delta_n)}}
\right)\rightarrow1\,.
%\label{eq77}
\end{multline*}

Из леммы~2 и последнего соотношения вытекает, что с вероятностью, стремящейся к единице 
при $n\hm\rightarrow\infty$, существует такое $\widehat{\alpha}_n\hm\in\N_n(\delta_n)$, 
для которого $R_n(\widehat{\alpha}_n)\hm=\overline{0}$. Чтобы доказать, 
что $\widehat{\alpha}_n$ является единственным корнем уравнения 
$R_n(\widehat{\alpha})\hm=\overline{0}$, достаточно повторить вывод соотношения~\eqref{eq111}, 
вычисляя нижнюю грань для $\alpha\hm\in\R^{kp_n}\backslash N_n(\delta_n)$ вместо 
$\alpha\hm\in\partial N_n(\delta_n)$.


\medskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\ теоремы~2.
По многомерной центральной предельной теореме для центрированных, независимых и 
одинаково распределенных векторов с конечным вторым моментом нормы
\begin{multline*}
\hspace*{-3pt}U_nG_n^{-1/2}R_n(\alpha^{0,n})=U_n\left(\fr{G_n}{n}\right)^{-1/2}
\fr{R_n(\alpha^{0,n})}{\sqrt{n}}\stackrel{d}\rightarrow Z,\\  
Z\sim N(0,E_k)\,, \quad
n\rightarrow\infty\,.
%\label{eq16}
\end{multline*}
Далее воспользуемся результатом теоремы~1. Тогда
\begin{multline*}
U_nG_n^{1/2}(\alpha^{0,n}-\widehat{\alpha}_n)=
U_n\left[G_n^{-1/2}\widetilde{Q}_n(\widehat{\alpha}_n)\times{}\right.\\
\left.{}\times G_n^{-1/2}\right]^{-1}G_n^{-1/2}
\left(R_n(\alpha^{0,n})-R_n(\widehat{\alpha}_n)\right)={}\\
{}=U_n\left[E+o_p(1)\right]^{-1}G_n^{-1/2}\left(R_n(\alpha^{0,n})-R_n(\widehat{\alpha}_n)\right)={}\\
{}=U_nG_n^{-1/2}R_n(\alpha^{0,n})+U_nG_n^{-1/2}o_p(1)\,,
%\label{eq78}
\end{multline*}
где $o_p(1)$ обозначает случайные матрицы, операторные нормы которых стремятся 
к нулю по вероятности с ростом~$n$. Вектор $U_nG_n^{-1/2}R_n(\alpha^{0,n})$ является 
асимптотически нормальным. Следовательно, $U_nG_n^{1/2}(\alpha^{0,n}\hm-\widehat{\alpha}_n)
\stackrel{d}{\rightarrow}Z$ при $n\hm\rightarrow\infty$, где $Z\hm\sim N(0,E_k)$. 
Теорема доказана. \hfill $\square$

\medskip

\noindent
Для д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,а\ следствия~1 достаточно заметить, что 
$\|(Q_n(\widehat{\alpha}_n)-G_n(\alpha^{0,n}))/n\|$ стремится к нулю по вероятности 
при $n\hm\rightarrow\infty$. Это было получено при доказательстве леммы~3.

\bigskip

В заключение автор хотел бы выразить глубокую благодарность профессору 
А.\,В.~Булинскому за постановку задачи, помощь в работе и неизменное внимание.

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{99}


\bibitem{ML}
\Au{Murphy K.\,P.} Machine learning: A~probabilistic perspective.~--- 
Cambridge, MA: MIT Press, 2012.
\bibitem{Francis}
\Au{Bach F.} Self-concordant analysis for logistic regression~//  Electron. J.~Stat., 2010. Vol.~4. P.~384--414.
\bibitem{LONG} %3
\Au{Yu H., Huang F., Lin~C.} Dual coordinate descent methods for logistic regression 
and maximum entropy models~// Machine Learning, 2011. Vol.~85. Issue~1-2. P.~41--75.

\bibitem{text} %4
\Au{Genkin A., Lewis D.\,D., Madigan~D.} Large-scale bayesian logistic 
regression for text categorization~// Technometrics, 2007. Vol.~49. No.\,3. P.~291--304.

\bibitem{tensor} %5
\Au{Guo W., Kotsia I., Patras~I.} Tensor learning for regression~// 
IEEE Trans. Image Proc., 2012. Vol.~21. No.\,2. P.~816--827.

\bibitem{Anderson}
\Au{Anderson J.\,A.} Separate sample logistic regression~//
Biometrika, 1972. Vol.~59. No.\,1. P.~19--35.
\bibitem{hossain}
\Au{Hossain S., Ejaz~Ahmed~S., Howlader~H.} Model selection
and parameter estimation of a multinomial logistic regression model~// 
J.~Stat. Comput. Simulation, 2012. P.~1--15.
\bibitem{gee}
\Au{Wang L.} GEE analysis of clustered binary data with diverging number of covariates~// 
Ann. Stat., 2011. Vol.~39. No.\,1. P.~389--417.
\bibitem{MLELR}
\Au{Liang H.} Maximum likelihood estimation in logistic regression models with 
a divering number of covariates~// Electron. J.~Stat., 2012. Vol.~6. P.~1838--1846.
\bibitem{Gramacy}
\Au{Gramacy R., Polson N.} Simulation-based regularized logistic regression~// 
Bayesian Anal., 2012. Vol.~7. No.\,3. P.~567--590.
\bibitem{rudin}
\Au{Rudin W.} Principles of mathematical analysis.~--- New York, Francisco, Toronto, London: 
McGraw-Hill Book Co., 1964.

\label{end\stat}
\bibitem{vectors}
\Au{Chen X.} A~new generalization of Chebyshev inequality for random vectors. 
{\sf http://arxiv.org/pdf/0707.0805v2.pdf}. 2007.
\end{thebibliography}
}
}

\end{multicols}