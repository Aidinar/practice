
\def\stat{timofeev}

\def\tit{ИДЕНТИФИКАЦИЯ ЗАВИСИМОСТЕЙ\\ ПРИЗНАКОВ
СТОХАСТИЧЕСКОЙ ПРИРОДЫ\\ НА~ОСНОВЕ РЕГРЕССИИ ДЕМИНГА}

\def\titkol{Идентификация зависимостей признаков
стохастической природы на~основе регрессии Деминга}

\def\autkol{В.\,С.~Тимофеев, В.\,Ю.~Щеколдин, А.\,Ю.~Тимофеева}

\def\aut{В.\,С.~Тимофеев$^1$, В.\,Ю.~Щеколдин$^2$, А.\,Ю.~Тимофеева$^3$}

\titel{\tit}{\aut}{\autkol}{\titkol}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Новосибирский государственный технический университет, netsc@rambler.ru}
\footnotetext[2]{Новосибирский государственный технический университет, raix@ngs.ru}
\footnotetext[3]{Новосибирский государственный технический университет, supernasty@mail.ru}

\vspace*{3pt}


  \Abst{Рассмотрены подходы к построению регрессионных зависимостей в
предположении стохастичности входных и выходных показателей. Предложена
оригинальная геометрическая интерпретация функционалов задачи оценивания параметров
для частных случаев регрессии Деминга. Доказано утверждение о взаимном расположении
прямой, обратной, диагональной и ортогональной регрессий. Получена величина смещения
и стандартного отклонения оценок параметров регрессий в зависимости от соотношения
весовых коэффициентов в модели Деминга.}

\vspace*{2pt}

  \KW{метод наименьших квадратов; регрессия Деминга; геометрическая интерпретация;
эллипс рассеяния}

\vspace*{3pt}

\vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}


\section{Введение}

  Одной из основных задач прикладного статистического анализа данных
является выявление и построение зависимостей. Для ее решения разработано
большое количество самых разнообразных методов, которые отличаются
друг от друга как применяемым аналитическим аппаратом, так и набором
условий и ограничений, при которых они могут быть корректно применены.

Наиболее широко проработана теоретическая база для метода наименьших
квадратов (МНК) и различных его модификаций, которые отличаются
простотой вычислений и понятной статистической интерпретацией
получаемых на их основе результатов. Одним из предположений МНК
является то, что значения входных переменных детерминированы
(неслучайны), а значения отклика имеют стохастическую природу. Однако
на практике при проведении экспериментов не всегда возможно обеспечить
выполнение этого условия. Например, даже при использовании современных
технических средств не всегда удается обеспечить точные заранее заданные
условиями эксперимента значения всех или некоторых входных факторов.
Это приводит к тому, что входные факторы также оказываются
стохастическими. Следовательно, применение МНК для идентификации
рассматриваемых моделей будет приводить к некоторым нежелательным
эффектам, таким как смещенность и неэффективность оценок,
гетероскедастичность и~др.

  Возможным выходом из этой ситуации является построение моделей, в
которых изначально предполагается стохастический характер всех
переменных. Для оценивания таких моделей разработан ряд методов,
каждый из которых имеет определенные ограничения по области
применения. Так, в методах группировки~[1, 2] предполагается, что
наблюдаемые значения независимых переменных упорядочены в
соответствии с их истинными значениями~[3]. 

Использование метода
инструментальных переменных~\cite{1-tim} связано с трудностями другого
плана: новые переменные, выбираемые в качестве инструментальных,
должны быть независимы от ошибок измерений регрессоров и тесно
коррелировать с заменяемыми переменными.

  Наличие проблем такого рода приводит к серь\-ез\-но\-му изменению
постановки решаемой задачи, а также к необходимости разработки, анализа
и применения специальных методов и алгоритмов ее решения.

  В представленной работе задача идентификации статистической
зависимости решается при помощи регрессии Деминга~[4]. Исследуется
техника оценивания такой регрессии, рассматриваются различные варианты
интерпретации получаемых результатов. Кроме того, акцентируется
внимание на особенностях этой постановки задачи и ее взаимосвязях с
традиционными методами, такими как МНК.

\begin{figure*}[b] %fig1
  \vspace*{1pt}
 \begin{center}
 \mbox{%
 \epsfxsize=161.764mm
 \epsfbox{tim-1.eps}
 }
 \end{center}
 \vspace*{-9pt}
  \Caption{Корреляционные поля рассматриваемых схем эксперимента}
  \end{figure*}

\section{Постановка задачи}

  Пусть исследуется зависимость между двумя признаками $(x,y)$, причем
признак~$x$ будем рас\-смат\-ри\-вать как входной, а признак $y$~--- как
выходной. По результатам экспериментов получена выборка
$\{(x_i,y_i)\}_{i=\overline{1,N}}$ значений этих признаков объемом~$N$.
В~зависимости от выбираемой схемы эксперимента и характера самих
признаков (стохастический или детерминированный) существует несколько
вариантов проведения экспериментов~[5]:
  \begin{itemize}
\item схема $S_1$: предполагается детерминированность входной
переменной при стохастическом характере выходной;
\item схема $S_2$: предполагается детерминированность выходной
переменной при стохастическом характере входной;
\item схема $S_3$: предполагается стохастический характер обеих
переменных.
\end{itemize}

  Для формализации предположений рас\-смот\-рен\-ных схем будем полагать,
что стохастический характер переменных обусловливается наличием
неконтролируемых ошибок, т.\,е.\ фактически вмес\-то пар $(x_i,y_i)$
фиксируются значения
  \begin{align}
  \xi_i&=x_i+\varepsilon_i^{(x)}\,;\label{e1-tim}\\
  \eta_i&= y_i+\varepsilon_i^{(y)}\,,\label{e2-tim}
  \end{align}
где $\varepsilon_i^{(x)}$ и $\varepsilon_i^{(y)}$~--- статистически независимые
случайные величины с нулевыми математическими ожиданиями и
постоянными дисперсиями $\sigma^2_{\varepsilon^{(x)}}$
и~$\sigma^2_{\varepsilon^{(y)}}$ соответственно. Распределения ошибок во
всех экспериментах считаются одинаковыми.

  Удобной графической интерпретацией результатов эксперимента является
корреляционное поле~\cite{6-tim}. Примеры корреляционных полей,
соответствующих схемам~$S_1$, $S_2$ и~$S_3$, приведены на
рис.~1,\,\textit{а}, 1,\,\textit{б} и~1,\,\textit{в} соответственно.

  

  Отметим, что применение одних и тех же методов для оценивания
зависимостей, соответ\-ст\-ву\-ющих рассмотренным корреляционным полям,
может приводить к существенным искажениям получаемых оценок и
строящихся на их основе интерпретационных выводов.

\section{Контурные эллипсы для~анализа корреляционного поля}

  Корреляционные поля, как правило, используются для визуального
(предварительного) анализа собранной статистической информации, по
итогам которого выдвигаются различные предположения\linebreak о наличии,
характере и форме изучаемой взаимосвязи. Поскольку визуальный анализ
всегда отличается известной степенью субъективности, целесо\-образно
проводить оценивание формы корреляционного поля на основе специальных
методов, среди которых одним из наиболее известных считается построение
контурных эллипсов (эл\-лип\-сов рассеяния).

  Базовым предположением этого метода является нормальность
распределения рассматриваемых случайных величин: $\xi\hm\sim
{\sf N}(\mu_\xi, \sigma_\xi)$ и $\eta\hm\sim
{\sf N}(\mu_\eta,\sigma_\eta)$. Согласно~\cite{6-tim}, при
статистической независимости переменных $\xi$ и~$\eta$ верно соотношение:
  \begin{equation}
  \left( \fr{\xi-\mu_\xi}{\sigma_\xi}\right)^2+ \left( \fr{\eta-\mu_\eta}
{\sigma_\eta} \right)^2 \sim \chi^2 (2)\,.
  \label{e3-tim}
  \end{equation}

  В этом случае граница соответствующего корреляционного поля может
быть описана некоторым контурным эллипсом~$C$. При этом вероятность
попадания произвольной точки $(\xi^{(0)},\eta^{(0)})$ внутрь эллипса равна
  $$
  {\sf P}\left\{ \left( \xi^{(0)},\eta^{(0)} \right)\in C\right\} ={\sf P}
  \left\{ \chi^2<\chi^2_{\mathrm{кр}}(1-\alpha,2)\right\}\,.
  $$

  Отметим, что главные оси эллипса~$C$ будут параллельны координатным
осям вследствие независимости~$\xi$ и~$\eta$.

  При работе с реальными данными необходимо строить оценку эллипса
рассеяния, определяемую выражением:
  $$
  \left( \fr{\xi-\overline{\xi}}{S_\xi}\right)^2+ \left( \fr{\eta-
\overline{\eta}}{S_\eta} \right)^2 = \chi^2_{
  \mathrm{кр}} (1-\alpha, 2)\,,
  $$
где $\chi^2_{\mathrm{кр}}(1-\alpha,2)$~--- критическое значение,
определяемое по таблицам $\chi^2$-рас\-пре\-де\-ле\-ния; $\alpha$~---
уровень значимости; $\overline\xi$ и~$\overline\eta$~--- выборочные средние;
$S_\xi$ и~$S_\eta$~--- выборочные среднеквадратические отклонения по~$\xi$
и~$\eta$ соответственно.

  При наличии линейной зависимости между переменными~$\xi$ и~$\eta$,
характеризуемой отличным от нуля коэффициентом корреляции
$\rho_{\xi\eta}$, выражение~(\ref{e3-tim}) будет принимать
  вид~\cite{7-tim, 8-tim}:
  \begin{multline*}
  \fr{1}{1-\rho_{\xi\eta}^2}\left(\left( \fr{\xi-\mu_\xi}{\sigma_\xi}\right)^2-
2\rho_{\xi\eta} \fr{\xi-\mu_\xi}{\sigma_\xi}\,\fr{\eta-\mu_\eta}{\sigma_\eta} +{}\right.\\
\left.{}+
\left( \fr{\eta-\mu_\eta}{\sigma_\eta}\right)^2 \right) \sim \chi^2(2)\,.
  \end{multline*}

  Оценка контурного эллипса может быть определена следующим образом:
  \begin{multline}
  \left( \fr{\xi-\overline{\xi}}{S_\xi} \right)^2 - 2r_{\xi\eta} \fr{\xi-
\overline{\xi}}{S_\xi}\, \fr{\eta-\overline{\eta}}{S_\eta}+ {}\\{}+\left( \fr{\eta-
\overline{\eta}}{S_\eta} \right)^2 =\left( 1-r_{\xi\eta}^2\right)
\chi^2_{\mathrm{кр}} (1-\alpha,2)\,,
  \label{e4-tim}
  \end{multline}
где $r_{\xi\eta}$~--- оценка коэффициента корреляции~$\rho_{\xi\eta}$.
Очевидно, что при статистической незави\-си\-мости признаков эллипс занимает
наибольший возможный объем, что соответствует нулевому значению
коэффициента корреляции и максимальной неопределенности при
прогнозировании.

\section{Обобщенная модель регрессии Деминга}

  Следующий этап анализа состоит в по\-стро\-ении и оценивании
аналитической формы изучаемой взаимосвязи. Дальнейшее изложение будет
проводиться в рамках наиболее простой линейной зависимости, модель
которой имеет вид:
  \begin{equation}
  y=\alpha+\beta x\,,
  \label{e5-tim}
  \end{equation}
где $\alpha$ и $\beta$~--- параметры, подлежащие оцениванию. Заметим, что
вследствие~(\ref{e1-tim}) и~(\ref{e2-tim}) будет рассматриваться зависимость
вида $\eta\hm=\alpha\hm+\beta\xi$.

  При оценивании параметров уравнения~(\ref{e5-tim}) в рамках
схемы~$S_1$ традиционно применяется метод наименьших
  квадратов~\cite{1-tim, 5-tim, 7-tim}, который может быть использован и
для схемы~$S_2$ путем идентификации модели обратной регрессии
($\xi\hm= \alpha^\prime\hm+\beta^\prime \eta$). В~случае третьей схемы
эксперимента такой подход может приводить к появлению существенно
смещенных, несостоятельных и неэффективных оценок~\cite{5-tim}.
Возможным решением этой проблемы может быть переход к обобщенной
модели регрессии
  Деминга~\cite{4-tim, 9-tim}.

  Регрессия Деминга, согласно~\cite{4-tim}, определяется как результат
решения оптимизационной задачи
  \begin{multline}
  \sum\limits_{i=1}^N \left[ w^2_x \left( \xi_i-x_i\right)^2 +w_y^2\left( \eta_i-
\alpha -\beta x_i\right)^2 \right] \to{}\\
{}\to \min\limits_{\alpha,\beta,x_i}\,,
  \label{e6-tim}
  \end{multline}
где $w_x$ и $w_y$~--- весовые коэффициенты по переменным~$x$ и~$y$
соответственно. Далее будем полагать, что они постоянны и не зависят от
номера наблюдения. Поскольку, в отличие от стандартной постановки
задачи оценивания параметров регрессии, решение задачи~(\ref{e6-tim})
зависит от неизвестных истинных значений переменной~$x$, то приравнивая
к нулю частную производную функционала в задаче~(\ref{e6-tim}) по
значениям~$x_i$, получим следующее выражение:
\begin{equation}
x_i = \fr{w^2_x \xi_i +w^2_y \beta (\eta_i-\alpha)}{w_x^2 + w_y^2 \beta^2}\,.
\label{e7-tim}
\end{equation}

  Учитывая соотношения~(\ref{e1-tim}) и~(\ref{e2-tim}), запишем
задачу~(\ref{e6-tim}) в виде:
  \begin{equation}
  \sum\limits_{i=1}^N \left[ \left( w_x \varepsilon_i^{(x)}\right)^2 +\left( w_y
\varepsilon_i^{(y)}\right)^2 \right] \to \min\limits_{\alpha,\beta, x_i}\,.
  \label{e8-tim}
  \end{equation}

  Выражения, находящиеся под знаком суммы в~(\ref{e8-tim}), с
геометрической точки зрения представляют собой квадраты диагоналей
прямоугольников со сторонами $\left\vert w_x \varepsilon_i^{(x)}\right\vert$ и
$\left\vert w_y \varepsilon_i^{(y)}\right\vert$, вершины которых
соответствуют точкам $(\xi_i,\eta_i)$ (см.\ рис.~1). Обозначая через
  $$
  e_i^{(x)}= -\fr{1}{\beta}\left( \eta_i -\alpha-\beta\xi_i\right)\,,\ e_i^{(y)}
=\eta_i-\alpha-\beta\xi_i
  $$
величины отклонений наблюдаемых значений от линии регрессии вдоль
координатных осей и используя~(\ref{e7-tim}), выразим взвешенные ошибки
в~(\ref{e8-tim}) через исходные данные $\{ (\xi_i,\eta_i)\}_{i=\overline{i,N}}$:
\begin{align*}
w_x\varepsilon_i^{(x)}&= -\fr{w_x w_y^2\beta^2} {w_x^2+ w_y^2\beta^2}
\,e^{(x)}_i\,;\\
 w_y \varepsilon_i^{(y)} &= \fr{w_y w_x^2}{w_x^2
+w_y^2\beta^2}\, e^{(y)}_i\,.
\end{align*}

  Тогда задачу минимизации~(\ref{e6-tim}) можно упростить, исключив
входную переменную~$x$:
  \begin{multline}
  \fr{w_x^2w_y^2}{w_x^2+w_y^2\beta^2}\sum\limits_{i=1}^N \left(
e_i^{(y)}\right)^2 ={}\\
{}= \fr{1}{1/w_y^2+(1/w_x^2)\beta^2} \sum\limits_{i=1}^N
\left( e_i^{(y)}\right)^2\to \min\limits_{\alpha,\beta}\,.
  \label{e9-tim}
  \end{multline}

  Из (\ref{e9-tim}) очевидно, что регрессия Деминга является обобщением
прямой и обратной регрессий при $w_x^2\hm\gg w_y^2$ и $w_y^2\hm\gg
w_x^2$ соответственно. Если предположить $w_x^2\hm=w_y^2$, то
полученная регрессия будет называться ортогональной.

  Для того чтобы выразить оценки параметров~$\alpha$, $\beta$ через
теоретические моменты распределения случайных величин~$\xi$, $\eta$ и
оценить смещение оценок, перейдем в задаче~(\ref{e9-tim}) от суммы к
математическому ожиданию:
  \begin{equation}
  \fr{1}{(1/w_y^2)+(1/w_x^2)\beta^2}\,{\sf E}\left( \eta-\alpha-\beta\xi\right)^2\to
\min\limits_{\alpha,\beta}\,.
  \label{e10-tim}
  \end{equation}

  Приравнивая к нулю частную производную функционала в
  задаче~(\ref{e10-tim}) по параметру~$\alpha$, получаем выражение:
  $$
  \alpha={\sf E}\eta-\beta {\sf E} \xi\,.
  $$

  Подставив это соотношение в частную производную от функционала
в~(\ref{e10-tim}) по параметру~$\beta$, приравняв ее к нулю и произведя
некоторые упрощения, получим следующее уравнение:
  \begin{multline*}
  \fr{1}{w_x^2}\,\beta {\sf E} \left( \left( \eta- {\sf E}\eta\right) -\beta\left( \xi - {\sf E}\xi\right)
\right)^2 +{}\\
{}+\left( \fr{1}{w_y^2} +\fr{1}{w_x^2}\,\beta^2 \right) {\sf E} \left( \xi \left(
\eta-{\sf E}\eta\right) -\beta \xi\left( \xi-{\sf E}\xi\right) \right) =0\,.
  \end{multline*}
После упрощения этого соотношения с учетом справедливости равенства
${\sf E}(\zeta_1(\zeta_2\hm-{\sf E}\zeta_2))\hm ={\sf E}((\zeta_1\hm-{\sf E}\zeta_1) (\zeta_2\hm-
{\sf E}\zeta_2))$ для случайных величин~$\zeta_1$ и~$\zeta_2$, уравнение примет
такой вид:
\begin{equation}
\lambda^2 \sigma_{\xi\eta}\beta^2 - \left( \lambda^2 \sigma^2_\eta-
\sigma^2_\xi\right) \beta -\sigma_{\xi\eta}=0\,,
\label{e11-tim}
\end{equation}
где $\sigma_{\xi\eta}$~--- ковариация признаков~$\xi$ и~$\eta$,
$\lambda^2\hm=w_y^2/w_x^2$. Решая квадратное уравнение
относительно~$\beta$, получаем:
\begin{multline}
\beta= \fr{1}{\sigma_{\xi\eta}}\left(
\vphantom{\sqrt{\left( \fr{\lambda^2\sigma^2_\eta -
\sigma^2_\xi}{2\lambda^2}\right)^2
+\fr{\sigma^2_{\xi\eta}}{\lambda^2}}}
 \fr{\lambda^2\sigma^2_\eta -
\sigma_\xi^2}{2\lambda^2}\pm {}\right.\\
\left.{}\pm\sqrt{\left( \fr{\lambda^2\sigma^2_\eta -
\sigma^2_\xi}{2\lambda^2}\right)^2
+\fr{\sigma^2_{\xi\eta}}{\lambda^2}}\,\right).
\label{e12-tim}
\end{multline}

  Поскольку решение~(\ref{e12-tim}) должно иметь тот же знак, что и
ковариация $\sigma_{\xi\eta}$, и второе слагаемое в скобках всегда больше
первого, то второй сомножитель в~(\ref{e12-tim}) должен быть
положительным, что достигается путем выбора знака~<<$+$>>. Это
позволяет далее ограничиться рассмотрением только ситуации
$\sigma_{\xi\eta}\hm>0$, в противном случае все последующие рассуждения
останутся справедливыми с точностью до знака ковариации.

  Проанализируем полученное решение~(\ref{e12-tim}). Предполагая, что
переменная~$x$ имеет дис\-пер\-сию~$\sigma_x^2$, воспользуемся
следующими выражениями для моментов случайных величин~$\xi$
и~$\eta$~\cite{10-tim}:
  $$
  \sigma^2_\xi=\sigma^2_x+\sigma^2_{\varepsilon^{(x)}}\,;\ \ 
  \sigma^2_\eta=\beta^2\sigma^2_x+\sigma^2_{\varepsilon^{(y)}}\,;\ \ 
  \sigma_{\xi\eta}= \beta \sigma_x^2
  $$
и, подставляя их в~(\ref{e12-tim}), получим:
\begin{equation}
\beta_D =\fr{\Psi_0}{2\lambda^2}+\sqrt{\left( \fr{\Psi_0}{2\lambda^2}\right)^2
+\fr{1}{\lambda^2}}\,,
\label{e13-tim}
\end{equation}
где $\Psi_0=\lambda^2\beta \hm- 1/\beta
+(\gamma_x^2/(\beta\delta^2))(\lambda^2 \hm- \delta^2)$; $\delta^2\hm=
\sigma^2_{\varepsilon^{(x)}}/\sigma^2_{\varepsilon^{(y)}}$;
$\gamma_x^2\hm=\sigma^2_{\varepsilon^{(x)}}/\sigma_x^2$~--- доля
дисперсии случайной ошибки~$\varepsilon^{(x)}$ в дисперсии входной
переменной~$x$, называемая уровнем шума. На практике при нахождении
оценки $\hat{\beta}_D$ регрессии Деминга в~(\ref{e13-tim}) следует заменить
все теоретические моменты их выборочными аналогами.

  Из (\ref{e13-tim}) следует, что если $\lambda\hm=\delta$, т.\,е.\ веса
в~(\ref{e6-tim}) обратно пропорциональны стандартным отклонениям
ошибок соответствующих переменных, то $E\hat{\beta}_D\hm=\beta$. Но на
практике, как правило, дис\-пер\-сии ошибок исследуемых признаков 
неизвестны, поэтому следует рассмотреть различные варианты соотношения
весов $w_x^2$ и~$w_y^2$.
  \begin{enumerate}[1.]
  \item
Пусть $w_x^2\gg w_y^2$, т.\,е. $\lambda\hm\to 0$. Тогда несложно
заметить, что в пределе уравнение~(\ref{e11-tim}) становится линейным
по~$\beta$, а угловой коэффициент регрессии Деминга, с учетом
определения коэффициента корреляции $\rho_{\xi\eta} \hm=
\sigma_{\xi\eta}/(\sigma_\xi \sigma_\eta)$, будет определяться как
\begin{equation}
\beta^{(y)} = \fr{\sigma_{\xi\eta}}{\sigma^2_\xi} =\fr{\sigma_\eta}
{\sigma_\xi}\,\rho_{\xi\eta}\,,
\label{e14-tim}
\end{equation}
что соответствует случаю прямой регрессии. Из~(\ref{e14-tim}) можно
получить смещение оценки Деминга
$$
\lim\limits_{\lambda\to 0} {\sf E} \hat{\beta}^{(y)} ={\sf E}\left( \fr{\beta \sigma_x^2}
{\sigma_x^2+\sigma^2_{\varepsilon^{(x)}}} \right) = \fr{1}
{1+\gamma_x^2}\,\beta\,.
$$

  В рамках схемы $S_1$ (т.\,е.\ при отсутствии ошибок по~$x$) считается,
что $\gamma_x^2\hm=0$; следовательно, оценка параметра~$\beta$ будет
несмещенной. Если же модель прямой регрессии будет оцениваться при
наличии шума по~$x$, оценка параметра~$\beta$ будет занижаться
относительно истинного его значения.
\item Пусть $w_x^2\ll w_y^2$, т.\,е.\ $\lambda\hm\to \infty$. В~этом случае
при делении уравнения~(\ref{e11-tim}) на~$\lambda^2$ и переходе к
пределу имеем:
$$
\beta \left( \sigma_{\xi\eta}\beta - \sigma_\eta^2\right) =0\,.
$$
Опуская тривиальное решение $\beta\hm=0$, получим, что угловой
коэффициент регрессии Деминга имеет вид:
\begin{equation}
\beta^{(x)} =\fr{\sigma^2_\eta}{\sigma_{\xi\eta}}=\fr{\sigma_\eta} {\sigma_\xi}\,
\fr{1}{\rho_{\xi\eta}}\,,
\label{e15-tim}
\end{equation}
что соответствует случаю обратной регрессии. Из~(\ref{e15-tim}) смещение
оценки Деминга определяется следующим образом:
\begin{multline*}
\lim\limits_{\lambda\to\infty} {\sf E} \hat{\beta}^{(x)} = \beta
+\fr{\gamma_x^2}{\beta\delta^2} = \left( 1+\fr{\gamma_x^2}{\beta^2\delta^2}
\right) \beta ={}\\
{}=\left(1+\gamma_y^2\right) \beta\,.
\end{multline*}

  Если отсутствуют ошибки по~$y$ ($\gamma_y^2\hm=0$), что
соответствует схеме~$S_2$, оценка параметра~$\beta$ оказывается
несмещенной. При наличии таких ошибок эта оценка будет приобретать
смещение в сторону завышения.
\item Пусть $w_x^2=w_y^2$, т.\,е.\ $\lambda\hm=1$. Получаемая регрессия
будет ортогональной с угловым коэффициентом, равным
\begin{multline}
\beta^\perp = \fr{\sigma_\eta^2-\sigma_\xi^2}{2\sigma_{\xi\eta}} +
\sqrt{\left(\fr{\sigma_\eta^2-\sigma_\xi^2}{2\sigma_{\xi\eta}}\right)^2+1}={}\\
{}=
\fr{2\rho_{\xi\eta}\Lambda}{1-\Lambda^2 +\sqrt{(1-\Lambda^2)^2
+4\rho^2_{\xi\eta} \Lambda^2}}\,,
\label{e16-tim}
\end{multline}
где $\Lambda=\sigma_\eta/\sigma_\xi$. Этот случай соответствует
схеме~$S_3$ с одинаковой дисперсией ошибок.
\item Пусть отношение дисперсий ошибок переменных пропорционально
отношению дисперсий наблюдаемых переменных
($\lambda^2=1/\Lambda^2$ или, для выборочных оценок, $\hat{\lambda}^2
=S^2_\xi/S^2_\eta$), что также соответствует схеме~$S_3$. В~этом случае
оценка Деминга принимает вид:
\begin{equation}
\hat{\rho}_D =\mathrm{sign}\, \left( r_{\xi\eta}\right) \fr{S_\eta}{S_\xi}\,.
\label{e17-tim}
\end{equation}

  Оценка~(\ref{e17-tim}) получила название оценки диагональной регрессии,
введенной Р.~Фришем в 1929~г.~\cite{11-tim}. Отметим, что без учета знака
выражение~(\ref{e17-tim}) представляет собой среднее гео\-мет\-ри\-че\-ское
оценок прямой и обратной регрессии. Следовательно, ее смещение будет
зависеть от уровней шума по~$x$ и~$y$ одновременно, т.\,е.
  $$
  E\hat{\beta}_D =  \beta  \sqrt{\fr{1+\gamma_y^2}{1+\gamma^2_x}}\,.
  $$
\end{enumerate}

\section{Графическая интерпретация регрессии Деминга}

  Построенная при тех или иных предположениях о соотношении дисперсий
ошибок оценка па\-ра\-мет\-ра~$\beta$ модели~(\ref{e5-tim}) представляет собой
тангенс угла наклона линии регрессии относительно положительного
направления оси абсцисс. Следовательно, расположение линии регрессии в
пространстве признаков будет варьироваться в зависимости от выбора
весовых коэффициентов $w_x$, $w_y$, что определяет свойства
минимизируемого функционала~(\ref{e9-tim}). Для построения графической
интерпретации регрессии Деминга (рис.~2) функционал~(\ref{e9-tim}) может
быть записан в следующих эквивалентных формах:
  \begin{equation}
   \fr{1}{1+\lambda\beta^2}\sum\limits_{i=1}^N \left( w_y e_i^{(y)}\right)^2\to
\min\limits_{\alpha,\beta}
  \label{e18-tim}
  \end{equation}
или
\begin{equation}
\fr{\lambda\beta^2}{1+\lambda\beta^2}\sum\limits_{i=1}^N \left( w_x e_i^{(x)}
\right)^2 \to \min\limits_{\alpha,\beta}\,.
\label{e19-tim}
\end{equation}

  Поскольку МНК предполагает минимизацию квадратов расстояний от
точек корреляционного поля до искомой линии регрессии, то можно
сопоставить каждой из этих точек квадрат, сторона которого определяется
соответствующим расстоянием (см.\ рис.~2). В~случае прямой регрессии это
квадрат со стороной $e^{(y)}$, т.\,е.\ отрезком~$AA_y$, что при
суммировании по всем наблюдениям приводит\linebreak\vspace*{-12pt} 

\pagebreak

\begin{center}  %fig2
\vspace*{-3pt}
\mbox{%
 \epsfxsize=75.632mm
 \epsfbox{tim-2.eps}
 }
 \end{center}
% \vspace*{6pt}
{{\figurename~2}\ \ \small{Графическая интерпретация остатков регрессий Деминга}}




%\pagebreak

\vspace*{15pt}

\addtocounter{figure}{1}

\noindent
 к задаче~(\ref{e18-tim}) при
$\lambda\hm=0$. В~случае обратной регрессии
 сторона квадрата
равна~$e^{(x)}$, т.\,е.\ длине отрезка~$AA_x$,
а решаемая задача имеет
вид~(\ref{e19-tim}) при $\lambda \hm =\infty$. Промежуточное положение
между ними занимает ортогональная регрессия, для которой сторона
квадрата равна~$AA_{\perp}$, причем оценивание параметров можно
осуществлять по любой из форм~(\ref{e18-tim}) или~(\ref{e19-tim}). Заметим,
что длина отрезка~$AA_{\perp}$ есть минимальное расстояние от точки до
линии регрессии, а условие $\lambda\hm=1$ означает равенство дисперсий
ошибок по обеим переменным. Из рис.~2 также следует, что при увеличении
дисперсии ошибок по переменной~$x$ рассматриваемый квадрат
поворачивается относительно точки~$A$ вверх, пока не достигнет
предельного положения, соответствующего обратной регрессии. Если же
увеличивается дисперсия ошибок по переменной~$y$, то квадрат
поворачивается в другую сторону до предельного положения,
определяемого линией прямой регрессии.

 

  Следовательно, крайними случаями являются прямая и обратная
регрессии, в то время как линии ортогональной и диагональной регрессии
всегда расположены между ними. Кроме того, линия ортогональной
регрессии совпадает с главной осью контурного эллипса~(\ref{e4-tim})~\cite{6-tim, 7-tim}. Авторами доказано утверждение, определяющее
расположение линии ортогональной регрессии относительно линий прямой,
обратной и диагональной регрессий.

  \smallskip

  \noindent
  \textbf{Утверждение.} \textit{При любом значении коэффициента
корреляции~$r_{\xi\eta}$ ортогональная регрессия находится на наибольшем
расстоянии (по значению угла наклона)}:
\begin{enumerate}[(1)]
\item \textit{от прямой регрессии, если соответствующая диагональная
регрессия образует угол $\pi/3$ с положительным направлением оси~$X$};
\item \textit{от обратной регрессии, если соответствующая диагональная
регрессия образует угол $\pi/6$ с положительным направлением оси~$X$}.
\end{enumerate}

\smallskip

\noindent
  Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \ Вследствие симметрии расположения
ортогональной регрессии относительно прямой и обратной (см.\ выражения~(14)--(16)
для $\beta^{(y)}$, $\beta^{(x)}$ и $\beta^\perp$), достаточно ограничиться
рас\-смот\-ре\-ни\-ем только прямой регрессии. Кроме того, без потери общности
будем считать положительной корреляцию признаков $\rho_{\xi\eta}\hm>0$.
Вычислим угол между ортогональной и прямой регрессией как угол между
двумя прямыми~\cite{12-tim} с угловыми коэффициентами $\beta^\perp$
и~$\beta^{(y)}$:
  \begin{multline*}
  \tg\varphi = \fr{\beta^\perp -\beta^{(y)}}{1+\beta^\perp \beta^{(y)}} ={}\\
  {}=
  \fr{\rho_{\xi\eta}\Lambda \left(1+\Lambda^2-\sqrt{(1-\Lambda^2)^2 +4
\rho^2_{\xi\eta}\Lambda^2}\,\right)} {1-\Lambda^2 +2\rho_{\xi\eta}\Lambda +
  \sqrt{(1-\Lambda^2)^2+4\rho^2_{\xi\eta}\Lambda^2}}\,.
  \end{multline*}

  Для определения максимального расстояния между регрессиями при
фиксированном коэффициенте корреляции вычислим производную
по~$\Lambda$ и приравняем к нулю числитель полученного выражения:
  \begin{multline*}
  2\rho_{\xi\eta}(1-\rho_{\xi\eta}) (1+\rho_{\xi\eta})(\Lambda^2-3)\times{}\\
  {}\times\left(
\Lambda^2 -1-\sqrt{\left(\Lambda^2-1\right)^2+\left(
2\rho_{\xi\eta}\Lambda\right)^2}\right) =0\,.
  \end{multline*}

  Очевидно, что последний сомножитель никогда не обращается в нуль.
Решение, получаемое при $\rho_{\xi\eta}\hm=0$, не имеет смысла, поскольку
ему соответствует случай отсутствия линейной зависимости между
признаками, а случаи $\rho_{\xi\eta}\hm=1$ и $\rho_{\xi\eta}\hm=-1$
означают функциональную линейную зависимость, когда все
рассматриваемые регрессии совпадают. Тогда наибольшее расстояние между
регрессиями будет достигаться при выполнении условия
$\Lambda^2\hm=\sigma_\eta^2/\sigma_\xi^2\hm=3$. Из~(\ref{e17-tim})
очевидно, что угловой коэффициент диагональной регрессии есть
$\Lambda\hm=\sqrt{3}$, что соответствует углу~$\pi/3$, образуемому с
положительным направлением оси~$X$. Утверждение доказано.

\section{Свойства оценки регрессии Деминга}

  Кроме расположения линий регрессии в пространстве признаков
задаваемое соотношение весовых коэффициентов~$w_x$ и~$w_y$
однозначно определяет и смещение оценок регрессии. Поэтому
определенный интерес представляет исследование влияния выбора
значений~$\lambda$ на отклонение оценки Деминга~$\beta_D$ от истинного
значения~$\beta$.

  При фиксированных значениях $\gamma_x^2$ и~$\beta$ определим
зависимость $\Delta\beta=\beta_D/\beta$ от задаваемых величин~$\lambda^2$
и коэффициента $\kappa\hm= \lambda^2/\delta^2$, показывающего, во
сколько раз заданное соотношение весов~$\lambda^2$ отличается от
соотношения дисперсий ошибок~$\delta^2$. Далее будем использовать
величину~$\Delta\beta$ как относительное смещение оценки Деминга
$\beta_D$ от истинного значения параметра~$\beta$. Без потери общности
считаем $\beta\hm>0$. Используя~(\ref{e13-tim}), выразим $\Delta\beta$
через~$\kappa$, $\gamma_x^2$~и
  $$
  \gamma_y^2= \fr{\sigma^2_{\varepsilon^{(y)}}}{\sigma^2_y}=
  \fr{\sigma^2_{\varepsilon^{(y)}}}{\beta^2\sigma^2_x}=
  \fr{\sigma^2_{\varepsilon^{(x)}}}{\delta^2}\,\fr{1}{\beta^2\sigma^2_x} =
\fr{\gamma_x^2}{\beta^2\delta^2}= \fr{\kappa}{\beta^2
\lambda^2}\,\gamma_x^2,
  $$
тогда
\begin{equation}
\Delta\beta =\Psi_1+\sqrt{\Psi_1^2+\fr{\gamma_y^2}{\kappa \gamma^2_x}}\,,
\label{e20-tim}
\end{equation}
где
$$
\Psi_1=\fr{1}{2}+\fr{1}{2}\,\gamma_y^2\left( 1-\fr{1}{\kappa}-\fr{1}{\kappa
\gamma_x^2}\right)\,.
$$
Оказывается, что в~(\ref{e20-tim}) $\Delta\beta$ не зависит от истинного
значения параметра~$\beta$. Поэтому можно проследить взаимосвязь между
$\Delta\beta$ и~$\kappa$ при фиксированных значениях уровней шума
по~$x$ и~$y$ (рис.~3). Для удобства интерпретации зависимости
представлены в двойном логарифмическом масштабе и взяты по модулю.
При этом левая часть графика попадает во вторую координатную четверть,
зеркально отражаясь относительно оси абсцисс. Тогда очевидно, что при
отклонении~$\lambda^2$ от истинного значения~$\delta^2$ в б$\acute{\mbox{о}}$льшую
сторону ($\ln\kappa\hm>0$) значение параметра $\beta_D$ будет завышено
по сравнению с истинным, а при
 $\kappa\hm<1$ ($\ln\kappa\hm<0$),
наоборот, занижено. При этом\linebreak

\begin{center}  %fig3
\vspace*{9pt}
 \mbox{%
 \epsfxsize=72.926mm
 \epsfbox{tim-3.eps}
 }
 \end{center}
% \vspace*{6pt}
{{\figurename~3}\ \ \small{Зависимость соотношения оценки и истинного значения параметра~$\beta$ от
$\ln \kappa$ при $\gamma_x^2\hm=0{,}05$ и заданном уровне шума $\gamma_y^2$: \textit{1}~--- 
0,2; \textit{2}~--- 0,1; \textit{3}~--- 0,05; \textit{4}~--- 0,025;
\textit{5}~--- 0,0125}}

%\vspace*{15pt}

\addtocounter{figure}{1}



\noindent
 величина отклонения $\Delta\beta$ при
значениях~$\kappa$ и $1/\kappa$  различна и зависит от уровня шума.
Отметим, что графики на рис.~3 несимметричны относительно оси ординат,
за исключением случая, когда $\gamma_x^2\hm=\gamma_y^2$. Это
позволяет условно разделить всю совокупность функций~(\ref{e20-tim}) на
два подмножества. Если $\gamma_x^2\hm<\gamma_y^2$ (линии, проходящие
выше графика функции при $\gamma_x^2\hm=\gamma_y^2$), то ошибка в
оценивании коэффициента~$\beta$ будет возрастать быстрее при
$\kappa\hm>1$, чем при $\kappa\hm<1$, т.\,е.\ если оценка отношения
дисперсий ошибок~$\lambda^2$ будет больше их истинного отношения.
В~другом подмножестве, когда уровень шума по~$x$ больше уровня шума
по~$y$, ошибка в оценивании коэффициента~$\beta$ будет возрастать
быстрее при $\kappa\hm<1$, чем при $\kappa\hm>1$.


  Такая особенность поведения функций~(\ref{e20-tim}) позволяет
предложить следующую рекомендацию для выбора величины соотношения
весов~$\lambda^2$: если известно, что уровень шума по переменной~$x$
больше уровня шума по~$y$, то с точки зрения повышения точности
оценивания параметра~$\beta$ выгоднее завышать отношение
весов~$\lambda^2$, чем занижать его в такое же число раз. Аналогичный
вывод можно сделать и для случая, когда уровень шума по~$x$ меньше
уровня шума по~$y$.

  Еще одним вариантом графической интерпретации результатов
оценивания при использовании регрессии Деминга может стать предлагаемая
авторами <<воронка Деминга>> (рис.~4). Она представляет собой
изображение семейства кривых, опи\-сы\-ва\-ющих зависимость оценок
стандартных отклонений $\hat{\sigma}_{\beta_D}$ оценок регрессии Деминга
от их смещения $\Delta\beta$ в логарифмическом масштабе при
фиксированном значении шума по $x$ ($\gamma_x^2\hm=0{,}05$) и разных
уровнях шума по~$y$. Оценки стандартных отклонений
$\hat{\sigma}_{\beta_D}$ получены по результатам статистического
моделирования с параметрами: $\beta\hm=1$, $X\sim {\sf N}(10,5)$,
${N}\hm=100$, $\varepsilon_i^{(x)}\sim {\sf N}(0,
\sigma_{\varepsilon^{(x)}})$, $\varepsilon_i^{(y)} \sim
{\sf N}(0,\sigma_{\varepsilon^{(y)}})$, число повторений~--- 10\,000.
При этом значения стандартных отклонений ошибок
$\sigma_{\varepsilon^{(x)}}$ и $\sigma_{\varepsilon^{(y)}}$ рассчитывались
исходя из фиксированных уровней шума~$\gamma_x^2$ и~$\gamma_y^2$,
а также оценки стандартного отклонения переменной~$X$. В~процессе
моделирования соотношение весовых коэффициентов~$\lambda^2$
задавалось регулярным образом по правилу:
  $$
  \lambda^2=
  \begin{cases}
  \delta^2 e^{0{,}3t}\,, &\ t=-12+j\,, \enskip \gamma_y^2>0{,}0125\,;\\[3pt]
  \delta^2 e^{0{,}5t}\,, &\ t=-30{,}25+1{,}25j\,, \enskip \gamma^2_y\leq 0{,}0125\,,
  \end{cases}
  $$
где $j=\overline{1,30}$. Кроме того, отдельно рассмотрены частные случаи
регрессии Деминга: прямая, обратная и ортогональная, оценки
параметра~$\beta$ которых определялись из~(\ref{e14-tim})--(\ref{e16-tim})
путем замены теоретических моментов выборочными.

  \begin{figure*} %fig4
   \vspace*{1pt}
 \begin{center}
 \mbox{%
 \epsfxsize=90.012mm
 \epsfbox{tim-4.eps}
 }
 \end{center}
 \vspace*{-6pt}
  \Caption{<<Воронка Деминга>>: \textit{1}~--- $\gamma_y^2\hm=0{,}000001$; \textit{2}~---
0,0125; \textit{3}~--- 0,025; \textit{4}~--- 0,05; \textit{5}~--- 0,1; \textit{6}~--- 0,15;
  \textit{7}~--- $\gamma_y^2\hm=0{,}2$; \textit{8}~--- прямая регрессия; \textit{9}~--- обратная
  регрессия; \textit{10}~---
ортогональная регрессия}
\vspace*{3pt}
  \end{figure*}

  Как видно из получаемого представления (см.\ рис.~4), границы воронки
соответствуют прямой и обратной регрессиям (левая и правая границы
соответственно), а линия, разделяющая воронку на две части~---
ортогональной. При этом, поскольку в эксперименте предполагается
варьирование отношения весов при фиксированном
значении~$\gamma^2_x$, левая граница воронки представляет собой
прямую, параллельную оси ординат, а правая~--- кривую, которая удаляется
от начала координат по мере увеличения веса, соответствующего
переменной~$y$. В~целом, если оценка параметра~$\beta$ занижена по
сравнению с его истинным значением, с увеличением смещения снижается
стандартная ошибка оценки, достигая своего минимального значения в
случае прямой регрессии. При завышении оценки параметра~$\beta$ ее
стандартное отклонение увеличивается с ростом смещения, причем в ряде
случаев (при уровне шума, превышающем 5\%) достигает максимального
значения и несколько снижается.

  Все представленные выше исследования проводились в предположении
(явном или неявном), что соотношение дисперсии ошибок является известной
величиной. В~то же время на практике проблема оценивания соотношения
дисперсий ошибок остается одной из самых сложных. Традиционный подход
предполагает, что дисперсии в точках факторного пространства должны
оцениваться по повторным наблюдениям. Однако такие наблюдения
зачастую или отсутствуют в выборке, или их доля достаточно мала, что не
позволяет с требуемой степенью надежности оценивать соответствующие
дисперсии. Выходом из такой ситуации может стать применение методов
репликации выборки таких, например, как бутстреп или метод <<складного
ножа>>
  (jack-knife)~\cite{13-tim}.

\section{Заключение}

  В работе рассмотрены три основные схемы эксперимента, отличающиеся
разной степенью детерминированности входных и выходных переменных
модели. Отмечены некоторые статистические свойства контурных эллипсов,
применяемых для оценивания конфигурации корреляционных полей.

  Исследованы различные варианты регрессии Деминга как одной из
наиболее общих регрессионных моделей, включая формы представления
оптимизируемых функционалов, свойства получаемых оценок регрессии.
Предложена оригинальная геометрическая интерпретация регрессии
Деминга, иллюстрирующая особенности изменения элементов
оптимизируемого функционала в зависимости от соотношения весовых
коэффициентов. Доказано утверждение о взаимном расположении линий
прямой, обратной, ортогональной и диагональной регрессий. Исследован
характер влияния соотношения уровней шума по обеим переменным на
величину смещения и стандартного отклонения оценки регрессии Деминга.
Обнаруженные закономерности представлены в виде <<воронки Деминга>>.

  Полученные результаты и предложенные способы их интерпретации
позволяют уточнить выводы, формируемые в процессе построения и
по\-сле\-ду\-юще\-го анализа зависимостей признаков стохастической природы.

\vspace*{-6pt}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{99}

\bibitem{2-tim} %1
\Au{Wald A.} The fitting of straight lines if both variables are subject to error~// Ann.
Math. Stat., 1940. Vol.~11. No.\,3. P.~284--300.

\bibitem{1-tim} %2
\Au{Демиденко Е.\,З.} Линейная и нелинейная регрессия.~--- М.: Финансы и
статистика, 1981.

\bibitem{3-tim}
\Au{Айвазян С.\,А., Богдановский И.\,М.} Методы статистического исследования
парных зависимостей в схемах конфлюентного анализа и их применение~//
Заводская лаборатория, 1974. Т.~40. №\,3. С.~285--295.
\bibitem{4-tim}
\Au{Deming W.\,E.} Statistical adjustment of data.~--- N.Y.: Dover Publications, 2011.
\bibitem{5-tim}
\Au{Айвазян С.\,А., Енюков И.\,С., Мешалкин~Л.\,Д.} Прикладная статистика:
Исследование зависимостей.~--- М.: Финансы и статистика, 1985.
\bibitem{6-tim}
\Au{Хальд А.} Математическая статистика с техническими приложениями.~--- М.:
Изд-во иностранной литературы, 1956.
\bibitem{7-tim}
\Au{Крамер Г.\,М.} Математические методы статистики.~--- М.: Мир, 1975.
\bibitem{8-tim}
\Au{Львовский Е.\,Н.} Статистические методы построения эмпирических
формул.~--- М.: Высшая школа, 1988.
\bibitem{9-tim}
\Au{Jones T.\,A.} Fitting straight lines when both variables are subject to error.
I.~Maximum likelihood and least-squares estimation~// Math. Geology, 1979.
Vol.~11. No.\,1. P.~1--25.
\bibitem{10-tim}
\Au{Кендалл М., Стьюарт А.} Статистические выводы и связи.~--- М.: Наука,
1973.
\bibitem{11-tim}
\Au{Frisch R.} Correlation and scatter in statistical variables~// Nord. Stat.~J., 1929.
No.\,1. P.~36--102.

\label{end\stat}

\bibitem{12-tim}
\Au{Гельфанд И.\,М.} Лекции по линейной алгебре.~--- М.: Наука, 1971.
\bibitem{13-tim}
\Au{Эфрон Б.} Нетрадиционные методы многомерного статистического
анализа.~--- М.: Финансы и статистика, 1988.
\end{thebibliography}

}
}


\end{multicols}