\def\stat{malashenko}

\def\tit{АНАЛИЗ ЗАДЕРЖЕК ПРИ ДИСПЕТЧЕРИЗАЦИИ ОДНОРОДНЫХ ЗАДАНИЙ В~УСЛОВИЯХ 
НЕОПРЕДЕЛЕННОСТИ}

\def\titkol{Анализ задержек при диспетчеризации однородных заданий в~условиях 
неопределенности}

\def\autkol{Ю.\,Е.~Малашенко, И.\,А.~Назарова}

\def\aut{Ю.\,Е.~Малашенко$^1$, И.\,А.~Назарова$^2$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{Работа выполнена при финансовой поддержке РФФИ (проект 11-01-00515а).}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Вычислительный центр им.\ А.\,А.~Дородницына 
Российской академии наук, malash09@ccas.ru} 
\footnotetext[2]{Вычислительный центр им.\ А.\,А.~Дородницына Российской 
академии наук, irina-nazar@yandex.ru}



\Abst{Рассматривается проблема управления  ресурсоемкими вычислительными заданиями 
переборного типа, 
допускающими распараллеливание по данным. За\-яв\-ки-за\-да\-чи  поступают в 
систему в произвольные моменты времени по одной или группами, время их решения 
заранее не известно. 
Для планирования процесса обработки используется оптимизационная модель, 
которая базируется на текущей информации о выполнении задания: длительности 
пребывания в системе и объеме уже обработанных данных. С~помощью модели для каждого 
задания определяется доля данных для обработки в плановом периоде. При расчетах 
используются оценки необходимых вычислительных затрат и  не делается предположений 
о законах распределения неизвестных характеристик заявок. 
Предложенное правило диспетчеризации позволяет в динамике формировать порядок 
выполнения заданий,  приоритет получают менее трудоемкие задачи.}

\KW{ресурсоемкие задачи; параллельные
вычисления; оптимизация управления;  принцип гарантированного
результата}

\DOI{10.14357/19922264140102}

\vskip 16pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}

\section{Введение}

Рассмотрим частный случай проблемы управления ресурсоемкими
вычислениями~\cite{Inf1-13}.  Диспетчеру специализированной системы,
состоящей из большого числа однотипных вычислительных модулей,
корпоративные пользователи в случайные моменты времени предоставляют
для решения однородные citu-за\-да\-чи~\cite{Mal412}. Поиск решения  для
каждой из citu-за\-дач  производится переборными алгоритмическими
процедурами  (далее~--- $\psi$-про\-це\-ду\-ры), которые сводятся к
просмотру набора исходных данных, разбитых на отдельные одинаковые
по размеру неделимые содержательно значимые фрагменты, и поиску
среди них \textit{уникального фрагмента}, удовлетворяющего
некоторому наперед заданному  критерию.  Citu-за\-да\-ние завершается,
если:
\begin{enumerate}[(1)]
\item  искомый фрагмент найден. Тогда соответствующая citu-задача
считается решенной;
\item
 просмотрен весь массив, но ничего найти не удалось. Citu-за\-да\-ча
считается нерешенной, но задание~--- выполненным.
\end{enumerate}

Массив исходных данных для каждого из заданий становится известен
после анализа  на входе в систему. Заявки одинаково важны, многие из
них взаимосвязаны, и по условию они должны быть завершены  все
вместе и каждая в отдельности как можно быстрее. В~противном случае
найденное решение может потерять актуальность и не будет
представлять интереса.

Все citu-задания являются ресурсоемкими, выполняются в режиме
реального времени и допускают распараллеливание по данным. В~общем
случае можно указать только верхнюю оценку для объема вычислений,
необходимых для выполнения конкретного задания; имеет ли решение
соответ\-ст\-ву\-ющая содержательная задача~--- неизвестно. Считается, что
большинство  citu-за\-дач имеют решение.

Рассмотрим модель~\cite{Inf1-13}, в которой citu-за\-да\-ния выполняются
высокопроизводительной специализированной вы\-чис\-ли\-тель\-ной сис\-те\-мой
(СВС),  со\-сто\-ящей из центрального управляющего устрой\-ст\-ва
(ЦУП-устрой\-ст\-ва) и набора однотипных  единичных вычислительных
модулей (ЕВ-модулей). Под\linebreak специализированной элементарной
вычислительной операцией (СЭВ) опе\-ра\-ци\-ей будем понимать\linebreak просмотр
$\psi$-про\-це\-ду\-рой отдельного неделимого\linebreak содержательно значимого
фрагмента данных и проверку  его уникальности.  Производительность
каж\-до\-го ЕВ-мо\-ду\-ля  определяется числом СЭВ-опе\-ра\-ций, выполняемых в
единицу времени, а мощ\-ность СВС равна суммарной производительности
входящих в нее ЕВ-мо\-ду\-лей. В~рамках модельного описания считается,
что архитектура СВС позволяет просматривать наборы фрагментов в
произвольном порядке, в том числе параллельно, т.\,е.\ любая часть
данных может обрабатываться независимо от других.

Для идентификации \textit{уникального фрагмента} для каждого
citu-за\-да\-ния требуется выполнить  \textit{вычислительную работу}~---
произвести определенное, заранее не известное число СЭВ-опе\-ра\-ций.
Искомый фрагмент может быть найден в любой момент после начала
просмотра, что в лучшем случае потребует небольших вычислительных
затрат, в худшем~--- безрезультатном~---  полного перебора всего
массива данных соответствующей заявки. Назовем \textit{необходимой
работой}~\cite{Prep1-13} число СЭВ-опе\-ра\-ций, которые требуются  для
выделения уникального фрагмента из набора данных конкретного
задания. Длительность  поиска уникального фрагмента зависит как от
априори не известного объема \textit{необходимой работы}, так и  от
стратегии  диспетчеризации в~СВС.

В рассматриваемой модели предполагается, что все предоставляемые
citu-за\-да\-чи \textit{равнозначны}, а пользователи
\textit{равноправны} в рамках правил распределения вычислительных
ресурсов, не являются антагонистами и стремятся к достижению
некоторой общей корпоративной цели, которая состоит в  наискорейшем
извлечении всей информации из имеющихся данных. Стратегии управления
СВС не должны быть дискриминирующими по отношению к той или иной
группе заявок.

Для анализа диспетчерских правил воспользуемся концептуальным
подходом, общая схема которого предложена в~\cite{Inf1-13, Prep1-13}
и состоит в следующем. При  организации вычислений не делается
никаких гипотез о времени поступления citu-за\-дач, объеме
\textit{необходимой работы} или наличии \textit{уникальных фрагментов} в
поступивших данных. В~модели используются только следующие параметры
и величины:
\begin{itemize}
\item фактическое время поступления задания в СВС;
\item  число обработанных фрагментов данных на текущий момент времени;
\item  производительность СВС. 
\end{itemize}

Все остальные неизвестные параметры рас\-смат\-ри\-ва\-ют\-ся как
неопределенность. Таким образом, в данной статье проблема
планирования работ и  распределения ограниченных вычислительных
ресурсов  для скорейшего выполнения требований пользователей
анализируется в рамках методологии исследо\-вания операций.

В условиях неопределенности управление СВС  при выполнении
\textit{работ} разбивается контрольными точками на отдельные этапы~---
плановые периоды, или операционные окна. Предполагается, что
диспетчер СВС выбирает  длительность планового периода исходя из
характера данных поступающих заявок, а планирование \textit{работ}
производится на ближайшее операционное окно.


Основными  объектами предложенной модели~\cite{Inf1-13, Prep1-13}
являются: база данных заданий (БД заданий),  буфер данных текущих
работ (ТР-бу\-фер), программный комплекс планирования и анализа
(ПК-план). При моделировании  процесса выполнения ресурсоемких
вычислений предполагается, что любая информация о citu-заданиях,
вновь поступивших или находящихся в обработке, помещается и далее
хранится в БД заданий. Все записи из последней  в реальном времени
доступны для анализа  ПК-планом.

В ПК-плане подготавливается список заданий, и для каждого из них
определяется размер подмассива фрагментов данных для обработки на
текущий плановый период. Выделенные подмассивы исходных данных
формируют пакет текущих работ (ТР-па\-кет). В~контрольный момент
времени корректируется содержимое БД заданий, составляется ТР-па\-кет,
который поступает в  ТР-бу\-фер,  и  в СВС начинается обработка
пакета. По завершении выполнения ТР-па\-ке\-та наступает следующая
контрольная диспетчерская точка~---  момент создания очередного списка
заданий,~--- и вся процедура, т.\,е.\ обращение к БД заданий,
формирование ТР-па\-ке\-та и его обработка, повторяется с учетом
изменения состояния СВС и со\-ста\-ва пакета заявок.

В ПК-плане процесс обработки citu-за\-да\-ний в СВС описывается сис\-те\-мой
квазидинамических уравнений и неравенств. В~рамках модели строятся
гарантированные оценки~\cite{germ} и формулируется оптимизационная
задача~\cite{Suh}, условия которой учитывают всю текущую информацию
(длительность пребывания задания в системе, объем обработанных
данных и~др.). Решение оптимизационной задачи позволяет определить
неулучшаемые относительные показатели времени пребывания каждого
конкретного задания в СВС и значения параметров управления сис\-темой.

Изучение частного случая проб\-ле\-мы управ\-ле\-ния однородными
ресурсоемкими вычислениями является продолжением исследований,
начатых в~\cite{Gol10}. В~настоящей работе результаты, полученные 
в~\cite{Prep11, Gol12} с помощью имитационного моделирования,
анализируются с позиции теории исследования операций.

\section{Относительные задержки при~выполнении заданий}

Для формального описания заданий будет использован ряд обозначений.

Пусть $z_{n}$~--- задание-задача с собственным идентификационным номером~$n$.

Предполагается, что для каждого задания~$z_n$ в момент его
поступления~ $t_n^0$ в СВС становится известна нормативная величина
$\textbf{Z}_{n}$~---  общее число  неделимых фрагментов данных
задания~$z_{n}$, которые необходимо будет обработать, если среди
них нет уникального.

Для любого $z_n$ неизвестной величиной является~$\psi_{n}$~--- общее
число неделимых фрагментов данных, которые  необходимо будет
обработать для заявки~$z_{n}$,  т.\,е.\ $\psi_{n}$~---
\textit{необходимая работа}, которую следует произвести для поиска
уникального фрагмента или полного перебора данных задания~$z_{n}$
объемом $\textbf{Z}_{n}$.

Монопольным режимом будем называть такой способ организации работы
СВС, при котором на  всех имеющихся ЕВ-мо\-ду\-лях одновременно
просматриваются фрагменты данных единственного задания~$z_n$.

Далее обозначим:

$\tau_n$~--- \textit{абсолютное время } выполнения задания $z_n$ в монопольном режиме СВС;

$P_0$~--- мощность (суммарная производительность) СВС, которая
измеряется  числом СЭВ-опе\-ра\-ций, которые могут быть выполнены всей
СВС в единицу времени. Тогда   в соответствии с определением~$\psi_n$ 
для каждого задания  $z_n$ объем \textit{необходимой работы} составит
$$
\psi_n \hm   =   \tau_n P_0\,.
$$

Далее в зависимости от контекста  переменная~$t$ будет обозначать
либо текущий момент календарного времени, либо контрольную точку~---
момент принятия решения о составе нового ТР-па\-ке\-та.

Для множества $\mathcal{Z}(t)$~---  заданий $z_n$, находящихся в СВС в момент $t$, --- обозначим:

$\mathcal{N}(t)$ --- множество   номеров заданий из $\mathcal{Z}(t)$;

$N(t) = |\mathcal{N}(t)|$~--- общее число заданий в $\mathcal{Z}(t)$;

$\Delta(t)$ --- операционное окно, плановый период, промежуток
(интервал) времени с началом в момент~$t$, измеряемый в единицах
календарного времени.  Длительность $\Delta(t)$  определяется
заранее или выбирается   ПК-планом.


 Обозначим через
$w_{n}(\Delta(t))$ число неделимых фрагментов данных для задания~$z_{n}$, 
кото\-рые войдут в состав ТР-па\-ке\-та, будут помещены в
\mbox{ТР-бу\-фер} и в момент времени~$t$ начнут просматри\-вать\-ся по команде
ЦУП-устрой\-ст\-ва на выделенных ЕВ-мо\-ду\-лях. Набор подмассивов данных
ТР-па\-ке\-та  обозначим через $ \textbf{w}(t) \hm= \{ w_{1}(\Delta(t)),
w_{2}(\Delta(t)), \ldots$\linebreak $\ldots , w_{N(t)}(\Delta(t))\}$. В~рамках модели
предполагается, что ТР-па\-кет начинает обрабатываться в контрольный
момент $t$ и будет завершен до конца планового периода, т.\,е.\ не
позднее  $t \hm+ \Delta(t)$.

Пусть $W^{\Delta} (\Delta(t))$~--- максимальное суммарное число
СЭВ-опе\-ра\-ций, которые планируется выполнить на заданном интервале
планирования $ \Delta(t)$,
$$
W^{\Delta} (\Delta(t)) = P_0 \Delta(t)\,.
$$

В рамках модельного описания $W^{\Delta} (\Delta(t))$~--- предельно
допустимое суммарное число фрагментов заданий из $\mathcal{Z}(t)$, которые
могут быть помещены в ТР-бу\-фер в момент времени~$t$ и будут
гарантированно  завершены не позднее  $t \hm+ \Delta(t)$.

Пусть $t_n^0$~--- время поступления задания~$z_n$ в СВС, и
предположим, что в момент~$t$ оно еще не завершено. Обозначим через
$z^-_{n}(t)$ число фрагментов данных, которые уже были просмотрены
для~$z_n$   до момента~$t$.

При формировании  ТР-па\-ке\-та предполагается, что весь комплект
$\textbf{w} (t)$ будет  обработан за время $\Delta(t)$. Если для
задания~$z_{n}$ выделяется  $w_{n}(\Delta(t))$ фрагментов данных в
состав ТР-па\-ке\-та   в момент~$t$, то к окончанию планового периода
$\Delta(t)$ справедливо равенство:
$$
z^-_{n}(t + \Delta(t))= z^-_{n}(t) + w_{n}(\Delta(t))\,,\enskip n \in \mathcal{N}(t + \Delta(t))\,. 
$$


Предположим, что в поднаборе $w_{n}(\Delta(t))$ либо находится
уникальный фрагмент данных задачи~$z_n$, либо $z_n$ не имеет
решения, но обработка $w_{n}(\Delta(t))$ завершает  выполнение
задания. Тогда значение $ z^-_{n}(t \hm+ \Delta(t))\hm=
z^-_{n}(t)\hm + w_{n}(\Delta(t))$ является оценкой сверху для общего
числа фрагментов данных, которые  в действительности необходимо
просмотреть для завершения задания~$z_n$   или для решения
соответствующей ему задачи. В~этом случае справедливо неравенство:
$$
 z^-_{n}(t) + w_{n}(\Delta(t)) \ge \psi_n\,,
 $$
а величина
\begin{equation}
\overline{\tau}_n (\Delta(t)) = \fr{z^-_{n}(t) + w_{n}(\Delta(t))}{P_0} 
\label{e1a-mal}
\end{equation}
в момент времени $t + \Delta(t)$ является оценкой сверху для~$\tau_n$~--- 
\textit{абсолютного времени} выполнения задания в монопольном режиме --- и
$$
 \overline{\tau}_n (\Delta(t))  \ge \tau_n\,.
 $$

Если же $w_{n}(\Delta(t))$ не содержит уникального фрагмента и в
момент  $t \hm+ \Delta(t)$  выполнение задания не
завершается, то обработка $z_n$ будет продолжена. При этом
\[ z^-_{n}(t) + w_{n}(\Delta(t)) \le \psi_n, \]
а величина~(1) в момент  $t+ \Delta(t)$ окажется оценкой снизу для $\tau_n$:
\[ \overline{\tau}_n (\Delta(t))  \le \tau_n.\]


Обозначим через $T_n(t)$ длительность пребывания  $z_n$ в СВС на момент $t$,
\[T_n (t)= t  - t_n^0, \]
где  $t_n^0$ --- время поступления задания $z_n$ в СВС.

Предположим, что  задание $z_n$ будет  закончено к моменту $t +
\Delta(t)$. Тогда время пребывания $z_n$ в СВС составит
\[T_n (t + \Delta(t))= t  + \Delta(t) - t_n^0. \]

Введем переменную
\begin{equation}
\chi_n (t + \Delta(t)) = \fr{\overline{\tau}_n (\Delta(t))}{T_n (t + \Delta(t))}\,,
\label{e1-mal}
\end{equation}
которую будем называть \textit{показателем относительной задержки
выполнения задания}~$z_{n}$ к моменту времени $t \hm+ \Delta(t)$. По
значению $\chi_n(t \hm+ \Delta(t))$ можно оценить, какую долю
составляет \textit{абсолютное время} обработки  $z_n$ в монопольном
режиме от фактического времени пребывания в СВС при условии, что оно
будет завершено к моменту $t \hm+ \Delta(t)$.

Величину, обратную~(\ref{e1-mal}), обозначим  $\ae_n (t \hm+ \Delta(t))\hm =
(\chi_n (t + \Delta(t)))^{-1}$ и назовем коэф\-фи\-циентом относительной
задержки. Значение\linebreak ${\ae}_n (t\hm + \Delta(t))$ показывает, во сколько
раз   время фактического пребывания в системе оказалось больше
необходимого времени обработки, т.\,е.\ характеризует задержку
выполнения $z_n$ относительно \textit{абсолютного времени} его
просмотра в монопольном режиме. Свойства функции ${\ae}_n (t \hm+
\Delta(t))$ подробно изучались в~\cite{Prep11, Gol12}, а результаты
ее применения при диспетчеризации изложены ниже в разд.~4.

В ПК-плане величины выполняемых подзаданий $w_{n}(\Delta(t))$
выбираются так, чтобы  для всех заданий~$z_{n}$ минимальная величина
$\chi_n(t \hm+ \Delta(t))$ оказалась максимальной из возможных.
Формально,  ведется поиск
\begin{equation}
\theta^*(t) = \max_{w}  \min\limits_{1 \le n \le N (t)}  
\chi_n (t + \Delta(t))\,. \label{e2-mal}
\end{equation}

Пусть в момент времени $t$ заданы плановый период $\Delta(t)$ и
предельно допустимый объем ТР-па\-ке\-та $W^{\Delta}(\Delta (t))$. 
В~сделанных предположениях поиск решения~(\ref{e2-mal}) можно свести к следующей
задаче линейного программирования:

найти
\begin{equation}
 \theta^*(t) = \max_{\theta,  w,  W, \chi} \theta(t) 
 \label{e3-mal}
 \end{equation}

при ограничениях:
\begin{itemize}
\item на $\theta(t)$~--- минимальную величину показателя относительной задержки:
\begin{equation}
\hspace*{-7mm}\left.
\begin{array}{rl}
  \theta(t + \Delta(t)) & \le \chi_n(t + \Delta(t))\,; \\[9pt]
\chi_n(t + \Delta(t)) &= \displaystyle\fr{z^-_{n}(t) + w_{n}(\Delta(t))}
{P_0 T_n(t + \Delta(t))}\,, \ n \in \mathcal{N}(t)\,; 
                    \end{array}
                    \!\right \} \!\!\!
                    \label{e4-mal}
                    \end{equation}
\item
на размеры поднаборов фрагментов данных:
\begin{equation}
\hspace*{-4mm}\left.  \begin{array}{rl}
  \textbf{Z}_{n} - z^-_n(t) &\ge  w_n(\Delta (t)) \ge 0\,,\ n \in \mathcal{N}(t);\\[9pt]
 \sum\limits_{n \in \mathcal{N}(t)} w_n(\Delta (t)) &=  W (\Delta (t))\,; \\[9pt]
W^{\Delta} (\Delta (t)) &\ge  W (\Delta (t))\,. 
                    \end{array}\!
                    \right \} \!\!
                    \label{e5-mal}
                    \end{equation}
                    \end{itemize}

Задача~(\ref{e3-mal})--(\ref{e5-mal}) может быть решена стандартными методами линейного
программирования~\cite{Dan}. Пусть найдено максимальное значение
функционала $\theta^*(t)$. Из множества оптимальных решений~(\ref{e3-mal})--(\ref{e5-mal})
для полученного $\theta^*(t)$ выделим вектор $\textbf{w}^*(t)$ по
следующему правилу:
\begin{equation}
 w^*_n(\Delta(t)) = \begin{cases}
0,  &\\
&\hspace*{-45mm}\mbox{если } \theta^*(t) \le \fr{z^-_{n}(t)}{P_0\cdot T_n(t + \Delta(t))}\,; \\
\theta^*(t)P_0 T_n(t + \Delta(t)) - z^-_{n}(t)\,, &\ \\
&\hspace*{-45mm}\mbox{если } \theta^*(t) > \fr{z^-_{n}(t)}{P_0 T_n(t + \Delta(t))}\,. 
\end{cases}
\label{e6-mal}
\end{equation}

Для заданного $\theta^*(t)$ и вектора $\textbf{w}^*(\Delta(t)) \hm=(
w^*_1(\Delta(t)),  w^*_2(\Delta(t)), \ldots ,  w^*_{N(t)}(\Delta(t))$
согласно~(\ref{e6-mal}) введем множества:
\begin{align*}
\mathcal{N}^0(t) &= \{ n \ | \ w^*_n(\Delta(t)) = 0,  n \in \mathcal{N}(t)\}\,,  \\
\mathcal{N}^*(t) &= \{ n \ | \ w^*_n(\Delta(t)) > 0,  n \in \mathcal{N}(t)\}\,.  
\end{align*}
Из определения следует
$$
\mathcal{N}(t) =\mathcal{N}^*(t) \bigcup \mathcal{N}^0(t)\,.
$$
Вектор значений $ \langle \theta^*(t), w_1^*(\Delta(t)), \ldots  ,
w_{N(t)}^*(\Delta(t))\rangle$ является оптимальным решением~(\ref{e3-mal})--(\ref{e5-mal}). 
Согласно~(\ref{e6-mal}) размеры подзаданий, планируемых для выполнения к моменту    $t\hm +
\Delta(t)$,  удовлетворяют равенствам:
\begin{equation*}
 \theta^*(t) =  \fr{  z_n^-(t) + w_n^*(\Delta (t)) }
 {  P_0   T_n(t  + \Delta(t))}\,, \enskip n \in \mathcal{N}^*(t)\,,
 \end{equation*}
 и согласно~(\ref{e5-mal}), (\ref{e6-mal})
$$
   \sum\limits_{n \in \mathcal{N}(t)} w_n^*(\Delta(t)) =
   \sum\limits_{n \in \mathcal{N}^*(t)} w_n^*(\Delta(t)) = W^* (\Delta (t))\,. 
   $$

После преобразований получим:
$$
\theta^*(t) = \fr{W^*(\Delta(t)) + \sum\limits_{n \in \mathcal{N}^*(t)}  z_n^-(t)}{ P_0 
\sum\limits_{n \in \mathcal{N}^*(t)}  T_n(t  + \Delta(t))}\,;   
$$


\vspace*{-12pt}

\noindent
\begin{multline*}
w_n^*(\Delta (t))= \theta^*(t)   P_0  T_n(t+\Delta(t))  - z_n^-(t) =  {}\\
{} =T_n(t + \Delta(t)) \fr{W^*(\Delta(t)) + \sum\limits_{n \in \mathcal{N}^*(t)}  z_n^-(t)}
{ \sum\limits_{n \in \mathcal{N}^*(t)} T_n(t + \Delta(t)) } - z_n^-(t)\,,\\
 n \in \mathcal{N}^*(t)\,.
\end{multline*}

Вектор значений $ \textbf{w}^*(t) \hm= \langle w_1^*(\Delta(t)),
w_2^*(\Delta(t)), \ldots$\linebreak $\ldots , w_{N(t)}^*(\Delta(t)) \rangle $ назовем
распределением выполняемых подзаданий $w_{n}(\Delta(t))$ по критерию~(\ref{e2-mal}). 
Для всех $z_n$, завершенных на интервале $\Delta(t)$,
показатель относительной задержки выполнения будет не меньше
$\theta^*(t)$.

Указанное распределение предполагает, что для всех заявок-заданий
просматривается  доля фрагментов данных с учетом оценок их
\textit{абсолютного времени}  решения  и  фактического пребывания в
СВС. Правило обработки заданий, основанное на учете показателя
относительной задержки выполнения, будем обозначать аббревиатурой
SWAP (\textit{от англ}.\ short work ahead performance) и называть
SWAP-дис\-пет\-че\-ри\-за\-цией.

\vspace*{-6pt}

\section{Анализ результатов выполнения пакета текущих работ}

\vspace*{-2pt}

Предположим, что осуществляется SWAP-дис\-пет\-че\-ри\-за\-ция поступающих
заданий. Исследуем результаты реализации такой стратегии. Будем
считать, что в  контрольный момент~$t$ на осно\-ва\-нии  решения задачи~(\ref{e3-mal})--(\ref{e5-mal}) 
и согласно~(\ref{e6-mal}) был сформирован ТР-па\-кет  $\textbf{w}^*(t )
= \left\langle\vphantom{w_2^*(\Delta(t)), \ldots , 
w_{N(t)}^*(\Delta(t))} w_1^*(\Delta(t)),\right.$\linebreak $\left. w_2^*(\Delta(t)), \ldots , 
w_{N(t)}^*(\Delta(t))\right\rangle$, обработка которого завершилась в течение
планового  пе\-ри\-о\-да $\Delta(t)$.

Пусть некоторая задача $z_{i_+}$ решена на интервале $\Delta(t)$.
Тогда в момент $t\hm + \Delta(t)$ справедливы следующие неравенства:

\noindent
\begin{align*}
 z^-_{i_+}(t)+w^*_{i_+}(\Delta(t))& \ge \psi_{i_+}\,; \\
\fr{z^-_{i_+}(t)+w^*_{i_+}(\Delta(t))}{P_0} &\ge \tau_{i_+}\,, 
\end{align*}
где $\tau_{i_+}$~--- \textit{абсолютное время} обработки задания $z_{i_+}$ в 
монопольном режиме.

Значения $ \theta^*(t), w_{i_+}^*(\Delta(t))$~--- оптимальное
решение~(\ref{e3-mal})--(\ref{e5-mal}) и согласно~(\ref{e6-mal}) удовлетворяют соотношениям:
\begin{align*}
 \theta^*(t)  (t + \Delta(t) - t^0_{i_+}) &=  
 \theta^*(t)  T_{i_+}(t + \Delta(t))  = {}\\
 &\hspace*{1mm}{}= \fr{z^-_{i_+}(t)+w^*_{i_+}(\Delta(t))}{P_0}  
 \ge \tau_{i_+}\,;\\
P_0 \theta^*(t)  (t + \Delta(t) - t^0_{i_+}) & \ge \psi_{i_+}\,, 
\end{align*}

\columnbreak

\noindent
а также справедливы неравенства
\begin{equation}
\left.  \begin{array}{rl}
 \theta^*(t) (t + \Delta(t)) &\ge \tau_{i_+} +   t^0_{i_+} \theta^*(t)\,;\\[9pt]
P_0 \theta^*(t)(t + \Delta(t)) &\ge \psi_{i_+} + t^0_{i_+} P_0 \theta^*(t) \,.
                    \end{array}
                    \right \}
                    \label{e7-mal}
                    \end{equation}

Рассмотрим группу заданий, которые поступили в СВС раньше или
одновременно с $z_{i_+}$, но не были завершены к моменту $t \hm+
\Delta(t)$. Обозначим множество номеров таких заданий через
$$
\mathcal{N}^+(i_+, t + \Delta(t)) = \{n \, \vert \,  t^0_{n} \le  t^0_{i_+}\,,\ 
n \in \mathcal{N}(t + \Delta(t))\}\,.
$$

Для любого задания $z_{j}$,  $j \hm\in \mathcal{N}^+(i_+, t + \Delta(t))$, к
моменту $t \hm+ \Delta(t)$ уникальный фрагмент не обнаружен, поэтому
справедливы оценки:
\begin{align*}
\psi_{j} &\ge   z^-_{j}(t)+w^*_{j}(\Delta(t))\,;\\
\tau_{j} &\ge   \fr{z^-_{j}(t)+w^*_{j}(\Delta(t))}{P_0}\,.
\end{align*}
Поскольку $w_{j}^*(\Delta(t))$~--- оптимальное решение~(\ref{e3-mal})--(\ref{e5-mal}), то
согласно~(\ref{e6-mal})
\begin{multline*}
\hspace*{-3.31975pt}\overline{\tau}_{j}(\Delta(t)) =  
\fr{z^-_{j}(t)+w^*_{j}(\Delta(t))}{P_0} =  \theta^*(t)  T_{j}(t + \Delta(t))  ={}\\
{} = \theta^*(t)  (t + \Delta(t) - t^0_{j})\le \tau_{j}
\end{multline*}
и справедливы неравенства:
\begin{equation}
 \left.  \begin{array}{rl}
\theta^*(t) (t + \Delta(t)) &\le \tau_{j} +   t^0_{j} \theta^*(t)\,;\\[9pt]
P_0 \theta^*(t)(t + \Delta(t)) &\le \psi_{j} + t^0_{j} P_0 \theta^*(t) \,.
                    \end{array}
                    \right \} \label{e8-mal}
                    \end{equation}

Сравнивая~(\ref{e7-mal}) и~(\ref{e8-mal}), получаем:
\begin{align*}
\tau_{j} +  \theta^*(t)  t^0_{j}& \ge \tau_{i_+} +  \theta^*(t)   t^0_{i_+}   \,;
\\
\tau_{j} &\ge   \tau_{i_+} +  \theta^*(t) (t^0_{i_+} -  t^0_{j})\,. 
\end{align*}
Так как $j \in \mathcal{N}^+(i_+, t + \Delta(t))$, то $t^0_{i_+} \hm\ge t^0_{j}$ и
$$   \tau_{j}  \ge \tau_{i_+}\,;\quad
\psi_{j}  \ge \psi_{i_+}\,. 
$$
Следовательно, для задачи $z_{i_+}$, завершенной на интервале
$\Delta(t)$, абсолютное время решения меньше, чем у незаконченных
заданий, поступивших в СВС одновременно или даже раньше $z_{i_+}$.
Другими словами, для любого задания~$z_{i_+}$, выполненного к
моменту  $t \hm+ \Delta(t)$, объем необходимой работы меньше, чем у
всех других заданий, поступивших в СВС одновременно или даже раньше~$z_{i_+}$, 
но не завершенных к моменту $t \hm+ \Delta(t)$.

\section{Одновременное поступление заданий в~систему}

Для иллюстрации особенностей SWAP-дис\-пет\-че\-ри\-за\-ции рассмотрим процесс
выполнения $t^0$-ком\-плек\-та~---  группы  однородных заданий, которые
поступили в СВС одновременно в момент~$t^0$.

Пусть  в момент  $t \hm= t^0$ заданы плановый период~$\Delta$ и общее
число фрагментов  $W^\Delta(\Delta)$, которые могут быть обработаны
за этот интервал.  Фактически    $W^\Delta(\Delta)$ определяется
вычислительными ресурсами, выделяемыми для выполнения
$t^0$-ком\-плекта.

Пусть  для $t^0$-комплекта в момент~$t^0$ для всех~$z_n$, $n\hm \in
\mathcal{N}(t^0)$, $ t_n^0 \hm= t^0$, $z_n^-(t^0) \hm= 0, \textbf{Z}_n \hm=
\textbf{Z}^0$, $N(t^0)\hm = N^0$, $P_0 \hm= P$, $\Delta(t) \hm= \Delta$. Кроме
того, в рамках примера, не ограничивая общности, предположим, что
$N^0 \textbf{Z}^0\hm \gg W^{\Delta} (\Delta )$. Запишем задачу~(\ref{e3-mal})--(\ref{e5-mal})
для этих исходных данных:

найти
\begin{equation}
 \theta^*(t^0) = \max\limits_{\theta, w} \theta(t^0)
 \label{e9-mal}
 \end{equation}

при ограничениях
\begin{gather*}
  \hspace*{-20pt}\theta(t^0)  \le \chi_n(t^0 + \Delta)\,,\hspace*{30mm} \\
\hspace*{15mm}\chi_n(t^0 + \Delta) = \fr{\displaystyle  w_{n}(\Delta)}{\displaystyle P \Delta}\,, \ 
n \in \mathcal{N}(t^0)\,;\\
 \sum\limits_{n \in \mathcal{N}(t^0)} w_n(\Delta ) \le  W^{\Delta} (\Delta )\,; \\
 \textbf{Z}^0 \ge w_n(\Delta ) \ge 0\,,\  n \in \mathcal{N}(t^0)\,.
 \end{gather*}
Согласно разд.~3, оптимальное решение задачи~(\ref{e9-mal}) для всех $n \hm\in
\mathcal{N}(t^0)$:
$$
w^*_n(\Delta ) = w^* = \fr{ W^{\Delta} (\Delta ) }{ N^0}\,.
$$
Таким образом, суммарный вычислительный <<ресурс>> делится на равные
части между всеми заданиями. Следовательно, для всех заданий $z_n, n
\hm\in \mathcal{N}(t^0)$, на интервале~$ \Delta$ предполагается обработать
одинаковое число фрагментов данных~--- $ w^*$, и ТР-па\-кет состоит из
равных  по размеру поднаборов данных всех задач.

В некоторый момент времени одна из задач будет решена. Пусть это
произошло в момент~$\hat t$ и решена $l$-я задача. Будем считать,
что~$\hat t$ является началом нового планового периода. При этом в
момент $t \hm= \hat t$  $ \mathcal{N}(t)\hm = 
\mathcal{N}(\hat t)\hm = \{1, 2, \ldots l \hm- 1,
l+1, \ldots , N(t^0)\}$ и  для любого $n\hm \in \mathcal{N}(\hat t)$ 
$z^-_n(t) \hm= z^-(\hat t)$, $T_n(t ) \hm=  \hat t \hm- t^0$.

Перепишем~(\ref{e3-mal})--(\ref{e5-mal}) для этих условий  в момент $t \hm= \hat t$:

найти
$$
\theta^*(\hat t) = \max\limits_{\theta, w} \theta(\hat t)        
$$

 при ограничениях
 \begin{gather*}
   \hspace*{-15mm}\theta(\hat t)  \le \chi_n(\hat t + \Delta)\,,\hspace*{25mm} \\
\hspace*{10mm}\chi_n(\hat t + \Delta) = \fr{z^-(\hat t) + w_{n}(\Delta)}{ P ( \hat t + \Delta - t^0) }\,, \ 
n \in \mathcal{N}(t^0)\,;\\
  \sum\limits_{n \in \mathcal{N}(\hat t )} w_n(\Delta ) \le  W^{\Delta} (\Delta )\,;\\
 \textbf{Z}^0 - z^-(\hat t) \ge  w_n(\Delta) \ge 0, n \in \mathcal{N}(\hat t)\,.
\end{gather*}
Согласно разд.~3, оптимальное решение задачи для всех $n \hm\in
\mathcal{N}(\hat t)$ состоит из равных  по размеру поднаборов данных:
$$
w^*_n(\Delta ) = w^* = \fr{W^{\Delta} (\Delta ) }{N(\hat t)} =  
\fr{ W^{\Delta} (\Delta ) }{ N^0 - 1}\,.
$$
Цепочку приведенных рассуждений можно продолжить дальше, при этом
оптимальный ТР-па\-кет после окончания очередной задачи будет состоять
из равных  по размеру поднаборов данных всех нерешенных на данный
момент задач.

Описанная стратегия обработки $t^0$-ком\-плек\-та однородных
citu-за\-да\-ний в~\cite{Prep11, Gol12} была названа
\textit{параллельной} обработкой ТР-па\-ке\-та и состояла в следующем: в
момент~$t$ каждому заданию~$z_n$  назначался некоторый фиксированный
набор ЕВ-мо\-ду\-лей, число которых для всех заданий комплекта
одинаково. Например, про\-грам\-ма-дис\-пет\-чер  формировала
соответствующий список, где указывала, какие ЕВ-мо\-ду\-ли  начиная с
момента~$t$ будут выполнять конкретное задание~$z_n$. При этом если
некоторая задача~$z_l$ была решена  в момент~$t$, то освободившийся
ресурс~---  работоспособные  ЕВ-мо\-ду\-ли~--- был разделен поровну и
использован ЦУП-устройством для обработки тех заданий~$z_j$, которые
еще не завершены.

В качестве примера рассмотрим выполнение\linebreak $t^0$-ком\-плек\-та  из $N^0 \hm>
1$ заданий, в котором все задачи требуют различных объемов
\textit{необходимой работы}~$\psi_n$. Кроме того, известно, что
ровно  одна из задач не имеет решения и для ее окончания потребуется
просмотреть все данные.

При SWAP-диспет\-че\-ри\-за\-ции  данного $t^0$-ком\-плек\-та первой будет
решена задача с минимальным объемом \textit{необходимой работы}.
Обозначим ее~$z_1$. Следующей по  порядку  из системы выйдет задача
с минимальным значением \textit{необходимой работы} из оставшихся,
обозначим ее через~$z_2$ и~т.\,д. В~результате все задания окажутся
перенумерованы по возрастанию объемов \textit{работы}, необходимой
для выполнения. Единственное задание, которое требует полного
перебора данных, завершится последним, получит номер~$N^0$, и для
него $\psi_{N^0} \hm= \textbf{Z}^0$. При этом
$$
\psi_1 < \psi_2 < \psi_3 < \cdots < \psi_{N^0 - 1} < \psi_{N^0} = \textbf{Z}^0\,.  
$$

Обозначим через $\psi^*$ объем \textit{необходимой работы} для
завершения последней задачи, имеющей решение, т.\,е.\ положим $\psi^*
\hm= \psi_{N^0 - 1}$.

Пусть задача $z_{N^0 - 1}$ решена в момент времени~$t^*$. Тогда для
единственного незавершенного задания~$z_{N^0}$ к этому моменту просмотрено
$$
z^-_{N^0 }(t^*)  = \psi_{N^0 - 1} = \psi^* 
$$
фрагментов и найдены все уникальные фрагменты рассматриваемого
$t^0$-ком\-плек\-та. Таким образом, к моменту времени~$t^*$ СВС обработала в сумме

\noindent
\begin{equation}
 \Psi^*_{\mathrm{par}} = \sum\limits_{n = 1}^{N^0 - 1} \psi_n +  
 z^-_{N^0 }(t^*) = \sum\limits_{n = 1}^{N^0 - 1} \psi_n + \psi^* 
 \label{e10-mal}
 \end{equation}
фрагментов данных для всех задач, включая единственную незавершенную.

В~\cite{Prep11, Gol12} рассматривалась также альтернативная схема
выполнения, при которой  задания $z_n$ выполнялись  в  случайном
порядке одно за другим, каж\-дое сразу на всех работоспособных
ЕВ-мо\-ду\-лях. Данное правило предполагало, что как только очередная
задача~$z_l$ завершена,  сразу начинается обработка набора данных
следующего задания, выбранного случайным образом из $\mathcal{Z}(t)$, и было
названо \textit{последовательным} монопольным режимом. Исследуем,
каким окажется объем \textit{необходимой работы} для обнаружения
всех уникальных фрагментов для рассмотренного выше примера
$t^0$-ком\-плек\-та при условии, что он выполняется последовательно.
Будем считать, что задания заранее пронумерованы в соответствии с
объемом \textit{необходимой работы}, т.\,е.\ в том порядке, в котором
они покидают систему при параллельной дисциплине обслуживания.

Согласно приведенному в~\cite{Prep11, Gol12} правилу в момент~$t^0$
очередность выполнения заданий в монопольном режиме при
последовательной обработке определяется по жребию. Тогда только в
одном случае из~$N^0$ задание~$z_{N^0}$ окажется в очереди строго на
последнем месте, а все уникальные фрагменты будут идентифицированы
до начала выполнения~$z_{N^0}$. Всего при этом   будет обработано

\noindent
\begin{equation}
\Psi^{\min}_{seq} = \sum\limits_{n = 1}^{N^0 - 1} \psi_n 
\label{e11-mal}
\end{equation} 
фрагментов.

Для случаев, когда задание~$z_{N^0}$ оказывается в очереди на любом
месте, кроме последнего, для идентификации всех уникальных фрагментов
необходимо будет обработать

\noindent
$$
\Psi^{\max}_{\mathrm{seq}} = \sum\limits_{n = 1}^{N^0 - 1} \psi_n + \textbf{Z}_{N^0} 
$$
фрагментов данных. Сравнивая эту величину с ~(\ref{e10-mal}) и~(\ref{e11-mal}), получим

\noindent
\begin{multline*}
\sum\limits_{n = 1}^{N^0 - 1} \psi_n = \Psi^{\min}_{\mathrm{seq}} <  
\Psi^*_{\mathrm{par}} = \sum\limits_{n = 1}^{N^0 - 1} \psi_n + \psi^* 
< {}\\
{}<\Psi^{\max}_{\mathrm{seq}} = \sum\limits_{n = 1}^{N^0 - 1} \psi_n + \textbf{Z}_{N^0}\,. 
\end{multline*}

При использовании SWAP-дис\-пет\-че\-ри\-за\-ции для выполнения конкретного
$t^0$-ком\-плек\-та объем выполненной \textit{необходимой работы}~---
значение~(\ref{e9-mal})~---  является <<постоянной>> величиной. При
использовании \textit{последовательной} дисциплины обслуживания со
случайной очередностью выполнения для идентификации всех уникальных
фрагментов, содержащихся в $t^0$-ком\-плек\-те, почти всегда (за
исключением одного случая из~$N^0$) потребуется больше времени, чем
при SWAP-дис\-пет\-че\-ри\-зации.

Для сравнения SWAP-дис\-пет\-че\-ри\-за\-ции и последовательной дисциплины
обслуживания при обработке различных по структуре $t^0$-ком\-плек\-тов
была проведена серия имитационных экспериментов, которые описаны 
в~\cite{Prep11, Gol12}. Остановимся на основных результатах
исследования. Последовательная стратегия при не известной заранее
дли\-тель\-ности выполнения является дискриминирующей по отношению к
заявкам, имеющим время решения меньше среднего для данного
$t^0$-комплекта.  Кроме того, случайный выбор заданий привносит
дополнительную неопределенность~--- место в очереди на обработку
оказывается произвольным. В~результате задачи с небольшим объемом
\textit{необходимой работы} задерживаются в СВС на неоправданно
большой промежуток времени, ожидая завершения более ресурсоемких
заданий.

Схема выполнения заданий $t^0$-ком\-плек\-та на основе показателя
относительной задержки (решения задачи~(\ref{e3-mal})--(\ref{e5-mal})) обладает следующими
свойствами:
\begin{itemize}
\item в первую очередь завершаются задания, име\-ющие наименьшее абсолютное время решения;
\item  в ходе выполнения  задания фактически упорядочиваются  в порядке неубывания 
длительности работ, а задания, требующие полного перебора всего массива данных, 
завершаются последними, при этом  число ЕВ-мо\-ду\-лей, выделяемое  для их обработки, 
монотонно воз\-рас\-тает;
\item  и, наконец, самое важное: в подавляющем чис\-ле случаев суммарное время 
извлечения всей содержащейся в $t^0$-ком\-плек\-те  информации, т.\,е.\ 
идентификации всех уникальных фрагментов, имеющихся во всех наборах данных, 
оказывается меньше, чем при последовательном правиле обслуживания в монопольном режиме.
\end{itemize}



\section{Заключение} 

При реализации правила SWAP не
делается никаких гипотез о времени поступления, объеме
\textit{необходимой работы} или наличии уникальных фрагментов в
поступивших данных. В~каждой контрольной точке для каждого задания
используются только следующие параметры и величины:
\begin{itemize}
\item  фактическое время поступления в СВС;
\item  объем обработанных и оставшихся непро\-смот\-рен\-ны\-ми фрагментов
данных.
\end{itemize}

Анализ выполнения однородных заданий в СВС с однотипными ЕВ-мо\-ду\-ля\-ми
наглядно демонстрирует преимущества SWAP-дис\-пет\-че\-ри\-за\-ции. В~условиях
объективной неопределенности   исполнение правила SWAP позволяет в
динамике  упорядочивать и завершать задания с учетом  объемов
\textit{необходимой работы}, при этом приоритет получают  <<менее
трудоемкие>> задачи.

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{9}
\bibitem{Inf1-13} 
\Au{Купалов-Ярополк И.\,К., Малашенко~Ю.\,Е., Назарова~И.\,А., Ронжин~А.\,Ф.} 
Методы оценки эффективности и  директивных сроков выполнения  ресурсоемких 
вычислительных заданий~// Информатика и её применения, 2013. Т.~7. Вып.~2. С.~4--12.

\bibitem{Mal412} 
\Au{Малашенко Ю.\,Е., Назарова~И.\,А.}  
Модель управления разнородными вычислительными заданиями на основе гарантированных 
оценок времени выполнения~// Изв. РАН. ТиСУ, 2012. №\,4. С.~29--38.

\bibitem{Prep1-13} 
\Au{Купалов-Ярополк И.\,К., Малашенко~Ю.\,Е., Назарова~И.\,А., Ронжин~А.\,Ф.} 
Модели и программы для сис\-те\-мы управления ресурсоемкими вычислениями.~--- 
М.: ВЦ РАН, 2013.  72~с. {\sf http://www.ccas.ru/depart/ malashen/papper/ronzhin\_2012\_preprint.pdf}.

\bibitem{germ} 
\Au{Гермейер Ю.\,Б.} Введение в теорию исследования операций.~--- М.: Наука, 1971.
384~с.

\bibitem{Suh} 
\Au{Сухарев А.\,Г., Тимохов А.\,В., Федоров~В.\,В.} 
Курс методов оптимизации.~--- М.: Наука, 1986. 368~с. 

\bibitem{Gol10} 
\Au{Голосов П.\,С., Козлов~М.\,В., Малашенко~Ю.\,Е., Назарова~И.\,А., Ронжин~А.\,Ф.} 
Модель сис\-те\-мы управ\-ле\-ния специализированным вычислительным комплексом.~--- 
М.: ВЦ РАН, 2010. 48~c. {\sf http://www.ccas.ru/ depart/malashen/papper/golosov\_2010\_preprint.pdf}.

\bibitem{Prep11} 
\Au{Козлов М.\,В., Малашенко Ю.\,Е., Назарова~И.\,А.,Ронжин~А.\,Ф.} 
Анализ режимов управ\-ле\-ния вычислительным комплексом в условиях неопределенности.~--- 
М.: ВЦ РАН, 2011. 60~с. 
{\sf http://www.\linebreak ccas.ru/depart/malashen/papper/ronzhin\_2011\_preprint.\linebreak pdf}.

\bibitem{Gol12} 
\Au{Голосов П.\,Е., Козлов М.\,В., Малашенко~Ю.\,Е., Назарова~И.\,А., Ронжин~А.\,Ф.}  
Анализ управления  специализированными вычислительными заданиями в условиях неопределенности~// 
Изв. РАН. ТиСУ, 2012. №\,1. С.~50--66.

\bibitem{Dan} 
\Au{Данциг Дж.\,Б. } Линейное программирование, его применения и обобщения~/ Пер. с 
англ.~--- М.: Прогресс, 1966. 600~c. 
(\Aue{Dantzig,~G.}  1963. \textit{Linear programming and extensions}. 
New Jersey: Princeton University Press. 589~p.)

\end{thebibliography}
} }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в редакцию 08.11.13}}


\vspace*{12pt}

\hrule

\vspace*{2pt}

\hrule

%\newpage

%\vspace*{-24pt}

\def\tit{ANALYSIS OF DELAYS IN SCHEDULING HOMOGENEOUS 
 TASKS UNDER~UNCERTAINTY}

\def\titkol{Analysis of delays in scheduling homogeneous 
 tasks under~uncertainty}

\def\aut{Yu.\,E.~Malashenko and I.\,A.~Nazarova}
\def\autkol{Yu.\,E.~Malashenko and I.\,A.~Nazarova}


\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-9pt}

\noindent
Dorodnicyn Computing Center, Russian Academy of Sciences, 40 Vavilov Str.,
Moscow 119333, Russian Federation


 
\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND APPLICATIONS\ \ \ 2014\ \ \ volume~8\ \ \ issue\ 1}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND APPLICATIONS\ \ \ 2014\ \ \ volume~8\ \ \ issue\ 1
\hfill \textbf{\thepage}}}   

\vspace*{6pt}
  
\Abste{The problem of management of the computationally resource-intensive 
tasks of search type allowing parallelization by the data is 
considered. Tasks arrive in a system at any time one by one or in groups; 
their service time is not known in advance. 
For processing planning, the optimization model is used which is based on current 
information on tasks performance: the sojourn time and the amount of data 
already processed.  Using the model for each task, the portion of data to 
be processed in the plan period is determined. In calculations, required computational 
expenses are estimated and assumptions about the distribution laws of unknown tasks 
characteristics are not made.
The proposed scheduling rule allows to form the order of  task execution in dynamics, 
priority being given to ``less intensive'' tasks.}


\KWE{computationally intensive tasks; parallel computing; 
scheduling optimization; principle of guaranteed result} 

\DOI{10.14357/19922264140102}

%\Ack
%\noindent


  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{9}

\bibitem{1-mal-1}
\Aue{Kupalov-Yaropolk, I.\,K., Yu.\,E.~Malashenko, I.\,A.~Nazarova, 
and A.\,F.~Ronzhin}. 2013. Metody otsenki effektivnosti i  direktivnykh 
srokov vypolneniya  resursoemkikh vychislitel'nykh zadaniy 
[Methods of estimating efficiency and directive deadlines for resource-intensive 
computational tasks]. \textit{Informatika i ee primenenija}~--- \textit{Inform. Appl}.  
7(2):4--12.
\bibitem{2-mal-1}
\Aue{Malashenko, Yu.\,E., and I.\,A.~Nazarova}. 2012. 
Control model for heterogeneous computational tasks based on guaranteed 
estimates of execution times. \textit{J.~Comput. Syst. Sci. Int.}  51:526--534.  

\bibitem{3-mal-1}
\Aue{Kupalov-Yaropolk, I.\,K., Yu.\,E.~Malashenko, I.\,A.~Nazarova, 
and A.\,F.~Ronzhin}. 2013. Modeli i programmy dlya sistemy upravleniya 
resursoemkimi vychisleniyami  
[Models and programs for intensive computing management]. 
Moscow: Vychisl. Tsentr Ross. Akad. Nauk Publ. 72~p.
Available at: {\sf http://www.ccas.ru/depart/malashen/papper/ronzhin\_\linebreak 2012\_preprint.pdf}. 

\bibitem{4-mal-1}
\Au{Germeier, Yu.\,B.} 1971. \textit{Vvedenie v teoriyu issledovaniya operatsiy} 
[\textit{An introduction to operations research theory}]. Moscow: Nauka Publ. 384~p. 

\bibitem{5-mal-1}
\Aue{Sukharev, A.\,G., A.\,V.~Timokhov, and V.\,V.~Fedorov}. 
1986. \textit{Kurs metodov optimizatsii}  
[\textit{A~course in optimization methods}]. Moscow: Nauka Publ. 368 p. 

\bibitem{6-mal-1}
\Aue{Golosov, P.\,E., M.\,V.~Kozlov, Yu.\,E.~Malashenko, I.\,A.~Nazarova, 
and A.\,F.~Ronzhin}.   2010. 
Model' sistemy upravleniya spetsializirovannym vychislitel'nym kompleksom 
[Control model for a special computer system]. Moscow: Vychisl. \mbox{Tsentr} Ross. 
Akad. Nauk Publ. 48~p. 
Available at: {\sf http://www.ccas.ru/depart/malashen/\linebreak papper/golosov\_2010\_preprint.pdf}.

\bibitem{7-mal-1}
\Aue{Kozlov, M.\,V.,  Yu.\,E.~Malashenko, I.\,A.~Nazarova, and A.\,F.~Ronzhin}. 
2011. Analiz rezhimov upravleniya vychislitel'nym kompleksom v usloviyakh neopredelen\-nosti 
[Analysis of a computer system control modes under uncertainty]. Moscow: Vychisl. 
Tsentr Ross. Akad. Nauk Publ. 60~p. 
Available at: {\sf http://www.ccas.ru/depart/malashen/ papper/ronzhin\_2011\_preprint.pdf}.  

\bibitem{8-mal-1}
\Aue{Golosov, P.\,E., M.\,V.~Kozlov, Yu.\,E.~Malashenko, I.\,A.~Nazarova, 
and A.\,F.~Ronzhin}. 2012. Analysis of computer job control under uncertainty. 
\textit{J.~Comput. Syst. Sci. Int.} 51:49--64. 
\bibitem{9-mal-1}
\Aue{Dantzig, G.}   
\textit{Linear programming and extensions}. 
New Jersey: Princeton University Press, 1963. 589~p.



\end{thebibliography}
} }


\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received November 8, 2013}}

\vspace*{-18pt}

\Contr

\noindent
\textbf{Malashenko Yuri E.} (b.\ 1946)~--- Doctor of Science in physics and 
mathematics, Head of Department of Operations Research, Dorodnicyn Computing Center, Russian Academy of
Sciences, 40 Vavilov Str.,
Moscow 119333, Russian Federation; malash09@ccas.ru 

\vspace*{2pt}

\noindent
\textbf{Nazarova I.\,A.} (b.\ 1966)~--- Candidate of Science (PhD) 
in physics and 
mathematics, scientist, Dorodnicyn Computing Center, Russian Academy of
Sciences, 40 Vavilov Str.,
Moscow 119333, Russian Federation; irina-nazar@yandex.ru



 \label{end\stat}
 
\renewcommand{\bibname}{\protect\rm Литература}





  
  