\def\stat{kozerenko}

\def\tit{ИНТЕГРАЛЬНОЕ МОДЕЛИРОВАНИЕ ЯЗЫКОВЫХ СТРУКТУР 
В~ЛИНГВИСТИЧЕСКИХ ПРОЦЕССОРАХ СИСТЕМ ОБРАБОТКИ ЗНАНИЙ И~МАШИННОГО ПЕРЕВОДА$^*$}

\def\titkol{Интегральное моделирование языковых структур 
в~лингвистических процессорах систем обработки знаний} % и~машинного перевода}

\def\autkol{Е.\,Б.~Козеренко}

\def\aut{Е.\,Б.~Козеренко$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]{Работа 
частично поддержана Российским фондом фундаментальных исследований, грант 
№\,11-06-00476-а.}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Институт проблем информатики Российской академии наук, kozerenko@mail.ru} 
    
 \vspace*{-10pt}         
      
      \Abst{Данная статья посвящена проблемам исследования и интегрального 
моделирования ког\-ни\-тив\-но-лингвистических представлений языковых структур и 
механизмов разрешения синтаксической неоднозначности в процессе создания 
лингвистических процессоров интеллектуальных систем обработки знаний и машинного 
перевода. Методика представления языковых структур и разрешения их неоднозначности 
построена на основе ло\-ги\-ко-лингви\-сти\-че\-ских правил и векторных пространств. 
Проведено сравнительное исследование методов классификации применительно к 
лингвистическим задачам; выработан эффективный метод отображения вектора 
      естест\-вен\-но-язы\-ко\-вых структур в расширенное пространство признаков для 
классификации новых языковых объектов и структур; сформирована фокусная выборка 
параллельных текстов деловых и научных документов на русском, английском и 
французском языках по различным отраслям науки и техники; сформирована 
расширенная система новых категорий, повышающая изобразительные возможности 
исходного варианта уни\-фи\-ка\-ци\-он\-но-по\-рож\-да\-ющей грамматики; выработаны 
пути развития базовых представлений на основе аппарата расширенных семантических 
сетей и метод применения векторных пространств, обеспечивающих разрешение 
неоднозначности ключевых языковых структур в процессе синтаксического анализа 
текста для извлечения знаний и машинного перевода. Разработан грамматический 
формализм и алгоритмические представления парсера, в котором учитываются реальные 
трудности перевода, такие как языковые трансформации.}

\vspace*{-6pt}
      
      \KW{параллельные тексты; векторные пространства; синтаксис; семантика; 
фразовые структуры; гибридные модели; машинный перевод}

\DOI{10.14357/19922264140109}

\vspace*{-3pt}

\vskip 12pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}
    
    \section{Введение}
     
  В данной работе рассматривается проблема создания целостной 
  ма\-те\-ма\-ти\-ко-линг\-ви\-сти\-че\-ской модели языковых структур для 
лингвистических процессоров информационных систем на основе 
синергетического подхода, в котором применяются лингвистические знания, 
логико-семантические представления, статистические методы и механизмы 
машинного обучения для извлечения новых грамматических правил из 
текстовых корпусов и разрешения неоднозначности. Для формализации 
лингвистических знаний используется когнитивная трансферная грамматика 
(КГТ)~[1, 2], учитывающая многовариантность и неоднозначность языковых 
структур, языковую синонимию, включая семантические соответствия на 
различных языковых уровнях и их вероятностные характеристики. 
Проведены эксперименты с грамматикой категориального типа~[3]. 

Методика построения интегрированной ког\-ни\-тив\-но-линг\-ви\-сти\-че\-ской модели 
представления языковых структур и разрешения их неоднозначности 
основана на сочетании ло\-ги\-ко-линг\-ви\-сти\-че\-ских правил и векторных 
пространств семантичесих характеристик фразовых структур, отражающих 
ка\-те\-го\-ри\-аль\-но-функ\-ци\-о\-наль\-ные значения. Для этого было сделано
следующее:
\begin{itemize}
\item 
проведено 
сравнительное исследование методов классификации применительно к 
лингвистическим задачам;\\[-13pt] 
\item выработан эффективный метод отображения 
вектора естест\-вен\-но-язы\-ко\-вых структур в расширенное пространство 
признаков для классификации новых языковых объектов и структур;\\[-13pt]  
\item сформирована фокусная выборка параллельных текстов деловых и научных 
документов на русском, английском и французском языках по различным 
отраслям науки и техники;\\[-13pt]  
\item сформирована расширенная система новых 
категорий для повышения изобразительных возможностей исходного 
варианта уни\-фи\-ка\-ци\-он\-но-по\-рож\-да\-ющей грамматики;\\[-13pt]  
\item выработаны 
пути расширения базовых представлений на основе аппарата расширенных
семантических сетей~[4] и результатов приме-\linebreak\vspace*{-12pt}

\pagebreak

\noindent 
нения метода векторных 
пространств, на\-прав\-лен\-но\-го на разрешение неоднозначности языковых 
структур для синтаксического разбора при распознавании текста в процессе 
извлечения знаний и машинного перевода.\\[-13pt] 
\end{itemize}
  
  Особое внимание в пред\-став\-лен\-ных исследованиях
уделяется явлениям синтаксической неоднозначности, вызывающим 
основные затруднения\linebreak при создании систем обработки естественного языка, 
созданию оптимальных методик разрешения неоднозначности на основе 
статистического подхода и семантического выравнивания параллельных\linebreak 
текстовых корпусов. Целью исследований является построение эффективных 
методов структурного анализа и компьютерного моделирования 
полнотекстовых научных и патентных документов, а также документов 
деловой сферы коммуникации, таких как финансы и управление. Разработана 
теоретиче\-ская концепция и алгоритмы автоматического выравнивания 
параллельных текстов для пополнения многоязычных фразеологических 
словарей и развития грамматических компонент систем машинного перевода 
и обработки знаний. Основной результат исследований~--- модель 
лингвистической составляющей интеллектуальных информационных систем, 
работающих в многоязычном пространстве для поиска информации, 
обеспечения оптимальных аналитических и управленческих решений. 
  
  Сформирована инструментальная среда ис\-следования параллельных 
текстов и подготовки син\-так\-ти\-ко-се\-ман\-ти\-че\-ских представлений 
для проектирования лингвистических процессоров интеллекту\-альных 
  сис\-тем. Результаты исследований применяются в 
  ло\-ги\-ко-се\-ман\-ти\-че\-ских и статистических процедурах обработки 
слабоструктурированной текстовой информации, при разработке технологии 
и инструментальных средств построения лингвистических компонент 
интеллектуальных сис\-тем и сис\-тем машинного перевода. 

\vspace*{-6pt}
     
\section{Моделирование динамического аспекта языковых 
преобразований}

\vspace*{-3pt}
  
  Процедуры анализа и синтеза естественно-язы\-ко\-вых высказываний 
отражают динамический характер языка как деятельности; соответственно, в 
модели, которая кладется в основу проекта системы обработки естест\-вен\-но-язы\-ко\-вых 
высказываний, должен быть заложен механизм, позволяющий 
строить представления движения. 
  
  Семантическое моделирование на основе правил служит основой для 
автоматического извлечения лингвистических данных с помощью 
машинного обучения. Исследования, представленные в данной статье, 
основаны на традициях сильного семантического подхода отечественной 
лингвистики: построение модели от значения~--- к форме. Представленный в 
данной работе подход на основе КТГ 
дает возможность компактного представления структуры составляющих 
предложения (грамматика фразовых структур), с одной стороны, а с другой 
стороны, учитывает механизмы зависимости между узлами дерева 
предложения. Ядро КТГ составляют прототипические структуры 
исследуемых языков (русского, английского и французского), их наиболее 
вероятные позиции в предложении, а также статистические данные о 
дистрибутивных характеристиках структур (т.\,е.\ информация о контекстных 
условиях употребления исследуемых объектов~--- о структурных 
контекстах), схемы полного разбора предложений. Методы машинного 
обучения на основе векторных моделей развиваются и используются в 
различных областях знаний, применительно к лингвистическим задачам эти 
методы вполне эффективны для разрешения лексической 
  многозначности~[5--10]. 
  
  Более сложной задачей и новым направлением исследований возможности 
применения векторных моделей для представления и обработки 
лингвистических данных является моделирование грамматических 
преобразований на основе векторных пространств и тензоров. Тензор (от 
\textit{лат}.\ tensus~--- напряженный)~--- объект линейной алгебры, преобразующий 
элементы одного линейного пространства в элементы другого. Часто тензор 
представляют как многомерную таблицу, заполненную числами~--- 
компонентами тензора $d\times d\times\cdots \times d$, где $d$~--- размерность, 
над которым задан тензор, а число сомножителей совпадает с так называемой 
валентностью, или рангом тензора. Важно, что такое представление (кроме 
скаляров, т.\,е.\ тензоров валентности ноль) возможно только после выбора 
базиса (или системы координат): при смене базиса компоненты тензора 
меняются определенным образом. Сам тензор как <<геометрическая 
сущность>> от выбора базиса не зависит, компоненты вектора меняются при 
смене координатных осей, но сам вектор, образом которого может быть 
прос\-то нарисованная стрелка, от этого не изменяется. Тензор обычно 
обозначают некоторой буквой с совокупностью верхних (контрвариантных) и 
нижних (ковариантных) индексов: $X^{i_1i_2\ldots i_r}_{j_1j_2\ldots j_s}$. 
При смене базиса ковариантные компоненты меняются так же, как и базис (с 
помощью того же преобразования), а контрвариантные~--- обратно 
изменению базиса (обратным преобразованием). Тензор является сущностью 
любой системы реального мира и со-\linebreak\vspace*{-12pt}

\pagebreak

\noindent
храняется, несмотря на происходящие 
изменения в этой системе~[11]. Эта особенность тензора чрезвычайно 
актуальна для моделирования языковых преобразований в лингвистических 
процессорах, когда необходимо выявлять сходные значения, выраженные 
многочисленными способами, системой разнородных языковых средств 
  
  В работе, представленной в данной статье, рассмотрены два основных 
подхода к представлению смысла в вычислительной лингвистике: 
символьный подход~\cite{13-koz, 14-koz} и подход на основе 
дистрибутивной семантики~[5--7, 10], поставлен основополагающий вопрос о 
том, как эти подходы могут быть объединены для достижения оптимального 
результата. Решение заключается в сочетании методов компьютерной 
лингвистики и когнитивной науки, в котором символьное и 
<<коннекционистское>> (т.\,е.\ основанное на модели машинного обучения, 
например \textit{нейронных сетях}) представления объединяются с 
  по\-мощью тензорных произведений. Исследованы возможные применения 
данного метода для обработки синтаксических структур и контекстов в 
русском, английском и французском языках и проведены межъязыковые 
сопоставления. 
  
  Изучены потенциально плодотворные связи между вычислительной 
лингвистикой и другими смежными областями, например поиском 
информации и машинным переводом. Для сис\-тем обработки естественного 
языка наиболее сложной проблемой является установление семантической 
эквивалентности языковых структур~[14--17], %\cite{12-koz, 15-koz, 16-koz, 17-koz}, 
имеющих сходное значение, но по-разному оформленных. В~частности, для 
машинного перевода наиболее сложной проблемой является реализация 
языковых трансформаций, которые необходимо производить при переводе с 
одного языка на другой. Текущий этап развития систем машинного перевода 
характеризуется междисциплинарными исследованиями в области 
когнитивной семантики и вероятностных языковых моделей и разработкой 
се\-ман\-ти\-ко-син\-так\-си\-че\-ских представлений, учитывающих 
многозначность и неоднозначность синтаксических 
  структур~[1, 2, 4, 6, 8--10, 15--18].
  
  \vspace*{-12pt}
     
    \section{Математические модели структуры предложения 
    на~основе категориальных грамматик}
    
    \vspace*{-3pt}
    
  Модели векторных пространств находят все \mbox{более} широкое применение в 
исследованиях, связанных с семантическими представлениями естественного 
языка, и имеют разнообразный спектр потенциальных и действующих 
приложений~\cite{9-koz, 8-koz, 19-koz}. Основными сферами применения 
дистрибутивных моделей являются: разрешение лексической 
неод\-но\-значности, информационный \mbox{поиск},\linebreak кластеризация документов, 
автоматическое {формирование} словарей (словарей семантических\linebreak
отношений, двуязычных словарей), создание семантических карт, 
моделирование перифраз,\linebreak определение тематики документа, определение\linebreak 
тональности высказывания, выявление именован\-ных сущностей. В~качестве 
вычислительного\linebreak инструмента и способа представления моделей 
используется линейная алгебра. 

Информация о дистрибуции 
лингвистических единиц представляется в виде многоразрядных векторов, а 
семантическая близость между лингвистическими единицами вычисляется 
как расстояние между векторами. Многоразрядные векторы образуют 
матрицу, где каждый вектор соответствует лингвистической единице (слову 
или словосочетанию), а каждое измерение вектора соответству-\linebreak ет контексту 
(документ, параграф, предложение,\linebreak словосочетание, слово). Для вычисления 
меры бли\-зости между векторами могут использоваться различные формулы: 
расстояние Минковского,\linebreak расстояние Манхеттена, евклидово расстояние, 
расстояние Чебышёва, скалярное произведение, косинусная мера. Наиболее 
популярной является косинусная мера~\cite{9-koz, 8-koz}.
  
  Формально-грамматической основой~[20--25] исчисления семантики 
предложения с учетом его структурных составляющих в векторных 
моделях~[26--30] служат различные варианты категориальных грамматик, 
которые позволяют отразить комбинаторные свойства фразовых структур в 
их линейной реализации во фразе. В~категориальных грамматиках в качестве 
базовых понятий используются синтаксические типы, или \textit{категории} 
(приблизительно соответствуют тому, что в традиционных грамматиках 
называется \textit{частями речи}), а механизм \textit{наложения} 
(\textit{juxtaposition}, \textit{superposition}) позволяет выразить 
функциональные значения структурных компонентов, которые реализуются в 
конкретном высказывании.
  
  Методы исчисления структуры предложения на основе категориальных 
гамматик восходят к работам Айдукевича~\cite{20-koz} и 
Бар-Хил\-ле\-ла~\cite{21-koz}. Деривация предложения в 
категориальных грамматиках~\cite{23-koz, 22-koz} выглядит следующим 
образом:
  \begin{center}
\underline{Microsoft} \underline{develops} 
\underline{Windows}\\[6pt]

   NP\quad     NP$\backslash$S/NP\quad   NP

---------------------------------$>$

NP$\backslash$S

---------$<$

S
\end{center}

  В работах~\cite{23-koz, 24-koz} был представлен аппарат грамматики на 
основе предгрупп. Предгруппа~--- это такой частично упорядоченный 
моноид, в котором каждый элемент~$a^l$ имеет левый адъюнкт~$a^l$ и 
правый адъюнкт $a^r$ такие, что 
  $$
  a^l\cdot a\to 1\,;\enskip a\cdot a^r\to 1\,.
  $$
  
  Такой моноид~--- это множество грамматических типов (NP, NP$^l$, 
NP$^r$, NP$^{ll}$, NP$^{rr}$, $S$, PP,\ \ldots) с оператором \textit{наложения} 
($\cdot$), которые используются для деривации сложных типов и пустой 
цепочки как единицы~(1):
  $\mathrm{NP}\cdot (\mathrm{NP}^r\cdot {S}\cdot  \mathrm{NP}^l)\cdot \mathrm{NP}$.
  
  Частичное упорядочение кодирует отношение деривации для более ранних 
дериваций или редукций:
  \begin{gather*}
     \mathrm{NP}\cdot  (\mathrm{NP}^r\cdot {S} \cdot \mathrm{NP}^l)\cdot \mathrm{NP} \to 1\,;\\
      ({S}\cdot \mathrm{NP}^l)\cdot \mathrm{NP}\to  1\,;\quad {S}\cdot 1\to {S}\,.
     \end{gather*}
     
  На абстрактном математическом уровне \textit{теории категорий} алгебра 
предгрупп и векторные пространства могут рассматриваться как 
эквивалентные.
  
  В целом категориальные грамматики ориентированы на алгебраический 
подход к моделированию естественного языка, что делает их вполне 
органич\-ной основой для интегрального пред\-став\-ле\-ния семантики 
предложений естественного языка в виде семантических векторных 
пространств (СВП). Важным понятием в категориальных грам-\linebreak матиках является 
\textit{композициональность}: правила\linebreak деривации предложения в целом по 
его со\-став\-ля\-ющим с учетом их линейного расположения во фразе. 
В~современных векторных моделях семантики предложения с учетом его 
синтаксиса наиболее популярны комбинаторная категориальная грамматика 
Стидмана (CCG)~\cite{22-koz}, грамматика 
Ламбека~\cite{23-koz, 24-koz}, применяются также формализмы 
Муртгата~\cite{25-koz}, аппликативная грамматика 
Шаумяна~\cite{3-koz}.
  
  Тензоры используются для выражения преобразований синтаксической 
структуры.
     
\section{Семантический подход к~выявлению статистических 
характеристик языковых структур в~параллельных корпусах}
  
  Категориальные грамматики активно применяются для сопоставления 
текстовых корпусов и извлечения перифраз. Параметры моделей 
статистического выравнивания оптимизируются с учетом критерия 
максимального сходства, который далеко не всегда отражает качество 
выравнивания. В~этой связи чрезвычайную важность имеет проблема 
перефразирования, и ей уделяется все больше внимания в работах ведущих 
исследовательских групп в области компьютерной лингвистики. 

Извлечение 
перифраз из двуязычных параллельных корпусов было описано в 
  работах~[14--17], %\cite{12-koz, 15-koz, 16-koz, 17-koz}, 
  которые выводили 
перифразы с использованием методов статистического машинного перевода 
на основе фраз. Затем путем введения комплексных синтаксических меток 
вместо использования только нетерминальных символов из деревьев разбора 
авторы смогли добиться существенного улучшения по сравнению с 
основным методом. Синтаксические ограничения значительно улучшают 
качество этого метода перифразы. 

В~работе~\cite{16-koz} представлен новый 
подход к перифразе на основе двуязычного корпуса. Автор демонстрирует, 
что более высокое качество может быть достигнуто, если ввести 
ограничение, что перифраза должна иметь такой же синтаксический тип, что 
и исходная фраза. В~работе предложены ограничения на перифразы на двух 
этапах: когда они выводятся на основе разобранных параллельных корпусов 
и когда они подставляются в разобранные тестовые предложения. Автор ввел 
синтаксические ограничения, пометив все фразы и перифразы (даже не 
входящие в число со\-став\-ля\-ющих) с помощью слэш-ка\-те\-го\-рий, 
исполь\-зу\-емых в  CCG. Однако автор не дает ни формального 
определения некоторой синхронной грамматики, ни предлагает систему 
декодирования, поскольку его система представлений не содержит 
иерархических правил (деревьев разбора). Правила синхронной грамматики 
для перевода извлекаются из пар предложений, автоматически разобранных 
и выравненных по словам. Методы извлечения варьи\-ру\-ют в зависимости от 
того, извлекают ли они только минимальные правила для фраз, у которых 
есть доминирующие узлы в дереве разбора, или более сложные правила, 
включающие фразы, не входящие в число составляющих~\cite{17-koz}. 

Главной мотивацией для использования синтаксических перифраз наряду с 
их исходными фразовыми соответствиями является их потенциальная 
возможность в более общем виде отразить лингвистические трансформации, 
сохраняющие значение. 
  
  Необходимость моделирования языковых трансформаций для систем 
машинного перевода и извлечения знаний из текстов обусловлена тем, что до 
сих пор эти явления мало исследованы с точки зрения возможностей их 
компьютерной реализации и, соответственно, недостаточно учтены в 
действующих системах машинного перевода и обработки знаний. 
В~КТГ~\cite{1-koz} 
функциональные значения языковых структур определяются 
категориальными значениями головных вершин, а именно пред\-став\-ля\-ют\-ся 
как наложение категорий (\textit{juxtaposition}), что имеет сходство с 
механизмами категориальных грамматик. Вероятностные характеристики 
вводятся в правила унификационной грамматики в виде весов, 
присваиваемых деревьям разбора. Когнитивная трансферная грамматика, 
разработанная автором данной статьи, содержит механизмы категориальных 
грамматик, такие как категоризация и наложение категориальных значений 
для выражения функциональных значений фразовых структур, а также 
механизмы уни\-фи\-ка\-ци\-он\-но-по\-рож\-да\-ющих грамматик для анализа 
и порождения не только отдельных типов фразовых структур, но и 
предложения в целом. 
  
  По определению, КТГ исходно является двуязычной грамматикой. В~КТГ 
элементарными структурами являются трансфемы. Трансфема~--- это 
единица когнитивного переноса, устанавливающая 
  функ\-ци\-о\-наль\-но-се\-ман\-ти\-че\-ское соответствие между 
структурами исходного языка и структурами целевого языка. Для процедур 
анализа и перевода в лингвистических процессорах трансфемы задаются как 
правила переписывания, в которых в левой части стоит нетерминальный 
символ, а в правой~--- выравненные пары цепочек терминальных и 
нетерминальных символов, принадлежащих исходному и целевому языкам. 
  
  Процессы синтаксических трансформаций очень сходны в ряде 
европейских языков. Включение статистических данных в системы, 
основанные на правилах, позволяет отразить динамику и разнообразие 
языковых форм и значений, порождаемых в процессе речевой деятельности. 
Функциональная и когнитивная мотивация правил исходной грамматики 
позволяет увеличить точность соответствий в среднем на 34\% в зависимости 
от типа со\-по\-став\-ля\-емых текстов.
  
  Применяется интегральный подход на основе правил формальной 
грамматики (грамматика когнитив\-ного трансфера~--- 
  уни\-фи\-ка\-ци\-он\-но-по\-рож\-да\-ющая грамматика на основе фразовых 
структур) и дистрибутивной семантики. Дистрибутивная семантика~--- 
  об\-ласть научных исследований, занимающаяся вычислением степени 
семантической близости между лингвистическими единицами на основании 
их дистрибутивных (контекстных) признаков в больших массивах 
лингвистических данных. Информация о дистрибуции лингвистических 
единиц представляется в виде многоразрядных векторов, а семантическая 
близость между лингвистическими единицами вычисляется как расстояние 
между векторами. Многоразрядные векторы образуют
СВП, где каждый вектор соответствует лингвистической 
единице (слово, словосочетание, языковая структура), а каждое измерение 
вектора соответствует контексту (документ, параграф, предложение, 
словосочетание, слово, языковая структура). Одной из главных целей 
исследования является применение модели СВП
для извлечения переводных соответствий языковых структур из 
параллельных текстов.
  
  Для разрешения неоднозначности языковых объектов и структур 
используются векторные пространства~\cite{18-koz, 19-koz}.
  
  Концепция СВП впервые была 
реализована в ин\-фор\-ма\-ци\-он\-но-по\-иско\-вой сис\-те\-ме SMART. Идея СВП 
состоит в представлении каждого документа из коллекции в виде точки в 
пространстве, т.\,е.\ вектора в векторном пространстве. Точки, 
расположенные ближе друг к другу в этом пространстве, считаются более 
близкими по смыслу. Пользовательский запрос рассматривается как 
псевдодокумент и тоже представляется как точка в этом же пространстве. 
Документы сортируются в порядке возрастания расстояния, т.\,е.\ в порядке 
уменьшения семантической близости от запроса, и в таком виде 
предоставляются пользователю. Впоследствии концепция СВП была 
успешно применена для других семантических задач. 
  
  Для выделения значимых словосочетаний в компьютерной лингвистике 
используются различные статистические меры (меры ассоциации, меры 
ассоциативной связанности~--- \textit{англ}.\ association measures), вычисляющие силу 
связи между элементами в составе коллокации. Мера MI (mutual information), 
введенная в работе~\cite{31-koz}, сравнивает зависимые 
  кон\-текст\-но-свя\-зан\-ные частоты с независимыми частотами слов в 
тексте. Если значение MI превосходит определенное пороговое значение, то 
словосочетание считают статистически значимым.

\section{Создание интегральной кросслингвистической модели 
предложения на~основе расширяемой грамматики}
  
  Основная цель исследований, проводимых автором данной работы,~--- 
извлечение из параллельных текстов на разных языках таких фразовых 
структур, которые выражают одинаковые значения, и включение их в 
систему правил рас\-ши\-ря\-емой грамматики для решения задач машинного 
перевода и извлечения знаний из многоязычных 
  пред\-мет\-но-ори\-ен\-ти\-ро\-ван\-ных текстов. Рас\-ши\-ря\-емая грамматика, 
которая при этом используется, содержит когнитивные и функциональные 
характеристики фразовых структур и базируется на формализме 
КТГ~\cite{1-koz}. 
  
  В статистической исследовательской парадигме термин <<фраза>> означает 
произвольный сегмент предложения, выделенный статистическим 
инструментом и вовсе не являющийся нетерминальным символом 
(синтаксической единицей) ка\-кой-ли\-бо формальной грамматики. 
В~отличие от такого подхода в представленных исследованиях фраза~--- это 
синтаксически значимая единица в составе предложения, которая 
рассматривается в парадигматическом и синтагматическом аспектах. 
Основные проблемы выравнивания параллельных\linebreak
 текстов и, соответственно, 
обучения стати\-сти\-ческих процессоров естественного языка обуслов\-лены 
наличием значительных трансформаций\linebreak
 предложений исходного и целевого 
текстов, поскольку каждый язык использует свои специфические механизмы 
описания референтной ситуации. Создание и исследование параллельных 
корпусов в рамках пред\-став\-лен\-ной здесь работы направлено на выявление 
наиболее типичных (частотных) и значимых трансформаций в изучаемых 
параллельных текстах и развитие типологии трансформаций,\linebreak представленных 
в исходном формализме КТГ.\linebreak Таким образом, необходимо разработать и 
применить такие стратегии и инструменты, которые обеспечивают наиболее 
адекватные средства для описания и выявления сопоставимых языковых 
структур.
    При этом сочетаются подходы КТГ и 
категориальной грамматики SUG (semiotic universal 
  grammar)~\cite{2-koz, 3-koz}. Динамика выравнивания реализуется в 
соответствиях~$M$, которые фиксируются посредством механизма 
категориальной грамматики SUG.
  
  Семантически-ориентированный этап выравнивания параллельных текстов 
проводится в двух режимах: 
\begin{enumerate}[(1)]
\item сопоставления на уровне трансфем, при этом 
выявляются языковые структуры, вы\-ра\-жа\-ющие сходные функциональные 
значения в параллельных текстах; 
\item сопоставления на уровне концептов и 
отношений.
\end{enumerate}
  
  Режим выравнивания первого типа базируется на понятиях 
трансфемы~$T$ (transfeme) и соответствия~$M$ (match).
  
  \medskip
  
  \noindent
  \textbf{Определение.} Трансфема~$T$~--- это единица парадигматического 
плана, относящаяся к языку как системе, соответствие~$M$~--- единица 
синтагматического плана, относящаяся к речи (дискурсу); таким образом, 
трансфемы~$T$ реализуются в соответствиях~$M$.
  
  \smallskip
  
  Соответствие $M$ может быть шире, чем трансфема~$T$, и часто 
включает контекст.
  
  Выравнивание на основе концептов (сущ\-ностей) и отношений (связей) 
параллельных и\linebreak кон\-цеп\-ту\-аль\-но-со\-по\-ста\-ви\-мых текстов на 
различных языках направлено на выявление языковых реализаций структур 
знаний и формирования многоязычных баз знаний, которые затем будут 
применяться в интеллектуальных аналитических сис\-те\-мах. Такой режим 
выравнивания будем \mbox{назы\-вать} 
  кон\-цеп\-ту\-аль\-но-ори\-ен\-ти\-ро\-ван\-ным, инструментом для него 
служит лингвистический процессор\linebreak \mbox{Semantix}. Механизмы 
  кон\-цеп\-ту\-аль\-но-ори\-ен\-ти\-ро\-ван\-но\-го выравнивания основаны 
на аппарате расширенных семантических сетей (РСС)~\cite{4-koz}, 
обла\-да\-ющих достаточной выразительной мощностью для представления 
естественно-языковых структур с высокой степенью вложенности и 
выполняющих роль язы\-ка-по\-сред\-ни\-ка. Все множество языковых 
объектов задается в виде пре\-ди\-кат\-но-аргу\-мент\-ных структур. Анализ 
предложения производится на основе унификационной грамматики. Модели 
управления и трансформационные свойства задаются в словаре в рамках 
словарных статей глаголов. В~результате трансформаций происходит сдвиг 
моделей управления.
  
  Особое внимание в исследованиях уделяется номинализации и изменению 
предложного управления на беспредложное, например: \textit{стрелять по 
уткам}~--- \textit{стрелять уток}.
  
  Таким образом, кон\-цеп\-ту\-аль\-но-ори\-ен\-ти\-ро\-ван\-ное 
выравнивание~--- это процесс извлечения знаний в многоязычном режиме и 
наполнения базы лингвистических знаний для последующего использо\-ва\-ния 
в системах машинного перевода и аналитической обработки текстовых 
знаний.
  
  \section{Заключение}
  
  Успешность вероятностной модели в значительной степени зависит от 
адекватного определения события. Обычный тип события в вероятностной 
обработке естественного языка~--- совместное появление одного или 
нескольких слов в определенном контексте. Для построения интегральной 
модели предложения соответствия, или события, составляют множество 
хорошо оформленных \textit{нетерминалов} (т.\,е.\ грамматических 
категорий и типов синтаксических структур), а динамически выявляемые 
контекстные структуры представляются в нотации категориальной 
грамматики (SUG)~\cite{2-koz, 3-koz}. Для разрешения неоднозначности 
языковых объектов и структур используются векторные пространства. 
Основной прием выравнивания параллельных текстов по трансфемам~--- 
установление соответствий между головными вершинами фразовых 
структур, в настоящее время осуществляется в полуавтоматическом режиме, 
автоматическое сопоставление находится в стадии разработки: выравнивание 
по головным элементам фраз и сравнение фразовых структур. Методы 
машинного обучения обеспечивают системе возможность извлекать 
значения, которые ожидаются в рамках определенных контекстов. Для 
вычисления вероятности реализации определенного значения в 
соответствующем контексте используются статистические данные, 
полученные из больших массивов текстовой информации (параллельных 
текстовых корпусов).
  
  В результате использования ло\-ги\-ко-линг\-ви\-стических правил 
анализа и перевода фразовых структур, представленных на основе аппарата 
расширенных семантических сетей, и метода векторных \mbox{пространств} 
построено системное межъязы\-ковое представление лингвистических 
объектов, отражающее взаимосвязи типа струк\-ту\-ра--свой\-ст\-во; 
сформирована представительная обучающая выборка семантически 
выровненных параллель-\linebreak ных текстов; собраны и систематизированы 
статистические данные о типах смысловых соответствий языковых структур 
в русском, английском и французском деловом и научном тексте; построены 
базовые векторные пространства признаков неоднозначных языковых 
структур; выявлены и формализованы различные типы линеаризации 
структур при разборе и переводе; проведено сравнительное исследование 
статистических методов анализа языковых структур с целью формирования 
оптимального аппарата вероятностных расширений 
  ло\-ги\-ко-линг\-ви\-сти\-че\-ских правил и выработки методов\linebreak создания 
логико-статистических алгоритмов разбора и трансфера языковых структур.
  
{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{99}
  \bibitem{1-koz}
  \Au{Kozerenko E.\,B.} Cognitive approach to language structure segmentation for machine 
translation algorithms~// Conference (International) on Machine Learning, Models, Technologies 
and Applications Proceedings.~--- Las Vegas, USA: CSREA Press, 2003. P.~49--55.
  %\bibitem{2-koz}
  %\Au{Kozerenko E.\,B.} Parallel textsaAlignment strategies: The semantic aspects~// 
%Informatics and Applications, 2013. Vol.~7. No.\,1. P.~82--89. 
  \bibitem{2-koz}
  \Au{Козеренко Е.\,Б.} Стратегии выравнивания параллельных текстов: семантические 
аспекты~// Информатика и её применения, 2013. Т.~7. Вып.~1. С.~82--89.
  \bibitem{3-koz}
  \Au{Shaumyan S.} Categorial grammar and semiotic universal grammar~// IC-AI'03: 
  Conference (International) on Artificial Intelligence Proceedings.~--- Las Vegas, USA: 
CSREA Press, 2003. P.~623--629.
  \bibitem{4-koz}
  \Au{Kuznetsov I\, P., Kozerenko E.\,B., Matskevich~A.\,G.} Intelligent extraction of 
knowledge structures from natural language texts~// 2011 IEEE/WIC/ACM  Joint 
Conferences (International) on Web Intelligence and Intelligent Agent Technology~--- Workshops WI-IAT 2011 
Proceedings.~--- Washington, DC, USA: IEEE Computer Society, 
2011. Vol.~03. P.~269--272.
  \bibitem{5-koz}
  \Au{Dempster A.\,P., Laird N.\,M., Rubin~D.\,B.} Maximum likelihood from incomplete data 
via the EM algorithm~// J.~Roy. Stat. Soc.~B, 1977. Vol.~39. No.\,1. P.~1--22.


  \bibitem{9-koz} %6
  \Au{Lund K., Burgess~C.} Producing high-dimensional semantic spaces from lexical 
  co-occurrence~// Behav. Res. Meth. Instr.  Comp., 1996. Vol.~28. 
No.\,2. P.~203--208.

  \bibitem{7-koz} %7
  \Au{Curran J.\,R.} From distributional to semantic similarity. PhD Thesis.~--- Edinburgh: 
University of Edinburgh, 2004. 177~p.

  \bibitem{10-koz} %8
  \Au{McCarthy D., Koeling R., Weeds~J., Carroll~J.} Finding predominant senses in 
untagged text~// 42nd Annual Meeting of the Association for Computational Linguistics 
Proceedings.~--- Barcelona, Spain: ACL, 2004. P.~280--287.

  \bibitem{6-koz} %9
  \Au{Clark S., Pulman S.} Combining symbolic and distributional models of meaning~// 
AAAI Spring Symposium on Quantum Interaction Proceedings.~--- 
Palo Alto, CA, USA: AAAI Press, 2007.  P.~52--55. {\sf 
http://www.cl.cam.ac.uk/$\sim$sc609/pubs/aaai07.pdf}.

  \bibitem{8-koz} %10
  \Au{Morozova Yu.} Method for extracting translation correspondences from a parallel 
corpus~// ICAI'13, WORLDCOMP'13 Proceedings.~--- Las Vegas, USA: CSREA Press, 2013. 
Vol.~II. P.~65--69.


  \bibitem{11-koz} %11
  \Au{Danielson D.\,A.} Vectors and tensors in engineering and physics.~--- 2nd ed.~--- 
Boulder, CO: Westview (Perseus), 2003. 282~p.

  \bibitem{13-koz} %12
  \Au{Montague R.} Universal grammar~// Theoria, 1970. Vol.~36. P.~373--398. (Reprinted: 
Formal Philosophy: Selected papers of Richard Montague~/ Ed. R.\,H.~Thomason.~--- New 
Haven\,--\,London: Yale University Press, 1974. P.~222--246.)

  \bibitem{14-koz} %13
  \Au{Partee B.} Compositionality~// Compositionality in Formal Semantics: Selected Papers 
by Barbara H.~Partee.~--- Oxford: Blackwell, 2004. P.~153--181. 

  \bibitem{12-koz} %14
  \Au{Pang B., Knight K., Marcu~D.} Syntax-based alignment of multiple translations: 
Extracting paraphrases and generating new sentences~// NAACL'03: 2003 Conference of the 
North American Chapter of the Association for Computational Linguistics on Human Language 
Technology Proceedings.~--- Stroudsburg, PA, USA: ACL, 2003. Vol.~1. P.~102--109.


  \bibitem{15-koz}
  \Au{Bannard C., Callison-Burch~C.} Paraphrasing with bilingual parallel corpora~// 43rd 
Annual Meeting of the ACL Proceedings.~--- Stroudsburg, PA, USA: 
ACL, 2005. P.~597--604.
  \bibitem{16-koz}
  \Au{Callison-Burch C.} Syntactic constraints on paraphrases extracted from parallel 
corpora~// EMNLP-2008 Proceedings.~--- Stroudsburg, PA, USA: ACL, 2008. P.~196--205.
  \bibitem{17-koz}
  \Au{Ganitkevitch Ju., Callison-Burch~C., Napoles~C., Van Durme~B.} Learning sentential 
paraphrases from bilingual parallel corpora for text-to-text generation~// 2011 Conference on 
Empirical Methods in Natural Language Processing Proceedings.~--- Stroudsburg, PA, USA: 
ACL, 2011. P.~1168--1179.
  \bibitem{18-koz}
  \Au{Bogatyrev K.} In defense of symbolic NLP~// MLMTA'06: Conference (International) 
on Machine Learning, Models, Technologies and Applications Proceedings.~--- Las Vegas, 
USA: CSREA Press, 2006. P.~63--68.
  \bibitem{19-koz}
  \Au{Malkov K.\,V., Tunitsky D.\,V.} On extreme principles of machine learning in anomaly 
and vulnerability assessment~// MLMTA'06: Conference (International) on Machine Learning, 
Models, Technologies and Applications Proceedings.~--- Las Vegas, USA: CSREA Press, 2006. 
P.~24--29.
  \bibitem{20-koz}
  \Au{Ajdukiewicz K.} Die Syntaktische Konnexitat~// Stud. Philos., 1935. Vol.~1. 
No.\,1. P.~1--27. 
%Eng. trans. as <<Syntactic Connexion>>. In McCall (ed.), 1967. 207--231.

  \bibitem{21-koz}
  \Au{Bar-Hillel Y.} A~quasiarithmetical notation for syntactic description~// Language, 1953. 
Vol.~29. No.\,1. P.~47--58. 

  \bibitem{23-koz} %22
  \Au{Lambek J.} The mathematics of sentence structure~// Am. Math. Mon., 
1958. Vol.~65. No.\,3. P.~154--170.

  \bibitem{22-koz} %23
  \Au{Steedman M.} Surface structure and interpretation.~--- Massachusetts: MIT Press, 1996. 140~p.


  \bibitem{24-koz}
  \Au{Lambek J.} From word to sentence: A~computational algebraic approach to 
  grammar.~--- Monza, Italy: Polimetrica Publ., 2008. 154~p.
  \bibitem{25-koz}
  \Au{Moortgat M.} Symmetric categorial grammar~// J.~Philos. Logic, 2009. Vol.~38. 
No.\,6. P.~681--710. 

  \bibitem{28-koz} %26
  \Au{Gazdar G.} Paradigm merger in natural language processing~// Computing tomorrow: 
Future research directions in computer science~/ Eds. R.~Milner, I.~Wand.~--- Cambridge, U.K.: 
Cambridge University Press, 1996. P.~88--109.

  \bibitem{27-koz}
  \Au{Clark S., Curran J.\,R.} Wide-coverage efficient statistical parsing with CCG and 
  log-linear models~// Comput. Linguist., 2007. Vol.~33. No.\,4. P.~493--552.
  \bibitem{26-koz} %28
  \Au{Baroni M., Zamparelli R.} Nouns are vectors, adjectives are matrices: Representing 
adjective--noun constructions in semantic space~// 2010 Conference on Empirical Methods in 
Natural Language Processing Proceedings.~--- Stroudsburg, PA, USA: ACL, 2010. 
  P.~1183--1193.

  \bibitem{29-koz}
  \Au{Grefenstette E., Sadrzadeh M.} Experimental support for a categorical compositional 
distributional model of meaning~// Conference on Empirical Methods in Natural Language 
Processing Proceedings.~--- Stroudsburg, PA, 
USA: ACL, 2011. P.~1394--1404. 
  \bibitem{30-koz}
  \Au{Hermann K.\,M., Blunsom~P.} The role of syntax in vector space models of 
compositional semantics~// 51st Annual Meeting of the Association for Computational 
Linguistics Proceedings.~--- Stroudsburg, PA, USA: ACL, 2013. P.~894--904.
  \bibitem{31-koz}
  \Au{Church K., Hanks P.} Word association norms, mutual information, and lexicography~// 
Comput. Linguist., 1996. Vol.~16. No.\,1. P.~22--29.
  
\end{thebibliography}
} }

\end{multicols}

\vspace*{-3pt}

\hfill{\small\textit{Поступила в редакцию 26.12.13}}


\vspace*{9pt}

\hrule

\vspace*{2pt}

\hrule

 
 \def\tit{INTEGRATED MODELING OF LANGUAGE STRUCTURES FOR~LINGUISTIC PROCESSORS 
 OF~KNOWLEDGE MANAGEMENT AND~MACHINE TRANSLATION SYSTEMS}

\def\titkol{Integrated modeling of language structures for~linguistic processors 
 of~knowledge management and~machine translation systems}

\def\aut{E.\,B.~Kozerenko}
\def\autkol{E.\,B.~Kozerenko}


\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-12pt}

\noindent
Institute of Informatics Problems, Russian
Academy of Sciences, 44-2 Vavilov Str., Moscow 119333, Russian Federation


 
\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND APPLICATIONS\ \ \ 2014\ \ \ volume~8\ \ \ issue\ 1}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND APPLICATIONS\ \ \ 2014\ \ \ volume~8\ \ \ issue\ 1
\hfill \textbf{\thepage}}}   

\vspace*{6pt}
  
\Abste{The paper is dedicated to research and integrated modeling 
of cognitive linguistic representations of language structures and the mechanisms 
for resolution of syntactic ambiguity in the process of creating linguistic processors 
for intelligent knowledge processing and machine translation systems. The technique of 
constructing the hybrid cognitive linguistic model for representation of language structures 
and resolution of their ambiguity on the basis of logical linguistic rules and vector spaces 
has been developed and specified. The method presented is new and rests on the 
modern level of development in science and technology. The following tasks have been carried 
out: comparative research of classification methods has been made with respect to linguistic 
problems; the effective method of mapping the vector of natural language structures into the 
expanded space of attributes for classification of new language objects and structures has 
been worked out; the focal sample of parallel texts of business and scientific documents in 
Russian, English, and French has been developed; the expanded system of new categories 
enhancing the representational power of the initial grammar variant has been formed; the 
extended semantic networks were employed for unified representation of the matched language 
structures and the experiments of vector spaces method application for resolution of 
syntactic ambiguity of the key language structures were performed; the grammatical formalism 
and the algorithmic representation have been designed of the parser in which the difficulties 
of translation including the language transformations are taken into account.}
  
\KWE{parallel texts; vector spaces; syntax; semantics; phrase structures; integrated models; 
machine translation; knowledge management}
  
\DOI{10.14357/19922264140109}

\Ack
\noindent
The work was partially supported by the Russian 
Foundation for Basic Research, Grant No.\,11-06-00476-a.

\vspace*{3pt}


  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{99} 
\bibitem{1-koz-1}
\Aue{Kozerenko, E.\,B.} 2003. 
Cognitive approach to language structure segmentation for machine translation algorithms. 
\textit{Conference (International) on Machine Learning, Models, Technologies and 
Applications Proceedings}. Las Vegas, USA: CSREA Press. 49--55.

\bibitem{2-koz-1}
\Aue{Kozerenko, E.\,B.} 2013. Strategii vyravnivaniya parallel'nykh tekstov: 
Semanticheskie aspekty [Parallel texts alignment strategies: The semantic aspects]. 
\textit{Informatika i ee primeneniya}~--- \textit{Inform. Appl}.] 7(1):82--89.

\bibitem{3-koz-1}
\Aue{Shaumyan, S.} 2003. Categorial grammar and semiotic universal grammar. 
\textit{IC-AI'03:  Conference (International) on Artificial Intelligence Proceedings}. 
Las Vegas, USA: CSREA Press. 623--629.
\bibitem{4-koz-1}
\Aue{Kuznetsov, I.\,P., E.\,B.~Kozerenko, and A.\,G.~Matskevich}. 
2011. Intelligent extraction of knowledge structures from natural language texts.  
\textit{2011 IEEE/WIC/ACM  Joint Conferences (International) on Web Intelligence and 
Intelligent Agent Technology Proceedings}. 
Washington, DC, USA: IEEE Computer Society. 03:269--272. 
doi:10.1109/WI-IAT.2011.235
\bibitem{5-koz-1}
\Aue{Dempster, A.\,P., N.\,M.~Laird, and D.\,B.~Rubin}.
1977. Maximum likelihood from incomplete data via the EM algorithm. 
\textit{J.~Roy. Stat. Soc. Ser.~B.} 39(1):1--22.

\bibitem{9-koz-1} %6
\Aue{Lund, K., and C.~Burgess}. 1996. 
Producing high-dimensional semantic spaces from lexical co-occurrence. 
\textit{Behav. Res. Meth. Instr. Comp}. 28(2):203--208.

\bibitem{7-koz-1} %7
\Aue{Curran, J.\,R.} 2004. From distributional to semantic similarity. PhD Thesis. 
Edinburgh: University of Edinburgh. 177~p. 
Available at: {\sf http://sydney.edu.au/ engineering/it/$\sim$james/pubs/pdf/phdthesis.pdf}.

\bibitem{10-koz-1} %8
\Au{McCarthy, D., R.~Koeling, J.~Weeds, and J.~Carroll}. 
2004. Finding predominant senses in untagged text. 
\textit{42nd Annual Meeting of the Association for Computational Linguistics
Proceedings}. Barcelona, Spain: ACL. 280--287.


\bibitem{6-koz-1} %9
\Aue{Clark, S., and S.~Pulman}. 2007. 
Combining symbolic and distributional models of meaning. 
\textit{AAAI Spring Symposium on Quantum Interaction Proceedings}. 
Palo Alto, CA, USA: AAAI Press. 52--55. 
Available at: {\sf http://www.cl.cam.ac.uk/$\sim$sc609/pubs/aaai07.pdf}.

\bibitem{8-koz-1} %10
\Aue{Morozova, Yu.} 2013. Method for extracting translation correspondences from a 
parallel corpus. \textit{ICAI'13, WORLDCOMP'13 Proceedings}. 
Las Vegas, USA: CSREA Press. II:65--69.


\bibitem{11-koz-1} %11
\Aue{Danielson, D.\,A.} 2003. \textit{Vectors and tensors in engineering and physics}. 2nd ed.  
Boulder, CO: Westview (Perseus). 282~p. 

\bibitem{13-koz-1} %12
\Aue{Montague, R.} 1970. Universal grammar. \textit{Theoria}.  36:373--398. 
(Reprinted: Thomason, R.\,H., ed. 1974. \textit{Formal philosophy: Selected papers of Richard Montague}. 
 New Haven\,--\,London: Yale University Press. 222--246.)
 
 \columnbreak
 
\bibitem{14-koz-1} %13
\Aue{Partee, B.} 2004. \textit{Compositionality. Compositionality in formal semantics: 
Selected papers by Barbara H.~Partee}. Malden, MA: Blackwell. 153--181. 
doi: 10.1002/ 9780470751305.ch7.

\bibitem{12-koz-1} %14
\Aue{Pang, B., K.~Knight, and D.~Marcu}. 
2003. Syntax-based alignment of multiple translations: Extracting paraphrases and 
generating new sentences. \textit{NAACL'03: 2003 Conference of the North American 
Chapter of the Association for Computational Linguistics on Human Language Technology
Proceedings}. Stroudsburg, PA, USA: ACL. 1:102--109.

\bibitem{15-koz-1}
\Aue{Bannard, C., and C.~Callison-Burch}. 
2005.  Paraphrasing with bilingual parallel corpora. 
\textit{43rd Annual Meeting of the ACL  Proceedings}.
Stroudsburg, PA, USA: ACL. 597--604.
\bibitem{16-koz-1}
\Aue{Callison-Burch, C.} 2008. Syntactic constraints on paraphrases extracted 
from parallel corpora. \textit{EMNLP-2008 Proceedings}. Stroudsburg, PA, USA: ACL. 196--205.
\bibitem{17-koz-1}
\Aue{Ganitkevitch, Ju., C.~Callison-Burch, C.~Napoles, and B.~Van Durme}. 
2011. Learning sentential paraphrases from bilingual parallel corpora for text-to-text 
generation. \textit{2011 Conference on Empirical Methods in Natural Language Processing
Proceedings}. Stroudsburg, PA, USA: ACL. 1168--1179.
\bibitem{18-koz-1}
\Aue{Bogatyrev, K.} 2006.  In defense of symbolic NLP. 
\textit{MLMTA'06: Conference (International) on Machine Learning, Models,
 Technologies and Applications Proceedings}. Las Vegas, USA: CSREA Press. 63--68.

\bibitem{19-koz-1}
\Aue{Malkov, K.\,V., and D.\,V.~Tunitsky}. 2006. 
On extreme principles of machine learning in anomaly and vulnerability assessment. 
\textit{MLMTA'06:  Conference (International) on Machine Learning, Models, 
Technologies and Applications Proceedings}. Las Vegas, USA: CSREA Press. 24--29.
\bibitem{20-koz-1}
\Aue{Ajdukiewicz, K.} 1935. Die Syntaktische Konnexitat. 
\textit{Stud. Philos.} 1(1):1--27. 
%Eng. trans. as ``Syntactic Connexion'', 
%in McCall (ed.). 1967. 207--231. Ajdukiewicz,~K. 1978. 
%The scientific world-perspective and other essays. Dordrecht: Reidel. 118--139.
\bibitem{21-koz-1}
\Aue{Bar-Hillel, Y.} 1953. A~quasi-arithmetical notation for syntactic description. 
\textit{Language} 29(1):47--58. 
Available at:  {\sf http://ling.umd.edu//$\sim$alxndrw/CGReadings/bar-hillel-53.pdf}.

\bibitem{23-koz-1} %22
\Aue{Lambek, J.} 1958. The mathematics of sentence structure. 
\textit{Am. Math. Mon.} 65(3):154--170.

\bibitem{22-koz-1} %23
\Aue{Steedman, M.} 1996. Surface structure and interpretation. 
Linguistic inquiry monographs. Massachusetts: MIT Press. 140~p.


\bibitem{24-koz-1} %24
\Aue{Lambek, J.} 2008. \textit{From word to sentence: A~computational algebraic approach 
to grammar}. 
Monza, Italy: Polimetrica Publ. 154~p. 
\bibitem{25-koz-1}
\Aue{Moortgat, M.} 2009. Symmetric categorial grammar. 
\textit{J.~Philos. Logic} 38(6):681--710.

\bibitem{28-koz-1} %26
\Aue{Gazdar, G.} 1996. Paradigm merger in natural language processing. 
\textit{Computing tomorrow: Future research directions in computer science}. 
Eds.\ R.~Milner and I.~Wand. Cambridge, U.K.: Cambridge University Press. 88--109.

\pagebreak

\bibitem{27-koz-1}
\Aue{Clark, S., and J.\,R.~Curran}. 2007. Wide-coverage efficient 
statistical parsing with CCG and log-linear models. 
\textit{Comput. Linguist.} 33(4):493--552.



\bibitem{26-koz-1} %28
\Aue{Baroni, M., and R.~Zamparelli}. 2010. Nouns are vectors, adjectives are matrices: 
Representing adjective--noun constructions in semantic space. 
\textit{2010 Conference on Empirical Methods in Natural Language Processing
Proceedings}. Stroudsburg, PA, USA: ACL. 1183--1193.

\bibitem{29-koz-1}
\Aue{Grefenstette, E., and M.~Sadrzadeh}. 2011.
Experimental support for a categorical compositional distributional model of meaning. 
\textit{Conference on Empirical Methods in Natural Language Processing Proceedings}.
Stroudsburg, PA, USA: ACL. 1394--1404.
\bibitem{30-koz-1}
\Aue{Hermann, K.\,M., and P.~Blunsom}. 2013. 
The role of syntax in vector space models of compositional semantics. 
\textit{51st Annual Meeting of the Association for Computational Linguistics
Proceedings}. Stroudsburg, PA, USA: ACL. 894--904.
\bibitem{31-koz-1}
\Aue{Church, K., and P.~Hanks}. 1996. 
Word association norms, mutual information, and lexicography. 
\textit{Comput. Linguist.} 16(1):22--29.

\end{thebibliography}
} }


\end{multicols}

\vspace*{-6pt}


\hfill{\small\textit{Received December 26, 2013}}

\vspace*{-18pt}

\Contrl

\noindent
\textbf{Kozerenko Elena B.} (b.\ 1959)~--- Candidate of Science (PhD) in linguistics,
Head of Laboratory, Institute of Informatics Problems, Russian
Academy of Sciences, 44-2 Vavilov Str., Moscow 119333, Russian Federation;
kozerenko@mail.ru




 \label{end\stat}
 
\renewcommand{\bibname}{\protect\rm Литература}