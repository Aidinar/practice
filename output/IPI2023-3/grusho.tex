\def\stat{grusho}

\def\tit{КЛАССИФИКАЦИЯ С ПОМОЩЬЮ ПРИЧИННО-СЛЕДСТВЕННЫХ СВЯЗЕЙ}

\def\titkol{Классификация с~помощью причинно-следственных связей}

\def\aut{А.\,А.~Грушо$^1$, Н.\,А.~Грушо$^2$, М.\,И.~Забежайло$^3$,  
Д.\,В.~Смирнов$^4$, Е.\,Е.~Тимонина$^5$}

\def\autkol{А.\,А.~Грушо, Н.\,А.~Грушо, М.\,И.~Забежайло и~др.}
%$^3$,   Д.\,В.~Смирнов$^4$, Е.\,Е.~Тимонина$^5$}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Грушо А.\,А.}
\index{Грушо Н.\,А.}
\index{Забежайло М.\,И.}
\index{Смирнов Д.\,В.}
\index{Тимонина Е.\,Е.}
\index{Grusho A.\,A.}
\index{Grusho N.\,A.}
\index{Zabezhailo M.\,I.}
\index{Smirnov D.\,V.}
\index{Timonina E.\,E.}


%{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
%{Работа выполнена с~использованием инфраструктуры Центра коллективного пользования <<Высокопроизводительные вы\-чис\-ле\-ния и~большие данные>> 
%(ЦКП <<Информатика>>) ФИЦ ИУ РАН (г.~Москва).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, \mbox{grusho@yandex.ru}}
\footnotetext[2]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, \mbox{info@itake.ru}}
\footnotetext[3]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{m.zabezhailo@yandex.ru}}
\footnotetext[4]{ПАО Сбербанк России, dvlsmirnov@sberbank.ru}
\footnotetext[5]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{eltimon@yandex.ru}}

\vspace*{-6pt}

 
  \Abst{По определению свойство~$A$ в~объекте~$O$ служит причиной появления 
следствия~$B$, которое до\-ступ\-но наблюдению в~информационном пространстве~$I$, если 
характеристики~$A$ могут породить объект в~пространстве~$I$, содержащий следствие~$B$, 
и~в~этом случае при по\-яв\-ле\-нии~$A$ детерминированно появляется~$B$. Поэтому мож\-но 
рас\-смат\-ри\-вать задачу классификации как вы\-чис\-ле\-ние следствий характеристик объекта, где 
в~качестве следствий вы\-сту\-па\-ют характеристики класса. В~этом случае характеристики 
объекта классификации мож\-но рас\-смат\-ри\-вать как причину, которая детерминированно 
(классификация как отображение) по\-рож\-да\-ет следствия (характеристики класса). 
В~рас\-смат\-ри\-ва\-емом случае каж\-дое из свойств~$A_i$, $i\hm= 1,\ldots , k$, служит причиной 
детерминированного появления не\-пус\-то\-го множества своих следствий. Если чис\-ло классов 
велико, так же как множества следствий каждого~$A_i$, то задача классификации может 
оказаться труд\-но вы\-чис\-ли\-мой из-за того, что воз\-мож\-ны повторения следствий в~множествах 
следствий. Поэтому целесообразно искать упрощенные схемы классификации объектов по 
находящимся в~них причинах следствий. Для этого может быть использован аппарат сис\-тем 
различных пред\-ста\-ви\-те\-лей (СРП). В~условиях задачи классификации причин по следствиям нельзя 
непосредственно воспользоваться тео\-ре\-мой Ф.~Холла об~СРП, 
так как нельзя разрывать элементы цепочек при\-чин\-но-след\-ст\-вен\-ных связей.
  В~статье показано, что преобразование каж\-дой из одинаковых цепочек при\-чин\-но-след\-ст\-вен\-ных 
  связей в~один общий новый элемент в~множествах следствий формирует 
возможности применения условий тео\-ре\-мы Ф.~Холла.}
  
  \KW{причинно-следственные связи; конечная классификация; поиск свойств 
в~ненаблюдаемых данных}

 \DOI{10.14357/19922264230310}{AKWBZD}
  
\vspace*{4pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}
  
  
  \section{Введение}
  
\vspace*{-3pt}
  
  Задача конечной классификации обычно рас\-смат\-ри\-ва\-ет\-ся как отобра\-же\-ние 
множества объектов~$D$ в~конечное множество классов~$K$. Такое отобра\-же\-ние 
порождает разбиение множества~$D$ на конечное чис\-ло классов. Существуют 
ситуации, когда требуется другое определение классов вплоть до воз\-мож\-ности 
пересечения классов. Если не оговорено иное, то под классификацией будем 
понимать отобра\-же\-ние объектов в~множество классов. Решение задачи 
классификации основано на использовании структуры объектов, которая 
поз\-во\-ля\-ет вы\-чис\-лить (вы\-чле\-нить) такие характеристики объекта, которые 
соответствуют описанию со\-от\-вет\-ст\-ву\-юще\-го класса. Поэтому можно 
рас\-смат\-ри\-вать задачу классификации как вы\-чис\-ле\-ние следствий характеристик 
объекта, где в~качестве следствий вы\-сту\-па\-ют характеристики класса. В~этом 
случае характеристики объекта классификации мож\-но рас\-смат\-ри\-вать как 
причину, которая детерминированно (классификация как отобра\-же\-ние) 
по\-рож\-да\-ет следствия (характеристики класса). 
  
  Применение при\-чин\-но-след\-ст\-вен\-ных связей в~задачах классификации 
исследовалось во многих научных работах. Сюда надо преж\-де всего отнести 
при\-клад\-ные исследования и~тео\-ре\-ти\-че\-ские обосно\-ва\-ния использования  
при\-чин\-но-след\-ст\-вен\-ных связей в~задачах медицинской диаг\-но\-сти\-ки. 
В~работах~[1--3] по\-стро\-ены модели каузального вывода в~медицинской 
диагностике. В~[4] по\-стро\-ена модель использования  
при\-чин\-но-след\-ст\-вен\-ных связей в~задачах классификации изображений 
с~применением байесовских сетей и~нейронных сетей.
  
  В данной работе предмет классификации рас\-смат\-ри\-ва\-ет\-ся как объект, 
об\-ла\-да\-ющий одним из нескольких воз\-мо\-жных ненаблюдаемых множеств 
характеристик. Каж\-дое такое множество характеристик служит причиной 
появления одного или нескольких следствий, и~любой алгоритм классификации 
принимает решение о~классе по наблюдениям следствий из ана\-ли\-зи\-ру\-емой 
причины. 

Использование при\-чин\-но-след\-ст\-вен\-ных связей в~классификации 
основано на двух свойствах причин и~следствий. Пер\-вое свойство со\-сто\-ит в~том, 
что появление причины детерминированно влечет появление следствия в~случае 
конструктивного взаимодействия причины с~пространством, в~котором может 
возникнуть следствие. Второе свойство означает, что нет свойств, появление 
которых не имеет причин. Если причина искажена, то следствие либо не 
возникает, либо обуслов\-ле\-но другими при\-чи\-нами. 

\vspace*{-3pt}
  
  \section{Модель причинно-следственных связей для~объектов}
  
  \vspace*{-3pt}
  
  Будем считать, что существует конечное множество~$U$ характеристик. 
Любой объект~$O$ определяется как некоторое подмножество множества~$U$. 
Пусть задано некоторое множество объектов~$\bm{O}$ и~только объекты этого 
множества могут появляться для анализа. Свойство~$A$ объекта~$O$ 
пред\-став\-ля\-ет собой некоторое подмножество характеристик объекта~$O$, при 
этом свойство~$A$ может не быть объектом. Со\-став характеристик свойства~$A$ 
может быть неизвестен. Пусть необходимо неоднократно классифицировать 
по\-сту\-па\-ющие объекты~$O$ из~$\bm{O}$ на предмет наличия в~них одного из 
свойств $A_1, A_2, \ldots , A_k$ в~предположении, что в~каж\-дом 
клас\-си\-фи\-ци\-ру\-емом объекте содержится ров\-но одно из этих свойств. 
  
  По определению свойство~$A$ в~объекте~$O$ служит причиной появления 
следствия~$B$, которое до\-ступ\-но наблюдению в~информационном 
пространстве~$I$, если характеристики~$A$ могут породить \mbox{объект} 
в~пространстве~$I$, со\-дер\-жа\-щий следствие~$B$, и~в~этом случае при 
появлении~$A$ детерминированно появляется~$B$. 
  
  В рассматриваемом случае каж\-дое из свойств $A_1, A_2,\ldots , A_k$ служит 
причиной детерминированного появления не\-пус\-то\-го множества своих следствий 
  $\{ B(A_i, j), j\hm= 1,\ldots , m_i\}$, $i\hm= 1,\ldots , k$, в~информационных 
пространствах $\{ I(A_i, j), j\hm= 1,\ldots m_i\}$, $i\hm= 1,\ldots , k$. Допускается, 
что у~некоторых следствий может быть несколько причин, т.\,е.\ некоторые 
следствия, по\-рож\-да\-емые разными причинами, могут совпадать. 

\vspace*{-3pt}
  
  \section{Определение множеств следствий с~помощью обучения}
  
  \vspace*{-3pt}
  
  Рассмотрим задачу построения множеств следствий в~условиях, когда для 
каждого~$A_i$ определена обуча\-ющая выборка объектов $\bm{S}_i\hm\subseteq 
\bm{O}$, содержащих это свойство. Для каж\-до\-го объекта~$S$ из обуча\-ющей 
выборки~$\bm{S}_i$ известны взаимодействия причины~$A_i$ 
с~информационными пространствами $I(A_i, j)$, $j\hm= 1,\ldots , m_i$, в~которых 
мож\-но наблюдать следствия этой причины. Из детерминированности появления 
следствий причины~$A_i$ в~этих пространствах $I(A_i, j)$, $j\hm=1,\ldots m_i$, 
получаем одинаковый набор следствий $V_i\hm= \{ B(A_i, j), j\hm= 1,\ldots , 
m_i\}$. В~до\-ступ\-ных для~$A_i$ информационных пространствах, где этот набор 
не появился, причина~$A_i$ не имеет следствий.
  
  Если объект~$O$ не принадлежит ни одной обуча\-ющей выборке, но обладает 
свойством~$A_i$, то он так\-же по\-рож\-да\-ет множество следствий $V_i \hm=\{B(A_i, 
j), j\hm=1,\ldots , m_i\}$. Отсюда следует \mbox{воз\-мож\-ность} классифицировать объекты, 
не при\-над\-ле\-жа\-щие обуча\-ющим вы\-бор\-кам. Если чис\-ло классов велико, так же как 
множества следствий каждого~$A_i$, то задача классификации может оказаться 
труд\-но вы\-чис\-ли\-мой из-за того, что воз\-мож\-ны повторения следствий в~множествах 
следствий. Поэтому целесообразно искать упрощенные схемы классификации 
объектов по находящимся в~них причинах следствий. Для этого может быть 
использован аппарат СРП.

%\vspace*{-3pt}
  
  \section{Системы различных представителей}
  
 % \vspace*{-3pt}
  
  Рассмотрим сле\-ду\-ющую конечную тео\-ре\-ти\-ко-мно\-жест\-вен\-ную схему. 
Пусть даны $k$ подмножеств $X_1, X_2, \ldots , X_k$ конечного множества~$X$.
  
  \smallskip
  
  \noindent
  \textbf{Определение.}\ Сис\-те\-ма различных пред\-ста\-ви\-те\-лей для подмножеств $X_1, X_2, \ldots , X_k$ 
конечного множества~$X$~--- это множество элементов $\{ x_1, x_2, \ldots , x_k\}$ этих множеств, таких что $x_i\hm\in X_i$ и~$x_i\not= x_j$, если $i\not= j$. 
  
  \smallskip
  
  Положим $X_i=V_i$, $i\hm = 1,\ldots , k$, где~$V_i$~--- множество следствий 
причины~$A_i$.
  
  \smallskip
  
  \noindent
  \textbf{Теорема~1.} \textit{Если все элементы множества}
  $$
  \mathop{\bigcup}\limits_{1\leq i\leq k} V_i = \mathop{\bigcup}\limits_{1\leq i\leq k} 
\left( B(A_i,j), j=1,\ldots , m_i\right)
  $$
\textit{различны, то существует СРП и~ее элементы од\-но\-знач\-но 
идентифицируют причины} $A_1, A_2, \ldots , A_k$.
  
  \smallskip
  
  \noindent
  Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \  Для каж\-дой причины~$A_i$ 
существует по крайней мере одно следствие (это следует из по\-ста\-нов\-ки задачи 
в~разд.~2), и~все они различные. Тогда пред\-ста\-ви\-те\-ли раз\-лич\-ных множеств 
следствий образуют СРП, которая однозначно определяет причины $A_1, A_2, \ldots , A_k$.
  
  В общем случае мож\-но воспользоваться тео\-ре\-мой Филиппа Холла~[5, 6]. 
Вернемся к~обо\-зна\-че\-ни\-ям определения СРП.
  
  \smallskip

%\pagebreak
  
  \noindent
  \textbf{Теорема~2.} \textit{Пусть даны $k$ подмножеств $X_1, X_2, \ldots$\linebreak $\ldots , 
X_k$ множества~$X$. Необходимым и~достаточным условием существования 
СРП, т.\,е.\ множества элементов $\{x_1, x_2, \ldots , x_k\}$, таких что 
$x_i\hm\in X_i$ и~$x_i\not= x_j$, если $i\not= j$, вы\-сту\-па\-ет условие~$C$: для 
каждого $r\hm = 1,\ldots , k$ и~каждой по\-сле\-до\-ва\-тель\-ности~$r$~раз\-лич\-ных 
индексов $i_1, i_2, \ldots , i_r$ в~объединении подмножеств $X_{i_1}, \ldots , 
X_{i_r}$ содержится не менее~$r$~раз\-ных элемен-\linebreak тов}.
  
  \smallskip
  
  К сожалению, в~условиях задачи классификации причин по следствиям 
непосредственно воспользоваться этой тео\-ре\-мой нельзя. Если причина~$A$, 
со\-сто\-ящая из характеристик множества~$U$, по\-рож\-да\-ет следствие~$B$ 
в~объекте информационного пространства характеристик~$U^*$, а~$B$ как 
причина по\-рож\-да\-ет в~объекте информационного пространстве 
характеристик~$U^{**}$ следствие~$E$, то из условия де\-тер\-ми\-ни\-ро\-ван\-ности 
при\-чин\-но-след\-ст\-вен\-ных связей следует тран\-зи\-тив\-ность причины~$A$ на 
следствие~$E$. Это означает, что~$A$ так\-же служит причиной появления 
след\-ст\-вия~$E$.
  
  Возможность появления транзитивных следствий у~причины~$A$ означает, что 
разрывать элементы цепочек таких при\-чин\-но-след\-ст\-вен\-ных связей нельзя. 
Приведем пример.
  
  \textbf{Пример.} Пусть необходимо классифицировать объект~$O$ на 
при\-над\-леж\-ность одному из двух классов, опре\-де\-ля\-емых причинами~$A_1$ 
и~$A_2$. Предположим, что воз\-мож\-ны повторы следствий, при этом~$A_1$ 
и~$A_2$ служат причинами следствий~$B_1$ и~$B_2$, а~$B_1$ служит 
причиной~$B_2$.
  
   Для множеств $X_1\hm= \{B_1, B_2\}$ и~$X_2\hm=\{ B_1, B_2\}$ существует сис\-те\-ма раз\-лич\-ных 
пред\-ста\-ви\-те\-лей ($B_1$) для идентификации~$X_1$ и~($B_2$) для 
идентификации~$X_2$. Однако для идентификации причин~$A_1$ и~$A_2$ 
по\-стро\-ен\-ная СРП не дает однозначной классификации причин~$A_1$ и~~$A_2$, 
так как в~обоих случаях при появлении~$B_1$ автоматически появляется~$B_2$ и~их нельзя раз\-де\-лять.
  
  Возможность появления не\-раз\-де\-ля\-емых цепочек следствий означает, что такие 
цепочки следует рас\-смат\-ри\-вать как один элемент. Тогда изменяется чис\-ло 
элементов в~множествах, участ\-ву\-ющих в~формулировке тео\-ре\-мы Филиппа Холла, 
и~необходимые условия могут не выполняться.
  
  Рассмотрим эту проб\-ле\-му детальнее. Для выполнения условий тео\-ре\-мы 
Филиппа Холла необходима воз\-мож\-ность формировать любые подмножества 
исходных множеств и~считать чис\-ло разных элементов. Тогда преобразование 
каж\-дой из одинаковых цепочек при\-чин\-но-след\-ст\-вен\-ных связей в~один 
общий новый элемент в~множествах следствий формирует возможности 
проверять условия тео\-ре\-мы Филиппа Холла. Однако по результатам обуче\-ния эти 
цепочки неизвестны. Отсюда следуют три воз\-мож\-ности.
  \begin{enumerate}[1.]
  \item Если набор следствий причины~$A_i$ встретился в~обучениях один раз, 
то любой его элемент может быть взят в~сис\-те\-му различных пред\-ста\-ви\-те\-лей. Это 
следует из доказательства тео\-ре\-мы~1 и~того факта, что все элементы класса, 
по\-рож\-ден\-но\-го причиной~$A_i$, будут обладать одним набором следствий.
  \item Если наборы следствий причин~$A_i$ и~$A_j$, $i\not= j$, обладают 
одинаковыми подмножествами следствий, а~в~других наборах следствий 
в~случаях появления ранее встре\-чав\-ших\-ся следствий~$A_i$ они появляются 
в~со\-ста\-ве тех же подмножеств, то все такие подмножества следует заменить на 
один новый символ. Также надо переобозначить другие множества одинаковых 
следствий в~других множествах следствий.
  \item Если в~наборах следствий причин~$A_i$ и~$A_j$, $i\not= j$, встретились 
разные подмножества одинаковых элементов, то каж\-дое из этих подмножеств 
следует переобозначить раз\-ны\-ми буквами, которые мож\-но использовать 
в~по\-стро\-ении СРП. Это следует из того, что эти подмножества соответствуют 
разным транзитивным следствиям одной причины.
  \end{enumerate}
  
  После указанных редукций множеств следствий мож\-но исследовать 
возможности по\-стро\-ения СРП на основе условий тео\-ре\-мы Филиппа Холла. Если 
СРП существует, то она однозначно классифицирует объект в~соответствии 
с~обладанием ров\-но одной из причин $A_1, A_2, \ldots , A_k$.
  
  Проверка выполнения условий тео\-ре\-мы Филиппа Холла и~по\-стро\-ение СРП 
мож\-но осуществить перебором $2^k\hm-1$ подмножеств редуцированных 
множеств следствий. В~книге~\cite{6-gr} приведены другие алгоритмы поиска 
СРП, об\-ла\-да\-ющие меньшими оцен\-ка\-ми слож\-ности.
  
  \section{Классификация в~условиях~шума}
  
  В работе~\cite{6-gr} приведено следствие тео\-ре\-мы Филиппа Холла о~чис\-ле 
СРП.
  
  \smallskip
  
  \noindent
  \textbf{Следствие.} Пусть даны $k$ подмножеств $X_1, X_2, \ldots$\linebreak $\ldots , X_k$ 
множества~$U$, которые имеют СРП. Если наименьшее из этих множеств 
содержит $t$ элементов, то при $k\hm\leq t$ существует не меньше чем\linebreak $t(t\hm-1) 
\cdots (t\hm- k\hm+1)$ раз\-лич\-ных СРП, а~при $t\hm< k$ существует не меньше чем~$t!$ 
различных СРП.
  
  \smallskip
  
  Применение этого следствия в~задаче классификации причин по следствиям 
воз\-мож\-но только после редукции множеств следствий, о~которой было сказано 
выше.
  
  В работе~\cite{7-gr} рас\-смат\-ри\-ва\-лась бинарная классификация на основе 
следствий в~условиях случайного шума, за\-труд\-ня\-юще\-го идентификацию 
следствий. Используя приведенное следствие тео\-ре\-мы Филиппа Холла, мож\-но 
создать избыточное множество различных СРП, если это воз\-мож\-но, 
и~использовать различные СРП как взаимно до\-пол\-ня\-ющую информацию для 
уточ\-не\-ния классификации. 

\vspace*{-3pt}
  
  \section{Заключение}
  
  Задачу конечной классификации можно пред\-став\-лять как задачу 
идентификации набора из нескольких причин по наблюда\-емым следствиям. При 
этом саму классификацию мож\-но по\-стро\-ить на сис\-те\-мах различных 
пред\-ста\-ви\-те\-лей множеств следствий. Это позволяет быст\-ро и~с~высокой 
на\-деж\-ностью проводить классификацию объектов на наличие причины из 
конечного множества.
  
  Определение множеств следствий по обуча\-ющей выборке не требует большого 
чис\-ла элементов такой выборки, так как основана на детерминизме появления 
следствий при появлении \mbox{при\-чины}.
   
  Глубокая и~трудоемкая работа требуется для пред\-став\-ле\-ния задачи 
классификации в~форме идентификации причин по наблюдаемым следствиям. 
Другая слож\-ная проб\-ле\-ма со\-сто\-ит в~поиске возможных следствий выделенных 
причин в~различных информационных пространствах.
  
   Непосредственное применение тео\-рем и~алгоритмов поиска СРП ослож\-не\-но 
не\-об\-хо\-ди\-мостью учитывать существование транзитивных причин.

\vspace*{-3pt}
  
{\small\frenchspacing
 { %\baselineskip=12pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9}

\bibitem{2-gr}
\Au{Pearl J.} Causal inference~// Causality: Objectives and assessment~/ Eds. I.~Guyon, D.~Janzing, B.~Scholkopf.~--- Proceedings of machine learning research 
ser.~--- Whistler, Canada, 2010. Vol.~6. P.~39--58.

\bibitem{1-gr}
\Au{Richens J.\,G., Lee~C.\,M., Johri~S.} Improving the accuracy of medical diagnosis with causal 
machine learning~// Nat. Commun., 2020. Vol.~11. Art.~3923. 9~p.  
doi: 10.1038/ s41467-020-17419-7.

\bibitem{3-gr}
\Au{Забежайло М.\,И., Грушо~А.\,А., Грушо~Н.\,А., Ти\-мо\-ни\-на~Е.\,Е.} Под\-держ\-ка решения задач 
диагностического типа~// Сис\-те\-мы и~средства информатики, 2021. Т.~1. №\,1. С.~69--81. doi: 
10.14357/08696527210106.
\bibitem{4-gr}
\Au{Zhang C., Zhang~K., Li~Y.} A~causal view on robustness of neural networks.~--- Cornell 
University, 2021. \mbox{arXiv}: 2005.01095v3 [cs.LG]. 21~p.
\bibitem{5-gr}
\Au{Hall Ph.} On representation of subsets~// J.~Lond. Math. Soc., 1935. Vol.~10. P.~26--30.
doi: 10.1112/JLMS/S1-10. 37.26.
\bibitem{6-gr}
\Au{Халл М.} Комбинаторика~/ Пер. с~англ.~--- М.: Мир, 1970. 424~с.
(\Au{Hall~M.} {Combinatorial theory}.~--- London: Blaisdell Pub. Co., 1967. 310~p.)
\bibitem{7-gr}
\Au{Грушо А.\,А., Забежайло~М.\,И., Куль\-чен\-ков~В.\,В., Смир\-нов~Д.\,В., Ти\-мо\-ни\-на~Е.\,Е., 
Шор\-гин~С.\,Я.} При\-чин\-но-след\-ст\-вен\-ные связи в~задачах анализа ненаблюдаемых 
процессов~// Сис\-те\-мы и~средства информатики, 2023. Т.~33. №\,2. С.~71--78.
doi: 10.14357/08696527230207.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 05.06.23}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule



\def\tit{CLASSIFICATION BY~CAUSE-AND-EFFECT RELATIONSHIPS}


\def\titkol{Classification by cause-and-effect relationships}


\def\aut{A.\,A.~Grusho$^1$, N.\,A.~Grusho$^1$, M.\,I.~Zabezhailo$^1$, D.\,V.~Smirnov$^2$, 
and~E.\,E.~Timonina$^1$}

\def\autkol{A.\,A.~Grusho, N.\,A.~Grusho, M.\,I.~Zabezhailo, et al.}
%D.\,V.~Smirnov$^2$,  and~E.\,E.~Timonina$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-10pt}


\noindent
$^1$Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences,  
44-2~Vavilov\linebreak
$\hphantom{^1}$Str., Moscow 119133, Russian Federation

\noindent
$^2$Sberbank of Russia, 19~Vavilov Str., Moscow 117999, Russian Federation


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 3}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 3
\hfill \textbf{\thepage}}}

\vspace*{3pt}



   
   \Abste{By definition, property~$A$ in object~$O$ is the cause for the occurrence of consequence~$B$ 
   which is available for observation in information space~$I$ if characteristics of~$A$ 
   can generate an object in space~$I$ containing consequence~$B$. 
   In this case, $B$ determinedly appears with the appearance of~$A$. Therefore, one can consider the classification problem 
   as calculating the consequences of the characteristics of the object where the consequences act as characteristics of the class. 
   In this case, the characteristics of the classification object can be considered
   as the cause that deterministically (classification as mapping) 
   generates consequences (characteristics of the class). Each of the properties~$A_i$, $i=1,\ldots , k$,  
   is the cause of the deterministic appearance of a~nonempty set of its consequences. If the number of classes is large as well 
   as the sets of consequences of each, then the classification problem can be complex to compute due to the fact that repetitions 
   of consequences in the sets of consequences are possible. Therefore, it is advisable to look for simplified schemes for 
   classifying objects according to the causes for
   the consequences in them. For this, an apparatus of systems of various 
   representatives can be used. In the context of
   the problem of classifying causes due to consequences, it is impossible to directly use~F. 
   Hall's theorem on systems\linebreak\vspace*{-12pt}}
   
   \Abstend{of various representatives, since elements of cause-and-effect chains cannot be broken. 
   The paper shows that the transformation of each of the same chains of cause-and-effect relationships
    into one common new element in the sets of consequences forms the possibility of applying the conditions of~F. Hall's theorem.}

\KWE{cause-and-effect relationships; finite classification; 
searching for the properties in unobservable data}

 \DOI{10.14357/19922264230310}{AKWBZD}

%\vspace*{-20pt}

%\Ack
%\noindent

  

%\vspace*{6pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9} 

\bibitem{2-gr-1}
\Aue{Pearl, J.} 2010. Causal inference. \textit{Causality: Objectives and 
assessment}. Eds. I.~Guyon, D.~Janzing, and B.~Scholkopf. Proceedings of machine learning 
research ser. Whistler, Canada. 6:39--58.

\bibitem{1-gr-1}
\Aue{Richens, J.\,G., C.\,M.~Lee, and S.~Johri.} 2020. Improving the accuracy of medical diagnosis 
with causal machine learning. \textit{Nat. Commun.} 11:3923. 9~p. doi:  
10.1038/s41467-020-17419-7.

\bibitem{3-gr-1}
\Aue{Zabezhailo, M.\,I., A.\,A.~Grusho, N.\,A.~Gru\-sho, and E.\,E.~Ti\-mo\-ni\-na.} 2021. Pod\-derzh\-ka 
re\-she\-niya za\-dach diag\-no\-sti\-che\-sko\-go ti\-pa [Support for solving diagnostic type problems]. 
\textit{Sis\-te\-my i~Sredstva Informatiki~--- Systems and Means of Informatics} 31(1):69--81. doi: 
10.14357/ 08696527210106.
\bibitem{4-gr-1}
\Aue{Zhang, C., K.~Zhang, and Y.~Li.} 2021. A~causal view on robustness of neural networks. 
\textit{arXiv.org}. 21~p. Available at:  https://arxiv.org/abs/2005.01095v3 (accessed June 28, 2023).
\bibitem{5-gr-1}
\Aue{Hall, P.} 1935. On representation of subsets. \textit{J.~Lond. Math. Soc.} 10:26--30. doi: 
10.1112/JLMS/S1-10.37.26.
\bibitem{6-gr-1}
\Aue{Hall, M.} 1967. \textit{Combinatorial theory}. London: Blaisdell Pub. Co. 310~p.
\bibitem{7-gr-1}
\Aue{Grusho, A.\,A., M.\,I.~Zabezhailo, V.\,V.~Kul\-chen\-kov, D.\,V.~Smir\-nov, E.\,E.~Ti\-mo\-ni\-na, and 
S.\,Ya.~Shor\-gin.} 2023.  Prichinno-sledstvennye svya\-zi v~za\-da\-chakh ana\-li\-za 
ne\-nablyuda\-emykh pro\-tses\-sov [Cause-and-effect relationships in analysis of unobservable process 
properties].\linebreak \textit{Sis\-te\-my i~Sredstva Informatiki~--- Systems and Means of Informatics} 
33(2):71--78. doi: 10.14357/08696527230207.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received June 5, 2023}} 

\vspace*{-12pt}

\Contr

\noindent
\textbf{Grusho Alexander A.} (b.\ 1946)~--- Doctor of Science in physics and mathematics, professor, 
principal scientist, Institute of Informatics Problems, Federal Research Center ``Computer Science and 
Control'' of the Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, Russian 
Federation; \mbox{grusho@yandex.ru}

\vspace*{3pt}

\noindent
\textbf{Grusho Nikolai A.} (b.\ 1982)~--- Candidate of Science (PhD) in physics and mathematics, 
senior scientist, Institute of Informatics Problems, Federal Research Center ``Computer Science and 
Control'' of the Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 119133, Russian 
Federation; \mbox{info@itake.ru}

\vspace*{3pt}

\noindent
\textbf{Zabezhailo Michael I.} (b.\ 1956)~--- Doctor of Science in physics and mathematics, principal 
scientist, A.\,A.~Dorodnicyn Computing Center, Federal Research Center ``Computer Science and 
Control'' of the Russian Academy of Sciences, 40~Vavilov Str., Moscow 119333, Russian Federation; 
\mbox{m.zabezhailo@yandex.ru}

\vspace*{3pt}

\noindent
\textbf{Smirnov Dmitry V.} (b.\ 1984)~--- business partner for IT security department, Sberbank of 
Russia, 19~Vavilov Str., Moscow 117999, Russian Federation; \mbox{dvlsmirnov@sberbank.ru}

\vspace*{3pt}

\noindent
\textbf{Timonina Elena E.} (b.\ 1952)~--- Doctor of Science in technology, professor, leading scientist, 
Institute of Informatics Problems, Federal Research Center ``Computer Science and Control'' of the 
Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 119133, Russian Federation; 
\mbox{eltimon@yandex.ru}



\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 