\def\stat{kudr}

\def\tit{БАЙЕСОВСКИЕ МОДЕЛИ МАССОВОГО ОБСЛУЖИВАНИЯ И~НАДЕЖНОСТИ:
ЭКСПОНЕНЦИАЛЬНО-ЭРЛАНГОВСКИЙ СЛУЧАЙ$^*$}
\def\titkol{Байесовские модели массового обслуживания и надежности:
экспоненциально-Эрланговский случай} 

\def\autkol{А.\,А.~Кудрявцев, С.\,Я.~Шоргин}
\def\aut{А.\,А.~Кудрявцев$^1$, С.\,Я.~Шоргин$^2$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
{Работа выполнена при поддержке РФФИ, проекты 08--07--00152 и 08--01--00567.}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский государственный университет им.\ М.\,В.~Ломоносова,
факультет ВМиК, nubigena@hotmail.com}
\footnotetext[2]{Институт проблем
информатики Российской академии наук, sshorgin@ipiran.ru}


%\input macros.tex

\vspace*{-8pt}


\Abst{В данной работе продолжается изучение байесовских моделей массового обслуживания и надежности. Соответствующий метод
предусматривает рандомизацию характеристик систем относительно некоторых априорных распределений параметров систем.
Такой подход может использоваться, в частности, для вычисления моментных характеристик для вероятностно-временных и
надежностных характеристик больших групп систем или устройств. В работе представлены новые результаты для случая, когда
в качестве пары априорных распределений рассматриваются экспоненциальное распределение и распределение Эрланга.}

\KW{байесовский подход; системы массового обслуживания; надежность; смешанные
распределения; моделирование; эрланговское распределение; экспоненциальное распределение}



      \vskip 24pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

      \label{st\stat}

\section{Введение и основные предположения}

Подробное изложение основ байесовского подхода к моделированию сис\-тем массового обслуживания 
(СМО) и ненадежных
восстанавливаемых сис\-тем содержится в~\cite{1k, 2k}. Здесь коснемся этого вопроса лишь вкратце.

В реальной практике нередки ситуации, когда исследуемая система задана в определенном смыс\-ле <<неточно>>; скажем,
если даже говорить о прос\-тей\-ших сис\-те\-мах типа $M\vert G\vert 1$, исследователю могут быть априори неизвестны параметр входящего
потока $\lambda$ и параметры обслуживания $\mu$ и $\sigma^2$. Такие ситуации возникают, скажем, в случае, когда
рассматривается целый класс устройств, описываемых однотипными СМО, относительно
которых известны только типы входящего потока и распределения обслуживания, а также дисциплина обслуживания, но
конкретные параметры этих потоков и распределений, вообще говоря, различны для различных СМО данного класса. В этом
случае, поскольку неизвестными являются именно <<исходные>> параметры потоков и времени обслуживания, естественным
является рандомизационный подход, при котором элементами вероятностного пространства становятся (если рассматривать
приведенный выше пример) значения $\lambda$, $\mu$ и $\sigma^2$ (а в общем случае можно говорить о вероятностном
пространстве, элементами которого являются сами однотипные СМО). При этом подлежащие вычислению характеристики такой
<<рандомизированной>> СМО, естественно, являются рандомизацией аналогичных характеристик <<обычной>> СМО аналогичного
типа --- с учетом того априорного распределения входных параметров СМО, которое взято исследователем за основу.

Таким образом, в том же примере с системой типа $M\vert G\vert 1$ возникают задачи рандомизации <<обычных>> характеристик таких
систем с учетом априорных распределений входных параметров. Скажем, может приниматься предположение о показательном,
равномерном или каком-то другом распределении одной или нескольких из величин $\lambda$, $\mu$ и $\sigma^2$ (которые
при таком подходе становятся случайными величинами), об их независимости или зависимости и~т.\,п. Полученные результаты
могут применяться, например, для вычисления средних значений, построения доверительных интервалов для тех или иных
характеристик рассматриваемого класса СМО <<в целом>>. Такой подход к по\-стро\-ению моделей массового обслуживания
естественно назвать \textit{байесовским}.

Другим направлением применения байесовского подхода является оценка надежности. Как известно (см.~\cite{3k}), коэффициент
готовности восстанавливаемого устройства в стационарном режиме может быть вычислен по формуле
$$
k=\fr{\lambda^{-1}}{{\lambda^{-1}+\mu^{-1}}}=\fr{\mu}{{\lambda+\mu}}\,,
$$
где $\lambda^{-1}$~--- среднее время безотказной работы, $\mu^{-1}$~--- среднее время восстановления. Если принять
сформулированное выше предположение, в соответствии с которым любое изучаемое устройство\linebreak выбирается случайным образом
из некоторого множества сходных устройств, различающихся сред\-ними величинами показателей надежности, то,\linebreak
 согласно
приведенным выше рассуждениям, значения $\lambda$ и $\mu$ могут рассматриваться в качестве случайных.
Следовательно, при таких предположениях коэффициент готовности $k$ также является случайной величиной и его
распределение зависит от распределений величин $\lambda$ и $\mu$. Результаты, получаемые в рамках этой постановки,
могут использоваться, в частности, для вычисления средних значений и построения доверительных интервалов для
надежностных характеристик всей изучаемой группы устройств.

Основным объектом рассмотрения на настоящем этапе является СМО  $M\vert M\vert 1$, в которой
интенсивность входящего потока $\lambda$ и интенсивность обслуживания $\mu$ независимы и имеют некоторые априори
известные распределения. При этом загрузка рассматриваемой системы имеет вид $\rho=\lambda/\mu$. Как известно, от
значения $\rho$ зависит наличие стационарного режима у рассматриваемой системы; величина $\rho$ входит во многие
формулы, описывающие характеристики разнообразных СМО. В~связи с этим рассмотрение величины $\rho$ избрано одной из
первоочередных задач, которые следует рассмотреть в рамках байесовской теории СМО. Кроме того, рассматриваются
распределения такой рандомизированной характеристики, как вероятность потерь $1-\pi$ (здесь $\pi$~--- вероятность того,
что входящий в СМО вызов не будет потерян).

Отметим, что значение коэффициента го\-тов\-ности $k$ при среднем времени безотказной работы $\lambda^{-1}$ и среднем
времени восстановления $\mu^{-1}$ совпадает с величиной

\noindent
$$
\pi=\fr{1}{{1+\rho}}=\fr{\mu}{{\lambda+\mu}}
$$
для системы $M\vert M\vert 1$, в которой $\lambda$~--- интенсивность входящего потока, а  $\mu$~--- интенсивность обслуживания.
Поэтому вычисление вероятностных характеристик величины $\pi$ означает одновременное вычисление вероятностных
характеристик величины~$k$ при соответствующих распределениях среднего времени безотказной работы и среднего времени
восстановления.

В настоящей работе всюду говорится об определении распределений величин, относящихся к байесовской модели СМО, включая
$\pi$. При этом подразумевается, что распределение величины $k$ в соответствующей <<надежностной>> постановке
специально вычислять не нужно, поскольку оно совпадает с распределением величины $\pi$.

Данная работа является логическим продолжением статей~\cite{1k, 2k}, в которых авторы рассматривали вероятностные
характеристики коэффициента загрузки $\rho$, вероятности потерь
 $1-\pi$\linebreak в системе $M\vert M \vert 1 \vert 0$ в предположении, что пару
<<априорных распределений>> (т.\,е.\ пару <<рас-\linebreak пре\-де\-ле\-ние параметра входящего потока\,--\,рас\-пре\-де\-ле\-ние параметра
обслуживания>>) со\-став\-ля\-ют:\linebreak  <<рав\-но\-мер\-ное--рав\-но\-мер\-ное>>, <<экспо\-нен\-циаль\-ное--экспо\-нен\-ци\-аль\-ное>>, 
<<вы\-рож\-ден\-ное\,--\,рас\-пре\-де\-ле\-ние Эрланга>> (естественно, одновременно\linebreak
 вычислялись характеристики коэффициента готовности $k$ в
соответствующей <<надежностной>> постановке).

В настоящей статье рассматриваются пары  <<экспоненциальное\,--\,распределение Эрланга>> и 
<<распределение Эрланга\,--\,экспоненциальное>>.

В дальнейшем авторы предполагают продолжить расширение множества пар априорных распределений, по которым производится
рандомизация параметров $\lambda$ и $\mu$. В табл.~1 отображены этапы рассмотрения предложенной задачи. Буквы D, M,
R, E и P обозначают вырожденное, экспоненциальное, равномерное, Эрланга и Парето распределения соответственно; символ
<<$*$>> относится к классической постановке задачи, символ <<$+$>> соответствует уже рассмотренным ранее
распределениям, символ <<$\oplus$>>~--- распределениям, о которых пойдет речь в данной работе, символом <<$-$>>
обозначаются распределения, для которых авторы планируют получить аналогичные результаты в дальнейшем.

\vspace*{10pt}

 \noindent
{\centerline{{\tablename~1}\ \ \small{Этапы рассмотрения задачи}}}
%\label{f1s}}
%\end{figure*}
\vspace*{1pt}

{\small
\begin{center}
\tabcolsep=10pt
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$\fr{\lambda}{\mu}$&D&M&R&E&P\\
&&&&&\\[-9pt]
\hline
D&*&$+$&$+$&$+$&$-$\\
M&$-$&$+$&$-$&$\oplus$&$-$\\
R&$+$&$-$&$+$&$-$&$-$\\
E&$-$&$\oplus$&$-$&$-$&$-$\\
P&$-$&$-$&$-$&$-$&$-$\\
\hline
\end{tabular}
\end{center}
}

%\bigskip
\addtocounter{table}{1}  

\section{Основные результаты}


Итак, рассмотрим систему $M\vert M\vert 1\vert 0$. Пусть интенсивность входящего потока $\lambda$ имеет экспоненциальное распределение с
параметром $\theta>0$, а интенсивность обслуживания $\mu$ имеет распределение Эрланга с параметрами $n\ge 1$ и $\alpha>0$,
причем~$\lambda$ и $\mu$ независимы. Целью исследования является нахождение функции распределения, плотности и первых моментов
случайных величин $\rho=\lambda/\mu$ и $\pi=1/(1+\rho)$.

Найдем функцию распределения $F_\rho(x)$ случайной величины $\rho$. Имеем
\begin{multline*}
F_\rho(x)=\p(\lambda<\mu x)={}\\
{}=\il{0}{\infty}\left(1-e^{-\theta x y}\right)\fr{y^{n-1}\alpha^n e^{-\alpha
y}}{{{(n-1)!}}}\, dy={}\\
{}=1-\left(\fr{\alpha}{{{\alpha+\theta x}}}\right)^n\,,\quad x>0\,.
\end{multline*}

Продифференцировав последнее выражение по~$x$, найдем плотность величины $\rho$:
$$
f_\rho(x)=\fr{n\theta\alpha^n}{{(\alpha+\theta x)^{n+1}}}\,, \quad x>0\,.
$$

Найдем первые два момента случайной величины $\rho$. Очевидно, что $\e\rho=\infty$ при $n=1$ и $\e\rho^2=\infty$ при
$n\le 2$. Для остальных натуральных $n$ по формуле 856.12 из~\cite{4k} имеем
\begin{multline*}
\e\rho=\il{0}{\infty}\fr{n\theta\alpha^n x}{{(\alpha+\theta x)^{n+1}}}\,
dx=\il{0}{\infty}\fr{n\alpha^n\, dx}{{(\alpha+\theta x)^n}}-{}\\
{}- \il{0}{\infty}\fr{n\alpha^{n+1}\, dx}{{(\alpha+\theta
x)^{n+1}}}=\fr{n\alpha}{\theta}\,\fr{\Gamma(1)\Gamma(n-1)}{{\Gamma(n)}}-{}\\
{}-\fr{n\alpha}{\theta}\,\fr{\Gamma(1)\Gamma(n)
}{{\Gamma(n+1)}}=\fr{\alpha}{{\theta(n-1)}}\,,\quad n\ge 2\,.
\end{multline*}

Аналогично получаем
\begin{multline*}
\e\rho^2=\il{0}{\infty}\fr{n\theta\alpha^nx^2}{{(\alpha+\theta x)^{n+1}}}\, dx=
\il{0}{\infty}\fr{n\alpha^n\,
dx}{{\theta(\alpha+\theta x)^{n-1}}}-{}\\
{}- \il{0}{\infty}\fr{2n\alpha^{n+1}\, dx}{{\theta(\alpha+\theta
x)^n}}+\il{0}{\infty}\fr{n\alpha^{n+2}\, dx}{{\theta(\alpha+\theta x)^{n+1}}}={}\\
{}=\fr{n\alpha^2(n-3)!}{{\theta^2(n-2)!}}-\fr{2n\alpha^2(n-2)!}{{\theta^2(n-1)!}}+\fr{n\alpha^2(n-1)!}{{\theta^2n!}}={}\\
{}=\fr{2\alpha^2}{{\theta^2(n-1)(n-2)}}\,,\quad n\ge3\,.
\end{multline*}

Рассмотрим характеристики вероятности <<непотери>> вызова $\pi$. Для функции распределения имеем
\begin{multline*}
F_\pi(x)=1-\p\left(\rho<\fr{1-x}{{x}}\right)={}\\
{}=\left(\fr{\alpha x}{\theta+(\alpha-\theta)x}\right)^n\,,\quad
x\in(0,\, 1)\,.
\end{multline*}

В этом случае плотность $\pi$, очевидно, имеет вид
$$
f_\pi(x)=\fr{n\theta\alpha^n x^{n-1}}{(\theta+(\alpha-\theta)x)^{n+1}}\,,\quad x\in(0,\, 1)\,.
$$

Для вычисления моментов случайной величины $\pi$ потребуется следующая формула, являющаяся следствием формулы~2.111 
из~\cite{5k}:
\begin{multline}
\int\fr{x^n\,
dx}{{(a+bx)^{n+1}}}=-\sum_{k=0}^{n-1}\fr{x^{n-k}}{{(n-k)b^{k+1}(a+bx)^{n-k}}}+{}\\
{}+\fr{\ln(a+bx)}{{b^{n+1}}}
+C\,,
\end{multline}
где $C$~--- некоторая константа.

При $\alpha=\theta$, очевидно, $\e\pi=n/(n+1)$, $\e\pi^2\;=$\linebreak $=\;n/(n+2)$. При $\alpha\neq\theta$, воспользовавшись~(1), имеем
\begin{multline*}
\e\pi=\il{0}{1}\fr{n\theta\alpha^n x^n\,
dx}{{(\theta+(\alpha-\theta)x)^{n+1}}}=-n\theta\alpha^n\times{}\\
{}\times
\left[\sum_{k=0}^{n-1}\fr{x^{n-k}}{{(n-k)(\alpha
-\theta)^{k+1}(\theta+(\alpha-\theta)x)^{n-k}}}-{}\right.\\
\left.{}-\fr{\ln \left(\theta+(\alpha-\theta\right) x)}{{(\alpha-\theta)^{n+1}}}
\vphantom{\sum_{k=0}^{n-1}}\right]
\Bigg|_0^1={}\\
{}=-\fr{n\theta}{\alpha}\sum_{k=0}^{n-1}\fr{1}{{n-k}}\left(\fr{\alpha}{{\alpha-\theta}}\right)^{k+1}+{}\\
{}+
\fr{n\theta}{{\alpha-\theta}}\left(\fr{\alpha}{{\alpha-\theta}}\right)^n\ln\fr{\alpha}{\theta}\,.
\end{multline*}

Для вычисления второго момента $\pi$ при $\alpha\neq\theta$ потребуется следующая формула, аналогичная~(1):
\begin{multline}
\int\fr{x^n\, dx}{{(a+bx)^n}}=\fr{x^n}{{b(a+bx)^{n-1}}}+{}\\
{}+\fr{an}{b}\sum_{k=0}^{n-2}\fr{x^{n-k-1}}{{(n-k-1)b^{k+1}(a+bx)^{n-k-1}}}-{}\\
{}-
\fr{an}{{b^{n+1}}}\ln\left (a+bx\right )+C\,.
\end{multline}
Имеем
\begin{multline*}
\e\pi^2=\il{0}{1}\fr{n\theta\alpha^nx^{n+1}\, dx}{{(\theta+(\alpha-\theta)x)^{n+1}}}={}\\
{}=n\theta\alpha^n\left[\fr{x^{n+1}}{{(\alpha-\theta)(\theta+(\alpha-\theta)x)^n}}+{}\fr{(n+1)\theta}{{\alpha-\theta}}\times{}\right.\\
{}\times \left.
\sum_{k=0}^{n-1}\fr{x^{n-k}}{{(n-k)(\alpha-\theta)^{k+1}(\theta+(\alpha-\theta)x)^{n-k}}}-{}\right.\\
\left.{}-\fr{(n+1)\theta\ln\left (\theta+(\alpha-\theta)x\right )}{{(\alpha-\theta)^{n+2}}}\right]\Bigg|_0^1={}
\end{multline*}

\noindent
\begin{multline*}
{}=\fr{n\theta}{{\alpha-\theta}}+\fr{n(n+1)\theta^2}{{\alpha(\alpha-\theta)}}\sum_{k=0}^{n-1}\fr{1}{{n-k}}\,
\left(\fr{\alpha}{{\alpha-\theta}}\right)^{k+1}-{}\\
{}-\fr{(n+1)\theta}{{(\alpha-\theta)^{n+2}}}\ln\fr{\alpha}{\theta}\,.
\end{multline*}

Зная первые два момента случайной величины~$\pi$, можно легко вычислить дисперсию рас\-смат\-ри\-ва\-емой характеристики.

Теперь в рамках системы $M \vert M \vert 1 \vert 0$ рассмотрим задачу, в которой интенсивность входящего потока $\lambda$ имеет распределение
Эрланга с параметрами $k\ge 1$ и $\theta>0$, а интенсивность обслуживания $\mu$ имеет экспоненциальное распределение с
па\-ра\-мет\-ром $\alpha>0$, причем $\lambda$ и $\mu$ независимы. Как и ранее, найдем функции распределения, плотности и
первые моменты случайных величин
$\rho=\lambda/\mu$ и  $\pi=1/(1+\rho)$.

Для плотности случайной величины $\rho$ имеем следующие соотношения:
\begin{multline*}
f_\rho(x)=\il{0}{\infty}\fr{\alpha\theta^k x^{k-1}y^ke^{-\alpha y}e^{-\theta x y}}{{(k-1)!}}\, dy={}\\[2pt]
{}=\fr{\alpha\theta^k x^{k-1}}{{(k-1)!(\alpha+\theta x)^{k+1}}}\il{0}{\infty}z^ke^{-z}\,dz={}\\[2pt]
{}=
\fr{k\alpha\theta^k x^{k-1}}{{(\alpha+\theta x)^{k+1}}}\,,\quad x>0\,.
\end{multline*}

Откуда, очевидно, $\e\rho=\infty$. Найдем функцию распределения случайной величины $\rho$. Будем использовать следующее
следствие формулы~2.111 из~\cite{5k} для $m\ge2$:
\begin{multline}
\int\fr{x^n\, dx}{{(a+bx)^{n+m}}}={}\\[2pt]
{}= -\fr{x^n}{{(m-1)b C_{n+m-1}^n(a+bx)^{n+m-1}}}\times{}\\[2pt]
{}\times
\sum_{l=0}^nC_{n+m-1}^{n-l}\left(\fr{a}{{bx}} \right)^l+C\,.
\end{multline}

По формуле~(3) имеем
\begin{multline*}
F_\rho(x)=\il{0}{x}\fr{k\alpha\theta^kt^{k-1}}{{(\alpha+\theta t)^{k+1}}}\, dt={}\\[2pt]
{}=-k\alpha\theta^k\left[\fr{(k-1)!}{{(\alpha+\theta
t)^k}}\sum_{l=0}^{k-2}\fr{\alpha^lt^{k-l-1}}{{(k-l-1)!(l+1)!\theta^{l+1}}}+{}\right.\\
\left.{}+\fr{(k-1)!\alpha^{k-1}}{{k!\theta^k(\alpha+
\theta t)^k}}
\vphantom{\sum_{l=0}^{k-2}} \right]
\Bigg|_0^x={}
\end{multline*}

\noindent
\begin{multline*}
{}=1-\fr{k!\alpha\theta^k}{{(\alpha+\theta x)^k}}\sum_{l=0}^{k-1}\fr{\alpha^lx^{k-l-1}}{{(k-l-1)!(l+1)!\theta^{l+1}}}={}\\[2pt]
{}=
\left(\fr{\theta x}{{\alpha+\theta x}}\right)^k\,,\quad x>0\,.
\end{multline*}

Теперь найдем основные характеристики распределения случайной величины $\pi$.
\begin{multline*}
F_\pi(x)=1-F_\rho\left(\fr{1-x}{x}\right)={}\\[2pt]
{}=1-\fr{\theta^k(1-x)^k}{{(\theta+(\alpha-\theta)x)^k}}\,,\quad
x\in[0,\,1]\,.
\end{multline*}

Для соответствующей плотности имеем сле\-ду\-ющие равенства:
\begin{multline*}
f_\pi(x)=\fr{1}{{x^2}}f_\rho\left(\fr{1-x}{
x}\right)={}\\[2pt]
{}=\fr{k\alpha\theta^k(1-x)^{k-1}}{{(\theta+(\alpha-\theta)x)^{k+1}}}\,,\quad x\in[0,\,1]\,.
\end{multline*}

Очевидно, что при $\alpha=\theta$ для первых двух моментов случайной величины $\pi$ выполнены соотношения
$$
\e\pi=k B(2,k)\quad \mbox{и}\quad  \e\pi^2=k B(3,k)\,,
$$
где $B(n,k)$~--- $\beta$-функция:
$$
B(n,k)=\il{0}{1}x^{n-1}(1-x)^{k-1}\, dx\,.
$$
При $\alpha\neq\theta$ получаем
\begin{multline*}
\e\pi=k\alpha\theta^k\il{0}{1}\fr{x(1-x)^{k-1}\,
dx}{{(\theta+(\alpha-\theta)x)^{k+1}}}={}\\[2pt]
{}=k\alpha\theta^k\il{0}{1}\fr{x\sum_{m=0}^{k-1}C_{k-1}^m(-1)^mx^m\,dx
}{{(\theta+(\alpha-\theta)x)^{k+1}}}={}\\[2pt]
{}=k\alpha\theta^k\sum_{m=0}^{k-1}(-1)^mC_{k-1}^m\il{0}{1}\fr{x^{m+1}\,dx}{{(\theta+(\alpha-\theta)x)^{k+1}}}\,.
\end{multline*}
Введем для фиксированных $\alpha\neq\theta$ обозначение
\begin{equation*}
A(p,q)=\il{0}{1}\fr{x^p\,dx}{{(\theta+(\alpha-\theta)x)^q}}\,.
\end{equation*}
Вычислим $A(k,k+1)$, используя~(1). Имеем

\noindent
\begin{multline}
A(k,k+1)={}\\
{}= -\sum_{l=0}^{k-1}\fr{1}{{(k-l)\alpha^{k-l}(\alpha-\theta)^{l+1}}}+
\fr{\ln (\alpha/\theta)
}{{(\alpha-\theta)^{k+1}}}\,.
\end{multline}
Для $m=0,\ldots,k-2$, используя~(3), получаем
\begin{multline}
A(m+1,k+1)={}\\[2pt]
{}=-\fr{\alpha^{-k}}{{(k-m-1)(\alpha-\theta)C_k^{m+1}}}\sum_{l=0}^{m+1}\fr{C_k^{m-l+1}\theta^l
}{{(\alpha-\theta)^l}}+{}\\[2pt]
{}+\fr{\theta^{m-k+1}}{{(k-m-1)C_k^{m+1}(\alpha-\theta)^{m+2}}}\,.
\end{multline}

Таким образом, при $\alpha\neq\theta$
\begin{multline*}
\e\pi=k\alpha\theta^k\sum_{m=0}^{k-2}(-1)^mC_{k-1}^mA(m+1,k+1)+{}\\
{}+k\alpha\theta^k(-1)^{k-1}A(k,k+1)\,,
\end{multline*}
где $A(p,k+1)$, $p=1,\ldots,k$, вычисляются по формулам~(4) и~(5).

Аналогично для $\alpha\neq\theta$ находим второй момент случайной величины $\pi$:
$$
\e\pi^2=k\alpha\theta^k\sum_{m=0}^{k-1}(-1)^mC_{k-1}^m\il{0}{1}\fr{x^{m+2}\, dx}{{(\theta+
(\alpha-\theta)x)^{k+1}}}\,.
$$
Воспользовавшись формулой~(2), получаем пред\-став\-ле\-ние для интеграла $A(k+1,k+1)$:
\begin{multline}
A(k+1,k+1)=\fr{1}{{\alpha^k(\alpha-\theta)}}+{}\\[2pt]
{}+\fr{(k+1)\theta}{{\alpha-\theta}}\sum_{l=0}^{k-1}
\fr{1}{{(k-l)\alpha^{k-l}(\alpha-\theta)^{l+1}}}-{}\\[2pt]
{}-\fr{(k+1)\theta\ln (\alpha/\theta)}{{(\alpha
-\theta)^{k+2}}}\,.
\end{multline}
Следовательно,
\begin{multline*}
\e\pi^2=k\alpha\theta^k\left (\vphantom{\sum_{m=0}^{k-3}}
\left(-1\right)^{k-1}A(k+1,k+1)+{}\right.\\
{}+\left(-1\right)^k(k-1)A(k,k+1)+{}\\
\left.{}+\sum_{m=0}^{k-3}(-1)^mC_{k-1}^m A(m+2,k+1)\right)\,,
\end{multline*}
где $A(p,k+1)$, $p=2,\ldots,k+1$, вычисляются по формулам~(4)--(6).

Представленные в статье результаты не являются полными в рамках проблематики байесовских СМО и байесовских моделей
надежности даже в рамках рассмотрения байесовских моделей систем $M\vert M\vert 1 \vert 0$. Очевидно, что дальнейшее продвижение в рамках
данной проблематики требует рассмотрения и других априорных распределений величин $\lambda$, $\mu$ и других
традиционных входных параметров для СМО и восстанавливаемых устройств, которые могут представлять интерес для практики,
и вычисление соответствующих распределений показателей функционирования и надежности различных типов систем (в том
числе систем вида $M \vert G \vert 1$, $M \vert M \vert n \vert 0$ и~др.) после их рандомизации с учетом наиболее важных для практики априорных
распределений параметров. В частности, объектом для рандомизации может послужить
стандартное отклонение обслуживания $\sigma$ в системе  $M \vert G \vert 1$, число каналов $n$ в системе $M\vert M\vert n\vert$
и~т.\,п.


{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{9}
\bibitem{1k} %Apice06}
\Au{D'Apice C., Manzo~R., Shorgin~S.}
Some Bayesian queueing and reliability models~// 
Electronic J. ``Reliability: Theory \& Applications'', 2006. Vol.~1. No.~4.

\bibitem{2k} %KuSh08}
\Au{Кудрявцев А.\,А., Шоргин С.\,Я.}
Байесовский подход к анализу систем массового обслуживания и показателей надежности~// 
Информатика и её применения, 2007. Т.~1. Вып.~2. С.~76--82.

\bibitem{3k} %Kozlov70}
\Au{Kozlov~B.\,A., Ushakov~I.\,A.}
Reliability handbook.~--- Holt, Rinehart \& Winston, 1970.

\bibitem{4k} %Dwhite66}
\Au{Двайт Г.}
Таблицы интегралов и другие математические формулы~/ Пер. с англ. --- М.: Наука, 1966. 228~с.


\label{end\stat}

\bibitem{5k} %GR71}
\Au{Градштейн И.\,С., Рыжик~И.\,М.}
Таблицы интегралов, сумм, рядов и произведений.~--- М.: Наука, 1971.  1108~с.
\end{thebibliography}
}
}
\end{multicols}