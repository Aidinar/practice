\def\stat{lapko}

\def\tit{НЕПАРАМЕТРИЧЕСКИЙ АЛГОРИТМ АВТОМАТИЧЕСКОЙ КЛАССИФИКАЦИИ 
ДАННЫХ ДИСТАНЦИОННОГО ЗОНДИРОВАНИЯ}

\def\titkol{Непараметрический алгоритм автоматической классификации 
данных дистанционного зондирования}

\def\aut{В.\,П.~Тубольцев$^1$, А.\,В.~Лапко$^2$, В.\,А.~Лапко$^3$}

\def\autkol{В.\,П.~Тубольцев, А.\,В.~Лапко, В.\,А.~Лапко}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Тубольцев В.\,П.}
\index{Лапко А.\,В.}
\index{Лапко В.\,А.}
\index{Tuboltsev V.\,P.}
\index{Lapko A.\,V.}
\index{Lapko V.\,A.}


%{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
%{Работа выполнялась с~использованием инфраструктуры Центра коллективного пользования 
%<<Высокопроизводительные вычисления и~большие данные>> (ЦКП <<Информатика>>) ФИЦ ИУ 
%РАН.}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Сибирский государственный университет науки и технологий им. академика М.\,Ф.~Решетнёва, \mbox{vitalya.98@mail.ru}}
\footnotetext[2]{Сибирский государственный университет науки и технологий им.\ академика М.\,Ф.~Решетнёва; 
Институт вычислительного моделирования Сибирского отделения Российской академии наук, 
\mbox{lapko@icm.krasn.ru}}
\footnotetext[3]{Сибирский государственный университет науки и технологий им.\ академика М.\,Ф.~Решетнёва; 
Институт вычислительного моделирования Сибирского отделения Российской академии наук, 
\mbox{valapko@yandex.ru}}

\vspace*{-14pt}



  

  \Abst{Предлагается непараметрический алгоритм автоматической классификации 
статистических данных большого объема. Эта задача возникает при обработке данных 
дистанционного зондирования природных объектов. Рассматриваемый алгоритм 
предполагает сжатие исходной информации на основе декомпозиции многомерного 
пространства признаков. В~результате статистическая выборка большого объема 
преобразуется в массив данных, составленный из центров многомерных интервалов 
дискретизации и соответствующих им частот принадлежности случайных величин. 
Полученная информация используется при синтезе регрессионной оценки плотности 
вероятности. Под классом понимается компактная группа наблюдений случайной величины, 
соответствующая одномодальному фрагменту плотности вероятности. На этой основе 
разрабатывается непараметрический алгоритм автоматической классификации, который 
основан на последовательной процедуре проверки близости центров многомерных 
интервалов дискретизации и соотношений между частотами принадлежности случайных 
величин из исходной выборки этим интервалам. Для повышения вычислительной 
эффективности пред\-ла\-га\-емо\-го алгоритма автоматической классификации используется 
многопоточный метод его программной реализации. Практическая зна\-чи\-мость 
разработанного алгоритма автоматической классификации под\-тверж\-да\-ет\-ся результатами его 
применения при оценивании со\-сто\-яния лесных массивов по данным дистанционного 
зондирования.}
  
  \KW{автоматическая классификация; выборки большого объема; дискретизация области 
значений случайных величин; регрессионная оценка плотности вероятности; данные 
дистанционного зондирования}

\DOI{10.14357/19922264230404}{MPEWAW}
  
\vspace*{-4pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}
  
\section{Введение}

\vspace*{-4pt}

  Обнаружение компактных групп наблюдений~--- одна из основных задач 
системного анализа данных дистанционного зондирования объектов различной 
природы~[1, 2]. 

Обзор методов автоматической классификации представлен 
в~работах~[3, 4]. Особое внимание уделяется разработке алгоритмов 
автоматической классификации для обнаружения компактных\linebreak групп 
наблюдений, со\-от\-вет\-ст\-ву\-ющих одномодальным фрагментам плот\-ности 
ве\-ро\-ят\-ности признаков ис\-сле\-ду\-емых объектов. Подобное определение класса 
было введено академиком Я.\,З.~\mbox{Цыпкиным}~[5] и~развито в~работах 
профессора В.\,И.~Васильева~[6] с использованием непараметрической оценки 
плотности вероятности Ро\-зен\-блат\-та--Пар\-зе\-на~[7--10].
  
  В этих условиях обоснована возможность решения задачи автоматической 
классификации путем итерационной процедуры последовательного 
непараметрического оценивания байесовского уравнения разделяющей 
поверхности между классами~[11]. 

Предложенный подход развит при решении 
задачи автоматической классификации в условиях больших объемов 
статистических данных~[12]. Его идея состоит в сжатии исходной информации 
путем декомпозиции пространства признаков в массив данных, составленный 
из центров многомерных интервалов дискретизации и соответствующих им 
частот принадлежности значений случайных величин. Основу этого подхода 
составляет анализ многомерной гистограммы признаков классифицируемых 
объектов.
  
  Цель статьи состоит в совершенствовании непараметрического алгоритма 
автоматической классификации статистической информации большого объема 
на примере данных дистанционного зондирования путем использования 
регрессионной оценки плотности вероятности, применение которой позволяет 
сгладить многомерную гистограмму признаков классифицируемых объектов.

\section{Оценивание плотности вероятности в~условиях 
статистических данных большого объема}

Имеется выборка
\begin{equation}
V=\left( x_{vi}, \ v=\overline{1,k}\,,\ i=\overline{1,n}\right),
\label{e1-l}
\end{equation}
составленная из статистически независимых наблюдений многомерной 
случайной величины $x\hm= (x_v, \ v\hm= \overline{1,k})$ размерности~$k$ 
большого объема~$n$. Подобная информация, например, отражает данные 
дистанционного зондирования $n$ элементов земной поверхности в пространстве 
спектральных признаков размерности~$k$. Вычислительная эффективность 
непараметрических алгоритмов принятия решений ядерного типа во многом 
зависит от объема~$n$ статистических данных. При оценивании плотности 
вероятности $p(x)$ эта проблема решается путем сжатия исходной 
информации, заданной выборкой~$V$ вида~(1), что предполагает выполнение 
следующих действий~\cite{10-l}.
\begin{enumerate}[1.]
\item  Разбить область определения плотности вероятности $p(x)$ случайной 
величины~$x$ по каждой ее компоненте~$x_v$ на $N$ непересекающихся 
интервалов длиной~$2\beta_v$, $v\hm= \overline{1,k}$. Для выбора числа~$N$ 
интервалов дискретизации можно использовать результаты 
исследований~\cite{10-l, 13-l, 14-l}.
  \item Определить оценки вероятностей попадания элементов выборки~$V$ 
в~каждый $j$-й многомерный интервал
  $$
  \overline{P}_j= \fr{n(j)}{n}\,,\enskip j=\overline{1, N^k}\,,
  $$
где $n(j)$~--- число наблюдений из выборки~$V$, принадлежащих 
многомерному интервалу $D(j)\hm= [z_v\hm\pm \beta_v,\ v\hm=\overline{1,k}]$, 
а~$z_j\hm= (z_{vj}, \ v\hm= \overline{1,k})$~--- координаты центра $j$-го 
интервала.
  \item Положить, что в каждом многомерном интервале $D(j)$, $j\hm= 
\overline{1, N^k}$, случайная величина $x\hm= \left( x_v.\ 
v\hm=\overline{1,k}\right)$ имеет равномерный закон распределения. С~этих 
позиций вычислить оценки плотности вероятности
  $$
  \overline{p}(x_j) =\overline{p}_j= \fr{\overline{P}_j}{\prod\nolimits^k_{v=1} 
(2\beta_v)} \ \forall\ x\in D(j),\ j=\overline{1,N^k}\,.
  $$
  \item На основе полученной информации сформировать массив данных
  \begin{equation}
  \overline{V} =\left( z_j,\ \overline{p}_j,\ j=\overline{1,N^k}\right)
  \label{e2-l}
  \end{equation}
и осуществить синтез регрессионной оценки плотности вероятности 
$p(x)$~\cite{10-l}:
\begin{equation}
\overline{p}(x)=\fr{1}{\prod\nolimits^k_{v=1} c_v} \sum\limits_{j=1}^{N^k} 
\overline{P}_j \prod\limits^k_{v=1} \Phi \left( \fr{x_v-z_{vj}}{c_v}\right).
\label{e3-l}
\end{equation}
Здесь ядерные функции $\Phi (u_v)$ удовлетворяют условиям~\cite{8-l, 10-l}:

\vspace*{-6pt}

\noindent
\begin{multline*}
\Phi(u_v) =\Phi(-u_v),\ 0\leq \Phi(u_v)<\infty\,,\\
 \int\limits_{-\infty}^\infty 
\Phi(u_v)\,du_v=1,\ \int\limits_{-\infty}^\infty  u_v^2 \Phi(u_v)\,du_v=1\,,\\
\int\limits_{-\infty}^\infty u_v^m \Phi(u_v)\,du_v< \infty,\ 0\leq m< \infty,\ 
v=\overline{1,k}\,.
\end{multline*}
  \end{enumerate}
  
  \vspace*{-6pt}
  
  Коэффициенты размытости~$c_v$ ядерных функций $\Phi (u_v)$ 
в~статистике~(\ref{e3-l}) убывают с ростом~$N$~\cite{10-l}. Значения~$c_v$ 
зависят от длины интервала изменения случайных величин~$x_v$, $v\hm= 
\overline{1,k}$. Поэтому будем полагать, что $c_v\hm= c\overline{\sigma}_v$, 
где $\overline{\sigma}_v$~--- оценка сред\-не\-квад\-ра\-тич\-но\-го отклонения 
случайной величины~$x_v$, $v\hm=\overline{1,k}$. 
Значения~$\overline{\sigma}_v$ оцениваются по данным 
массива~$\overline{V}$.
  
  Выбор оптимального значения~$\overline{c}$ параметра~$c$ определяется из 
условия минимума сред\-не\-квад\-ра\-тич\-ной ошибки аппроксимации регрессионной 
оценкой~(\ref{e3-l}) плотности вероятности $p(x)$:
  $$
  W(c)=\fr{1}{N^k}\sum\limits_{i=1}^{N^k} \left( \overline{p}_i- 
\overline{p}(z_i)\right)^2.
  $$
  %
  При вычислении $\overline{p}(z_i)$ значение~$z_i$ исключается из 
статистики~$\overline{p}(x)$.
  
  Процедура оптимизации регрессионной оценки плотности вероятности 
случайной величины~$x$ повышает вычислительную эффективность 
процедуры выбора коэффициентов размытости ядерных функций по сравнению 
с традиционной методикой~\cite{10-l}.
  
  Традиционная методика основана на выборе коэффициента размытости 
ядерной функции из условия минимума оценки среднеквадратического 
отклонения $\overline{p}(x)$ от $p(x)$~\cite{10-l}:

\pagebreak

\noindent
\begin{multline*}
  W_1(c)=\int\limits_{-\infty}^\infty\! \cdots\! \int\limits_{-\infty}^\infty 
\overline{p}^2(x_1,\ldots , x_k)\,dx_1\cdots  dx_k -{}\\
{}-2\sum\limits^{N^k}_{i=1} 
\overline{P}_i p ( x_{1i},\ldots , x_{ki}),
  \end{multline*}
где
\begin{multline*}
\overline{p} (x_{1i},\ldots , x_{ki})={}\\  
{}= \fr{1}{\prod\nolimits_{v=1}^k c_v} \sum\limits^{N^k}_{\substack{{j=1}\\ {j\not=i}}}
\overline{P}_j \prod\limits^k_{v=1} \Phi \left( \fr{x_{vi}- z_{vj}}{c_v}\right).
\end{multline*}
  
  Нетрудно заметить, что процедура вычисления критерия~$W(c)$ более 
проста по сравнению с критерием~$W_1(c)$.
  
  Из условия минимума среднеквадратичного отклонения $\overline{p}(x)$ 
от~$p(x)$ в работах~\cite{10-l, 13-l} определено оптимальное число~$N$ 
интервалов дискретизации об\-ласти значений одномерной случайной 
величины~$x$, которое соответствует целому числу вы\-ра\-жения
\begin{equation}
 \left( n\Delta \int\limits_{-\infty}^\infty p^2(x)\,dx\right)^{1/2}.
 \label{e4-l}
\end{equation}
  
  Значение $N$ определяется видом плотности вероятности и не зависит от ее 
параметров. Для равномерного закона распределения одномерной случайной 
величины с плотностью вероятности $p(x)$ выражение для $N$ совпадает с 
формулой дискретизации Хайн\-холь\-да--Га\-е\-де~\cite{15-l}. В~этих 
условиях выражение 
$$
\Delta \int\limits_a^b p^2(x)\,dx\hm=1
$$
 не зависит от 
конечных пределов интегрирования~$a$ и~$b$ ($\Delta\hm= b\hm-a$). При 
нормальном законе распределения 
$$
\Delta \int\limits_a^b p^2(x)\,dx\hm= 
1{,}693\,,
$$
 где $a\hm= {\sf M}(x)\hm-3\sigma$; $b\hm= {\sf M}(x)\hm+3\sigma$. Здесь 
${\sf M}(x)$~--- математическое ожидание случайной величины~$a$; $\sigma$~--- 
среднеквадратичное отклонение~$x$. Вероятность попадания случайной 
величины~$x$ в~эти пределы равна~0,997.
  
  В работе~\cite{10-l} обоснована возможность оценивания 
произведения~$\Delta$ на интеграл от квадрата плотности вероятности 
одномерной случайной величины в выражении~(\ref{e4-l}) по значению 
коэффициента контрэксцесса. На этой основе предложена формула оценивания 
числа интервалов дискретизации многомерной случайной величины $x\hm= 
(x_v,\ v\hm=\overline{1,k})$.
  
  Регрессионная оценка плотности ве\-ро\-ят\-ности~(\ref{e3-l}) лежит в~ основе 
синтеза непараметрического алгоритма автоматической классификации в~условиях большого объема статистических данных.
  
\section{Алгоритм автоматической классификации}

Пусть имеется выборка многомерных статистических данных~$V$~(1) 
большого объема~$n$, распределенная с~неизвестной плот\-ностью ве\-ро\-ят\-ности 
$p(x)\hm= p(x_1, \ldots , x_k)$. Необходимо выборку~$V$ разбить на группы 
компактных наблюдений~$V_j$, $j\hm=\overline{1,M}$, чис\-ло~$M$ которых 
неизвестно. Под компактной группой наблюдений (классом) случайной 
величины~$x$ будем подразумевать об\-ласть ее значений, которая 
соответствует одномодальному фрагменту многомерной плот\-ности 
ве\-ро\-ят\-ности~$p(x)$~\cite{11-l, 12-l}.

  Следуя методике синтеза регрессионной оценки плотности вероятности, 
определим статистику $\overline{p}(x)$ по формуле~(\ref{e3-l}). Для 
обнаружения наблюдений первого класса по информации массива 
данных~$\overline{V}$ вида~(\ref{e2-l}) выберем элемент $(z_j, 
\overline{p}_j)$, который определяется условием:
  \begin{equation}
  \overline{p}_j= \max\limits_{i=\overline{1,N^k}} \overline{p}_i.
  \label{e5-l}
  \end{equation}
  %
  Этот элемент $(z_j, \overline{p}_j)$ соответствует максимальному значению 
оценки плот\-ности ве\-ро\-ят\-ности~$\overline{p}(x)$. Тогда начальный этап 
формирования элементов массива данных~$\overline{V}_1$ из~$\overline{V}$, 
принадлежащих первому классу~$\Omega_1$, определяется правилом:
  \begin{multline}
  D(j) \subset \Omega_1,\ \mbox{если } \prod\limits_{v=1}^k \Phi \left( \fr{z_{vi}-
z_{vj}}{c_v}\right) 1\left( \overline{p}_i, \overline{p}_j\right) >0\,,\\
 i=\overline{1, 
N^k},\ i\not= j\,.
  \label{e6-l}
  \end{multline}
  %
  Здесь, например, ядерная и индикаторная функции имеют вид:
  \begin{align*}
  \Phi\left( \fr{z_{vi}-z_{vj}}{c_v}\right) &= \begin{cases}
  0{,}5, &\mbox{если } \vert z_{vi}-z_{vj}\vert \leq c_v\,;\\
  0\,, &\mbox{если } \vert z_{vi}-z_{vj}\vert >c_v\,;
  \end{cases}
  \\
  1\left( \overline{p}_i, \overline{p}_j\right) &= \begin{cases}
  1\,, &\mbox{усли } \overline{p}_i\leq \overline{p}_j\,;\\
  0\,, &\mbox{если } \overline{p}_i>\overline{p}_j\,,
  \end{cases}
  \end{align*}
где $c_v\geq 2\beta_v$, так как при конкретных значениях~$c_v$ ядерные 
функции определяют элементы массива~$\overline{V}$, смежные с элементом 
$(z_j, \overline{p}_j)$. Индикаторная функция $1(\overline{p}_i,\overline{p}_j)$ 
позволяет определять элементы $(z_{i}, \overline{p}_i)$ массива 
данных~$\overline{V}$, которые характеризуются убывающими значениями 
плотности вероятности при изменении значений~$x$ в окрестности~$z_j$. На 
этом этапе индикаторная функция принимает значение $1(\overline{p}_i, 
\overline{p}_j)\hm=1$, так как выполняется условие~(\ref{e5-l}).
  
  Элементы выборки~$V$, принадлежащие интервалу $D(j)$, включаются 
в~выборку наблюдений~$V_1$ первого класса. Данное правило сохраняется 
и~для последующих этапов классификации.

 \begin{figure*} %fig1
    \vspace*{1pt}
\begin{center}
   \mbox{%
\epsfxsize=163mm 
\epsfbox{lap-1.eps}
}
\end{center}
\vspace*{-9pt}
  \Caption{Отображение исходных данных, составленных из материалов дистанционного 
зондирования космическим аппаратом Sentinel-2A за 4~августа 2018~г.~(\textit{а}) и~23~мая 
2022~г.~(\textit{б})}
\vspace*{6pt}
  \end{figure*}
  
  \begin{figure*}[b]  %fig2
 \vspace*{7pt}
\begin{center}
   \mbox{%
\epsfxsize=163mm 
\epsfbox{lap-2.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Отображение результатов классификации непараметрическим алгоритмом 
автоматической классификации исходных данных за 4~августа 2018~г.~(\textit{а}) и~23~мая 
2022~г.~(\textit{б})}
\end{figure*}
  
  Обозначим через~$I_1$ множество номеров элементов массива 
данных~$\overline{V}$, отнесенных на первом этапе автоматической 
классификации в соответствии с~правилом~(\ref{e6-l}) к первому 
классу~$\Omega_1$. Множество~$I_1$ включает номер~$j$~элемента $(z_j, 
\overline{p}_j)$.

 
  
  Второй этап классификации реализует ре\-ша\-ющее правило
  \begin{multline}
  D(i)\subset \Omega_1, \\
   \mbox{если\ }
 \! \sum\limits_{j\in I_1} \prod\limits^k_{v=1} \Phi\left( \fr{z_{vi}-
z_{vj}}{c_v}\right) 1 \left(\overline{p}_i, \overline{p}_j\right)>0\,,\\
 i\in I\backslash 
I_1,\ I=\overline{1,N^k}\,,\ j\in I_1.
  \label{e7-l}
  \end{multline}
  
  По аналогии на $t$-м этапе автоматической классификации элементы 
массива данных~$\overline{V}$, принадлежащие первому классу~$\Omega_1$, 
определяются правилом: 
  \begin{multline}
  D(i)\subset \Omega_1,\\ 
  \mbox{если\ } 
\sum\limits_{j\in I_{t-1}} \prod\limits^k_{v=1}  \Phi\left( \fr{z_{vi}-
z_{vj}}{c_v}\right) 1 \left(\overline{p}_i, \overline{p}_j\right)>0\,,\\
 i\in I\backslash 
\left(I_1\cup I_2\cup\cdots \cup I_{t-1}\right), \ j\in I_{t-1}.
\label{e8-l}
\end{multline}
  
  Последовательная процедура автоматической  
классификации~(\ref{e6-l})--(\ref{e8-l}) продолжается до выполнения условия 
$I_t\hm= \varnothing$, когда прекратится обнаружение новых элементов 
массива данных~$\overline{V}$ из класса~$\Omega_1$.
  
  Обнаруженный первый класс характеризуется регрессионной оценкой 
плотности вероятности
  $$
  \overline{p}_1(x) =\fr{1}{\prod\nolimits^k_{v=1} c_v} \sum\limits_{i\in I_{t-
1}} \overline{P}_i \prod\limits^k_{v=1} \Phi \left( \fr{x_v-z_{vi}}{c_v}\right),
  $$
которая восстанавливается по данным $\overline{V}_1$. В~этом случае 
оптимальные коэффициенты размытости~$c_v$ соответствуют значениям 
$\overline{c}_v\hm= \overline{c} \,\overline{\sigma}_v$, $v\hm=\overline{1,k}$. 
Массив данных $\overline{V}_1\hm\in \overline{V}$ определяется процедурами 
автоматической классификации, заданными  
соотношениями~(\ref{e6-l})--(\ref{e8-l}).
  
  При обнаружении элементов выборки~$V_1$ исходной статистической 
информации~$V$, принадлежащих первому классу~$\Omega_1$, используются 
результаты автоматической классификации массива данных~$\overline{V}$.
  
  Для обнаружения элементов массива $\overline{V}_2\hm\in \overline{V}$, 
принадлежащих второму классу~$\Omega_2$, из оставшихся данных 
$\overline{V}\backslash\overline{V}_1$ выбирается элемент $(z_j, 
\overline{p}_j)$ с максимальным значением~$\overline{p}_j$ и предложенная 
выше процедура автоматической классификации используется для определения 
класса~$\Omega_2$. По аналогии формируются оставшиеся классы, число 
которых априори не определено.

\vspace*{-6pt}
  
\section{Оценивание состояния лесных массивов, поврежденных 
полиграфом, по~данным дистанционного зондирования}

\vspace*{-3pt}

  Территория исследования определялась юго-за\-пад\-ной частью Дзержинского 
района Красноярского края. На этой территории преобладают пихтовые, 
кедровые и~еловые древостои, встречаются березы и осины. Высота территории 
варьирует в~диапазоне от~370 до~610~м над уровнем моря.


  
  Исходная информация формировалась по данным дистанционного 
зондирования аппаратом Европейского космического агентства Sentinel-2A за 
4~августа 2018~г.\ и 23~мая 2022~г. Сним\-ки получены с геопортала Earth 
Explorer, из которых вырезаны тестовые участки в~6000~га (рис.~1). 
Каждый из них определяется 605\,414~пикселями. Каждый пиксель 
характеризуется шестью спектральными признаками $x\hm= (x_1, \ldots , x_6)$, 
которым соответствуют длины волн (нм): 492,7~($x_1$); 559,8~($x_2$); 
664,6~($x_3$); 740,5~($x_4$); 832,8~($x_5$); 2202,4~($x_6$). На рис.~1,\,\textit{а} 
и~1,\,\textit{б} представлены RGB-изоб\-ра\-же\-ния исходных данных за 2018 
и~2022~гг. соответственно. Каналам~R, G и~B соответствуют признаки $x_6$, 
$x_5$ и~$x_3$.
  


  
  В центральной части исследуемой территории располагались лесные 
массивы усохших темнохвойных древостоев, поврежденных полиграфом 
уссурийским. Их отличительная особенность~--- куртинный характер 
повреждений. Они отображаются на рисунке ярким фиолетовым цветом 
и~имеют гладкие границы, приближенные к овалу или кругу. Ярким розовым 
цветом отображаются сплош\-ные руб\-ки лесных насаждений, которые 
отличаются правильной формой, близкой к прямоугольнику. Части 
изображения в темных оттенках фиолетового и зеленого соответствуют 
хвойным лесным насаждениям. Фрагменты рисунка зеленого цвета, от темных 
к светлым тонам, соответствуют лиственным древостоям  
и~тра\-вя\-но-кус\-тар\-ни\-ко\-вым сообществам. На изображении отчетливо 
различаются дороги. Они представляют собой линии различной толщины 
с~ярким зеленым или желтым оттенком.
  
  Для обнаружения компактных групп наблюдений (классов) в пространстве 
спектральных признаков $x\hm= (x_1,\ldots , x_6)$ использовался метод анализа 
данных ISODATA (Iterative Self-Organizing Data\linebreak Analysis) и~пред\-ла\-га\-емый не\-па\-ра\-мет\-ри\-че\-ский алгоритм 
автоматической классификации. Его программная реализация NAC~v.2.0 
поз\-во\-ля\-ет выполнять сле\-ду\-ющие функции: за\-гру\-жать \mbox{изоб\-ра\-же\-ния} в~формате 
GeoTIFF; проводить классификацию с~воз\-мож\-ностью выбора метода расчета 
чис\-ла интервалов дискретизации исходного пространства признаков; получать 
изобра\-же\-ние для дальнейшей гео\-об\-ра\-бо\-тки~\cite{16-l}. В~этой программе 
реализованы методы многопоточных вы\-чис\-ле\-ний, которые повышают ско\-рость 
обработки данных большого объема.

\begin{figure*} %fig3
 \vspace*{1pt}
\begin{center}
   \mbox{%
\epsfxsize=163mm 
\epsfbox{lap-3.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Отображение результатов автоматической классификации алгоритмом ISODATA 
спектральных данных, полученных 4~августа 2018~г.~(\textit{а}) и~23~мая 
2022~г.~(\textit{б})}
%\end{figure*}
%\begin{figure*}[b] %fig4
 \vspace*{7pt}
\begin{center}
   \mbox{%
\epsfxsize=163mm 
\epsfbox{lap-4.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Отображение классов, наиболее точно характеризующих пиксели, 
соответствующие лесным насаждениям различной степени по\-вреж\-де\-ния полиграфом 
уссурийским. Результаты классификации по данным 4~августа 2018~г.\ (левый столбец) и~23~мая 2022~г.\ (правый столбец)
пред\-ла\-га\-емым не\-па\-ра\-мет\-ри\-че\-ским алгоритмом~(\textit{а}) и~алгоритмом 
ISODATA~(\textit{б})}
\end{figure*}
  
  Применение программы NAC~v.2.0. позволило в исходных изображениях за 
2018 и 2022~гг.\ обнаружить соответственно 84 и 177~компактных групп точек 
(рис.~2). При выборе метода расчета чис\-ла интервалов 
дискретизации был установлен флажок <<агрегация>>, что позволило избежать 
в~итоговом\linebreak классифицированном изображении большого чис\-ла классов. 
С~увеличением порядкового номера компактной группы наблюдений чис\-ло 
пикселей, ей при\-над\-ле\-жа\-щих, уменьшается. Это можно\linebreak объяснить тем, что 
алгоритм основан на по\-сле\-до\-ва\-тель\-ном опре\-де\-ле\-нии класса как 
одномодального фрагмента плот\-ности ве\-ро\-ятн\-ости спект\-раль\-ных 
признаков исследуемого объекта. \mbox{Обнаруженные} классы соответствуют лес\-ным 
массивам с~различной сте\-пенью поражения полиграфом уссурийским, 
усохшим и~лиственным древостоям, тра\-вя\-но-кус\-тар\-ни\-ко\-вым 
сообществам и вырубкам различной дав\-ности.



  Применение алгоритма ISODATA, реализованного в программном продукте 
ArcGIS ArcMap, требует указания необходимого числа классов. При 
классификации исходных изображений за~2018 и~2022~гг.\ алгоритмом 
ISODATA число классов принималось равным~84 и~177 соответственно. Это 
число классов было обнаружено при использовании программы NAC~v.2.0. 
В~результате обработки данных 2018 и 2022~гг.\ алгоритмом ISODATA были
выявлены только~73 и~128~классов соответственно (рис.~3). В~обоих результатах число пикселей в~классах распределено 
равномерно и не зависит от порядкового номера класса.
  



  По результатам классификации экспертами определены классы 
(рис.~4), которые характеризуют пиксели, 
соответствующие лесным на\-саж\-де\-ни\-ям с~раз\-ной сте\-пенью по\-вреж\-де\-ния 
полиграфом уссурийским. 

Полученные классы позволили рассчитать площадь 
по\-вреж\-де\-ний полиграфом уссурийским лесных на\-саж\-де\-ний ис\-сле\-ду\-емой 
территории. Программа NAC~v.2.0 позволила определить площадь 
по\-вреж\-де\-ний в~2018 и~2022~гг.\ в~размере 503,5 и~635,0~га соответственно. При 
использовании алгоритма ISODATA по\-вреж\-де\-нные площади со\-ста\-ви\-ли~323,6 
и~795,4~га. Пространственное распределение обнаруженных классов 
рас\-смат\-ри\-ва\-емы\-ми методами автоматической классификации различается на 
участ\-ках изображения, ха\-рак\-те\-ри\-зу\-ющих вырубки, переход от поврежденных 
лес\-ных на\-саж\-де\-ний к~здоровым и~открытые поч\-вы. Например, на изображении 
2018~г.\ в~центральной час\-ти алгоритм ISODATA объединил в~один класс 
пиксели, ха\-рак\-те\-ри\-зу\-ющие все темнохвойные на\-саж\-де\-ния и~по\-вреж\-ден\-ные 
лесные массивы. В~юго-вос\-точ\-ной части изображения этот алгоритм отнес 
вы\-руб\-ку к~по\-вреж\-ден\-ным древостоям. При этом пиксели рас\-смат\-ри\-ва\-емо\-го 
клас\-са характеризуют по\-вреж\-ден\-ные насаждения полиграфом уссурийским 
в~северной час\-ти изоб\-ра\-же\-ния.
  

  
  Экспертный анализ показал, что пред\-ла\-га\-емый метод автоматической 
классификации обладает преимуществом по сравнению с~алгоритмом 
\mbox{ISODATA}, что следует из анализа рис.~2--4. Пред\-ла\-га\-емый алгоритм 
автоматической классификации достаточно пол\-но выделяет зоны 
по\-вреж\-ден\-ных древостоев, разделяет темнохвойные и~лиственные породы, 
определяет участ\-ки с~открытой почвой, территории вырубок различной 
дав\-ности.


 Алгоритм ISODATA в этих условиях показал схожий результат 
классификации. Отличия наблюдаются на участках вырубок и поврежденных 
лесных насаждений, что вызывает разницу в их итоговой расчетной площади. 

Сравниваемые алгоритмы определили одинаковые участки изображения, 
со\-от\-вет\-ст\-ву\-ющие по\-вреж\-ден\-ным лесным на\-саж\-де\-ни\-ям. По результатам 
автоматической классификации алгоритмом \mbox{ISODATA} и~не\-па\-ра\-мет\-ри\-че\-ским 
классификатором рас\-счи\-та\-ны площади территорий по\-вреж\-ден\-ных древостоев 
полиграфом уссурийским (см.\ рис.~4). По данным 2022~г.\ они со\-ста\-ви\-ли~795,4 
и~635,0~га лесных массивов соответственно, что указывает на их 
различие в~25\%.

\section{Заключение}
  
  Разработанный непараметрический алгоритм автоматической классификации 
статистических данных большого объема основан на их сжатии путем 
декомпозиции многомерного пространства признаков исследуемых объектов 
и~алгоритмизации традиционной процедуры классификации. В~пред\-ла\-га\-емом 
алгоритме автоматической классификации использование многомерной 
гистограммы заменено на анализ регрессионной оценки плот\-ности ве\-ро\-ят\-ности 
случайных величин. Его применение позволяет обнаруживать классы, 
соответствующие одномодальным фрагментам плот\-ности ве\-ро\-ят\-ности. 
Использование многопоточной технологии обработки данных поз\-во\-ля\-ет 
в~2~раза сократить время автоматической классификации, что под\-тверж\-да\-ет\-ся 
результатами обработки спект\-раль\-ных данных дистанционного зондирования 
лесных массивов. Установлены условия преимущества непараметрического 
алгоритма по сравнению с методом ISODATA.

{\small\frenchspacing
 {\baselineskip=10.6pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
\bibitem{1-l}
\Au{Abbas A.\,W., Minallh~N., Ahmad~N., Abid~S.\,A.\,R., Khan~M.\,A.\,A.} K-means and 
ISODATA clustering algorithms for landcover classification using remote sensing~// Sindh 
University Research~J. (Science Series), 2016. Vol.~48. No.\,2. P.~315--318.
\bibitem{2-l}
\Au{Manthena N.\,R., Kumaran~N., Chandra~S.\,V.} Remote sensing image classification using 
CNN--LSTM model~// Revue d'Intelligence Artificielle, 2022. Vol.~36. No.\,1. P.~147--153. doi: 
10.18280/ria.360117.
\bibitem{3-l}
\Au{Дорофеюк А.\,А.} Алгоритмы автоматической классификации (обзор)~// Автоматика 
и~телемеханика, 1971. №\,12. С.~78--113.
\bibitem{4-l}
\Au{Дорофеюк А.\,А.} Методология экс\-перт\-но-клас\-си\-фи\-ка\-ци\-он\-но\-го анализа в~задачах 
управления и~обработки сложноорганизованных данных (история и перспективы 
развития)~// Проб\-ле\-мы управ\-ле\-ния, 2009. №\,3.1. С.~19--28. EDN: \mbox{KJUOIN}.
\bibitem{5-l}
\Au{Цыпкин Я.\,З.} Основы теории обучающихся систем.~--- М.: Наука, 1970. 252~c.
\bibitem{6-l}
\Au{Васильев В.\,И., Эш~С.\,Н.} Особенности алгоритмов самообучения и кластеризации~//  
Управ\-ля\-ющие сис\-те\-мы и машины, 2011. №\,3. С.~3--9.
\bibitem{7-l}
\Au{Parzen E.} On estimation of a probability density function and mode~// Ann. Math. Stat., 1962. 
Vol.~33. No.\,3. P.~1065--1076. doi: 10.1214/aoms/1177704472.
\bibitem{8-l}
\Au{Епанечников В.\,А.} Непараметрическая оценка многомерной плотности вероятности~// 
Теория вероятностей и ее применения, 1969. Т.~14. №\,1. С.~156--161.
\bibitem{9-l}
\Au{Тарарушкин Е.\,В.} Восстановление плотности распределения частиц дисперсных 
материалов методом окна Пар\-зе\-на--Ро\-зен\-блат\-та~// Вестник МГСУ, 2018. Т.~13. 
Вып.~7(118). С.~855--862. doi: 10.22227/1997-0935.2018.7.855-862. EDN: UVNCVV.
\bibitem{10-l}
\Au{Лапко А.\,В., Лапко В.\,А.} Ядерные оценки плотности вероятности и их применение.~--- 
Красноярск: СибГУ им.\ М.\,Ф.~Решетнева, 2021. 308~с.
\bibitem{11-l}
\Au{Лапко А.\,В., Лапко В.\,А.} Непараметрический алгоритм автоматической классификации 
в условиях статистических данных большого объема~// Информатика и~сис\-те\-мы  
управ\-ле\-ния, 2018. Т.~57. №\,3. С.~59--70. doi: 10.22250/isu.2018.57.59-70.
\bibitem{12-l}
\Au{Зеньков~И.\,В., Лапко~А.\,В., Лапко~В.\,А., Им~С.\,Т., Тубольцев~В.\,П., Авдеенок~В.\,Л.} 
Непараметрический алгоритм автоматической классификации многомерных статистических 
данных большого объема и его применение~// Компьютерная оптика, 2021. Т.~45. №\,2. 
С.~253--260. doi: 10.18287/2412-6179-CO-801. EDN: WUOYYA.

\bibitem{13-l}
\Au{Scott D.\,W.} Multivariate density estimation: Theory, practice, and visualization.~--- Hoboken, 
NJ, USA: John Wiley \& Sons, 2015. 384~p.
\bibitem{14-l}
\Au{Fushimi T., Saito~K., Motoda~H.} Constructing outlier-free histograms with variable bin-width 
based on distance minimization~// Intell. Data Anal., 2023. Vol.~27. No.\,1. P.~5--29.
\bibitem{15-l}
\Au{Heinhold I., Gaede~K.\,W.} Ingeniur statistic.~--- M$\ddot{\mbox{u}}$nchen, Wien: 
Springer-Verlag, 1964. 352~p.
\bibitem{16-l}
\Au{Лапко А.\,В., Лапко В.\,А., Им~С.\,Т., Тубольцев~В.\,П., Авдеенок~В.\,Л.} Программа 
автоматической классификации данных дистанционного зондирования Земли на основе 
непараметрических алгоритмов принятия решений (NAC v.~2.0). Свидетельство 
о~государственной регистрации программы для ЭВМ №\,2022619023 от 18.05.2022.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-10pt}

\hfill{\small\textit{Поступила в~редакцию 16.01.23}}

\vspace*{6pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule



\def\tit{NONPARAMETRIC ALGORITHM FOR~AUTOMATIC CLASSIFICATION OF~REMOTE 
SENSING DATA\\[-5pt]}


\def\titkol{Nonparametric algorithm for~automatic classification of~remote 
sensing data}


\def\aut{V.\,P.~Tuboltsev$^1$, A.\,V.~Lapko$^{1,2}$, and~V.\,A.~Lapko$^{1,2}$}

\def\autkol{V.\,P.~Tuboltsev, A.\,V.~Lapko, and~V.\,A.~Lapko}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-14pt}


\noindent
$^1$M.\,F.~Reshetnev Siberian State University of Science and Technology, 31~Krasnoyarsky Rabochy 
Av., Krasno-\linebreak
$\hphantom{^1}$yarsk 660037, Russian Federation

\noindent
$^2$Institute of Computational Modelling of the Siberian Branch of the Russian Academy of 
Sciences, 50/44~Akadem-\linebreak
$\hphantom{^1}$gorodok, Krasnoyarsk 660036, Russian Federation


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 4}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 4
\hfill \textbf{\thepage}}}

\vspace*{2pt}




\Abste{A nonparametric algorithm for automatic classification of large-volume statistical data 
is proposed. The algorithm under consideration assumes compression of initial information 
based on decomposition of  multidimensional feature space. As a~result, a~large statistical 
sample is transformed into a~data array composed of the centers of multidimensional sampling 
intervals and their corresponding frequencies of random variables. The information obtained is used 
in the synthesis of the regression estimate of the probability density. A~class is understood as 
a~compact group of observations of a~random variable corresponding to a unimodal fragment of 
the probability density function. On this basis, a~nonparametric automatic classification algorithm is 
developed which is based on the sequential procedure for checking the proximity of the centers of 
multidimensional sampling intervals and the ratios between the frequencies of belonging of random 
variables from the original sample to these intervals. To improve the computational efficiency of 
the proposed automatic classification algorithm, a~multithreaded method of its software 
implementation is used. The practical significance of the developed algorithm for automatic 
classification is confirmed by the results of its application for assessing the state of the forests areas using 
remote sensing data.}


\KWE{automatic classification; large-volume samples; sampling of the range of values of random 
variables; regression estimation of probability density; remote sensing data}

\DOI{10.14357/19922264230404}{MPEWAW}

%\vspace*{-12pt}

%\Ack
%\noindent


\vspace*{-8pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99} 
 
 \vspace*{-2pt}
 
 
\bibitem{1-l-1}
\Aue{Abbas, A.\,W., N.~Minallh, N.~Ahmad, S.\,A.\,R.~Abid, and M.\,A.\,A.~Khan.} 2016.  
K-means and ISODATA clustering algorithms for landcover classification using remote sensing. 
\textit{Sindh University Research~J. (Science Series)} 48(2):315--318.
\bibitem{2-l-1}
\Aue{Manthena, N.\,R., N.~Kumaran, and S.\,V.~Chandra.} 2022. Remote sensing image 
classification using CNN--LSTM model. \textit{Revue d'Intelligence Artificielle} 36(1):147--153. 
doi: 10.18280/ria.360117.
\bibitem{3-l-1}
\Aue{Dorofeyuk, А.\,А.} 1971. Algoritmy avtomaticheskoy klassifikatsii (obzor)
[Algorithms of automatic classification (review)]. \textit{Automat. 
Rem. Contr.} 12:78--113.
\bibitem{4-l-1}
\Aue{Dorofeyuk, А.\,А.} 2009. Metodologiya ekspertno-klassifikatsionnogo analiza v~zadachakh 
upravleniya i~obrabotki slozhnoorganizovannykh dannykh (istoriya i~perspektivy razvitiya) 
[Expert-ranging analysis methodology in complex organized data processing and control problems 
(history of development and perspectives)]. \textit{Problemy upravleniya} [Control Sciences] 
3S1:19--28. EDN: KJUOIN.
\bibitem{5-l-1}
\Aue{Tsypkin, Ya.\,Z.} 1970. \textit{Osnovy teorii obuchayushchikhsya sistem} [Foundations of the 
theory of learning systems]. Moscow: Nauka. 252~p.
\bibitem{6-l-1}
\Aue{Vasil'ev, V.\,I., and S.\,N.~Esh.} 2011. Osobennosti algoritmov samoobucheniya 
i~klasterizatsii [Features of self-learning algorithms and clustering]. \textit{Upravlyayushchie 
sistemy i~mashiny} [Control Systems and Computers] 3:3--9.
\bibitem{7-l-1}
\Aue{Parzen, E.} 1962. On estimation of a probability density function and mode. \textit{Ann. 
Math. Stat.} 33(3):1065--1076. doi: 10.1214/aoms/1177704472.
\bibitem{8-l-1}
\Aue{Epanechnikov, V.\,A.} 1969. Non-parametric estimation of a multivariate probability density. 
\textit{Theor. Probab. Appl.} 14(1):153--158. doi: 10.1137/1114019.
\bibitem{9-l-1}
\Aue{Tararushkin, E.\,V.} 2018. Vosstanovlenie plotnosti raspredeleniya chastits dispersnykh 
materialov metodom okna Parzena--Rozenblatta [Reconstructing distribution density of particles for 
disperse materials by the Parzen--Rozenblatt window method]. \textit{Vestnik MGSU} 
 13(7):855--862. doi: 10.22227/1997-0935.2018.7.855-862. EDN: UVNCVV.
\bibitem{10-l-1}
\Aue{Lapko, A.\,V., and V.\,A.~Lapko.} 2021. \textit{Yadernye otsenki plotnosti veroyatnosti i~ikh 
primenenie} [Kernel probability density estimates and their application]. Krasnoyarsk: Reshetnev 
University Publs. 308~p.
 \bibitem{11-l-1}
\Aue{Lapko, A.\,V., and V.\,A.~Lapko.} 2018. Ne\-pa\-ra\-met\-ri\-che\-skiy algoritm avtomaticheskoy 
klassifikatsii v~usloviyakh sta\-ti\-sti\-che\-skikh dannykh bol'shogo ob"ema [Nonparametric algorithm 
of automatic classification under conditions of large-scale statistical data]. \textit{Informatika 
i~sistemy upravleniya} [Information Science and Control Systems] 57(3):59--70. doi: 
10.22250/isu.2018.57.59-70. EDN: YACMRN.
\bibitem{12-l-1}
\Aue{Zenkov, I.\,V., A.\,V.~Lapko, V.\,A.~Lapko, S.\,T.~Im, V.\,P.~Tuboltsev, and 
V.\,L.~Avdeenok.} 2021. A nonparametric algorithm for automatic classification of large 
multivariate statistical data sets and its application. \textit{Computer Optics} 45(2):253--260. doi:  
10.18287/2412-6179-CO-801. EDN: WUOYYA.
\bibitem{13-l-1}
\Aue{Scott, D.\,W.} 2015. \textit{Multivariate density estimation: Theory, practice, and 
visualization}. Hoboken, NJ: John Wiley \&~Sons. 384~p.
\bibitem{14-l-1}
\Aue{Fushimi, T., K.~Saito, and H.~Motoda.} 2023. Constructing outlier-free histograms with 
variable bin-width based on distance minimization. \textit{Intell. Data Anal.} 27(1):5--29.
\bibitem{15-l-1}
\Aue{Heinhold, I., and K.\,W.~Gaede.} 1964. \textit{Ingeniur statistic}. 
M$\ddot{\mbox{u}}$nchen, Wien: Springler Verlag. 352~p.
\bibitem{61-l-1}
\Aue{Lapko, A.\,V., V.\,A.~Lapko, S.\,T.~Im, V.\,P.~Tuboltsev, and V.\,L.~Avdeenok.} 2022. 
Programma avtomaticheskoy klassifikatsii dannykh distantsionnogo zondirovaniya Zemli na 
osnove neparametricheskikh algoritmov prinyatiya resheniy (NAC v.~2.0) [The program for 
automatic classification of Earth remote sensing data based on nonparametric decision-making 
algorithms (NAC v.~2.0)]. Certificate of State Registration of the Computer Program RF 
No.\,2022619023.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received January 16, 2023}} 

%\vspace*{-18pt}

\Contr

\vspace*{-4pt}

     \noindent
     \textbf{Tuboltsev Vitaly P.} (b.\ 1998)~--- PhD student, M.\,F.~Reshetnev Siberian State University 
of Science and Technology, 31~Krasnoyarsky Rabochy Av., Krasnoyarsk 660037, Russian 
Federation; \mbox{vitalya.98@mail.ru}
     
     \vspace*{3pt}
     
     \noindent
     \textbf{Lapko Alexander V.} (b.\ 1949)~--- Doctor of Science in technology, professor, 
Honored Scientist of the RF, principal scientist, Institute of Computational Modelling 
of the Siberian Branch of the Russian Academy of Sciences, 50/44~Akademgorodok, Krasnoyarsk 
660036, Russian Federation; professor, Department of Space Facilities and Technologies, 
M.\,F.~Reshetnev Siberian State University of Science and Technology, 31~Krasnoyarsky Rabochy Av., 
Krasnoyarsk 660037, Russian Federation; \mbox{lapko@icm.krasn.ru}
     
     \noindent
     \textbf{Lapko Vasiliy A.} (b.\ 1974)~--- Doctor of Science in technology, professor, leading 
scientist, Institute of Computational Modelling of the Siberian Branch of the Russian Academy of 
Sciences, 50/44~Akademgorodok, Krasnoyarsk 660036, Russian Federation; head of 
department, M.\,F.~Reshetnev Siberian State University of Science 
and Technology, 31~Krasnoyarsky Rabochy Av., Krasnoyarsk 660037, Russian Federation; 
valapko@yandex.ru

\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 