\def\stat{bosov}

\def\tit{ТЕХНОЛОГИЯ МНОГОФАКТОРНОЙ КЛАССИФИКАЦИИ МАТЕМАТИЧЕСКОГО КОНТЕНТА\\ 
ЭЛЕКТРОННОЙ СИСТЕМЫ ОБУЧЕНИЯ$^*$}

\def\titkol{Технология многофакторной классификации математического контента 
электронной системы обучения}

\def\aut{А.\,В.~Босов$^1$, А.\,В.~Иванов$^2$}

\def\autkol{А.\,В.~Босов, А.\,В.~Иванов}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Босов А.\,В.}
\index{Иванов А.\,В.}
\index{Bosov A.\,V.}
\index{Ivanov A.\,V.}


{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Исследование выполнено за счет гранта Российского научного фонда №\,22-28-00588 ({\sf 
https://rscf.ru/project/22-28-00588/}). Работа выполнялась с~использованием инфраструктуры Центра 
коллективного пользования <<Высокопроизводительные вычисления и~большие данные>> (ЦКП 
<<Информатика>> ФИЦ ИУ РАН, Москва).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{avbosov@ipiran.ru}}
\footnotetext[2]{Федеральный исследовательский центр <<Информатика и~управление>>
   Российской академии наук, 
\mbox{aivanov@ipiran.ru}}


%\vspace*{-12pt}



\Abst{Статья продолжает исследование задачи классификации контента 
электронной обучающей системы (ЭОС). Разработанная ранее технология 
тематической классификации математического контента, содержащегося в~блоках 
задач и~примеров ЭОС, усовершенствована и~дополнена новыми функциями. Для 
этого использованная ранее модель контента с~двумя свойствами~--- 
традиционной текстовой формулировкой и~формульной частью в~формате \TeX~--- дополнена рядом дополнительных числовых атрибутов, таких как наличие 
трансцендентных и~производных функций, число формул в~задании. Этот блок 
атрибутов позволил повысить качество имеющегося тематического 
классификатора и~реализовать два новых, а~именно: в~дополнение к~тематической 
классификации задач реализована  возможность автоматического 
определения, во-пер\-вых,  слож\-ности задания и,~во-вто\-рых, набора компетенций, фор\-ми\-ру\-емых 
у~обуча\-емо\-го заданием. Такая многофакторная классификация представляется 
важным этапом перспективного направления развития ЭОС~--- 
автоматизированного оценивания качества образовательного контента. Проверка 
работоспособности предлагаемых алгоритмов, обучение классификаторов и~анализ качества классификации выполнены по той же дисциплине теории 
функций комплексного переменного, но на существенно расширенном материале, 
включая задания для самостоятельной работы студентов~--- расчетные 
и~экзаменационные работы.}

\KW{электронная обучающая система; математический контент; машинное 
обучение; многофакторная классификация; оценка качества контента}

\DOI{10.14357/19922264230405}{LISHHZ}
  
\vspace*{-6pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}

\section{Введение}

\vspace*{-3pt}

     Электронные обучающие системы используются повсеместно, 
достаточно давно и~стали привычными, в~том числе и~в~качестве средств 
дистанционного обучения. Несмотря на их разнообразие, от простого 
электронного учебника до интегрированной обучающей среды вуза, 
неотъемлемой и~наиболее ответственной частью ЭОС остается учебный 
контент, т.\,е.\ сам материал, предоставляемый системой учащемуся и~преподавателю. И~актуальным был и~остается вопрос качества этого 
контента. В~статье не затрагивается <<ручной>> экспертный анализ качества 
учебного контента, в~фокусе~--- вопрос автоматического анализа. Этот 
вопрос довольно сложный и~со временем вполне возможно сформирует 
самостоятельное направление~[1, 2]. На данный момент ясно, что здесь есть 
богатый источник прикладных задач для методов машинного обучения, что 
продемонстрировано в~предыдущих работах по этой тематике~[3, 4]. В~этих 
работах подтверждена принципиальная возможность автоматизировать 
тематическую классификацию математических задач. По комбинации 
математических формул, размеченных в~формате \TeX, и~традиционных 
текстовых формулировок заданий оказалось возможным очень эффективно 
определять тематику задания. С~исследовательской позиции полезной 
оказалась смешанная модель заданий, объединяющая формулы и~текст. 
С~прикладной~--- средство, автоматически определяющее тему (раздел 
курса) конкретного задания. Это средство позволяет сделать первый шаг 
в~автоматизации анализа качества обучающего контента, позволив 
автоматизировать определение объемных и~сравнительных показателей 
распределения элементов контента по темам, делать выводы о достаточности 
примеров и~самостоятельных заданий и~т.\,п.


     
     На основе этой технологии в~данной статье исследуется возможность 
анализа других показателей. При классификации по более сложным, чем 
тематика, показателям обнаружилось недостаточное качество модели. 
Поэтому она была расширена третьим блоком свойств, уточняющих разметку 
формульной части. Уточненной модели посвящен\linebreak следующий раздел статьи. 
Здесь же обсуждается и~главный методический вопрос~--- определение 
показателей для классификации. Самый \mbox{простой}~--- атрибут слож\-ности 
задания~--- не вызывает сомнений. Как и~в~постановке с~тематикой, этот 
атрибут\linebreak позволит определять понятные объемные и~сравнительные 
показатели распределения элементов контента по уровням слож\-ности. Для 
содержательного анализа было использовано понятие \mbox{компетентностного} 
подхода в~образовании, очень популярного и~активно развиваемого, в~том 
чис\-ле и~с~целями определения содержания образования и~оцен\-ки 
образовательных результатов~[5, 6]. Применительно к~имеющемуся 
в~распоряжении контенту~--- заданиям по курсу тео\-рии функций 
комплексного переменного~--- эта идея свелась к~разметке заданий перечнем 
фор\-ми\-ру\-емых компетенций. Полный перечень компетенций не\-труд\-но 
определить в~соответствии с~федеральными государственными 
образовательными стандартами высшего образования.

\begin{figure*} %fig1
 \vspace*{1pt}
\begin{center}
   \mbox{%
\epsfxsize=162.491mm 
\epsfbox{bos-1.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Обновленная модель задания}
\end{figure*}
     
     Задача классификации, которую надо решать,~--- это типичная задача 
машинного обучения. Принципиальное условие успеха~--- качество данных,\linebreak 
используемых для обучения алгоритмов. Если предыду\-щая задача 
тематической классификации успешно решалась на данных, извлеченных по 
большей части из единственного электронного учебного пособия, то первые 
же эксперименты с~многофакторными моделями, включающими наборы 
компетенций, показали недостаточность имеющегося набора. Практический 
вклад в~подготовку обуча\-ющей выборки сделали авторы пособия~[7], 
предоставив для исследования массив задач, ис\-поль\-зу\-емых для 
самостоятельной работы студентов и~при проведении экзаменов. Этот 
расширенный\linebreak массив был ими же размечен для выбранных показателей 
слож\-ности и~компетенций. Таким образом сформирован объемный, 
размеченный компетентными экспертами массив \mbox{классифицированных} 
данных. Соответственно, для рас\-смат\-ри\-ва\-емой задачи стал до\-сту\-пен 
практически весь име\-ющий\-ся методический и~алгоритмический аппарат в~об\-ласти классификации~[8--11]. К~настоящему времени этот богатейший 
аппарат нашел множество приложений, порой довольно неочевидных, 
в~экономике, производстве, телекоммуникациях~[12--17]. Поэтому главные 
усилия были направлены на совершенствование модели и~качества 
обуча\-ющей выборки, проб\-ле\-мы формирования которой решить час\-то 
слож\-нее, чем подобрать хороший алгоритм~[18]. Помимо модели  
и~обуча\-юще\-го набора улучшены процедура стратификации обуча\-ющей 
выборки и~мет\-ри\-ка обуче\-ния, проведены эксперименты 
с~распространенными многоклассовыми классификаторами.

\section{Исходные данные и~модель~задания}

      Основной учебный материал, использованный в~статьях~[3, 4], 
включал 200~заданий из 9~разделов курса <<Тео\-рия функций комплексного 
переменного>>. Модель задания содержала два независимо формируемых 
вектора признаков: первый формировался на основе текстовой части задачи 
с~по\-мощью типовых процедур обработки текстов на естественном языке, 
второй~--- на основе формул в~формате \TeX\ с~по\-мощью специальных 
процедур обработки формульных описаний. На рис.~1 эта часть модели 
отмечена как <<модель задания \TeX>>.
      
      Поскольку для классификации применяется парадигма <<обучение 
с~учителем>>, чтобы применить модель для классификации дополнительных 
категорий, потребовалось выполнить разметку данных дополнительными 
целевыми атрибутами. Необходимость иметь достаточное чис\-ло примеров по 
каж\-до\-му из новых атрибутов потребовала существенного расширения 
обуча\-ющей выборки. Так\-же была предпринята попытка расширить модель за 
счет дополнительных признаков, по\-сколь\-ку ис\-поль\-зу\-емые подходы 
к~формированию векторов при\-зна\-ков со\-про\-вож\-да\-ют\-ся потерей час\-ти 
информации о~структуре задания. Дополнена модель задания сле\-ду\-ющи\-ми 
элементами (на рис.~1 отмечены как <<модель задания эксперт>>):
\begin{enumerate}[(1)]
\item тремя дополнительными признаками формульной части задания: 
числом формул в~задании, наличием трансцендентных функций и~числом 
производных;
\item атрибутом сложности задания~--- целым чис\-лом из диапазона 1--7;
\item 20 атрибутами формируемых компетенций~--- набором индикаторов, 
принимающих значение~0 или~1 и~соответствующих номеру компетенции, 
определенному образовательным стандартом для данной дисциплины.
\end{enumerate}

      Надо отметить, что информация первого раздела может быть 
получена и~получается автоматически. Собственно, она была доступна в~процессе предварительной обработки заданий, \mbox{описанном} в~[3], но не 
использовалась. Разметка заданий по признакам~2 и~3~--- это задача, 
выполняемая исключительно экспертом. В~данном исследовании эту 
разметку выполнили авторы пособия~[7], а~главным вызовом 
представленных далее расчетов было подтверждение возможности 
автоматизации навыков экспертов по этим признакам  
(слож\-ность\;+\;ком\-пе\-тен\-ции) типовыми средствами \mbox{машинного}  
обуче\-ния.
      


      Список компетенций (рис.~2) содержит 20~навыков, которые должны 
быть сформированы у~учащегося в~результате прохождения курса. Эксперт 
без особых трудностей определяет тот перечень компетенций, который 
отвечает конкретному заданию. Трудность классификации размеченного 
материала состоит в~том, что чис\-ло компетенций, на\-зна\-ча\-емых заданиям, 
переменно: одному заданию могут отвечать от~1 до~4 раз\-ных навыков. 
Соответственно, при таком характере образовательного материала важно не 
только правильно выбрать и~на\-стро\-ить алгоритмы классификации, но 
и~получить сбалансированную обуча\-ющую выборку.
      


      Уже при выполнении расчетов в~[3, 4] с~единственным целевым 
атрибутом объем в~200~заданий с~учетом~9~классов (тематик) не 
представлялся достаточным. Успех тематической \mbox{классификации} был 
обеспечен только на смешанной модели, соединяющей две группы 
разнотипных признаков. В~случае 20~целевых атрибутов число классов, 
определяемых их сочетаниями, выросло более чем до~100, при этом 
количество примеров в~каждом классе не превышало нескольких штук. 
Поэтому увеличение выборки было критически необходимо. При этом 
ресурсы существующих пособий уже были практически исчерпаны. Решение 
позволили получить авторы~[7], предоставившие значительный объем 
заданий, используемых для самостоятельной работы студентов, т.\,е.\ для 
проведения рас-\linebreak\vspace*{-12pt}

{ \begin{center}  %fig2
 \vspace*{6pt}
    \mbox{%
\epsfxsize=79mm 
\epsfbox{bos-2.eps}
}

\vspace*{6pt}

\noindent
{{\figurename~2}\ \ \small{Выписка компетенций из стандарта
}}
\end{center}
}

%\vspace*{12pt}

\addtocounter{figure}{1}

\pagebreak


\noindent
четных, контрольных и~экзаменационных работ. По понятной 
причине эти задания не публиковались и~не будут публиковаться в~открытом 
доступе. Но благодаря этому материалу общий объем обучающей выборки 
после исключения дубликатов был доведен до~750~заданий, что позволило 
получить удовлетворительные результаты клас\-си\-фи\-ка\-ции.
{\looseness=1

}
      
\section{Алгоритмы}

      За исключением специфической модели, рассматриваемая задача 
классификации представляется достаточно типичной, поэтому применялись 
самые распространенные алгоритмы. В~данном разделе они указаны для 
каждого этапа решения задачи: подготовки обучающей выборки; выбора 
классификаторов; выбора методов многозначной классификации; 
интерпретации результатов.
      
      Этап \textit{подготовки обучающей выборки} в~основном повторяет 
описанный в~[3]. Отличия состоят в~добавлении процедуры генерации 
дополнительных признаков формульной части задания, написанной на языке 
Python, и~замене алгоритма формирования обучающей и~тестовой выборок. 
При неограниченном или хотя бы достаточно большом объеме обучающей 
выборки вопрос формирования выборок можно решать предельно просто~--- 
задать размеры и~набирать кандидатов случайным образом, выбирая образцы 
с~равными вероятностями и~независимо (случайный выбор). Если при 
распределении примеров учитывать их число для каждого из имеющихся 
классов, например делить примеры каждого класса пополам, направляя 50\% 
для обучения и~50\% для тестирования и~выбирая образцы с~равными 
вероятностями, то стратифицированный характер такого разбиения 
обеспечен. Такой вариант использовался в~[3, 4] и~показал свою 
эффективность. Однако в~случае классификации задач по компетенциям 
стратификация должна выполняться по~20~целевым атрибутам, комбинации 
значений которых образуют 109~классов. Стандартные алгоритмы 
используемой библиотеки scikit-learn не позволяют в~этом случае добиваться 
сбалансированных разбиений. Нужен более гибкий алгоритм, учитывающий 
распределение примеров в~обуча\-ющей выборке. Если это распределение не 
учитывать, то для ка\-ких-то классов можно получить разбиение, либо 
содержащее избыток тес\-то\-вых примеров, либо не содержащее их вообще, что 
исказит оценку качества классификации. Хороший вариант балансировки 
обучающей выборки предложен в~[19]. Этот алгоритм итеративной 
стратификации последовательно выбирает признаки и~образцы из выборки 
так, чтобы для каждого сочетания компетенций получалось примерно 
одинаковое число примеров в~обучающей и~тестовой группах. Его 
результативность иллюстрируется на рис.~3. Здесь показаны некоторые 
наиболее неудачные результаты, возникшие при формировании обучающей 
и~тестовой выборок по признакам компетенций. В~двух левых колонках 
показаны распределения для некоторых наборов компетенций, 
сформированные типовым алгоритмом случайного выбора, и~видно, что 
число примеров в~обучающей выборке оказывается меньше, местами~--- 
значительно меньше, чем в~тестовой выборке. При этом есть случаи, когда 
тестовая выборка пустая. Две правых колонки~--- результаты итеративной 
стратификации, которая со всеми име\-ющи\-ми\-ся данными справляется 
успешно. Этот же алгоритм теперь использовался и~при формировании 
выборок для классификации задач по тематике и~слож\-ности.



      Следующий тип алгоритмов~--- это \textit{многоклассовые 
классификаторы}, позволяющие отнести образец к~одному из классов по 
одному признаку. Для атрибутов тематики и~сложности алгоритм дает 
окончательный результат, для атрибута компетенций~--- промежуточный, 
используемый на следующем шаге для определения набора компетенций 
алгоритмом многозначной классификации.



      
      Для классификации были выбраны четыре типовых алгоритма 
классификации.
      \begin{enumerate}[1.]
\item Логистическая регрессия или модель логит (Logit)~[20], т.\,е.\ 
обобщенная линейная регрессионная модель, адаптированная для 
классификации (детали реализации~--- 
 {\sf https://}\linebreak {\sf scikit-learn.org/stable/modules/linear\_model.html} {\sf \#logistic-regression}). Для 
тематической классификации и~классификации по компетенциям 
использовался вариант с~$l_1$-ре\-гу\-ля\-ри\-за\-ци\-ей, обратным 
коэффициентом регуляризации~100 и~алгоритмом координатного спуска. 
Для классификации по сложности использовался вариант  
с~$l_2$-ре\-гу\-ля\-ри\-за\-ци\-ей, обратным коэффициентом 
регуляризации~10 и~алгоритмом Нью\-то\-на--Раф\-со\-на, использующим 
метод сопряженных градиентов.
\item Метод $k$-ближайших соседей (kNN)~[11] (детали реализации~--- {\sf 
https://scikit-learn.org/stable/}\linebreak {\sf modules/neighbors.html\#nearest-neighbors-classifi} {\sf cation}). Для тематической 
классификации чис\-ло соседей рав\-но~6, веса распределены равномерно. Для 
классификации по слож\-ности чис\-ло соседей рав\-но~10, веса распределены 
обратно пропорционально рас\-сто\-янию меж\-ду образцами. Для\, классификации\, 
по\, компетен- %\linebreak %\vspace*{-2pt}
\end{enumerate}


%\pagebreak

\end{multicols}

\setcounter{figure}{2}
\begin{figure*} %fig3
\vspace*{1pt}
\begin{center}
   \mbox{%
\epsfxsize=160.176mm 
\epsfbox{bos-3.eps}
}
\end{center}
\vspace*{-6pt}
\Caption{Результаты распределения задач по группам обучения и~тестирования: 
\textit{1} и~\textit{2}~--- случайный выбор примеров для обучения и~тестирования соответвтвенно, \textit{3} и~\textit{4}~---
стратифицированный выбор примеров для обучения и~тестирования соответственно}
\vspace*{6pt}
\end{figure*}


\begin{multicols}{2}

\begin{enumerate}[1.]
\setcounter{enumi}{2}
\item[\,] циям число соседей рав\-но~8, веса распределены обрат\-но 
пропорционально расстоянию меж\-ду образцами. Все классификаторы для 
вычисления расстояний меж\-ду образцами используют евклидову норму.
\item Метод чрезвычайно рандомизированных деревьев (ExtraTrees)~[21] 
(детали реализации~---
{\sf https://scikit-learn.org/stable/modules/ensemble.} {\sf html\#random-forests-and-other-randomized-tree-ensembles}). Для 
тематической классификации число деревьев в~ансамбле равно~200, 
критерием классификации служит энтропия, при раз\-би\-ении пространства 
признаков рассматривается все множество признаков. Для классификации по 
сложности число деревьев в~ансамбле равно~200, критерием классификации 
служит энтропия, при разбиении пространства признаков рассматривается 
подмножество с~размером, равным логарифму по основанию~2 от числа 
признаков. Для классификации по компетенциям число деревьев в~ансамбле 
равно~30, критерием классификации служит примесь Джини, при разбиении 
пространства признаков рассматривается подмножество с~размером, равным 
корню из чис\-ла признаков.
\item Многослойная нейронная сеть прямого распространения (MLP~--- multilayer perceptron)~[22] 
с~двумя скрытыми слоями и~функцией активации $f(x)\hm= \max(0,x)$ 
(детали реализации~--- {\sf  
https://scikit-learn.org/stable/} {\sf modules/neural\_networks\_supervised.html\#neural-networks-supervised}). Для тематической 
классификации число нейронов в~первом и~втором скрытых слоях равно 
соответственно~20 и~28. Для классификации по сложности число нейронов в~первом и~втором скрытых слоях равно соответственно~20 и~24. Для 
классификации по компетенциям число нейронов в~первом и~втором скрытых 
слоях равно соответственно~120 и~8.
      \end{enumerate}
      
            \begin{table*}[b]\small 
            \vspace*{-4pt}
      \begin{center}
      \begin{tabular}{|c|r|r|r|r|}
      \multicolumn{5}{c}{Анализ качества классификации}\\
      \multicolumn{5}{c}{\ }\\[-6pt]
      \hline
Класси-&\multicolumn{4}{c|}{Атрибут}\\
\cline{2-5}
фикатор&\multicolumn{1}{c|}{Тематика}&\multicolumn{1}{c|}{Сложность}&\multicolumn{1}{c|}{Компетенции\;+\;OneVsRest}&
\multicolumn{1}{c|}{Компетенции\;+\;ClassifierChains}\\
\hline
Logit&\tabcolsep=0pt\begin{tabular}{r}Accuracy\;=\;0,981\\
LogLoss\;=\;0,055\end{tabular}&\tabcolsep=0pt\begin{tabular}{r}Accuracy\;=\;0,869\\
LogLoss\;=\;0,403\end{tabular}&\tabcolsep=0pt\begin{tabular}{r}Accuracy\;=\;0,851\\
LogLoss\;=\;\textbf{1,343}\end{tabular}\hspace*{7mm}&\tabcolsep=0pt\begin{tabular}{r}Accuracy\;=\;0,856\\
LogLoss\;=\;\textbf{1,328}\end{tabular}\hspace*{11mm}\\
\hline
kNN&\tabcolsep=0pt\begin{tabular}{r}Accuracy\;=\;0,965\\
LogLoss\;=\;0,099
\end{tabular}&\tabcolsep=0pt\begin{tabular}{r}
Accuracy\;=\;0,837\\
LogLoss\;=\;0,817
\end{tabular}&\tabcolsep=0pt\begin{tabular}{r}
Accuracy\;=\;0,795\\
LogLoss\;=\;2,073
\end{tabular}\hspace*{7mm}&\tabcolsep=0pt\begin{tabular}{r}Accuracy\;=\;0,785\\
LogLoss\;=\;1,872\end{tabular}\hspace*{11mm}\\
\hline
ExtraTrees&\tabcolsep=0pt\begin{tabular}{r}Accuracy\;=\;0,987\\
LogLoss\;=\;0,090\end{tabular}&
\tabcolsep=0pt\begin{tabular}{r}Accuracy\;=\;0,877\\
LogLoss\;=\;\textbf{0,367}\end{tabular}&\tabcolsep=0pt\begin{tabular}{r}
Accuracy\;=\;0,827\\
LogLoss\;=\;1,718
\end{tabular}\hspace*{7mm}&\tabcolsep=0pt\begin{tabular}{r}
Accuracy\;=\;0,830\\ LogLoss\;=\;1,537\end{tabular}\hspace*{11mm}\\
\hline
MLP&\tabcolsep=0pt\begin{tabular}{r}Accuracy\;=\;0,981\\
LogLoss\;=\;\textbf{0,046}\end{tabular}&\tabcolsep=0pt\begin{tabular}{r} Accuracy\;=\;0,848\\LogLoss\;=\;0,914\end{tabular}&
\tabcolsep=0pt\begin{tabular}{r} Accuracy\;=\;0,851\\ LogLoss\;=\;1,401\end{tabular}\hspace*{7mm}&
\tabcolsep=0pt\begin{tabular}{r} Accuracy\;=\;0,856\\ LogLoss\;=\;1,459\end{tabular}\hspace*{11mm}\\
\hline
\end{tabular}
\end{center}
\end{table*}
      
      Следующий этап касается только классификации задания по 
компетенциям, где требуемый результат не может быть получен с~помощью 
единичного классификатора. Существует довольно много методов 
\textit{многозначной классификации}~[23], хотя не все из них могут быть 
использованы в~рассматриваемой задаче. Распространенный прием 
заключается в~трансформации задачи, когда для каждого целевого атрибута 
создается свой классификатор. Это и~было сделано для определения набора 
компетенций. Для целей данной работы выбраны два метода. Первый, 
наиболее простой и~<<справедливый>>, определяется стратегий  
OneVsRest~--- <<один против остальных>>~--- и~состоит в~том, что для 
каждой компетенции обучается и~используется свой классификатор, не 
зависящий от остальных, и~набор компетенций получается как 
комбинация~20~решений по каждому из имеющихся вариантов. 
<<Справедливость>> этой стратегии очевидным образом компрометируется 
неучетом взаимного влияния однофакторных классификаций друг на друга. 
А~влияние это, судя по данным и~по содержанию компетенций (см.\ рис.~2), 
весьма велико. Достаточно сказать, что имеющиеся 
размеченные~750~заданий формируют всего 109~разных групп 
компетенций, что, конечно, существенно меньше возможного числа $2^{20}$ 
множества всех подмножеств имеющихся компетенций. Это подтвердили 
и~результаты классификации: хотя существенная доля классификаторов 
нижнего уровня имела точ\-ность~1, общий результат оказался существенно 
ниже. Для учета этих влияний был опробован метод классификационных 
цепочек (Classifier Chains), при котором результирующий\linebreak набор формируется 
цепочкой решений однофакторных классификаторов, каждое из которых 
учитывает результат предстоящего в~цепочке классификатора. Формировался 
ансамбль из~15~таких\linebreak \mbox{цепочек}, порядок классификаторов в~каждой цепочке 
выбирался случайным неповторяющимся образом, все варианты 
компетенции предполагались равновероятными.
      
      Наконец, последний этап~--- интерпретация результатов, т.\,е.\ оценка 
качества реализованных \mbox{алгоритмов}, их сравнение. Этот этап требует 
мет\-ри\-ки качества. Первый вариант дает обычная <<точ\-ность>> (accuracy), 
т.\,е.\ доля правильных классификаций. Недостатки этой 
<<прямолинейной>> оценки проявляются в~случае классификации по 
компетенциям, поскольку правильной классификацией считается только 
полное совпадение всего списка компетенций. В~результате оценка 
оказывается занижена. Так\-же на эту оценку негативно влияет 
несбалансированность классов, что ярко проявляется в~рассматриваемой 
задаче (достаточно с~этой целью посмотреть на рис.~3). Более точное 
представление о~работе классификатора дает мет\-ри\-ка LogLoss, т.\,е.\ функция 
потерь логистической регрессии, основанная на суммировании логарифмов 
потерь от ошибочной классификации. Этот вариант представляется более 
объективным, но использовать его без accuracy, наверное, не вполне 
правильно из-за отсутствия физической интерпретации абсолютного 
значения оценки потерь.
      
\section{Экспериментальная классификация}

      Итак, для проведения расчетов имеются 750~заданий, подготовленных 
в~соответствии с~предложенной моделью (рис.~1) и~размеченных 
атрибутами тематики, сложности и~набором компетенций.\linebreak \mbox{Размеры} 
обучающей и~тестовой выборок определены равными, т.\,е.\ по~375~заданий. 
Стратификация по всем группам атрибутов выполнена итеративным 
алгоритмом. Обучены четыре алгоритма\linebreak классификации (обозначены Logit, 
kNN, \mbox{ExtraTrees} и~MLP) и~два алгоритма многозначной классификации 
(обозначены OneVsRest и~\mbox{ClassifierChains}). Метрики Accuracy и~LogLoss 
вычислены для всех~16~возможных комбинаций алгоритмов классификации, 
результаты приведены в~таб\-ли\-це (полужирным выделены 
<<победители>>).
      

     
     Отметим, что гиперпараметры для всех использованных алгоритмов 
оптимизированы путем поиска по сетке с~перекрестной валидацией по 
критерию минимизации метрики LogLoss. Несмотря на то что процедура 
оптимизации требует значительных затрат вычислительных ресурсов, 
эффективность оптимизации гиперпараметров алгоритмов классификации 
весьма существенна: метрики, вычисленные при использовании 
оптимизированных гиперпараметров, против значений по умолчанию 
отличались в~1,5--2~раза. Исключение здесь наблюдалось только для 
многослойной нейронной сети прямого распространения. Этот метод 
демонстрирует низкую чувствительность к~выбору па\-ра\-мет\-ров, что,  
по-ви\-ди\-мо\-му, вполне объяснимо тем, что сам по себе алгоритм содержит 
большое число самонастраиваемых параметров, которые в~любом случае 
позволяют извлечь из имеющегося контента всю информацию, 
содержательную с~точки зрения классификации. Собственно, такое 
поведение персептронов~--- это именно то, что от них ожидалось. Но 
с~позиции затрат вычислительных ресурсов этот метод безусловно 
и~значительно проигрывает всем остальным.

\section{Выводы}

     Основной полученный результат~--- это доказательство 
принципиальной возможности автоматизировать классификацию 
математических задач не только по признаку тематики~[3, 4], но и~по 
другому признаку, причем гораздо более сложному,~--- многозначному 
признаку компетенций. Попутно была подтверждена эффективность 
предложенной модели математического задания (цифрового 
образовательного контента на языке научной разметки \TeX) для другого 
содержания. Усилия по созданию модели и~подготовке обучающей выборки 
привели к~тому, что все выбранные типовые методы классификации 
работают вполне эффективно, и~нет сомнений, что будут работать и~другие 
известные алгоритмы. По-ви\-ди\-мо\-му, это означает, что наиболее 
ценными в~задачах такого типа оказываются модель и~обучающий контент, 
а~существующих на данный момент методов и~алгоритмов достаточно.
     
     Важно еще обратить внимание на перспективу дальнейшего развития и~использования пред\-став\-лен\-ных результатов. Описанная выше технология 
обладает несомненным потенциалом в~вопросах автоматизации анализа 
качества образовательного контента. На первый взгляд, анализ качества, 
т.\,е.\ экспертиза,~--- вопрос довольно сложный, поскольку в~случае с~экс\-пер\-том-че\-ло\-ве\-ком возникает проб\-ле\-ма объ\-ек\-тив\-ности, учет которой крайне сложен. 
Но, с~другой стороны, как видим, средства машинного обучения, которые в~последние годы продемонстрировали способности решения самых разных 
задач, прекрасно справляются и~с~контентом данного типа. При этом 
объективность таких решений не вызывает сомнений. Более того, им под 
силу объединить (обобщить, усреднить, при\-вес\-ти к~общему знаменателю) 
мнения многих экспертов, что при <<ручной>> экспертизе сделать практически 
невозможно. Таким образом, получается,\linebreak что проб\-ле\-ма\-ти\-ка 
автоматизированного анализа качества циф\-ро\-во\-го образовательного 
контента является богатым источником при\-клад\-ных задач для 
методов машинного обуче\-ния, а~пред\-став\-лен\-ная в~статье технология хорошо 
вписывается в~это при\-клад\-ное на\-прав\-ление.

{\small\frenchspacing
 {\baselineskip=10.6pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
\bibitem{1-bos}
\Au{Мартюшова Я.\,Г.} Теоретические основания конструирования электронных 
учебников для студентов технических университетов~// Отечественная и~зарубежная 
педагогика, 2018. Т.~1. №\,5. С.~151--165. doi: 10.24411/2224-0772-2018-10010. EDN: YOCAOT.
\bibitem{2-bos}
\Au{Босов А.\,В., Мартюшова~Я.\,Г., Наумов~А.\,В.} Выбор направлений оценивания 
качества электронных средств обучения для организации учебного процесса вуза~// 
Сибирский педагогический~ж., 2022. №\,2. С.~54--63. doi: 10.15293/1813-4718.2202.05.
EDN: \mbox{KNPIQX}.
\bibitem{3-bos}
\Au{Босов А.\,В., Иванов А.\,В.} Технология классификации типов контента электронного 
учебника~// Информатика и~её применения, 2022. Т.~16. Вып.~4. С.~63--72. doi: 
10.14357/19922264220410. EDN: YERCNH.
\bibitem{4-bos}
\Au{Bosov A.\,V., Ivanov A.\,V.} Two approaches to E-book content classification~// Artificial 
intelligence application in networks and systems~/ Eds. R.~Silhavy, P.~Silhavy.~--- Lecture notes in networks and systems 
ser.~--- Cham, Switzerland: Springer, 2023. Vol.~724. P.~77--87. doi:  
10.1007/978-3-031-35314-7\_6.
\bibitem{5-bos}
\Au{Хуторской А.\,В.} Дидактическая эвристика: Теория и~технология креативного 
обучения.~--- М.: МГУ, 2003. 416~с.
\bibitem{6-bos}
Модернизация образовательного процесса в~начальной, основной и~старшей школе: 
варианты решения~/ Под ред.\ А.\,Г.~Каспржака.~--- М.: Просвещение, 2004. 415~с. EDN: QTGWNX.
\bibitem{7-bos}
\Au{Битюков Ю.\,И., Мартюшова Я.\,Г.} Решение задач по теории функций комплексного 
переменного.~--- М.: МАИ, 2022. 87~с.
\bibitem{8-bos}
\Au{Айвазян С.\,А., Бухштабер~В.\,М., Енюков~И.\,С., Мешалкин~Л.\,Д.} Прикладная 
статистика: классификация и~снижение размерности.~--- М.: Финансы и~статистика, 1989. 
608~с.

\bibitem{11-bos} %9
\Au{Mitchell T.} Machine learning.~--- New York, NY, USA: McGraw-Hill Education, 1997. 
432~p.

\bibitem{9-bos} %10
\Au{Журавлев Ю.\,И., Рязанов~В.\,В., Сенько~О.\,В.} Распознавание. Математические 
методы. Программная сис\-те\-ма. Практические применения.~--- М.: Фазис, 2006. 
159~с.
\bibitem{10-bos} %11
\Au{Hastie T., Tibshirani~R., Friedman~J.} The elements of statistical learning.~--- New York, 
NY, USA: Springer, 2009. 745~p. doi: 10.1007/978-0-387-84858-7.

\bibitem{16-bos} %12
\Au{Goebel P.\,C., Palik~B.\,J., Kirkman~L.\,K., Drew~M.\,B., West~L., Pederson~D.\,C.} 
Forest ecosystems of a~Lower Gulf Coastal Plain landscape: Multifactor classification and 
analysis~// J.~Torrey Bot. Soc., 2001. Vol.~128. No.\,1. P.~47--75. doi: 
10.2307/3088659.


\bibitem{13-bos} %13
\Au{Щербакова С.\,А.} Международный туризм: экономика и~география.~--- М.: Финансы 
и~статистика, 2007. 144~с.

\bibitem{15-bos} %14
\Au{Кулешков И.\,В., Колбиков~В.\,С., Басниев~К.\,С.} Классификация нефтегазовых 
эксплуатационных объектов с~оценкой степени сложности выработки запасов 
углеводородов~// Технологии нефти и~газа, 2010. №\,2(67). С.~29--38. EDN: LKYHCP.
\bibitem{14-bos} %15
\Au{Задорожнева Ю.\,В., Калинина~А.\,Э.} Многофакторная оценка эф\-фек\-тив\-ности 
реализации со\-ци\-аль\-но-эко\-но\-ми\-че\-ской политики региона~// Современные  
проб\-ле\-мы науки и~образования, 2012. №\,4. С.~192--192. EDN: PBIRUD.

\bibitem{12-bos} %16
\Au{Казарин О.\,В., Шаряпов~Р.\,А., Ященко~В.\,В.} Многофакторная классификация 
угроз информационной безопас\-ности киберфизических сис\-тем~// Вестник РГГУ. 
Сер. Информатика. Информационная безопас\-ность. Математика, 2018. №\,1.  
С.~39--55. EDN: FNXARP.


\bibitem{17-bos}
\Au{Xiong Y., Wang~L., Wang~Q., Liu~S., Kou~B.} Improved convolutional neural network 
with feature selection for imbalanced ECG multi-factor classification~// Measurement, 2022. 
Vol.~189. Art.~110471. doi: 10.1016/j.measurement.2021.110471.
\bibitem{18-bos}
\Au{Кафтанников И.\,Л., Парасич~А.\,В.} Проблемы формирования обучающей выборки 
в~задачах машинного обуче\-ния~// Вестник ЮУрГУ. Сер. Компьютерные технологии, 
управление, радиоэлектроника, 2016. Т.~16. №\,3. С.~15--24. doi: 10.14529/ct·sr160302. EDN: TZWHTS.
\bibitem{19-bos}
\Au{Sechidis K., Tsoumakas~G., Vlahavas~I.} On the stratification of multi-label data~// 
Machine learning and knowledge discovery in databases~/ Eds. 
D.~Gunopulos, T.~Hofmann, D.~Malerba, M.~Vazirgiannis.~--- Lecture notes in computer 
science ser.~--- Berlin, Heidelberg: Springer, 2011. Vol.~6913. P.~145--158. doi:  
10.1007/978-3-642-23808-6\_10.
\bibitem{20-bos}
\Au{Hosmer D.\,W., Lemeshow~S., Sturdivant~R.\,X.} Applied logistic regression.~--- 
 3rd ed.~--- New York, NY, USA: Wiley, 2013. 528~p. doi: 
10.1002/9781118548387.
\bibitem{21-bos}
\Au{Breiman L.} Random forests~// Mach. Learn., 2001. No.\,45. P.~5--32. doi: 
10.1023/A:1010933404324.
\bibitem{22-bos}
\Au{Haykin S.} Neural networks and learning machines.~--- 3rd ed.~--- Cranbury, NJ, USA: 
Pearson Education, 2009. 906~p.
\bibitem{23-bos}
\Au{Bogatinovski J., Todorovski~L., \mbox{D{\!\ptb{\!\v{z}}}eroski}~S., Kocev~D.} 
Comprehensive comparative study of multi-label classification methods~// Expert Syst.  
Appl., 2022. Vol.~203. Art.~117215. doi: 10.1016/j.eswa.2022.117215.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-10pt}

\hfill{\small\textit{Поступила в~редакцию 15.10.23}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule



\def\tit{MULTIFACTOR CLASSIFICATION TECHNOLOGY 
OF~MATHEMATICAL CONTENT OF~E-LEARNING SYSTEM}


\def\titkol{Multifactor classification technology 
of~mathematical content of~e-learning system}


\def\aut{A.\,V.~Bosov and~A.\,V.~Ivanov}

\def\autkol{A.\,V.~Bosov and~A.\,V.~Ivanov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-10pt}


\noindent
Federal Research Center ``Computer Science and Control'' of the Russian 
Academy of Sciences, 44-2 Vavilov Str., Moscow 119333, Russian Federation


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 4}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 4
\hfill \textbf{\thepage}}}

\vspace*{3pt}



\Abste{The article continues the study of the problem of classifying the content of 
an e-learning system. The previously developed technology for thematic 
classification of mathematical content contained in the blocks of tasks and 
examples of e-learning system has been improved and supplemented with new 
functions. For this purpose, the previously used content model with two 
properties~--- a~text description of a task and its formula part in \TeX format~--- 
has been supplemented with a~number of formal numerical attributes, such as the 
presence of transcendental and derived functions, and the number of 
formulas in the task. This block of attributes made it possible to improve the 
quality of the existing thematic classifier and to implement two new ones. The first 
classifier determines the level of complexity of the task. The second multilabel 
classifier determines the set of student competencies that the task should form. 
Such a multifactorial classification is an important stage in the promising direction 
of the development of e-learning system~--- automated assessment of the quality 
of educational content. Performance testing of the proposed algorithms, training of 
classifiers, and analysis of classification quality were carried out using the tasks from 
the same discipline of the theory of functions of a~complex variable but on 
significantly expanded set of data, including tasks for independent work of 
students~--- calculation and examination tasks.}

\KWE{e-learning system; mathematical content; machine learning; multifactor 
classification; content quality assessment}




\DOI{10.14357/19922264230405}{LISHHZ}

\vspace*{-12pt}

\Ack

\vspace*{-4pt}

\noindent
The research has been supported by the Russian Science 
Foundation according to the research project No.\,22-28-00588 
({\sf 
https://rscf.ru/project/22-28-00588/}). The research was 
carried out using the infrastructure of the Shared Research Facilities ``High 
Performance Computing and Big Data'' (CKP ``Informatics'') of FRC CSC RAS 
(Moscow).

\vspace*{2pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99} 
\bibitem{1-bos-1}
\Aue{Martyushova, Ya.\,G.} 2018. Teoreticheskie osnovaniya konstruirovaniya 
elektronnykh uchebnikov dlya studentov tekhnicheskikh universitetov [Theoretical 
foundations of designing electronic textbooks for students of technical 
universities]. \textit{Otechestvennaya i~zarubezhnaya pedagogika} [Domestic and 
Foreign Pedagogy] 1(5):151--165. doi: 10.24411/2224-0772-2018-10010. 
EDN: YOCAOT.
\bibitem{2-bos-1}
\Aue{Bosov, A.\,V., Ya.\,G.~Martyushova, and A.\,V.~Naumov.} 2022. Vybor 
napravleniy otsenivaniya kachestva elektronnykh sredstv obucheniya dlya 
organizatsii uchebnogo protsessa vuza [Directions selection for assessing the 
quality of electronic learning tools for the organization of the educational process 
of the higher educational process]. \textit{Sibirskiy pedagogicheskiy zh.} 
[Siberian Pedagogical~J.] 2:54--63. doi: 10.15293/1813-4718.2202.05. EDN: 
\mbox{KNPIQX}.
\bibitem{3-bos-1}
\Aue{Bosov, A.\,V., and A.\,V.~Ivanov.} 2022. Tekhnologiya klassifikatsii tipov 
kontenta elektronnogo uchebnika [Technology for classification of content types of 
e-textbooks]. \textit{Informatika i~ee Primeneniya~--- Inform. Appl.}  
16(4):63--72.  doi: 10.14357/19922264220410. EDN: YERCNH.
\bibitem{4-bos-1}
\Aue{Bosov, A.\,V., and A.\,V.~Ivanov.} 2023. Two approaches to E-Book content 
classification. \textit{Artificial intelligence application in networks and systems}. Eds.~R. Silhavy and P.~Silhavy. Lecture 
notes in networks and systems ser. Cham, Switzerland: Springer. 724:77--87. doi: 
10.1007/978-3-031-35314-7\_6.
\bibitem{5-bos-1}
\Aue{Khutorskoy, A.\,V.} 2003. \textit{Didakticheskaya evristika: Teoriya 
i~tekhnologiya kreativnogo obucheniya} [Didactic heuristics: Theory and 
technology of creative learning]. Moscow: MSU. 416~p.
\bibitem{6-bos-1}
Kasprzhak, A.\,G., ed. 2004. \textit{Mo\-der\-ni\-za\-tsiya ob\-ra\-zo\-va\-tel'\-no\-go pro\-tses\-sa 
v~na\-chal'\-noy, osnov\-noy i~star\-shey shko\-le:\linebreak va\-ri\-an\-ty re\-she\-niya} [Modernization of 
the educational process in primary, secondary and high schools: Solution options]. 
Moscow: Prosveshchenie. 415~p. EDN: \mbox{QTGWNX}.
\bibitem{7-bos-1}
\Aue{Bityukov, Yu.\,I., and Ya.\,G.~Martyushova.} 2022. \textit{Reshenie zadach 
po teorii funktsiy kompleksnogo peremennogo} [Solving problems in the theory of 
functions of a complex variable]. Moscow: MAI. 87~p.
\bibitem{8-bos-1}
\Aue{Ayvazyan, S.\,A., V.\,M.~Bukhshtaber, I.\,S.~Enyukov, and 
L.\,D.~Meshalkin.} 1989. \textit{Prikladnaya statistika: klas\-si\-fi\-ka\-tsiya 
i~snizhenie razmernosti} [Applied statistics: Classification and dimensionality 
reduction]. Moscow: Finansy i~statistika. 608~p.
\bibitem{11-bos-1} %9
\Aue{Mitchell, T.} 1997. \textit{Machine learning}. New York, NY: McGraw-Hill 
Education. 432~p.
\bibitem{9-bos-1} %10
\Aue{Zhuravlev, Yu.\,I., V.\,V.~Ryazanov, and O.\,V.~Sen'ko.} 2006. 
\textit{Raspoznavanie. Matematicheskie metody. Programmnaya sistema. 
Prakticheskie primeneniya} [Recognition. Mathematical methods. Software 
system. Practical applications].  Moscow: Fazis. 159~p.
\bibitem{10-bos-1} %11
\Aue{Hastie, T., R.~Tibshirani, and J.~Friedman.} 2009. \textit{The elements of 
statistical learning}. 2nd ed. New York, NY: Springer. 745~p. doi: 
10.1007/978-0-387-84858-7.
\bibitem{16-bos-1} %12
\Aue{Goebel, P.\,C., B.\,J.~Palik, L.\,K.~Kirkman, M.\,B.~Drew, L.~West, and 
D.\,C.~Pederson.} 2001. Forest ecosystems of a~Lower Gulf Coastal Plain 
landscape: Multifactor classification and analysis. \textit{J.~Torrey Bot. 
Soc.} 128(1):47--75. doi: 10.2307/3088659.

\bibitem{13-bos-1} %13
\Aue{Shcherbakova, S.\,A.} 2007. \textit{Mezhdunarodnyy turizm: ekonomika 
i~geografiya} [International tourism: Economics and geography]. Moscow: 
Finansy i~statistika. 144~p.
\bibitem{15-bos-1} %14
\Aue{Kuleshkov, I.\,V., V.\,S.~Kolbikov, and K.\,S.~Basniev.} 2010. 
Klassifikatsiya neftegazovykh ekspluatatsionnykh ob''ektov s~otsenkoy stepeni 
slozhnosti vyrabotki zapasov uglevodorodov [Oil and gas production facilities 
classification with complexity of hydrocarbon reserves production assessment]. 
\textit{Tekhnologii nefti i~gaza} [Oil and Gas Technologies] 2(67):29--38. EDN: 
LKYHCP.
\bibitem{14-bos-1} %15
\Aue{Zadorozhneva, Yu.\,V., and A.\,E.~Kalinina}. 2012. Mnogofaktornaya 
otsenka effektivnosti realizatsii sotsial'no-ekonomicheskoy politiki regiona 
[Multifactor assessment of efficiency realization of socio-economic policy of the region]. 
\textit{Sovremennyye problemy nauki i~obrazovaniya} [Modern Problems of 
Science and Education] 4:192--192. EDN: \mbox{PBIRUD}.
\bibitem{12-bos-1} %16
\Aue{Kazarin, O.\,V., R.\,A.~Sharyapov, and V.\,V.~Yashchenko}. 2018. 
Mnogofaktornaya klassifikatsiya ugroz informatsionnoy bezopas\-nosti 
kiberfizicheskikh sistem [Multifactorial classification of threats to information 
security of cyber-physical systems]. \textit{Vestnik RGGU. Ser. Informatika. 
Informatsionnaya bezopasnost'. Matematika} [RGGU Bulletin. Ser. Information 
science. Information security. Mathematics] 1:39--55. EDN: \mbox{FNXARP}.

\bibitem{17-bos-1}
\Aue{Xiong, Y., L.~Wang, Q.~Wang, S.~Liu, and B.~Kou.} 2022. Improved 
convolutional neural network with feature selection for imbalanced ECG  
multi-factor classification. \textit{Measurement} 189:110471. doi: 
10.1016/j.\linebreak measurement.2021.110471.
\bibitem{18-bos-1}
\Aue{Kaftannikov, I.\,L., and A.\,V.~Parasich.} 2016. Problemy formirovaniya 
obuchayushchey vyborki v~zadachakh mashinnogo obucheniya [Problems of 
training set's formation in machine learning tasks]. \textit{Vestnik YuUrGU. Ser. 
Komp'yuternye tekhnologii, upravlenie, radioelektronika} [Bulletin of the South 
Ural State University. Ser. Computer technologies, automatic control, radio 
electronics] 16(3):15--24. doi: 10.14529/ct·sr160302. EDN: \mbox{TZWHTS}.
\bibitem{19-bos-1}
\Aue{Sechidis, K., G.~Tsoumakas, and I.~Vlahavas.} 2011. On the stratification of 
multi-label data. \textit{Machine learning}\linebreak\vspace*{-12pt}

\pagebreak

\noindent
\textit{and knowledge discovery in databases}. 
Eds. D.~Gunopulos, T.~Hofmann, D.~Malerba, and M.~Vazirgiannis. Lecture 
notes in computer science ser. Berlin, Heidelberg: Springer. 6913:145--158. doi: 
10.1007/978-3-642-23808-6\_10.
\bibitem{20-bos-1}
\Aue{Hosmer, D.\,W., S.~Lemeshow, and R.\,X.~Sturdivant.} 2013. \textit{Applied 
logistic regression}. 3rd ed. New York, NY: Wiley. 528~p. doi: 
10.1002/9781118548387.
\bibitem{21-bos-1}
\Aue{Breiman, L.} 2001. Random forests. \textit{Mach. Learn.} 45:5--32. doi: 
10.1023/A:1010933404324.
\bibitem{22-bos-1}
\Aue{Haykin, S.} 2009. \textit{Neural networks and learning machines}. 3rd ed. 
Cranbury, NJ: Pearson Education. 906~p.
\bibitem{23-bos-1}
\Aue{Bogatinovski, J., L.~Todorovski, S.~\mbox{D{\!\ptb{\v{z}}}eroski}, 
and D.~Kocev.} 2022.  
Comprehensive comparative study of multi-label classification methods. 
\textit{Expert Syst. Appl.} 203:117215. 23~p. doi: 10.1016/j.eswa.2022.117215.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received October 15, 2023}} 

%\vspace*{-18pt}

\Contr

\vspace*{-4pt}

\noindent
\textbf{Bosov Alexey V.} (b.\ 1969)~--- Doctor of Science in technology, 
principal scientist, Federal Research Center ``Computer Science and Control'' of 
the Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, Russian 
Federation; \mbox{avbosov@ipiran.ru}

\vspace*{3pt}

\noindent
\textbf{Ivanov Alexey V.} (b.\ 1976)~--- Candidate of Science (PhD) in 
technology, senior scientist, Federal Research Center ``Computer Science and 
Control'' of the Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 
119333, Russian Federation; \mbox{aivanov@ipiran.ru}

\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 