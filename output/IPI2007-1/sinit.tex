\def\Ex{П\enskip р\enskip и\enskip м\enskip е\enskip р\enskip}
\def\eps{\varepsilon}
\def\tr{\,,\,\ldots\,,\,}
\def\rv{\right\vert\,}
\def\rrv{\right\vert}
\def\lv{\,\left\vert}
\def\rk{\,\right]}
\def\lk{\left[\,}
\def\rf{\right\}}
\def\lf{\left\{}
\def\W{\Omega}
\def\w{\omega}
\def\bcup{{\textstyle \bigcup}}
\def\bcap{{\textstyle \bigcap}}
\def\bcp{\mathop \bcup}
\def\eps{\varepsilon}
\def\tr{\,,\,\ldots\,,\,}
\def\la{\lambda}
\def\si{\sigma}
\def\alp{\alpha}
\def\iii{\int\limits}
\def\sss{\sum\limits}
\def\dl{\Delta}

\def\yhxt{(U_t,Y_t, t)}
\def\yxt{( X_t,Y_t, t)}
\def\yutt{(Y_t, U_t,t)}
\def\yxtt{( X_t,Y_t,t)}
\def\hx{U_t}
\def\xthe{(x;\theta)}

\def\stat{sinit}
\def\tit{
РАЗВИТИЕ ТЕОРИИ ФИЛЬТРОВ ПУГАЧЕВА
  ДЛЯ ОПЕРАТИВНОЙ ОБРАБОТКИ ИНФОРМАЦИИ
  В СТОХАСТИЧЕСКИХ СИСТЕМАХ$^{*}$}
\def\titkol{Развитие теории фильтров Пугачева
  для оперативной обработки информации
  в стохастических системах}
\def\autkol{И.\,Н.~Синицын}
\def\aut{И.\,Н.~Синицын$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]{Работа 
выполнена при финансовой поддержке Российского фонда фундаментальных 
исследований (проект 07-07-00031) и программы ОИТВС РАН <<Фундаментальные 
основы информационных технологий и систем>> (проект~1.5).}
\renewcommand{\thefootnote}{\arabic{footnote}}}

\footnotetext[1]{ИПИ РАН, sinitsin@dol.ru}

\index{Синицын И.\,Н.}

\Abst{В современной статистической информатике важное место занимают 
статистические методы оперативной обработки (фильтрации, экстраполяции, 
интерполяции и~т.д.) информации в стохастических системах. Дается аналитический 
обзор работ и рассматриваются основные тенденции развития нелинейных условно 
оптимальных фильтров Пугачева. Рассматриваются фильтры Пугачева для регулярных 
и нерегулярных, непрерывных и дискретных, гауссовских и негауссовских 
стохастических систем, в том числе с автокоррелированными помехами в 
наблюдениях. Устанавливается связь между фильтрами Калмана и Пугачева. 
Обсуждаются фильтры Пугачева по различным вероятностным критериям, а также 
вопросы совместной условно оптимальной фильтрации и распознавания. 
Сформулированы направления дальнейшего развития фильтров Пугачева.}

\KW{стохастическая система; условно оптимальная
фильтрация; экстраполяция и интерполяция; фильтр Пугачева;
оперативная обработки информации; автокоррелированная помеха}

\vskip 24pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}


\label{st\stat}
\section{Введение}

Как отмечается~[1, 2], к концу 1970-х  возник\-ла настоятельна необходимость 
распространения нашедшей широкое применение калмановской тео\-рии линейной 
фильтрации на нелинейные сто\-хасти\-че\-ские системы (СтС). Многочисленные 
попыт\-ки получить решение этой задачи путем линеаризации исходных уравнений 
СтС с различными уточнениями на протяжении 20~лет не привели к 
удовлетворительным результатам, а методы субоптимальной фильтрации часто 
приводили на практике к противоречивым результатам. Владимир Семенович Пугачев 
предложил принципиально новый подход, основанный на идее условно оптимального 
оценивания и применения хорошо разработанной к этому времени теории нелинейных 
дифференциальных СтС. Была разработана тео\-рия условно оптимальной оперативной 
(в реальном  масштабе времени) фильтрации процессов в дифференциальных СтС, и 
дан метод нахождения оптимального по Парето фильтра в классе допустимых 
фильтров, описываемых дифференциальными уравнениями заданного вида. 
Разработанный метод позволяет оценивать не только состояние СтС, но и 
неизвестные параметры в ее уравнениях. Для решения уравнений, определяющих 
неизвестные функции в дифференциальном уравнении условно оптимального фильтра, 
было использовано уравнение для одномерной характеристической функции. В этом 
случае все неизвестные функции определяются заранее в процессе проектирования 
фильтра, а не во время его оперативной работы. Для проектирования фильтра 
используется только априорная информация. При практическом применении тео\-рии  
для получения требуемых оценок необходимо лишь интегрирование дифференциального 
уравнения фильтра в темпе получения текущей (оперативной) информации.

В связи с необходимостью решать задачи статистического анализа
дискретных нелинейных СтС при проектировании условно оптимальных
дискретных фильтров и экстраполяторов потребовалось распространить
хорошо  разработанные методы анализа стохастических
дифференциальных уравнений на системы, описываемые стохастическими
разностными уравнениями. Это было сделано В.\,С.~Пугачевым в~[3].

Итогом многолетних исследований В.\,С.~Пугачева, его учеников и последователей 
в области статистического анализа дифференциальных СтС, а также фильтрации, 
экстраполяции и оценивания па\-ра\-мет\-ров в таких системах является 
монография~[4]. В этом труде дано систематическое изложение теории 
дифференциальных СтС на базе единого подхода с применением уравнения  Пугачева 
для конечномерной характеристической функции. Развита точная теория линейных 
дифференциальных СтС, в частности получены явные формулы для конечномерных 
характеристических функций, а также основные приближенные методы 
статистического анализа нелинейных систем. Изложены методы нормальной 
аппроксимации, моментов, семиинвариантов и методы, основанные на  ортогональных 
разложениях плотностей вероятностей, в частности на разложениях по полиномам 
Эрмита. Выведены основные формулы и уравнения теории оптимальной фильтрации. 
Рассматриваются теория оптимальной линейной фильтрации и методы субоптимальной 
нелинейной фильтрации. Впервые дано полное изложение теории условно оптимальной 
фильтрации, экстраполяции и оценивания па\-ра\-мет\-ров в дифференциальных СтС. 
В эту монографию вошли многие новые научные результаты. Материал иллюстрирован 
большим количеством примеров и задач, многие из которых имеют самостоятельное 
значение.

Библиография  и краткий обзор работ по теории Фильтра Пугачева (ФП), 
выполненных до 1998~г.,  даны в~[1, 2]. Рассмотрим современное состояние и 
развитие тео\-рии~ФП.

\section{Задачи условно оптимального оценивания
в~непрерывных стохастических системах}

Практическое применение субоптимальных методов 
фильтрации ограничивается высоким порядком фильтров, особенно в
задачах большой размерности. Поэтому единственным способом
получения практически реализу\-емых фильтров в задачах большой
размерности является понижение порядка фильтров. Чтобы понять, как
это может быть достигнуто для непрерывных СтС, достаточно
проанализировать структуру уравнения для субоптимальной оценки.
Легко видеть, что все эти методы дают для оценки  вида
$\hat X_t= AU_t$ уравнение 
\begin{equation}
dU_t =\alp_t \xi \yhxt dt + \beta_t\eta \yhxt dY_t +
    \gamma_t dt\,,
\end{equation}
где  $\xi \yhxt$, $\eta\yhxt$~--- некоторые функции текущих
значений наблюдаемого процесса $Y_t$, оценки $\hx$ и времени $t$;
$\alp_t$, $\beta_t$ и  $\gamma_t$~--- некоторые функции времени.
То, что они становятся известными вмес\-те с ковариационной матрицей
ошибки $R_t$ только после интегрирования полной системы уравнений,
определяющей все неизвестные параметры функции $p^*\xthe$,
аппроксимирующей апостериорную плотность $p_t(x)$, для дальнейших
рассуждений не имеет значения. Так, например, в методе нормальной
аппроксимации~[4] $\xi = \lk f^T - f^{(1)T} h^T\rk^T$, $\eta=h$.
Соответственно, коэффициент $\alp$ имеет блочную структуру
$\alp_t=\lk I_{n_x}\,I_{n_x}\rk$, где  $I_{n_x}$~--- единичная
(${n_x}\times {n_x}$)-матрица,  $\beta_t = I_{n_x}$, $\gamma_t=0$. Чтобы
определить функцию $\xi$ в методе ортогональных разложений~[4],
подставим в уравнение для оценки выражения значения функций  $f$, $f^{(1)}$, $h$:
\begin{align*}
f&= f_0 +\sss_{k=3}^N \sss_{\lv\nu\rv=k} f_\nu c_\nu\,,\\
f^{(1)} &= f_0^{(1)} +\sss_{k=3}^N \sss_{\lv\nu\rv=k} f_\nu^{(1)} c_\nu\,,\\
h&= h_0 +\sss_{k=3}^N \sss_{\lv\nu\rv=k} h_\nu c_\nu
\end{align*}
 и перепишем это уравнение в виде
\begin{multline*}
d\hx =\biggl[ f_0 - h_0 f_0^{(1)}  +\sss_{k=3}^N \sss_{\lv\nu\rv=k} \left (
f_\nu - h_0 f_\nu^{(1)} -{}\right.\\
{}-\left. h_\nu f_0^{(1)}\right ) c_\nu - \sss_{k,l=3}^N
\sss_{\substack{\lv\nu\rv=k\\ \lv\mu\rv=l}} h_\nu f_\mu^{(1)}
c_\nu c_\mu\biggr] dt +{}\\
{}+     \left( h_0 +\sss_{k=3}^N \sss_{\lv\nu\rv=k} h_\nu c_\nu\right) dY_t\,.
\end{multline*}
Отсюда видно, что компонентами векторной функции  $\xi$ в этом
случае служат все компоненты  ${n_x}$-мерных векторных функций
$f_0$,  $-h_0 f_0^{(1)}$, $f_\nu$,  $-h_0 f_\nu^{(1)}$, $-h_\nu f_0^{(1)}$,
 $-h_\nu f_\mu^{(1)}$ $(\lv\nu\rv, \lv\mu\rv =
3\tr N)$ и соответственно матрица  $\alp_t$ состоит из
горизонтально расположенных диагональных блоков, первые два из
которых представляют собой единичную матрицу  $I_{n_x}$, а
остальные~--- произведения  $I_{n_x}$ на соответствующие
коэффициенты $c_\nu$ и на произведения  $c_\nu c_\mu$. Если
некоторые компоненты векторых функций $f_0$,  $-h_0 f_0^{(1)}$,
$f_\nu$,  $-h_0 f_\nu^{(1)}$,  $-h_\nu f_0^{(1)}$,  $-h_\nu f_\mu^{(1)}$
не зависят от $\hx$, то линейную комбинацию этих
компонент с соответствующими столбцами матрицы  $\alp_t$ можно
выделить и принять за вектор  $\gamma_t$ в уравнении~(1). Матричная функция
$\eta$ представляет собой блочную матрицу, состоящую из всех
расположенных по вертикали  (${n_x}\times n_y$)-матриц $h_0$,
$h_\nu$ $(\lv\nu\rv = 3\tr N)$, а матрица $\beta_t$ состоит из
горизонтально расположенных блоков, первый из которых представляет
собой единичную матрицу  $I_{n_x}$, а остальные~---   произведения
$I_{n_x}$ на соответствующие коэффициенты  $c_\nu$ $(\lv \nu\rv =
3\tr N)$. Аналогично и применение метода моментов или метода
семиинвариантов~[4] приводит к виду~(1).

Если бы коэффициенты  $\alp_t$, $\beta_t$, $\gamma_t$ в уравнении~(1) были
известными функциями времени, то уравнение~(1) определило бы
фильтр того же  порядка  ${n_x}$, что и уравнение, описывающее
поведение системы. Поэтому естественно возникает мысль попытаться
непосредственно определить коэффициенты $\alp_t$, $\beta_t$,
$\gamma_t$ в уравнении~(1) как функции времени из условия минимума
среднего квадрата ошибки,  ${\rm M}\lv \hat X_t - X_t\rrv^2
=\min$, при всех  $t>t_0$. Это приводит к теории условно
оптимальной фильтрации Пугачева, в которой уравнение фильтра
задается заранее и оптимизируются только коэффициенты этого
уравнения.

Итак, мы приходим к идее решения задачи оценивания путем
нахождения оптимального фильтра в некотором классе допустимых
фильтров, определяемом условием, чтобы поведение фильтра
описывалось дифференциальным уравнением заданного порядка и
заданной формы. Таким образом, мы отказываемся от абсолютной
оптимизации и ограничиваемся условной оптимизацией в заданном
ограниченном классе фильтров.

Определив класс допустимых фильтров, следует решить вопрос о том, какой фильтр 
в этом классе считается оптимальным. Следуя В.\,С.~Пугачеву, будем считать 
оптимальным такой фильтр, который дает в известном смысле наилучшую оценку при 
всех значениях $t>t_0$. Однако в общем случае нелинейной СтС в классе 
допустимых фильтров может не быть такого фильтра, который давал бы наилучшую 
оценку при всех значениях $t>t_0$. В самом деле, такой фильтр был бы 
оптимальным одновременно по множеству критериев. В каждый данный момент $t>t_0$ 
условие  ${\rm M}\lv\hat X_t  - X_t\rrv^2 =\min$ или ${\rm M}\lv\hat X_t  - 
X_{t+\Delta}\rrv^2 =\min$ представляет собой один определенный критерий 
оптимальности. Требование, чтобы это условие выполнялось для некоторого 
множества значений $t$, равносильно требованию оптимальности фильтра 
одновременно по соответствующему множеству критериев. Иными словами, задача 
оптимизации фильтра при всех значениях $t>t_0$ представляет собой задачу 
многокритериальной оптимизации. Такие задачи, как правило, не имеют решения. 
Фильтр Калмана--Бьюси (ФКБ), дающий оптимальную линейную оценку состояния 
линейной системы в каждый момент времени $t>t_0$, пред\-став\-ля\-ет собой 
исключение.

Исходя из приведенных соображений, будем считать оптимальным такой фильтр из 
класса до\-пус\-ти\-мых фильтров, который при  любом совместном распределении 
величин  $Y_t$, $X_t$, $\hx$ в момент $t\ge t_0$ дает наилучшую оценку  $\hat 
X_s$ вектора  $X_s$ или вектора $X_{s+\Delta}$, $\Delta >0$, в бесконечно 
близкий момент $s> t$, $s\to t$, реализующую минимум среднего квадрата ошибки 
${\rm M}\lv \hat X_s - X_s\rrv^2$ или соответственно ${\rm M}\lv \hat X_s - 
X_{s+\Delta}\rrv^2$. Иными словами, будем считать оптимальным такой допустимый 
фильтр, который на каждом бесконечно малом интервале времени совершает 
оптимальный переход из того состояния, в котором он оказался в начале этого 
интервала, в новое состояние. Такой допустимый фильтр будем называть  {\bf  
условно оптимальным\/}. Тогда задачи фильтрации и экстраполяции сведутся к 
нахождению оптимальных значений
 $\alp_t$, $\beta_t$ и  $\gamma_t$ в уравнении~(1) в любой момент
времени $t\ge t_0$, обеспечивающих минимум
среднего квадрата ошибки фильтрации ${\rm M}\lv \hat X_s -
X_s\rrv^2$ или экстраполяции ${\rm M}\lv \hat X_s
-X_{s+\Delta}\rrv^2$, $\Delta
>0$, в бесконечно близкий будущий момент  $s> t$, $s\to t$.

Условно оптимальный фильтр обладает тем свойством, что в данном
классе допустимых фильтров не существует фильтра, который при
данном начальном распределении  $Y_t$, $X_t$ и  $\hx$ в момент
$t_0$ был бы лучше условно оптимального при всех  $t>t_0$. Это
значит, по терминологии теории многокритериальной оптимизации, что
условно оптимальный фильтр представляет собой один из множества
допустимых фильтров, {\bf оптимальный по Парето\/}.

В задаче условно
оптимальной фильтрации возьмем уравнения системы и уравнение
наблюдения в общей форме:
\begin{align}
    dX_t &=\varphi \yxt\, dt +\psi\yxt\, dW\,,\notag\\[-6pt]
&\\[-6pt]
    dY_t &=\varphi_1 \yxt\, dt +\psi_1\yxt\, dW\notag
\end{align}
и будем предполагать, что  $W(t)$ представляет собой процесс с
независимыми приращениями с нулевым математическим ожиданием  и
конечной ковариационной функцией
%\end{multicols}
%\end{document}
\begin{align}
k_w (t_1, t_2) &= k(\min (t_1, t_2))\,,\notag\\[-6pt]
&\\[-6pt]
k(t) &= k(t_0) +\int\limits_{t_0}^t \nu(\tau)\, d\tau\,.\notag
\end{align}

Для задачи экстраполяции необходимо ограничиться случаем, когда
функции  $\varphi$ и $\psi$ не зависят от наблюдаемого вектора
$Y_t$, процесс  $W(t)$ состоит из двух независимых блоков
$W_1(t)$, $W_2(t)$ и соответственно матрицы $\psi$, $\psi_1$ имеют
блочную структуру $\psi =\lk \psi'\,0\rk$, $\psi_1 =\lk
0\,\psi_1'\rk$, так что  $\psi dW =\psi' dW_1$, $\psi_1 dW
=\psi_1' dW_2$. В этом случае, отбрасывая штрихи у функций  $\psi$
и  $\psi_1$, напишем уравнения~(2) в виде:
\begin{align*}
dX_t&=\varphi (X_t,t)\,dt +\psi (X_t,t)\,dW_1,\\
dY_t&=\varphi_1 \yxt\,dt +\psi_1 \yxt\,dW_2,
\end{align*}
где  $W_1(t)$, $W_2(t)$~--- независимые процессы с независимыми
приращениями с нулевыми математическими ожиданиями и конечными
ковариационными функциями вида~(3).

Что же касается точности фильтрации, то следует отметить, что методы 
параметризации распределений дают возможность оценивать по априорным данным 
точность любого фильтра, описываемого конечным числом стохастических 
дифференциальных уравнений, независимо от того, каким методом получен этот 
фильтр. Это позволяет сравнивать по точности методы теории условно оптимальной 
фильтрации с методами субоптимальной фильтрации. Кроме того, принятый в теории 
условно оптимальной фильтрации метод построения классов допустимых фильтров 
позволяет построить класс допустимых фильтров, содержащий любой наперед 
заданный фильтр, описываемый конечным чис\-лом дифференциальных уравнений. 
Оптимальный фильтр этого класса будет, как правило, лучше и уж во всяком случае 
не хуже, чем данный фильтр.

Таким образом, теория условно оптимальной фильтрации Пугачева
обладает двумя несомненными преимуществами по сравнению с методами
субоптимальной фильтрации~[4]. Во-первых, она позволяет получать
фильтры более низкого порядка и, следовательно, более простые в
реализации. Во-вторых, она дает возможность получать фильтры не
меньшей, а при желании и большей точности, чем фильтры, даваемые
методами субоптимальной нелинейной фильтрации~[4].

\section{Основные теоремы условно оптимального
 оценивания\newline для непрерывных стохастических систем}

В~[4] применительно к СтС (2), где  $W(t)$~--- процесс с независимыми
приращениями, получены уравнения условно оптимальной фильтрации и
экстраполяции для различных классов непрерывных СтС.

В частности, для винеровского процесса  $W(t)$, если уравнения~(2)
допускают существования одномерных моментов, тогда входящие
в уравнение ФП~(1) коэффициенты  $\alp_t$,
$\beta_t$, $\gamma_t$ определяются следующими уравнениями:
\begin{equation} %4
A\alp_t m_1 + A\beta_t m_2 + A\gamma_t=m_0\,,
\end{equation}
\vspace*{-12pt}
где\\[-12pt]  %\vspace*{-12pt}        $$
\begin{align*}
m_0 &= {\rm M}\varphi \yxtt\,,\\ %\enskip 
m_1 &= {\rm M}\xi \yutt\,, \\ %$$        $$ 
m_2 &= {\rm M}\eta \yutt \varphi_1\yxtt\,; %$$ 
\end{align*}
\vspace*{-12pt}
    \begin{equation} %5
A\beta_t =\kappa_{02} \kappa_{22}^{-1}\,,
\end{equation}
где\\[-18pt] % \vspace*{-12pt}
\begin{multline*}
\kappa_{02} = {\rm M} (X_t - AU_t) \varphi_1 \yxtt^T \eta\yutt^T+{}\\
        {}+ {\rm M}\psi \yxtt \nu(t) \psi_1 \yxtt^T \eta \yutt^T\,, %\\ [-24pt]
\end{multline*}
\vspace*{-24pt}
\begin{multline*}
\kappa_{22}  = {\rm M}\eta\yutt \psi_1 \yxtt \nu(t)\times {}\\
{}\times\psi_1 \yxtt^T \eta\yutt^T\,; %\\[-24pt]
\end{multline*}
\vspace*{-18pt}
\begin{multline} A\alp_t\kappa_{11} + {\rm M}\left( 
AU_t-X_t\right)\left(\xi^T \alp_t^T +\gamma_t^T\right)
   \fr{\partial \xi^T}{\partial u}={} \\
{}=\kappa_{01}'-A\beta_t\kappa_{21}'\,,%\\[-24pt]
\end{multline}
где\\[-12pt]
\begin{align*}
\kappa_{01} &= {\rm M}\lk \varphi \yxtt - m_0\rk \xi \yutt^T\,,\\
 \kappa_{11} &= {\rm M}\lk \xi \yutt - m_1\rk \xi \yutt^T\,,\\
    \kappa_{21}' &= {\rm M} \lk \eta\yutt)\varphi_1-m_2\rk \xi\yutt^T\, , %\\[-24pt]
\end{align*}
\vspace*{-24pt}
\begin{multline*}
\kappa_{01}' =\kappa_{01} + {\rm M} (X_t-AU_t)  \frac{\partial \xi^T}{\partial 
t} +
     {\rm M}\bigl\{ (X_t-AU_t) \varphi_1^T +{}\\
{}+\psi\nu\psi_1^T - A\beta_t\eta\psi_1\nu\psi_1^T\bigr\} \left(
    \frac{\partial}{\partial y}+\eta^T\beta_t^T \frac{\partial}{\partial u}\right)\xi^T+{}\\
    {}+\frac{1}{2} {\rm M}(X_t-AU_t) \biggl\{ {\rm tr} \biggl[ \psi_1\nu\psi_1^T
    \left( \frac{\partial}{\partial y}+{} \right.\\
\left.    {}+2 \eta^T\beta_t^T \frac{\partial}{\partial u}\right)
    \frac{\partial^T}{\partial y}\biggr]+{}\\
{}+    {\rm tr}\left[ \beta_t\eta\psi_1\nu\psi_1^T\eta^T\beta_t^T 
\frac{\partial}{\partial u}
    \frac{\partial^T}{\partial u}\right]\biggr\} \xi^T dt\,.
\end{multline*}

Для вычисления математических ожиданий в $m_0$, $m_1$, $m_2$,
$\kappa_{02}$, $\kappa_{22}$, $\kappa_{11}$, $\kappa_{21}$,
$\kappa_{01}$, $\kappa_{01}'$, $\kappa_{21}'$ в общем случае
необходимо
 знать совместное распределение векторов  $Y_t$, $X_t$, $U_t$ при
 любом  $t\ge t_0$, т.е.\ одномерное распределение составного
 случайного процесса  $Z_t = \lk Y_t^T X_t^T U_t^T\rk^T$. Это
 распределение определяется уравнением Пугачева для характеристической функции, соответствующем
 системе стохастических дифференциальных уравнений~(1) и~(2):
 \begin{multline}
\fr{\partial g_1 (\la_1,\la_2,\la_3;t)}{\partial t}
= {\rm M}\bigl\{ i\la_1^T \varphi_1 + i\la_2^T \varphi+{}\\
{}+i\la_3^T\bigl[ \alp\xi \yutt+\beta_t\eta\yutt \varphi_1 +\gamma_t\bigr]+{}\\
    {}+\chi (\psi_1^T \la_1 +\psi^T\la_2+{}\\
    {}+\psi_1^T\eta \yutt^T\beta_t^T \la_3;t)\bigr\} \exp \bigl\{ i\la_1^T Y_t+{}\\
    {}+i\la_2^T X_t + i\la_3^T U_t\bigr\}\,.
\end{multline}
К этому уравнению следует добавить начальное условие
 $$g_1 (\la_1,\la_2,\la_3;t_0)=g_0
 (\la_1,\la_2,\la_3)\,,$$
где $g_0 (\la_1,\la_2,\la_3)$~--- совместная характеристическая
функция начальных значений  $Y_0 = Y(t_0)$, $X_0 = X(t_0)$,
$U_0=U(t_0)$  процессов  $Y_t$, $X_t$, $U_t$.
Разумеется, начальное распределение определяемого уравнением~(2)
процесса $U_t$ не может быть известным. Поэтому его неизбежно надо
задавать более или менее произвольно. Единственное требование,
которому следует подчинить это распределение, состоит в том, чтобы
в начальный момент $t=t_0$ удовлетворялись условие несмещенности
оценки и условие ${\rm M} (\hat X_t - X_t)\xi_t^T=0$. Только в
этом случае фильтр, определяемый формулой  $\hat X_t = AU_t$ и
уравнением~(1) будет условно оптимальным.

 Уравнение~(7) можно решить
совместно с уравнениями~(4)--(6) любым приближенным методом~[4]. При этом,
взяв достаточно большое $N$, можно найти решение с любой степенью
точности. Вычисления, необходимые для определения коэффициентов
$\alp_t$, $\beta_t$, $\gamma_t$ в уравнении~(1) условно
оптимального фильтра и совместного распределения  $Y_t$, $X_t$,
$U_t$ при любом  $t\ge t_0$, конечно, очень сложны, особенно в
многомерных задачах. Однако эти вычисления используют только
априорные данные и не опираются на результаты наблюдений, поэтому
их надо выполнять для каждой конкретной задачи (или класса задач)
только один раз при синтезе фильтра (алгоритма фильтрации).
Практическое применение фильтра при каждом конкретном эксперименте
требует только решения уравнения~(1) при известных функциях
времени $\alp_t$, $\beta_t$, $\gamma_t$.

Для рассматриваемого фильтра формула для производной
ковариационной матрицы ошибки принимает вид:
\begin{multline*}
\dot R_t = {\rm M}[( X_t -\hat X_t) \varphi \yxtt^T +{}\\
{}+\varphi\yxtt (X_t^T -\hat X_t^T)-{}\\
{}-A\beta_t \eta \yutt \psi_1 \yxtt \nu(t)\times{}\\
{}\times \psi_1\yxtt^T \eta \yutt^T \beta_t^T A^T+{}\\
{}+\psi \yxtt \nu(t) \psi \yxtt^T]\,.
\end{multline*}

В~[5--7] основные теоремы условно оптимального оценивания обобщены
на случай непрерывных СтС с винеровскими и пуассоновскими шумами:
\begin{align*}
dX_t &=\varphi(X_t, Y_t, t) dt +\psi'(X_t, Y_t, t)d W_0+{}\\
&\ \ \ \ \ \ \ \ \ \ \ \ \ \ {}+ \int\limits_{R_0^q}
\psi'' (X_t, Y_t, t,v) P^0 (dt, dv)\,,\\
dY_t &=\varphi_1(X_t, Y_t, t) dt +\psi_1'(X_t, Y_t, t)d W_0+{}\\
&\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ {}+ \int\limits_{R_0^q} \psi_1'' (X_t, Y_t, t,v) P^0 (dt, dv)\,.
\end{align*}
Здесь $W_0 = W_0(t)$~--- винеровский процесс, а $P^0 (dt, dv)$~---
центрированная пуассоновская мера.

Среди новых результатов общей теории условно оптимального
оценивания следует выделить следующие:
\begin{itemize}
\item оптимальную в среднеквадратическом теорию оценивания при автокоррелированных
помехах в наблюдениях~[4, 5, 7--9];
\item
 теорию оценивания по различным вероятностным критериям~[7, 10--13].
\item
теорию совместного оценивания и распознавания  [4, 7, 14--16].
\end{itemize}

\section{Фильтры Калмана--Бьюси\newline и линейные
фильтры Пугачева}

 Как известно~[4, 7], для линейной негауссовской
дифференциальной СтС
\begin{align}
    dX_t &=( aY_t +a_{1}X_t+a_{0}) dt+ \psi dW\,,\notag\\[-6pt]
&\\[-6pt]
    dY_t &=( bY_t +b_{1}X_t+b_{0}) dt+ \psi_1 dW\,,\notag
\end{align}
где  $a,a_{1}$, $b, b_1$, $\psi, \psi_1$~--- функции  времени $t$, не
зависящие от $X_t =\lk X_1\ldots X_{n_x}\rk^T$,  $Y_t=\lk
Y_1\ldots Y_{n_y}\rk^T$.

Линейный ФП определяется уравнением:
\begin{multline*}
d\hat X_t =(a Y_t +a_{1}\hat X_t + a_{0}) dt +{}\\
{}+\beta_t \lk dY_t - (b Y_t + b_{1}\hat X_t+ b_{0}) dt\rk\,.
\end{multline*}

Для определения  $\beta_t$ необходимо найти математическое
ожидание $m_t$ и ковариационную матрицу  $K_t$ случайного вектора
$Q_t=$\linebreak $=[ Y_1\ldots Y_{n_y} X_1\ldots \hat X_{n_x}]^T$,
ковариационную матрицу $R_t$ ошибки  $\tilde X _t=\hat X_t
-X_t$. Эти уравнения в нашем случае имеют вид:
\begin{align*}
\dot m_t &= \bar a m_t+\bar a_0\,,\\
    \dot K_t &= \bar a K_t + K_t\bar a^T + \bar c_0\nu \overline{c}_0^{T}\,,
\end{align*}
где\\[-12pt]
\begin{equation*}
\bar a=\begin{bmatrix}
b&b_{1}\\
a&a_{1}
\end{bmatrix},\quad
\bar a_0=
    \begin{bmatrix}
b_{0} \\
a_{0}
\end{bmatrix},\quad
\overline{c}_0=
\begin{bmatrix}
\psi_1\\
\psi
\end{bmatrix}\,.
%\eqno(14)
\end{equation*}
Уравнение для матрицы  $R_t$ имеет вид:
\begin{multline*}
\dot R_t = a_{1} R_t + R_t a_{1}^T +\psi\nu\psi^T-{}\\
{}-\lk R_t b_{1}^T+ \psi \nu
    \psi_1^T\rk \kappa_{22}^{-1} \lk
    b_{1}R_t + \psi_1 \nu \psi^T \rk\,,
\end{multline*}
При этом коэффициент  $\beta_t$ равен:
\begin{equation*}
\beta_t =\lk R_t b_1^T +\psi \nu\psi_1^T\rk \kappa_{22}^{-1}\,,
\end{equation*}
где $\kappa_{22} = \psi_1\nu\psi_1^T$.
%\eqno(16)

Для уравнения~(8) при  $a=b=0$ при негауссовском белом шуме
 интенсивности  $\nu$ линейный ФП (ЛФП) при $N=n_x$
 имеет вид ФКБ~[4, 7].

В случае независимых негауссовских шумов c интенсивностями $\nu_1$
и $\nu_2$ ЛФП совпадает с ФКБ для
независимых шумов с интенсивностями $\nu_1$ и $\nu_2$.

Таким образом, ЛФП обладает следующими особенностями по
сравнению в ФКБ:
\begin{itemize}
\item линейный ФП в отличие от ФКБ справедлив для
дифференциальных СтС~(8), содержащих одновременно и переменные
состояния $X_t$, и наблюдения  $Y_t$, при этом белые шумы могут
быть негауссовскими;
\item
при  $N=n_x$ для гауссовских шумов в~(8) не
зависящих от  $Y_t$ $(a=b=0)$, ЛФП совпадает с ФКБ. При этом
порядок уравнений для синтеза фильтра составляет
$Q_{\mbox{ФКБ}} = n_x (n_x + 3)/2$;
\item
при одинаковой точности (более простых в
реализации) порядок ЛФП может быть меньше $Q_{\mbox{ФКБ}}$.
\end{itemize}

В~[4, 7] содержатся новые результаты по теории линейного условно
оптимального оценивания в случае автокоррелированной помехи в
наблюдениях, а также совместного условно оптимального оценивания и
распознавания. Получены необходимые и достаточные условия
глобальной устойчивости ЛФП.

Наконец, упомянутые результаты удалось распространить на линейные
дифференциальные СтС~(8) с параметрическими шумами, когда
коэффициенты при $dW$ имеют следующий вид:
\begin{align*}
    \psi &= c_{10} +\sum\limits_{r=1}^{n_y} c_{1,r} Y_r
    +\sum\limits_{r=1}^{n_x} c_{1, n_y +r} X_r\,,\\
    \psi_1 &= c_{20} +\sum\limits_{r=1}^{n_y} c_{12,r} Y_r
    +\sum\limits_{r=1}^{n_x} c_{12, n_y +r} X_r\,,
\end{align*}
а также на случай автокоррелированной помехи в наблюдениях.

\section{Особенности условно оптимального
 оценивания\newline для дискретных\newline стохастических систем}

Те же рассуждения, которые привели нас в разд.~2 к классам
допустимых фильтров, описы\-ва\-емых дифференциальными уравнениями,
подсказывают мысль использовать дискретные фильтры, описываемые
разностными уравнениями, и дискретные наблюдения в задачах
оценивания. Для решения этих задач в реальном масштабе времени
рассмотрим принцип дискретного условно оптимального оценивания
Пугачева. Этот принцип состоит в отказе от абсолютной
оптимальности и ограничении оптимальными оценками для некоторых
узких классов допустимых оценок, удовлетворяющих некоторым
простым в реализации разностным уравнениям, которые могут быть
вычислены на основе результатов наблюдений в масштабе реального
времени. Главная трудность при синтезе условно оптимальных
фильтров состоит в выборе класса допустимых фильтров. Обычно в
практических задачах за класс допустимых дискретных условно
оптимальных фильтров принимают множество фильтров, описываемых
конечномерными разностными уравнениями с некоторыми неизвестными
коэффициентами. В этом случае проблема оптимизации сводится к
определению оптимальных значений всех неизвестных коэффициентов,
которые в общем случае зависят от времени.

Первой особенностью нелинейного условно оптимального оценивания
служит то обстоятельство, что такое оценивание является
многокритериальным, поскольку требуется минимизация  ${\rm M} \lv
\hat X_k - X_k\rrv^2$ для любого момента времени $k$ из некоторого
интервала.

Второй особенностью нелинейного условно оптимального оценивания
является то, что оптимальные коэффициенты фильтров должны
определяться в ходе проектирования фильтра только априорными
данными без использования текущих наблюдений, как это имеет место
в фильтрах Калмана. Данные текущих наблюдений используются только
в процессе фильтрации при рекуррентном решении уравнений фильтра.

Поставим задачу найти условно оптимальную оценку $\hat X_k$ для
любого момента времени $k$ случайных величин $\hat X_k$, используя
наблюдения случайных величин $Y_1^k = \lf Y_1\tr Y_k\rf$ в классе
допустимых фильтров.

 Рассмотрим сначала нелинейную регрессионную дискретную СтС:
    \begin{align}
    X_{k+1} &= \w_k (X_k,Y_k,  V_k)\,,\notag\\[-6pt]
&\\[-8pt]
    Y_k &=\w_{1k} (X_k, Y_k,  V_k) \quad (k=1,2,\ldots)\,.\notag
\end{align}
 Определим класс
допустимых фильтров формулой
\begin{equation}
\hat X_k = AU_k
\end{equation}
 и разностным уравнением
 \begin{equation}
U_{k+1} = \delta_k\zeta_k (Y_k, U_k) +\gamma_k\,.
\end{equation}
Здесь $A$~--- некоторая постоянная  $(n_x\times N)$-матрица, $N\ge
n_x$, ранга  $n_x$; $\zeta_k$~--- некоторые известные, так
называемые структурные функции (в общем случае векторные
функции размерности $q$); $\delta_k$~--- произвольные  $(N\times
q)$-матрицы коэффициентов фильтров; а  $\gamma_k$~--- произвольные
$(N\times 1)$-матрицы столбцы смещений нуля. Каждому выбору
значений  $\delta_k, \gamma_k$ соответствует определенный
допустимый фильтр, а все возможные значения $\delta_k$, $\gamma_k$
определяют класс допустимых фильтров для данных функций $\zeta_k$.
Различные последовательности функций $\lf \zeta_k\rf$ определяют
различные классы допустимых фильтров. Каждому выбору $\lf
\zeta_k\rf$ соответствует определенный класс допустимых фильтров.

Последовательность функций $\lf \zeta_k\rf$ в~(11) может быть в
принципе произвольной. Но точность фильтрации зависит от выбора
$\lf \zeta_k\rf$. Таким образом, встает вопрос о рациональном
выборе $\lf \zeta_k\rf$.  Априори можно только сказать, что чем
больше размерность структурных векторных функций $\zeta_k$, тем
выше может быть точность фильтрации.

Следуя В.\,С.~Пугачеву, примем за оптимальный такой допустимый фильтр, который 
минимизирует средний квадрат ошибки  ${\rm M}\bigl\vert \hat X_{k+1} - 
X_{k+1}\bigr\vert^2$ на каж\-дом шаге (при каж\-дом $k$) путем выбора 
$\delta_k$, $\gamma_k$ в~(11) при данных значениях $\delta_h$, $\gamma_h$, 
$h\le k$, найденных в результате предыду\-щих шагов. Такой фильтр называется 
\textbf{дискретным условно оптимальным фильтром} или \textbf{дискретным ФП}. 
Значения $\delta_k$ и $\gamma_k$ в~(11), со\-от\-вет\-ст\-ву\-ющие условно 
оптимальному фильтру, принимаются за оптимальные значения $\delta_k$, 
$\gamma_k$.

Уравнение~(11) показывает, каким образом допустимый фильтр использует в каждый 
момент времени  $(k+1)$ информацию, содержащуюся в предыду\-щих результатах 
наблюдений  $Y_1 \tr Y_{k}$. А именно, эта информация используется только через 
$U_k$. И только текущий результат наблюдения  $Y_k$ используется 
непосредственно при формировании оценки  $\hat X_{k+1}$ в момент времени  $k$. 
Таково условие, при котором  ${\rm M}\lv \hat X_{k+1}- X_{k+1}\rrv^2$ 
минимизируется в каждый момент времени $(k+1)$ условно оптимальным фильтром.

Таким образом, задача синтеза ФП сводится к
нахождению оптимальных последовательностей $\lf \delta_k\rf $ и
$\lf\gamma_k\rf$ в~(11).

Как показано в~[3, 7], при условии существования одномерных
моментов в основе теории условно оптимального оценивания, согласно~(10),
(11) для СтС~(9) лежат следующие рекуррентные уравнения:
\begin{align}
A\gamma_k &= m_{k+1} - A \delta_k \rho_k\,,\notag\\
A\delta_k &= D_k B_k^{-1}\,,\notag\\
 m_{k+1}&= {\rm M} \w_k (X_k, V_k)\,,\notag\\
 \rho_k &= {\rm M} \zeta_k (\w_{1k} (X_k, V_k) , U_k)\,,\notag %\\
 \end{align}
\begin{align}
        B_k &= {\rm M} [ \zeta_k (\w_{1k} (X_k, V_k), U_k) -{}\notag\\
&\hspace*{10mm}  {}- \rho_k ] \zeta_k (\w_{1k} (X_k, V_k),U_k)^T\,,\notag \\
D_k &=\mathrm{M} \left[ \w_k (X_k, V_k) - m_{k+1}\right ]\times{}\notag\\
&\hspace*{10mm}  {}\times \zeta_k (\w_{1k} (X_k, V_k), U_k)^T\,,\notag \\
     g_{1,k+1} (\la,\mu) &= {\rm M} \exp\lf i \la^T \w_k (X_k, V_k) +{}\right.\notag\\
&\!\!\!\!\!\!\!\!\!\!\!\!\!\left. {}+ i\mu^T \lk \delta_k
     \zeta_k( \w_{1k} (X_k, V_k), U_k) + \gamma_k\rk\rf\,.
\end{align}
Начальным условием для рекуррентного уравнения~(12) служит
начальное значение характеристической функции
 $$g_{1,1} (\la, \mu) ={\rm M} \exp \lf i\la^T X_1 + i\mu^T U_1\rf,$$
вычисляемое для начальных значений $X_1$ и $U_1$.

Для нелинейной авторегрессионной дискретной СтС вида:
    \begin{align}
\!\!\!\!X_{k+1} &= \varphi_k (X_k,Y_k ) +\psi_k (X_k,Y_k ) V_k\,,\notag\\[-6pt]
     &\\ %[-6pt]
\!\!\!\!Y_k &=\varphi_{1k}(X_k,Y_k ) +\psi_{1k} (Y_k) V_k \quad
    (k=1,2,\ldots)\notag
        \end{align}
уравнения условно оптимального фильтра имеют вид:
\begin{align*}
\hat X_{k+1} &= \alp_k \xi_k (\hat X_k) + \beta_k\eta_k(\hat X_k) Y_k +\gamma_k 
\,,\\
\alp_k \kappa_{11}^{(k)}+\beta_k \kappa_{21}^{(k)}&=\kappa_{01}^{(k)}\,,\\
\alp_k \kappa_{12}^{(k)}+\beta_k \kappa_{22}^{(k)}&=\kappa_{02}^{(k)}\,,\\
\gamma_k &=\rho_{0}^{(k)}-\alp_k \rho_{1}^{(k)}-\beta_k\rho_{2}^{(k)}\,,
\end{align*}
где
\begin{align*}
\rho_k &=\lk \rho_1^{(k)T}\rho_2^{(k)T}\rk^T\,,\\
\rho_1^{(k)} & = \mathrm{M} \xi_k (\hat X_k)\,,\quad
\rho_2^{(k)}=\mathrm{M} \eta_k (\hat X_k) \varphi_{1k} (X_k)\,,\\
\kappa_{01}^{(k)} &={\rm M} \lk \varphi_k (X_k) - m_{k+1}\rk \xi_k (\hat X_k)^T\,,\\
\kappa_{02}^{(k)} &= {\rm M} \lk \varphi_{k} (X_k) - m_{k+1}\rk \varphi_{1k} (X_k)^T \eta_k (\hat X_k)^T+{}\\
&\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ {}+ {\rm M} \psi_k (X_k) \nu_k \psi_{1k} (X_k)^T \eta_k (\hat X_k)^T\,;\\
m_{k+1}&=\rho_0^{(k)},\quad \rho_0^{(k)}= {\rm M} \varphi_k (X_k)\,,\\
B_k &=\begin{bmatrix}
\kappa_{11}^{(k)}&\kappa_{12}^{(k)}\\
\kappa_{21}^{(k)}&\kappa_{22}^{(k)}
\end{bmatrix}\,,
\quad \det \lv B_k\rv \ne 0\,,\\
\kappa_{11}^{(k)} &={\rm M} \left [ \xi_k (\hat X_k) -\rho_1^{(k)}\right ] \xi_k (\hat X_k)^T\,,\\
\kappa_{12}^{(k)} &=\kappa_{21}^{(k)T}={\rm M} \left [ \xi_k (\hat X_k) -{}\right.\\
&\ \ \ \ \ \ \ \ \ \ \ \ \ {} - \left. \rho_1^{(k)}\right ] \varphi_{1k} 
(X_k)^T \eta_k
(\hat X_k)^T\,,\\
\kappa_{22}^{(k)} &= {\rm M} \left [ \eta_k (\hat X_k) \varphi_{1k} (X_k)-{}\right.\\
&\ \ \ \ \ \ \ \ \ \ \ \ \ \ {}-\left. \rho_2^{(k)}\right ] \varphi_{1k} 
(X_k)^T
\eta_k(\hat X_k)^T+{}\\
& \ \ \ \ \ \ \ {}+ {\rm M} \eta_k (\hat X_k) \psi_{1k} (X_k) \nu_k \psi_{1k} (X_k)^T \eta_k(\hat X_k)^T\,, %\\[-24pt]
\end{align*}
\begin{multline*}
g_{1,k+1} (\la,\mu) = {\rm M} h_k \bigl( \psi_k (X_k)^T \la +{}\\
{}+ \psi_{1k} (X_k)^T \eta_k (\hat X_k)
\beta_k^T\mu \bigr) \exp \bigl\{ i\la^T \varphi_k (X_k) +{}\\
{}+ i\mu^T [ \alp_k \xi_k (\hat X_k)+ \beta_k\eta_k (\hat X_k) \varphi_{1k} 
(X_k) +\gamma_k]\bigr\}\,,
\end{multline*}
где $h_k$ --- характеристическая функция $V_k$.

Следует обратить внимание, что в своих работах В.\,С.~Пугачев трактовал 
дискретный фильтр Калмана не так, как это принято большинством авторов. Он 
принимал
 за
дискретный фильтр Калмана обычный {\bf одношаговый линейный предсказатель\/} и 
так же построил изложенную выше нелинейную {\bf дискретную\/} условно 
оптимальную фильтрацию. В западной литературе делают различие между алгоритмами 
фильтрации и одношаговыми предсказателями~[7]. А В.\,С.~Пугачев отождествлял 
их. Это просто разная трактовка термина {\bf фильтрация\/}. Владимир Семенович 
Пугачев понимал под \textbf{дискретной фильтрацией} то, что невозможно в один и 
тот же момент времени $k$ одновременно и получать наблюдение, и тут же 
(мгновенно в этот же момент времени) оценивать состояние. Поэтому, например, 
структуру линейного дискретного фильтра он записывал в сле\-ду\-ющей форме:
 \begin{equation} %14
X_{k+1} =\alp_k X_k +\beta_k Y_k +\gamma_k
\end{equation}
и таким образом получался либо ФП, либо <<одношаговый
предсказатель>>:
 \begin{equation*}
  (X_k,Y_k) \xrightarrow[\mathrm{прогноз}]{\ } X_{k+1}\,,
\end{equation*}
который В.\,С.~Пугачев называл {\bf дискретным фильтром Калмана\/}~[3]. В 
западной литературе
 (и Калман сам) записывают дискретную версию фильтра Калмана <<по определению>>, когда в один и тот
 же момент времени $k$ мы и получаем наблюдение, и тут же (мгновенно) производим оценку состояния.
 Тогда уравнение для оценки запишется в сле\-ду\-ющем виде:
 \begin{equation} %15
X_{k+1} =\bar\alp_k X_k +\bar\beta_k Y_{k+1} +\bar\gamma_k\,.
\end{equation}
Вследствие разницы форм~(14) и~(15) получаются разные уравнения
для коэффициентов усиления фильтров $\alp_k, \beta_k, \gamma_k$.

Наиболее полное изложение современной теории дискретных ЛФП
для линейных дискретных СтС, в том числе с
па\-ра\-мет\-ри\-че\-ски\-ми, гауссовскими и негауссовскими шумами, а также в
случае дискретной автокоррелированной помехи в наблюдениях
содержится в~[3, 4, 7]. Теория условно оптимальной интерполяции
для СтС~(9) и~(13) разработана в~[7, 17, 18]. Вопросы дискретной
теории условно оптимального оценивания по различным вероятностным
критериям, теории совместного дискретного условно оптимального
оценивания, идентификации и распознавания обсуждаются в~[4, 7, 19--27].

\section{Заключение}

В настоящее время теория условно оптимальных линейных и нелинейных ФП для 
конечномерных непрерывных и дискретных СтС получила широкое применение для 
оперативной обработки инфор\-ма\-ции в информационных и 
ин\-фор\-ма\-ци\-он\-но-управ\-ля\-ющих системах морской, 
авиа\-ци\-он\-но-кос\-ми\-че\-ской, медицинской и другой техники. Создание 
программных средств (ПС), реализующих ФП, представляет собой нетривиальную 
задачу. Сложность задачи для нелинейных СтС заключается в том, что ПС должны 
автоматически по исходным нелинейным уравнениям СтС составлять и решать систему 
уравнений высокого порядка для определения неизвестных параметров 
распределения, а также вычислять коэффициенты ФП. Известные ПС в основном 
представляют собой отдельные программы, предназначенные для решения конкретных 
задач. Проблема разработки информационной технологии  и базового 
про\-грам\-мно\-го обеспечения впервые была поставлена и решена в ИПИ РАН. 
Вопросам создания и применения ПС для ФП посвящена обширная литература (см., 
например, [4, 7, 28--41]).

Среди направлений дальнейшего развития ФП можно выделить
следующие:
\begin{itemize}
\item совершенствование методического обеспечения синтеза ФП на базе
использования эффективных методов параметризации распределений
(эллипсоидальных фильтров~[4, 7, 40, 41], модифицированных методов
параметризации ненормированных распределений~[7], квазилинейных
методов [4, 7, 42] и~др.), а также непараметрических методов~[43, 44];
\item развитие алгоритмического обеспечения с учетом архитектурных
особенностей ис\-поль\-зу\-емых средств вычислительной техники~[45--47];
\item
создание новых комплексных информационных технологий для
анализа и синтеза ФП для СтС, в том числе в бесконечных
пространствах для контроля и мониторинга, управления
функционированием и обеспечения безопасности~[7, 48--62].
\end{itemize}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{99}
\bibitem{1sin}
\Au{Доступов~Б.\,Г., Емельянов~С.\,В., Казаков~И.\,Е., Кибзун~А.\,И.,
Кузнецов~Н.\,А., Мизин~И.\,А., Синицына~И.\,В., Синицын~И.\,Н., Синицын~В.\,И.}
Обзор научных трудов академика В.\,С.~Пугачева~// Автоматика
и телемеханика, 1998. №\,11. С.~8--20.

\bibitem{2sin}
\Au{Синицын~И.\,Н., Синицын~В.\,И., Соколов~И.\,А.}
О работах академика В.\,С.~Пугачева в области математических методов информатики~//
В кн. <<Системы средства информатики>>. Спец. вып.
<<Математические методы информатики>>. М.: Наука, Физматлит,
2001. С.~5--15.

\bibitem{3sin}
\Au{Пугачев~В.\,С.}
Теория вероятностей и математическая
статистика. Учеб. пособие. М.: Наука, 1-е изд. 1979; 2-е изд. 2002.

\bibitem{4sin}
\Au{Пугачев~В.\,С., Синицын~И.\,Н.}
Стохастические дифференциальные системы. Анализ и фильтрация.
М.: Наука, 1-е изд. 1985; 2-е изд. 1990.
[Англ. пер.:  Stochastic differential
systems. Analysis and  filtering.  Chichester, New York: John
Wiley, 1987.]

\bibitem{5sin}
\Au{Пугачев~В.\,С., Синицын~И.\,Н.}
Стохастические сис\-те\-мы. Теория
и программное обеспечение. Юбилейный сборник трудов институтов
Отделения информатики, вычислительной техники и автоматизации РАН.
М.: Изд. ОИТВС РАН, 1993. Т.~1. С.~75--93.

\bibitem{6sin}
\Au{Пугачев~В.\,С., Синицын~И.\,Н.}
 Прикладные методы анализа стохастических систем.
М.: Изд-во ОИТВС РАН. Вестник МАИ,
1994. №\,1. С.~39--47.

\bibitem{7sin}
\Au{Синицын~И.\,Н.}
Фильтры Калмана и Пугачева. М.: Изд-во Логос, 2006.

\bibitem{8sin}
\Au{Sinitsyn~I.\,N.}
Ill problems of on-line
conditionally optimal filtering~// Ill-Posed Problems in
Natural Sciences: Proceedings of the International Conference.
Moscow, August, 19--25, 1991. %Eds.\ F.\,N.~Tilhonov \textit{et al}.  
Utrecht: VSP. Moscow: TVP Sci.\ Publ. P.~174--183.

\bibitem{9sin}
\Au{Синицын~И.\,Н., Синицын~В.\,И., Корепанов~Э.\,Р., Белоусов~В.\,В.}
Современное методическое и программное обеспечение анализа качества и 
моделирования стохастических сис\-тем управления~// В кн. Труды III 
международной конференции <<Идентификация сис\-тем и задачи управления>> 
(SICPRO'04), 2004. CD-ROM. C.~17--43.


\bibitem{10sin}
\Au{Синицын~И.\,Н., Шин~В.\,И.}
Условно оптимальная фильтрация
процессов в стохастических дифференциальных системах по сложным
статистическим критериям~// Докл. АН СССР, 1991. Т.~320. №\,4.
С.~813--817.

\bibitem{11sin}
\Au{Синицын~И.\,Н., Мощук~Н.\,К., Шин~В.\,И.} Условно оптимальная фильтрация в 
стохастических дифференциальных системах по бейесовым критериям~// Докл.\ РАН, 
1993. Т.~330. №\,4. С.~436--439.

\bibitem{12sin}
\Au{Синицын~И.\,Н., Шин~В.\,И., Корепанов~Э.\,Р.}
Теория условно оптимальной фильтрации стохастических процессов по сложным
статистическим критериям~// В кн. <<Системы и средства
информатики>>. Вып.~5. М.: Наука, 1993.  С.~106--120.

\bibitem{13sin}
\Au{Sinitsyn~I.\,N., Korepanov~E.\,R., Shin~V.\,I.}
Methods, algorithms and
software tools for CAE of stochastic control systems~//
 EUROSIM'98 Congress Proceedings. Helsinki University of
Technology, Espoo, Finland. April 14--15, 1998. P.~200--205.

\bibitem{14sin}
\Au{Синицын~И.\,Н., Корепанов~Э.\,Р.}
Теория и программное обеспечение
условно оптимальной фильтрации и распознавания сигналов в
стохастических системах~// Тез. докл. 2-й Всероссийской конференции
<<Распознавание образов  и анализ изображений: новые информационные
технологии>> (РОАИ-2-95). Ульяновск, 1995. Часть~2. С.~8--9.

\bibitem{15sin}
\Au{Синицын~И.\,Н.}
 Условно оптимальная фильтрация и распознавание
сигналов в стохастических дифференциальных системах~//
Автоматика и телемеханика, 1997. №\,3. С.~124--130.

\bibitem{16sin}
\Au{Синицын~И.\,Н., Шин~В.\,И.}
Распознавание процессов,
определяемых стохастическими дифференциальными уравнениями~//
Докл.\ РАН, 1998. Т.~359. №\,2. С.~1--5.

\bibitem{17sin}
\Au{Синицын~И.\,Н., Шин~В.\,И.}
Условно оптимальная интерполяция
случайных последовательностей, определяемых разностными
уравнениями~// Докл.\ РАН, 1994. Т.~336. №\,4. С.~453--456.

\bibitem{18sin}
\Au{Синицын~И.\,Н., Шин~В.\,И., О~M.}
Условно оптимальная интерполяция случайных
процессов с фиксированной точкой в стохастических дифференциальных
сис\-те\-мах~//
Автоматика и телемеханика, 1997. №\,2. С.~224--233.

\bibitem{19sin}
\Au{Shin~V.\,I.}
Statistical analysis and suboptimal
filtering of random processes in nonlinear stochastic systems~//
 Workshop (International) on Advanced Electronics Technology-95. Moscow,
Russia,  1995. P.~11--15.

\bibitem{20sin}
\Au{Shin~V.\,I.}
Statistical analysis and filtering
of processes in nonlinear stochastic systems. Seoul, Korea: The Korean
Mathematical Society,  1995. Vol.~32. No.\,1. Р.~4--8.

\bibitem{21sin}
\Au{Lee~Y., Cho~Y., Oh~M., Shin~V.\,I.}
Iterated conditionally optimal filters~//
Automation and Remote Control,  1997. Vol.~58. No.\,6.
P.~961--968.

\bibitem{22sin}
\Au{Менхо~О., Чангхи~Хан, Синицын~И.\,Н., Шин~В.\,И.}
Рекуррентная фильтрация в дискретных нелинейных системах с неизвестными
параметрами~// Автоматика и телемеханика, 1998. №\,1. С.~44--63.

\bibitem{23sin}
\Au{Oh~M., Shin~V.\,I., Lee~Y., Choi~U.\,J.} Suboptimal discrete filters for 
stochastic systems with different types of observations~// Computer and 
Mathematics with Applications,  1998. Vol.~35. No.\,3. P.~17--27.

\bibitem{24sin}
\Au{Oh~M., Han~C., Sinitsyn~I.\,N., Shin~V.\,I.}
Recursive
filtering in discrete non-linear systems with unknown
parameters~//  Automation and Remote Control, 1998.
Vol.~59. No.\,1. P.~36--43.

\bibitem{25sin}
\Au{Азаров~С.\,В., Менхо~О., Синицын~И.\,Н., Шин~В.\,И.}
Метод нормальной аппроксимации в задачах адаптивной дискретной фильтрации и
распознавания~//  Автоматика и телемеханика, 1998. №\,11. С.~21--31.

\bibitem{26sin}
\Au{Lee~Y., Oh~M., Shin~V.\,I.} Adaptive nonlinear continuous-discrete 
filtering~// Applied Numerical Mathematics,  2001. No.\,47. P.~45--56.

\bibitem{27sin}
\Au{Shin~V.\,I., Shevlyakov~G.}
 An optimal mean square combination of estimates with application to
filtering problems~// 7th Conference (International) оn
Pattern Recognition and Image Analysis (PRIA-7-2004) Proceedings.
St.\,Petersburg, Russia. Vol.~2. P.~394--397.

\bibitem{28sin}
\Au{Пугачев~В.\,С., Синицын~И.\,Н.}
Направления развития
математического обеспечения для исследования стохастических
систем~// В кн. <<Информатика: проблемы, перспективы>>.  М.:
Наука, 1986. С.~30--38.

\bibitem{29sin}
\Au{Pugachev~V.\,S., Sinitsyn~I.\,N., Shin~B.\,I.}
Problems of analysis and on-line
conditionally optimal filtering of processes in nonlinear
stochastic systems~// 2nd IFAC  Symposium on
Stochastic Control. Vil'nius, USSR,  1986. Moscow.
Preprints. Part~1. P.~4--18.

\bibitem{30sin}
\Au{Синицын~И.\,Н., Петрова~Е.\,В., Шин~В.\,И.}
Алгоритмическое и
программное обеспечение для фильтрации случайных процессов с
использованием ПЭВМ~// Тез. докл. 3-го межведомственного семинара по
актуальным вопросам вычислительной техники и информатики
<<Электронный офис для научных исследований>>. М.: ИАЭ
им.~Курчатова, 1988. С.~20--23.

\bibitem{31sin}
\Au{Пугачев~В.\,С., Синицын~И.\,Н.}
Современное состояние и
перспективы развития математического обеспечения для исследования
стохастических сис\-тем~// Тез. докл. Всесоюзного совещания <<Проблемы
управления-89>>. Ташкент, 1989. Т.~1. С.~504--505.

\bibitem{32sin}
\Au{Синицын~И.\,Н., Карпенко~А.\,П., Чередничено, Корепанов~Э.\,Р.}
Диалоговый комплекс для исследования и моделирования
стохастических систем на базе ПЭВМ~// В сб. трудов 3-й Всесоюзной
школы <<Прикладные проблемы управления мак\-ро\-сис\-те\-ма\-ми>>.
Апатиты. М.: Изд-во ВНИИСИ, 1989. С.~237--239.

\bibitem{33sin}
\Au{Sinitsyn~I.\,N.}
Problems of signal
analysis and conditionally optimal processing in stochastic
differential systems~// Latvian Signal
Processing  Conference (International) Proceedings. Riga, 1990. Vol.~2. P.~60--64.

\bibitem{34sin}
\Au{Пугачев~В.\,С., Синицын~И.\,Н.}
(ред.). Принципы разработки
интеллектуализированных ППП для построения условно оптимальных
фильтров. Пакет прикладных программ <<СтС-Фильтр>>.
Г.\,К.~Алдушин, Р.\,Н.~Бабкина, В.\,Ф.~Бурлака, В.\,Ю.~Вигдерович,
Б.\,И.~Гершиков, Э.\,Р.~Корепанов, О.\,А.~Куленко, В.\,С.~Пугачев,
В.\,И.~Синицын, И.\,Н.~Синицын, А.\,П.~Хатунцев. В.\,И.~Шин. Препринт.
М.: ИПИ АН СССР, 1991.

\bibitem{35sin}
\Au{Синицын~И.\,Н., Маишева~Е.\,Ю., Корепанов~Э.\,Р., Мощук~Н.\,К.,
Огнева~О.\,С., Синицын~В.\,И., Шин~В.\,И., Хатунцев~А.\,П.}
Программные средства
для анализа и моделирования случайных процессов, проектирования
фильтров и идентификаторов на ПЭВМ~// Тез. докл. IV~Всесоюзной
научно-технической  конференции <<Перспективные методы
планирования и анализа экспериментов при исследовании случайных
полей и процессов>>. Петрозаводск, 1991. М.: Изд-во
МЭИ, 1991. С.~82--83.

\bibitem{36sin}
\Au{Пугачев~В.\,С., Синицын~И.\,Н., Хатунцев~А.\,П., Шин~В.\,И.,
Корепанов~Э.\,Р., Синицын~В.\,И.}
Проблемы разработки математического обеспечения
для проектирования дискретных условно оптимальных фильтров~// В
кн. <<Системы и средства информатики>>. Вып.~3. М.: Наука,
1992.  С.~3--19.

\bibitem{37sin}
\Au{Пугачев~В.\,С., Синицын~И.\,Н., Хатунцев~А.\,П., Шин~В.\,И.,
Корепанов~Э.\,Р., Синицын~В.\,И.}
Математическое обеспечение для проектирования
условно оптимальных фильтров и анализа процессов в дискретных
стохастических системах~// Автоматика и телемеханика, 1992.
№\,6. С.~78--85.

\bibitem{38sin}
\Au{Sinitsyn~I.\,N., Karpenko~A.\,P.}
Combined parallel statistical and analysis modeling methods,
algorithms and software for dynamical  stochastic systems
research~// EUROSIM 1996  Conference (International) Proceedings.
L.~Dekker, W.~Smit, J.\,C.~Zuidervaat (eds.).
Elsevier Science B.V., 1996. P.~187--194.

\bibitem{39sin}
\Au{Корепанов~Э.\,Р.}
Развитие алгоритмического и программного
обеспечения для синтеза фильтров Пугачева~// В кн. <<Системы и
средства информатики>>. Спец. вып.  М.: Наука, Физматлит, 2001.
С.~37--42.

\bibitem{40sin}
\Au{Синицын~И.\,Н., Синицын~В.\,И., Корепанов~Э.\,Р., Белоусов~В.\,В.}
Информационные технологии синтеза параметризованных фильтров
Пугачева. М.:  Наукоемкие технологии, 2004. №\,7. С.~50--79.

\bibitem{41sin}
\Au{Синицын~И.\,Н., Синицын~В.\,И.,  Корепанов~Э.\,Р.,  Белоусов~В.\,В.,
Чумин~Ю.\,В.} Методические и про\-грам\-мное обеспечение анализа качества и 
моделирования сингулярных стохастических систем~//  Труды IV~международной 
конференции <<Идентификация систем и проблемы управления>> (SICPRO'05), 2005. 
CD-ROM. C.~1713--1743.

\bibitem{42sin}
\Au{O~M., Shin~V.\,I.}
Modified quasilinear filtering method
for estimation of processes in multidimentional nonlinear
stochastic systems~//  Kybernetika, 1997.  Vol.~33. No.\,4.
P.~399--408.

\bibitem{43sin}
\Au{Добровидов~А.\,В., Кошкин~Т.\,М.}
Непараметрическое  оценивание сигналов. М.: Наука, Физматлит, 1997.

\bibitem{44sin}
\Au{Васильев~В.\,А., Добровидов~А.\,В., Кошкин~Г.\,М.}
Непараметрическое оценивание функционалов от распределений
стационарных последовательностей. М.: Наука, 2004.

\bibitem{45sin}
\Au{Sinitsyn~I.\,N.} Parallel simulation technologies for stochastic systems~// 
In Lectures Notes in Computer Science, 1277. Parallel Computing Technologies, 
4th Conference (International) PACT-97 Proceedings. Springer, 1997. 
P.~383--388.

\bibitem{46sin}
\Au{Синицын~И.\,Н., Синицын~В.\,И., Степанов~А.\,М., Ушмаев~О.\,С.}
Проблемы реализации вычислительных методов обработки и анализа
сигналов и изоб\-ра\-же\-ний на архитектурах с ассоциативной памятью~//
Труды 1-й Всероссийской конференции <<Методы и средства
обработки информации>>. М.: Изд-во МГУ им.~М.\,В.~Ломоносова, 2003.
С.~137--141.

\bibitem{47sin}
\Au{Синицын~И.\,Н., Степанов~А.\,М., Ушмаев~О.\,С.}
Проблемы синтеза фильтров и идентификаторов с ассоциативной памятью~//
 Труды III~международной конференции <<Идентификация систем и проблемы
управления>> (SICPRO'04), 2004. CD-ROM.
C.~1896--1911.

\bibitem{48sin}
\Au{Казаков~И.\,Е., Мальчиков~С.\,В.}
Приближенное построение фильтров
Пугачева заданной сложности~// Автоматика и телемеханика,
1981. №\,12. С.~48--55.

\bibitem{49sin}
\Au{Пугачев~В.\,С.}
Управление летными и испытаниями летательных
аппаратов как средство повышения их надежности~// В кн.
<<Проблемы надежности летательных аппаратов>>. М.: Машиностроение,
1985. С.~25--37.

\bibitem{50sin}
\Au{Казаков~И.\,Е., Гладков~Д.\,И.} Методы оптимизации стохастических систем.  
М.: Наука, Гл. ред. физ\-мат\-лит, 1987.

\bibitem{51sin}
\Au{Руденко~Е.\,А.}
  Оптимальная структура дискретных нелинейных
фильтров произвольного порядка~// В кн. <<Статистические методы в теории 
управления ЛА>>. Тем. сб. науч. тр. МАИ. М.: Изд-во МАИ, 1990. С.~53--60.

\bibitem{52sin}
\Au{Руденко~Е.\,А.}
Адаптивный дискретный нелинейный фильтр для
реализации на борту ЛА~// В кн. <<Управление и навигация ЛА в
условиях па\-ра\-мет\-ри\-че\-ских неопределенности>>. Тем. сб. науч. тр.
МАИ. М.: Изд-во МАИ, 1991. С.~23--30.

\bibitem{53sin}
\Au{Корепанов~Э.\,Р.}
Дискретные условно оптимальные фильтры с
памятью~// Докл.\ РАН, 1992. Т.~324. №\,1. С.~50--55.

\bibitem{54sin}
\Au{Панков~А.\,Р.}
Рекуррентная условно-минимаксная фильтрация
процессов в разностных нелинейных стохастических системах~//
Изв. АН СССР. Техническая кибернетика, 1992. №\,3. С.~63--70.

\bibitem{55sin}
\Au{Руденко~Е.\,А.}
Оптимальная структура дискретных алгоритмов
конечномерной непрерывно-дискретной нелинейной фильтрации
при марковских помехах~// В кн. <<Оптимизация алгоритмов
обработки информации и управления>>. Тем. сб. науч. тр. МАИ. М.:
Изд-во МАИ, 1992. С.~62--70.

\bibitem{56sin}
\Au{Pankov~A.\,R.} Conditionally-minimax nonlinear filter for differential 
system with discrete observations~//  Advances in Modelling and Analysis. Ser. 
B. AMSE Press., 1993. Vol.~28.  No.\,1. P.~31--39.

\bibitem{57sin}
\Au{Pankov~A.\,R., Bosov~A.\,V.} Conditionally-miminax algorithm of nonlinear 
system state estimation~// IEEE Trans. Autom. Control,  1994. Vol.~39. No.\,8. 
P.~1617--1620.

\bibitem{58sin}
\Au{Синицын~И.\,Н.}
Из опыта преподавания статистических основ
информатики в технических университетах~// В кн. <<Системы и
средства информатики>>. Спец. вып.~8, посвященный
II~международному конгрессу ЮНЕСКО <<Образование и информатика>>. М.:
Наука, Физматлит, 1996. С.~68--73.

\bibitem{59sin}
\Au{Шин~В.\,И.}
Фильтры Пугачева для комплексной обработки
информации~// Автоматика и телемеханика, 1998. №\,11. С.~195--206.

\bibitem{60sin}
\Au{Босов~А.\,В.}
Условно-минимаксные алгоритмы оценивания и
управления для нелинейных стохастических систем~// Автоматика и
телемеханика, 1998. №\,11. С.~46--59.

\bibitem{61sin}
\Au{Синицын~И.\,Н., Синицын~В.\,И., Корепанов~Э.\,Р., Белоусов~В.\,В.,
Ильясов~Д.\,Ф., Ушмаев~О.\,С.}
Субоптимальные обучающиеся
информационные технологии и системы~// Материалы межрегиональной
на\-уч\-но-тех\-ни\-че\-ской конференции <<Интеллектуальные
информационные системы>> (Интеллект-2003). Тула:
Изд-во Тульского государственного университета, 2003. С.~25--27.

%\bibitem{62sin}
%\Au{Борисов~А.\,В.}
%Условно оптимальное оценивание специальных
%марковских скачкообразных процессов~// Автоматика и
%телемеханика, 2006.

\bibitem{63sin}
\Au{Синицын~И.\,Н., Синицын~В.\,И., Корепанов~Э.\,Р., Белоусов~В.\,В.,
Лавренюк~Ю.\,А.}
Условно оптимальные стохастические информационные
технологии  контроля сложных динамических систем~// В кн.
<<Системы и средства информатики>>. ИПИ РАН. Вып.~16. М.: Наука,
2006. С.~72--108.
\end{thebibliography}

}
}

\end{multicols}

%\centerline{\bf DEVELOPMENT OF PUGACHEV FILTERING FOR
%STOCHASTIC SYSTEMS}


% I.\,N.~Sinitsyn$^1$
%\footnote{$^1$IPI RAS, sinitsin@dol.ru}

%Statistical methods of information processing
%(filtering, extrapolation, interpolation etc) in stochastic
%systems (StS) are the basis of modern statistical informatics.
%Analytical survey and main tendencies of nonlinear conditionally
%optimal Pugachev filters (PF) for StS are considered. PF for
%regular and nonregular, continuous and discrete, gaussian and non
%gaussian StS are discussed. Interconnection between PF and Kalman
%filters is condidered including various statistical criteria is
%given. Problems of joint filtering and recognition and PF trends
%and PF trends are considered.
\label{end\stat}