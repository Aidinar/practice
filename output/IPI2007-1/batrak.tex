\def\stat{batr}

\def\tit{НОВЫЙ МЕТОД ВЕРОЯТНОСТНО-СТАТИСТИЧЕСКОГО\newline
АНАЛИЗА ИНФОРМАЦИОННЫХ ПОТОКОВ
В~ТЕЛЕКОММУНИКАЦИОННЫХ СЕТЯХ$^*$}
\def\titkol{Новый метод вероятностно-статистического
анализа информационных потоков
в~телекоммуникационных сетях}
\def\autkol{Д.\,А.~Батракова, В.\,Ю.~Королев, С.\,Я.~Шоргин}
\def\aut{Д.\,А.~Батракова$^1$, В.\,Ю.~Королев$^2$, С.\,Я.~Шоргин$^3$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]{Работа 
выполнена при поддержке РФФИ, проекты №№\,04-01-00671, 05-07-90103.} 
\renewcommand{\thefootnote}{\arabic{footnote}}}
 \footnotetext[1]{ИПИ РАН, 
daria.batrakova@gmail.com} \footnotetext[2]{Факультет вычислительной математики 
и кибернетики МГУ им.~М.\,В.~Ломоносова, ИПИ РАН, vkorolev@comtv.ru} 
\footnotetext[3]{ИПИ РАН, sshorgin@ipiran.ru}



\Abst{В данной работе предлагается метод исследования стохастической структуры
хаотических информационных потоков в сложных телекоммуникационных
сетях. Предлагаемый метод основан на стохастической модели
телекоммуникационной сети, в рамках которой она представляется в виде
суперпозиции некоторых простых последовательно-параллельных структур.
Эта модель естественно порождает смеси гамма-распределений для времени
выполнения (обработки) запроса сетью. Параметры получаемой смеси
гамма-распределений характеризуют стохастическую структуру
информационных потоков в сети. Для решения задачи статистического
оценивания параметров смесей экспоненциальных и гамма-распределений
(задачи разделения смесей) используется ЕМ-алгоритм. Чтобы проследить
изменение стохастической структуры информационных потоков во времени,
ЕМ-алгоритм применяется в режиме скользящего окна. Описывается
программный инструментарий для применения полученного решения к
реальным статистическим данным. Приводится интерпретация результатов.}

\KW{телекоммуникационные сети; информационные потоки;
разделение смесей  распределений;
метод скользящего окна;  программа для разделения смесей}

\vskip 24pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}


\label{st\stat}

\section{Введение}

Развитие телекоммуникационных сетей, их усложнение поставило перед
инженерами важную прикладную задачу исследования характеристик
информационных потоков, возникающих в этих сетях. Здесь под
информационным потоком мы будем понимать упорядоченное движение
любого вида информации по сети.

Если на заре эры телекоммуникаций, в эпоху первых телефонных линий и
телеграфа эта проблема не была столь насущной, то со временем, при
постепенном охвате мирового пространства сетями возникла необходимость в
построении и исследовании адекватных моделей сетей и процессов,
происходящих в них.

\thispagestyle{headings}


Современные сети~--- это \textit{конвергентные} сети, т.е.\ совокупность крайне
разнородных как по топологии, так и по физической архитектуре сетей, которые
предлагают конечному пользователю самые разнообразные сервисы. Это~--- огромное
виртуальное и физическое пространство, состоящее из миллионов процессоров,
операционных платформ, линий передачи данных и стыковочных узлов.
%
Существует множество классификаций телекоммуникационных сетей по различным
признакам:
\begin{itemize}
\item масштабу (локальные сети~--- LAN, масштаба города~---
MAN, широкого масштаба~--- WAN);
\item топологии, или логической организации (<<звезда>>,
<<кольцо>>, <<шина>>);
\item физической организации (оптические сети, радио);
\item предлагаемым услугам (сотовые сети, для доступа в
Интернет);
\item назначению (военные, гражданские) и~др.
\end{itemize}


Конвергентная сеть входит во все эти классы, причем, как правило,
обладает всеми этими признаками. Поэтому построение модели для ее анализа
является и очень важной, и очень сложной задачей.

Существуют достаточно многочисленные математические методы, ориентированные на
моделирование и анализ телекоммуникационных сетей. В~большинстве своем они
основываются на теории массового обслуживания, то есть разделе теории
вероятностей, посвященном описанию функционирования сложных систем обслуживания
(в том чис\-ле телекоммуникационных сетей и систем) с помощью стохастических
процессов особого вида и анализу таких процессов. Указанная теория является
весьма развитой и широко применяется на практике. Тем не менее, ее применимость
ограничена~--- во-первых, все возрастающей сложностью структур и дисциплин
обслуживания в рас\-смат\-ри\-ва\-емых реальных сетях. Эта сложность во многих
случаях принципиально не может найти адекватного отображения в моделях
массового обслуживания, даже несмотря на постоянно растущую сложность самих
этих моделей. В результате даже модели, допускающие точный математический
анализ, дают возможность расчета всего лишь приближенных значений характеристик
реальных сетей, ибо предположения, принимаемые при построении моделей, во
многих случаях не соответствуют практике. Во-вторых, для описания
телекоммуникационной сети в виде сети массового обслуживания исследователь
должен располагать детальным описанием структуры сети, что далеко не всегда
имеет мес\-то на практике. В-третьих, разработано крайне мало моделей массового
обслуживания, в которых используется в качестве входной информация о
наблюдаемых (статистических) показателях функционирования сети; в то же время,
такая информация очень часто доступна исследователю, и ее использование при
анализе сети весьма целесообразно.

В данной работе предлагается в определенной степени альтернативный подход к
моделированию сложных телекоммуникационных сетей. Строится и исследуется
вероятностная модель сложной телекоммуникационной сети как суперпозиции
достаточно простых структур. При этом практически никакая априорная информация
о структуре исследуемой сети не используется~--- наоборот, в результате
исследования модели исследователь получает приближенное представление об этой
структуре. Характеристики типовых простых структур, составляющих в совокупности
модель сети, и сети в целом при этом подходе описываются
гам\-ма-рас\-пре\-де\-ле\-ни\-я\-ми. Ставится задача оценки параметров модели
на основе статистических данных о функционировании сети, а также предлагается
математическое решение этой задачи. В статье описан также созданный на основе
разработанных математических методов программный инструментарий и приведены
результаты расчетов для реального трафика. {\looseness=-1

}

\section{Математическая модель и~постановка задачи}

\subsection{Логическая модель сети}
 %1.1

Рассмотрим абстрактную \textit{конвергентную телекоммуникационную
сеть}. Это может быть как крупномасштабная транспортная сеть (WAN), сеть
отдельного оператора масштаба города (MAN) с различными сервисами, так и
локальная сеть (LAN).

Любой из этих случаев можно описать как ($p,\,q$)-\textit{сеть}.

\medskip
\textbf{Определение 1.} В теории графов и сетей под ($p,\,q)$-сетью понимается
набор вида $S =$\linebreak $=(G,\,V^\prime ,\,V^{\prime\prime})$, где $G$~---
граф, а $V^\prime$ и $V^{\prime\prime}$~--- выборки из множества $V(G)$ (вершин
графа) длины~$p$ и $q$ соответственно. При этом выборка $V^\prime$
($V^{\prime\prime}$) считается \textit{входной} (\textit{выходной}) выборкой, а
ее $i$-я вершина называется $i$-\textit{м} \textit{входным} (\textit{выходным})
\textit{полюсом} или, иначе, $i$-\textit{м} \textit{входом} (\textit{выходом})
сети~$S$. Вершины, не участвующие во входной и выходной выборках сети,
считаются ее внутренними вершинами~\cite{1bat}.

Сеть $S$ (рис.~\ref{f1bat}) имеет $p$ точек входа~--- точек соединения
с внешней средой (это могут быть точки стыковки разнородных сетей, сетей
различных операторов, физические подключения к интерфейсам
маршрутизаторов и~т.п.). Под \textit{внешней средой} будем понимать другие
сети, которые передают данные в сеть~$S$. Отдельные <<единицы>> данных
(кадры, сообщения, датаграммы, пакеты) поступают на входы сети~$S$,
обрабатываются и подаются на каждый из $q$ выходов, которые могут быть
соединены как с конечными пользователями, так и с другими сетями.
\begin{figure*} %fig1
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=139.7mm \epsfbox{bat-1.eps}
%\epsfxsize=139.698mm
%\epsfbox{bek-3.eps}
}
\end{center}
\vspace*{-9pt} \Caption{Абстрактная телекоммуникационная сеть \label{f1bat}}
\end{figure*}

Следует отметить, что структура сложных телекоммуникационных сетей обладает
свойством некоторого самоподобия, т.е.\ на каком бы уровне сетевой архитектуры
мы ни рассматривали поведение информационных потоков, мы можем выделить
некоторые базовые структуры, субпотоки, суперпозицией которых мы можем получить
модель конкретной сети, какой бы уровень <<детализации>> сегментов сети мы ни
взяли. Так, например, физические подключения к интерфейсам оптического
кросс-коннекта в этом смысле подобны <<виртуальным>> подключениям к портам TCP
на сервере приложений.

Итак, независимо от уровня сетевой архитектуры мы можем
рассматривать некоторую величину, характеризующую количество каких-либо
ресурсов сети~$S$, занимаемых в процессе передачи и обработки данных.  Это
могут быть ресурсы, относящиеся как к <<объему>> (памяти сетевого
устройства, количеству занятых линий, размеру пакета), так и ко <<времени>>
(времени обслуживания заявки, времени простоя). Эта величина случайна, т.к.\
мы не можем абсолютно точно сказать для сложной телекоммуникационной
сети, какое сообщение на какой из входов поступит и какого размера оно будет.
Таким образом, случайный характер данной величины определяется
случайностью поведения внешней среды.

Пусть $R$~--- это описанная выше случайная величина, $R>0$. Далее, не
ограничивая общности, будем подразумевать под ней время, необходимое для
какой-либо операции сети (обработки <<единицы>> данных), предполагая, что
время обработки прямо зависит от объема сообщения.

\subsection{Вероятностная модель сети} %1.2.

Даже не зная реальной топологии сети, мы можем описать
функционирование некоторых ее участков как процесс выполнения операций
(задач сети) в последовательном  порядке (например, если доступен только
один канал данных) или как процесс одновременного выполнения субопераций
(когда доступно более одного пути выполнения). Это значит, что мы можем
представить функционирование сложной телекоммуникационной сети как
\textit{суперпозицию} таких <<последовательных>> и <<параллельных>>
блоков.

Для построения вероятностной модели распределения~$R$ используется
комбинация асимптотического подхода, основанного на предельных теоремах
теории вероятностей, и принципа максимальной неопределенности (энтропии).

Рассмотрим следующую модель. Предположим, что мы можем разделить
сеть~$S$ на несколько сегментов $S_i$. Пусть $T$~--- случайная величина,
время выполнения операции в отдельно взятом блоке $S_i$ (сегменте сети).

Если операции выполняются \textit{параллельно}, то время, необходимое
для их выполнения~--- это максимальное время, затрачиваемое на какую-либо
субоперацию:
$$
T = \underset{i}{\max}\, T_i\,,
$$
где $T_i$~--- случайные величины для со\-от\-вет\-ст\-ву\-ющих субопераций.
Модель такого выполнения пред\-став\-ле\-на на рис.~\ref{f2bat}.

\begin{figure*} %fig2
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=117.271mm
\epsfbox{bat-2.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Параллельное выполнение
\label{f2bat}}
\end{figure*}

Известно, что предельное распределение экстремальных значений для
выборок ~--- это экспоненциальное распределение с плотностью~\cite{2bat}
$$
f(x) =
\begin{cases}
\lambda e^{-\lambda x}\,, & x>0\,,\\
0\,, & x\leq 0\,,
\end{cases}
$$
где $\lambda >0$~--- параметр масштаба.

 Учитывая также энтропийный подход, естественно будет считать
распределение $T$ экспоненциальным, т.к.\ экспоненциальное распределение
обладает наибольшей энтропией среди всех распределений с $x>0$.

Если же операции сети выполняются \textit{последовательно}, то величина
$T$~--- это сумма времен $T_i$, необходимых для выполнения каждой
субоперации:
$$
T = \sum\limits_i T_i\,,
$$
где $T_i$~--- случайные величины для со\-от\-вет\-ст\-ву\-ющих субопераций.
%
Такая модель представлена на рис.~\ref{f3bat}.

\begin{figure*} %fig3
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=139.592mm
\epsfbox{bat-3.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Последовательное  выполнение
\label{f3bat}}
\end{figure*}

Это значит, что распределение общей длительности $T$ выполнения
блока~--- это свертка распределений <<элементарных>> времен $T_i$
(экспоненциально распределенных).

Известно, что результатом свертки экспоненциальных распределений
является гамма-распределение, определяемое плотностью
$$
\g_{\lambda , \alpha} (x) =
\begin{cases}
\fr{\lambda_0^{\alpha_0}}{\Gamma (\alpha_0 )}\,x^{\alpha_0-1}
e^{\lambda_0 x}\,, & x>0\,,\\
0,\, & x\leq 0\,,
\end{cases}
$$
где $\alpha >0$~--- параметр формы,  $\lambda >0$  параметр масштаба, а
$\Gamma (z)$~--- гамма-функция Эйлера:
$$
\Gamma (z) = \int\limits_0^\infty x^{z-1} e^{-x}\,dx\,.
$$

\begin{figure*} %fig4
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=120.831mm
\epsfbox{bat-4.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Модель пути  обработки сообщения сетью~$S$
\label{f4bat}}
\end{figure*}

Известно~\cite{2bat}, что класс гамма-распределений замкнут над операцией
свертки, поэтому ре\-зуль\-ти\-ру\-ющее распределение случайной величины~$R$
будет также гамма-распределением
$$
\g_{\lambda , \alpha} (x) =
\begin{cases}
\fr{\lambda^{\alpha}}{\Gamma (\alpha )}\,x^{\alpha -1} e^{-\lambda x}\,, &
x>0\,,\\
0,\, & x\leq 0\,.
\end{cases}
$$

В силу случайного характера ввода данных в сеть~$S$ из внешней среды маршрут
передачи данных становится случайным, что представлено на рис.~\ref{f4bat}. Это
означает, что параметры ре\-зуль\-ти\-ру\-юще\-го распределения~$R$ тоже
случайны. Отсюда имеем следующую модель \textit{смеси
гам\-ма-рас\-пре\-де\-ле\-ний}, определяемой плотностью

\begin{equation} %1
p(x) = \iint \g_{\lambda , \alpha}(x)\,dH (\lambda ,\,\alpha )\,,
\end{equation}
где $H(\lambda , \alpha )$~--- смешивающая функция, функция распределения
входных параметров.

Поясним понятие \textit{смеси распределений}.

\medskip
\textbf{Определение~2.} Пусть имеется двух\-па\-ра\-мет\-ри\-че\-ское
семейство $n$-мерных плотностей  распределения
\begin{equation}
F = \{ f_\omega (x;\, \theta (\omega ))\}\,,
\end{equation}
где одномерный (целочисленный или непрерывный) параметр $\omega$ в
качестве нижнего индекса функции $f$ определяет специфику общего вида
каж\-до\-го компонента~--- распределения смеси, а в качестве аргумента при
многомерном, вообще говоря, параметре $\theta$ определяет зависимость
значений хотя бы части компонентов этого параметра от того, в каком именно
составляющем распределении $f_\omega$ он присутствует. Кроме того, пусть
$P = \{P(\omega )\}$~--- \textit{семейство смешивающих функций}
распределения.

Функция плотности распределения
\begin{equation}
f(x) = \int f_\omega (x;\,\theta(\omega ))\,dP (\omega )
\end{equation}
называется $P$-\textit{смесью} (или просто \textit{смесью})
\textit{распределений} семейства~$F$,  интеграл в~(3) понимается в смысле
Лебега--Стильтьеса~\cite{3bat}.

\medskip
\textbf{Определение 3.} Семейство смесей~(3) называется
\textit{идентифицируемым} (\textit{различимым}), если из равенства
$$
\int f_\omega (x;\,\theta(\omega ))\,dP (\omega ) =\int f_\omega
(x,\,\theta(\omega )) dP^*(\omega )
$$
следует, что $P(\omega ) \equiv P^*(\omega )$ для всех $P \in P(\omega
)$~\cite{3bat}.

\subsection{Постановка задачи} %1.3.

Перед нами встает задача \textit{разделения} такой смеси. Вообще говоря,
задача разделения смесей распределений со смешивающими функциями
общего вида является \textit{некорректно поставленной}, т.к.\ она допускает
существование нескольких решений. Поэтому будем искать решение в классе
\textit{конечных идентифицируемых смесей распределений}, где смешивающая
функция дискретна.

Для этого сузим данное выше определение и будем рассматривать в дальнейшем лишь 
случай конечного числа $k$ возможных значений па\-ра\-мет\-ра~$\omega$, что 
соответствует конечному числу скачков смешивающих функций $P(\omega )$.  
Величины этих скачков как раз и будут играть роль \textit{удельных весов} 
(\textit{априорных вероятностей}) $p_j$ компонентов смеси. Более того, в нашем 
случае мы постулируем также однотипность компонентов распределений $f_j$, т.е.\ 
принадлежность всех $f_j$ к одному общему па\-ра\-мет\-ри\-че\-ско\-му 
семейству $\{ f(X;\,\theta )\}$, где $\theta$~--- многомерный, вообще говоря, 
параметр. Так что~(3) в этом случае может быть записано в виде
\begin{equation} %4
p(x) = \sum\limits^k_{j=1} p_j f_j (x;\,\theta_j )\,.
\end{equation}

Переформулируем понятие идентифицируемости (различимости) смесей
специально применительно к такому виду смесей.

\medskip
\textbf{Определение 4.} \textit{Конечная смесь}~(3) называется
\textit{идентифицируемой} (\textit{различимой}), если из равенства
$$
\sum\limits_{j=1}^k p_j f_j (x;\,\theta_j ) = \sum\limits_{l=1}^{k^*} p_l^* f_l
(x;\,\theta_l^* )
$$
следует, что $k=k^*$ и для любого $j$ ($1\leq j \leq k$) найдется такое $l$ 
($1\leq l \leq k^*$), что $p_j = p_l^*$ и $f_j (x;\,\theta_j ) = f_l 
(x;\,\theta_l^* )$~\cite{3bat}.

Решить эту задачу в выборочном варианте~--- значит по выборке
классифицируемых наблюдений
$X_1,\ldots , X_n, $ извлеченной из генеральной совокупности, яв\-ля\-ющей\-ся смесью~(3)
генеральных совокупностей типа~(2) (при заданном общем виде составляющих
смесь функций $f_j (x;\,\theta_j )$), построить статистические оценки для числа
компонентов смеси~$k$, их удельных весов $p_j$ и, главное, для каждого из
компонентов %f_j (x;\,\theta_j )$ анализируемой смеси. Далее будет считать, что
функции $f_j$ однозначно определяются своими параметрами $\theta_j$: $f_j
=f(x;\,\theta_j)$.

Однако не следует ставить знак тождества между задачей разделения смеси
и задачей статистического оценивания параметров в модели~(4) по выборке $
X_1,\ldots , X_n$, поскольку задача разделения сохраняет смысл и
применительно к генеральным совокупностям, т.е.\ в теоретическом
варианте~\cite{3bat}.

Итак, для статистического анализа на основе реальных данных мы
аппроксимируем нашу общую модель~(1) следующей:
$$
p(x) \approx \hat{p}(x) = \sum\limits_{j=1}^k p_j \g_{\lambda_j , \alpha_j}
(x)\,,
$$
где $p_j$~--- дискретные смешивающие параметры, $\g_{\lambda_j , \alpha_j}
(x)$~--- плотности гамма-распределений.

Такая аппроксимация не только позволяет решить поставленную статистическую
задачу, но и полу\-чить наглядную визуализацию результатов. Существуют
достаточно эффективные методики разделения смесей распределений, среди них~---
семейство так называемых \textit{ЕМ-алгоритмов}
(\textit{Expectation-Maximization Algorithms}).

Полученные результаты могут быть достаточно просто интерпретированы. Число
компонентов смеси символизирует число типичных параллельных или
последовательных структур. Значения параметров составляющих смесь
гам\-ма-рас\-пре\-де\-ле\-ний показывают <<степень параллелизма>>
соответствующей структуры: чем ближе параметр формы к~1, тем выше эта
<<степень>>. И наоборот, чем дальше значение параметра формы от~1, тем больше
последовательных операций выполняется в соответствующем блоке.

Веса компонентов характеризуют примерную долю использования
ресурсов для сообщений, соответствующих каждому распределению входных
данных.

Итак, предложенный подход позволяет получить представление о
стохастической структуре телекоммуникационной сети.

\section{ЕМ-алгоритм разделения смесей распределений}

\subsection{Описание алгоритма} %2.1.

Определяемый ниже итерационный алгоритм решения поставленной в
предыдущем разделе задачи относится к процедурам, базирующимся на
\textit{методе максимального правдоподобия}.

Этот алгоритм позволяет находить максимум логарифмической функции
правдоподобия по параметрам $p_1,\,p_2,\ldots ,\,p_k$, $\theta_1 ,\,\theta_2,\ldots ,\,
\theta_k$ при фиксированном $k$ по выборке $X_1, \ldots , X_n$, т.е.\ решение
оптимизационной задачи вида

\begin{equation} \sum\limits_{i=1}^n \ln \left ( \sum\limits_{j=1}^k p_j f_j
(X_i;\,\theta_j )\right ) \rightarrow \underset{p_j,\,\theta_j}{\max}\,.
\end{equation}

Конкретные алгоритмы, построенные по этой схеме, часто называют
\textit{алгоритмами типа ЕМ}, поскольку в каждом из них можно выделить два
этапа, находящихся по отношению друг к другу в последовательности
итерационного взаимодействия: \textit{оценивание} (\textit{Estimation}) и
\textit{максимизация} (\textit{Maximization})~\cite{4bat}.

Введем в рассмотрение так называемые апостериорные вероятности
$\g_{ij}$ принадлежности наблюдения $X_i$ к $j$-му классу:
\begin{equation} %6
\g_{ij} = \fr{p_j f(X_i;\,\theta_j )}{\sum\limits_{l=1}^k p_l f(X_i;\,\theta_l 
)} \ (i=1,\ldots , n;\ j=1,\ldots ,k)\,.\!\!\end{equation} 
Очевидно, что для 
всех $i=1,\ldots ,n$ и $j=1,\ldots ,k$
$$
\g_{ij} \geq 0,\quad \sum_{j=1}^k \g_{ij} =1\,.
$$


Далее обозначим $\Theta = (p_1,\ldots p_k,\,\theta_1,\ldots ,\theta_k )$ и
представим анализируемую логарифмическую функцию правдоподобия
$$
\ln L(\Theta ) = \sum\limits_{i=1}^n \ln \left (\sum\limits_{j=1}^k p_j f_j
(X_i;\,\theta_j )\right )
$$
в виде
\begin{multline}
\ln L (\Theta ) = \sum\limits_{j=1}^k\sum\limits_{i=1}^n \g_{ij} \ln p_j+{}\\
{}+\sum\limits_{j=1}^k\sum\limits_{i=1}^n \g_{ij} f(X_i;\,\theta_j)-
\sum\limits_{j=1}^k\sum\limits_{i=1}^n \g_{ij} \ln \g_{ij}\,.
\end{multline}

Справедливость этого тождества легко проверяется с учетом
$$
\sum\limits_{j=1}^k \g_{ij} =1\,.
$$

Далее идея построения итерационного алгоритма вычисления оценок
$\hat{\Theta} = (\hat{p}_1,\ldots , \hat{p}_k,\
\hat{\theta}_1,\ldots , \hat{\theta}_k)$
для параметров $\Theta = (p_1,\ldots , p_k,\ \theta_1,\ldots , \theta_k)$ состоит в
следующем:
\begin{enumerate}[1.]
\item Выбирается некоторое \textit{начальное приближение}~$\hat{\Theta}^0$.
\item \textbf{E-step:} вычисляются по формулам~(6) начальные приближения
$\g_{ij}^0$ для апостериорных вероятностей $\g_{ij}$~--- \textit{этап
оценивания}.
\item \textbf{M-step:} затем, возвращаясь к~(7), при вычисленных значениях
$\g^0_{ij}$ следует определить значения $\hat{\Theta}^1$ из условия
максимизации отдельно каждого из первых двух слагаемых правой
части~(7), поскольку первое слагаемое
$$
\sum_{j=1}^k \sum_{i=1}^n \g_{ij} \ln p_j
$$
зависит только от параметров $p_j$, а второе слагаемое
$$
\sum_{j=1}^k \sum_{i=1}^n \g_{ij} f(X_i;\,\theta_j )
$$
зависит только от параметров $\theta_j$~--- \textit{этап максимизации}.
\item Проверяется \textit{условие останова}:
$$
\parallel \Theta^{(t)} - \Theta^{t-1}\parallel <\varepsilon\,,
$$
где $t$~--- номер итерации, а
$\parallel\bullet\parallel$~--- евклидова норма, для некоторого $\varepsilon
>0$.
\end{enumerate}

Очевидно, решение оптимизационной задачи
$$
\sum\limits_{j=1}^k\sum\limits_{i=1}^n \g_{ij}^{(t)}\ln p_j \rightarrow
\underset{p_j}{\max}
$$
дается выражением (с учетом $\sum_{j=1}^k p_j =1$):
$$
p_{ij}^{(t+1)} =\fr{1}{n}\,\sum\limits_{i=1}^n \g_{ij}^{(t)}\,,
$$
где $t$~--- номер итерации, $t = 0$, 1, 2,\,\ldots

Решение оптимизационной задачи
$$
\sum\limits_{j=1}^k \sum\limits_{i=1}^n \g_{ij}^{(t)} f(X_i;\,\theta_j )
\rightarrow \underset{\theta_j}{\max}
$$
получить намного проще решения задачи~(5): выражение для $\theta_j$
записывается с учетом знания конкретного вида функций
$f(X,\,\theta)$~\cite{3bat}.

\subsection{О сходимости алгоритма} %2.2.

В работе М.\,И.~Шлезингера~\cite{5bat}, где эта схема (позднее названная
ЕМ-схемой) впервые предложена, установлены и основные свойства
реа\-ли\-зу\-ющих ее алгоритмов. В частности, было доказано, что при достаточно
широких предположениях \textit{предельные точки} всякой последовательности,
порожденной итерациями ЕМ-алгоритма, являются стационарными точками
оптимизируемой логарифмической функции правдоподобия $\ln L(\Theta )$ и что
найдется неподвижная точка алгоритма, к которой будет сходиться каждая из таких
последовательностей. Если дополнительно потребовать положительной
определенности информационной мат\-ри\-цы Фишера для $\ln L(\Theta )$ при
истинных зна\-че\-ни\-ях па\-ра\-мет\-ра $\Theta$, то можно показать, что
асимптотически по $n\rightarrow\infty$ (т.е.\ при больших выборках) существует
единственное сходящееся (по веро\-ят\-но\-сти) решение $\hat{\Theta}(n)$
уравнений метода максимального правдоподобия и, кроме того, существует в
пространстве параметров $\Theta$ норма, в которой последовательность
$\Theta^{(t)}(n)$, порожденная ЕМ-ал\-го\-рит\-мом, сходится к $\hat{\Theta}
(n)$, если только начальная аппроксимация $\hat{\Theta}^0$ не была слишком
далека от~$\hat{\Theta} (n)$. {%\looseness=1

}

Таким образом, результаты исследования свойств ЕМ-алгоритмов метода
максимального правдоподобия разделения смеси и их практическое
использование показали, что они являются достаточно работоспособными (при
известном чис\-ле компонентов смеси) даже при большом чис\-ле $k$ компонентов и
при высоких размерностях анализируемого признака~$X$~\cite{3bat}.

\subsection{Уравнения для смеси экспоненциальных распределений}
%2.3.

Применим описанный выше алгоритм к разделению смеси
экспоненциальных распределений:
$$
p(x) = \sum\limits_{j=1}^k p_j \lambda_j e^{-\lambda_j x}\,.
$$
Получаем следующие итерационные уравнения:
\begin{align*}
\g_{ij}^{(t+1)} & = \fr{p_j^{(t)}\lambda_j^{(t)}e^{-
\lambda_j^{(t)}X_i}}{\sum\limits_{l=1}^k p_l^{(t)}\lambda_l^{(t)}
e^{-\lambda_l^{(t)}X_i}}\,,\\
p_j^{(t+1)} & = \fr{1}{n}\,\sum\limits_{i=1}^n \g_{ij}^{(t)}\,.
\end{align*}

Чтобы найти  оценки $\lambda_j$, подсчитаем первую производную функции
$$\sum_{j=1}^k\sum_{i=1}^n \g_{ij}^{(t)} \ln (\lambda_j e^{-\lambda_j X_i}):$$
\vspace*{-8pt}
\begin{multline*}
\left ( \sum\limits_{j=1}^k \sum\limits_{i=1}^n
\g_{ij}^{(t)}\ln \left ( \lambda_j
e^{-\lambda_j X_i} \right ) \right )^\prime \lambda_j =\\[-3pt]
{}= \left (
\sum\limits_{j=1}^k\sum\limits_{i=1}^n \g_{ij}^{(t)}\ln (\lambda_j -\lambda_j X_i )
\right )^\prime \lambda_j =\\[-3pt]
{}= \sum\limits_{i=1}^n \g_{ij}^{(t)}\left (
\fr{1}{\lambda_j} - X_i \right )\,.
\end{multline*}

Разрешая уравнение
$$
\sum\limits_{i=1}^n \g_{ij}^{(t)}\left ( \fr{1}{\lambda_j} -X_i\right ) =0
$$
относительно $\lambda_j$, получаем следующее итерационное уравнение:
$$
\lambda_j^{(t+1)} = \fr{\sum\limits_{i=1}^n
\g_{ij}^{(t)}}{\sum\limits_{i=1}^n \g_{ij}^{(t)} X_i}\,.
$$

\subsection{Уравнения для смеси гамма-распределений } %2.4.

Применим теперь ЕМ-алгоритм к смеси гам\-ма-рас\-пре\-де\-ле\-ний вида
$$
p(x) = \sum\limits_{j=1}^k p_j \fr{\alpha_j^{\alpha_j} x^{\alpha_j -
1}}{\lambda_j^{\alpha_j} \Gamma (\alpha_j )}\,e^{-(\alpha_j / \lambda_j)x}\,.
$$

Такая параметризация удобна для нахождения
оценок~$\alpha_j$~\cite{6bat}.

Аналогичным способом выписываются итерационные уравнения:
\begin{align*}
\g_{ij}^{(t+1)} & =   \fr{p_j^{(t)}\fr{(\alpha_j^{\alpha_j} )^{(t)}
x^{\alpha_j - 1}}{(\lambda_j^{\alpha_j} )^{(t)}\Gamma (\alpha_j)}\,
e^{-(\alpha_j /\gamma_j)^{(t)}x}}{\sum\limits_{l=1}^k
p_l^{(t)}\fr{(\alpha_l^{\alpha_l})^{(t)} x^{\alpha_l -
1}}{(\lambda_l^{\alpha_l})^{(t)}\Gamma (\alpha_l )}\,
e^{-(\alpha_l /\lambda_l)^{(t)} x}}\,,\\
p_j^{(t+1)} & = \fr{1}{n}\,\sum\limits_{i=1}^n \g_{ij}^{(t)}\,.
\end{align*}

Далее найдем оценки $\lambda_j$ для данного случая, приравнивая
производную
\begin{equation} %8
\sum\limits_{j=1}^k \sum\limits_{i=1}^n \g_{ij}^{(t)} \ln \left (
\fr{\alpha_j^{\alpha_j} x^{\alpha_j -1}}{\lambda_j^{\alpha_j}\Gamma
(\alpha_j)}\,e^{-(\alpha_j /\lambda_j) x}\right )
\end{equation}
по $\lambda_j$ к нулю и разрешая относительно~$\lambda_j$ уравнение:
$$
\sum\limits_{i=1}^n \g_{ij}^{(t+1)}\left ( \fr{\alpha_j^{(t)}}{\lambda_j^{(t)}}
- \fr{\alpha_j^{(t)}X_i}{\left ( \lambda_j^{(t)}\right )^2}\right ) =0 \,.
$$
Получаем
$$
\lambda_j^{(t+1)} = \fr{\sum\limits_{i=1}^n \g_{ij}^{(t)}
X_i}{\sum\limits_{i=1}^n \g_{ij}^{(t)}}\,.
$$

Для того чтобы получить итерационные уравнения для $\alpha_j$, найдем
первую производную~(8):
\begin{multline*}
\left ( \sum\limits_{j=1}^k\sum\limits_{i=1}^n \g_{ij}^{(t)}\ln \left (
\fr{\alpha_j^{\alpha_j} x^{\alpha_j -1}}{\lambda_j^{\alpha_j}\Gamma (\alpha_j
)}\,e^{-(\alpha_j /\lambda_j ) x} \right ) \right )^\prime \alpha_j ={}\\[-3pt]
{}=\left ( \sum\limits_{j=1}^k\sum\limits_{i=1}^n \g_{ij}^{(t)}\ln \left (
\fr{\alpha_j^{\alpha_j}}{\lambda_j^{\alpha_j}}\right ) - \ln \Gamma (\alpha_j )+{} \right.\\[-3pt]
{}+\left.
(\alpha_j -1 )\ln X_i - \fr{\alpha_j}{\lambda_j}\,X_i \right )^\prime \alpha_j =\\[-3pt]
{}=\sum\limits_{i=1}^n \g_{ij}^{(t)} \left ( \ln \alpha_j +1-\ln \lambda_j -
\fr{\Gamma^\prime (\alpha_j )}{\Gamma (\alpha_j)}\right.+\\[-3pt]
{}+\left. \ln X_i - \fr{X_i}{\lambda_j}\right )\,;
\end{multline*}
\begin{multline*}
\sum\limits_{i=1}^n \g_{ij}^{(t)} \left(  \ln \alpha_j +1 -\ln \lambda_j -{}\right. \\[-3pt]
\left. {}-\fr{\Gamma^\prime (\alpha_j )}{\Gamma (\alpha_j )}+\ln X_i 
-\fr{X_i}{\lambda_j} \right) =0\,;
\end{multline*}
\begin{multline}
\fr{\Gamma^\prime (\alpha_j )}{\Gamma (\alpha_j )} ={}\\[-3pt]
{}= \fr{\sum\limits_{i=1}^n \g_{ij}^{(t)} \left ( \ln \alpha_j +1-\ln\lambda_j 
+\ln X_i -\fr{X_i}{\lambda_j} \right )}{\sum\limits_{i=1}^n \g_{ij}^{(t)}}\,.
\end{multline}
%
Здесь $\Gamma^\prime (\alpha_j ) / \Gamma (\alpha_j )$~--- это
\textit{логарифмическая производная гамма-функции}. Для нее существует так
называемое \textit{разложение Абрамовитца}--\textit{Стигана}~\cite{4bat}:
$$
\fr{\Gamma^\prime (\alpha ) }{ \Gamma (\alpha )} = \mathrm{log}\,\alpha -
\fr{1}{2\alpha }-\fr{1}{12\alpha^2 }+\ldots
$$

Подставим первые три члена разложения в~(9) и разрешим это уравнение
относительно~$\alpha_j$:
$$
\alpha_{ij}^{(t+1)} = \fr{\sum\limits_{i=1}^n
\g_{ij}^{(t+1)}}{2\sum\limits_{i=1}^n \g_{ij}^{(t +1)}\left ( \fr{X_i}{\lambda_j^{(t)}} -
\ln \fr{X_i}{\lambda_j^{(t)}} -1\right )}\,.
$$
В итоге получаем итерационные уравнения для ~$\alpha_j$.

\section{Описание программного обеспечения (программа~ЕМ)}

\subsection{Назначение программы} %3.1.

Разработанная авторами статьи программа ЕМ предназначена для решения задачи
разделения смесей экспоненциальных и гамма-распределений, поставленной в
разд.~2, с использованием ЕМ-ал\-го\-рит\-ма и формул, описанных в разд.~3.

\subsection{Инструменты разработки} %3.2.

Для создания программы была использована среда разработки Microsoft
Visual Studio .NET 2005 и объектно-ориентированный язык C\#. Для
визуализации результатов была использована свободно распространяемая
графическая библиотека ZedGraph~\cite{7bat}.


\subsection{Возможности  программы} %3.3.

\noindent
\begin{itemize}
\item Загрузка выборочных данных из текстового файла
\item Оценивание по выборке параметров смеси экспоненциальных
распределений
\item Оценивание по выборке параметров смеси гамма-распределений
\item Отслеживание изменений параметров смесей распределений во
времени в режиме <<скользящего окна>>
\item Построение гистограммы по выборке
\end{itemize}

\subsection{Входные и выходные данные. Функционирование
программы} %3.4.

В качестве \textit{входных данных} программа ЕМ получает:
\begin{itemize}
\item выборочные данные из текстового файла;
\item число компонентов смеси;
\item размер <<скользящего окна>>;
\item размер класса гистограммы.
\end{itemize}

На \textit{выходе} мы получаем:
\begin{itemize}
\item точечные оценки параметров смеси экспоненциальных
распределений;
\item точечные оценки параметров смеси гамма-распределений;
\item графическое изображение результирующей смеси распределения;
\item графическое изображение компонентов каж\-дой смеси;
\item графическое изображение того, как меняются параметры смесей
распределений с течением времени в режиме <<скользящего окна>>;
\item гистограмма, построенная по выборке;
\item значение статистического теста.
\end{itemize}

Выборочные данные загружаются из текстового файла в память программы и подаются
на вход двум независимо работающим реализациям ЕМ-алгоритма~--- для
идентификации смеси экспоненциальных распределений и для идентификации смеси
гамма-распределений. Результатом их работы являются наборы значений оцениваемых
параметров модели, предложенной в разд.~2. Кроме того, результирующие
распределения визуализируются в виде графиков. В программе можно запустить
режим <<скользящего окна>>, который для всех подвыборок заданного
размера с помощью ЕМ-алгоритма оценивает параметры смесей распределений этих
подвыборок. Все действия программы документируются в окне информации.

\section{Описание тестовых расчетов}

С использованием разработанной программы были проведены тестовые
расчеты на выборочных данных реального сетевого трафика.

На вход программы EM были поданы выборки трафика:
\begin{enumerate}[I]
\item Между лабораторией Lawrence Berkeley (Berkeley, California) и
внешним миром размера примерно 7000~\cite{8bat}~--- \textit{выборка~1}.
\item
Сети радиодоступа ЗАО <<Синтерра>> размера примерно 1000~\cite{9bat}~---
 \textit{выборка~2}.
\end{enumerate}

\subsection{Выборка 1 ``Berkeley''} %5.1.

При числе компонентов смеси~5 и случайном начальном приближении
были получены результаты, представленные в табл.~\ref{t1bat}.


Данные результаты иллюстрирует рис.~\ref{f5bat}.

Гистограмма  на рис.~\ref{f6bat} показывает статистическую значимость
полученных результатов.

Данная выборка обладает той особенностью, что она собиралась в течение
достаточно длительного времени и в ней агрегирован самый разнородный
трафик. Поэтому в ней присутствует не только большое количество
<<коротких>> сообщений (что обычно для выборок из телетрафика), но и
некоторый массив сообщений средней длины, а также определенный
<<выброс>> больших сообщений. Это свидетельствует о \textit{пиковости}
телетрафика на довольно больших промежутках времени.

Как мы видим, ЕМ-алгоритм удачно справился с задачей идентификации
смеси.

\subsection{Выборка~2 ``Synterra''} %5.2.

Результаты применения ЕМ-алгоритма к выборке ``Synterra''
представлены в табл.~\ref{t2bat}.
\begin{table*}\small
\begin{minipage}[t]{76mm}
\begin{center}
\Caption{Результаты применения ЕМ-алго\-рит\-ма к выборке~1 ``Berkeley'' 
\label{t1bat}} \vspace*{2ex}

\tabcolsep=8.7pt
\begin{tabular}{|c|c|c|}
\hline
№&Начальное приближение&Результат\\
\hline
\multicolumn{3}{|c|}{$P$}\\
\hline
0&0,2&0,1896\\
1&0,2&0,1858\\
2&0,2&0,1830\\
3&0,2&0,2259\\
4&0,2&0,2154\\
\hline
\multicolumn{3}{|c|}{$\alpha$}\\
\hline
0&2,7028&10,9783\hphantom{9}\\
1&3,6273&5,8621 \\
2&5,7598&2,7092\\
3&0,2315&1,0235\\
4&0,9110&0,4772\\
\hline
\multicolumn{3}{|c|}{$\lambda$}\\
\hline
0&85,2066&137,1714  \\
1&23,9592&136,7349\\
2&63,8425&132,6482\\
3&\hphantom{9}1,8026&116,7317\\
4&98,3882&102,5278\\
\hline
\end{tabular}
\end{center}
\end{minipage}\hfill
\begin{minipage}[t]{76mm}
%\end{table*}
%\begin{table*}\small
\begin{center}
\Caption{Результаты применения ЕМ-алго\-рит\-ма к выборке~2 ``Synterra'' 
\label{t2bat}} \vspace*{2ex}

\tabcolsep=8.7pt
\begin{tabular}{|c|c|c|}
\hline
№&Начальное приближение&Результат\\
\hline
\multicolumn{3}{|c|}{$P$}\\
\hline
0&0,2&$0{,}3815\hphantom{{}\cdot 10^{-9}}$\\
1&0,2&$0{,}3594\hphantom{{}\cdot 10^{-9}}$\\
2&0,2&$0{,}2589\hphantom{{}\cdot 10^{-9}}$\\
3&0,2&$0{,}4401\cdot 10^{-9}$\\
4&0,2&$0{,}0\hphantom{{}\cdot 10^{-9}999}$\\
\hline
\multicolumn{3}{|c|}{$\alpha$}\\
\hline
0&6,0804&1,5833\\
1&3,1838&0,8554\\
2&1,4886&0,4557\\
3&4,6407&0,2278\\
4&3,7843&0,1139\\
\hline
\multicolumn{3}{|c|}{$\lambda$}\\
\hline
0&17,3387&15,8682\\
1&47,8294&16,9150\\
2&54,1984&19,2866\\
3&\hphantom{1}8,6254&19,2866\\
4&\hphantom{1}5,7252&19,2866\\
\hline
\end{tabular}
\end{center}
\end{minipage}
\end{table*}


Данные результаты иллюстрируют рис.~\ref{f7bat}.


Эти результаты также отражают действительную картину, как показано на
рис.~\ref{f8bat}.


Этот трафик был снят с базовой станции <<Лукойл-Юго-Запад>> сети
широкополосного радиодоступа ЗАО <<Синтерра>>. Сеть радиодоступа
является реализацией так называемой <<последней мили>>, переносящей два
разных вида трафика: данные (Ethernet пакеты) и голос (IP-телефония, VoIP).
Поэтому здесь присутствуют в качестве основной массы короткие, но
интенсивные сообщения (пакеты SIP и голосовые фреймы), а также длинные
сообщения, содержащие данные.

Как мы видим, программная реализация ЕМ-ал\-го\-рит\-ма успешно справилась с
задачей разделения смесей распределений для этих двух выборок, что делает
данную программу удобным инструментом построения стохастической картины
конкретной сети. По полученным данным, используя метод интерпретации,
предложенный в разд.~2, можно получить представление о количестве
последовательных и параллельных структур вероятностной модели сети.

\subsection{Режим <<скользящего окна>>} %5.3.

Результаты для выборки
``Berkeley'' в режиме <<скользящего окна>>  представлены
на рис.~\ref{f9bat}.


Данные графики показывают изменение параметров распределений подвыборок выборки 
``Berkeley''. Видно, что параметры распределений подвыборок не остаются 
неизменными во времени, наоборот, они имеют внешне случайный характер. На 
рис.~\ref{f9bat},\,\textit{в} видна даже своеобразная пульсация первой 
компоненты.
%
На основании расчетов можно сделать вывод о том, что пиковость трафика
обусловливается как формой, так и интенсивностью сообщений.

\section{Заключение}

В данной работе исследована вероятностная модель  информационных потоков,
возникающих в сложных телекоммуникационных конвергентных сетях, построенная с
помощью асимптотического и энтропийного подходов. Эта модель предполагает, что
функционирование сложной телекоммуникационной сети можно представить в виде
суперпозиции довольно простых стохастических структур~--- последовательных и
параллельных, которые по\-рож\-да\-ют смеси гамма-распределений для случайной
величины времени обработки и передачи сообщений в сети. Предложена простая
интерпретация параметров данной модели.
\begin{figure*} %fig5
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=130mm %145.109mm 
\epsfbox{bat-5.eps} }
\end{center}
\vspace*{-13pt} \Caption{Компоненты смеси начального приближения~(\textit{а}) и 
результата~(\textit{б}) для выборки~1 ``Berkeley'' \label{f5bat}}
%\end{figure*}
%\begin{figure*} %fig6
\vspace*{12pt}
\begin{center}
\mbox{%
\epsfxsize=130mm %148.256mm 
\epsfbox{bat-7.eps} }
\end{center}
\vspace*{-13pt} \Caption{График смеси распределений~(\textit{1}) и гистограмма 
для выборки~1 ``Berkeley''~(\textit{2}) \label{f6bat}}
\end{figure*}



\begin{figure*} %fig7
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=130mm %144.283mm 
\epsfbox{bat-8.eps} }
\end{center}
\vspace*{-16pt} \Caption{Компоненты смеси начального приближения~(\textit{а}) и 
результата~(\textit{б}) для выборки~2 ``Synterra'' \label{f7bat}}
%\end{figure*}
%\begin{figure*} %fig8
\vspace*{12pt}
\begin{center}
\mbox{%
\epsfxsize=130mm %148.256mm 
\epsfbox{bat-10.eps} }
\end{center}
\vspace*{-11pt} \Caption{График смеси распределений~(\textit{1}) и гистограмма
для выборки~2 ``Synterra''~(\textit{2}) \label{f8bat}}
\end{figure*}

\begin{figure*} %fig9
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=119.041mm
\epsfbox{bat-11.eps} }
\end{center}
\vspace*{-9pt} \Caption{Изменение  смешивающих параметров~(\textit{а}), 
параметров формы~(\textit{б}) и параметров масштаба~(\textit{в}) во времени для 
выборки~1 ``Berkeley'' \label{f9bat}}
\end{figure*}

Для решения вытекающей из модели задачи предложен итерационный алгоритм,
базирующийся на методе максимального правдоподобия~--- ЕМ-ал\-го\-ритм, для
которого получены формулы для конкретного вида смесей~--- экспоненциальных и
гамма-распределений.
%
Кроме того, разработан программный инструментарий для оценки параметров 
предложенной модели на выборках из реальных трафиковых данных. Проведены 
исследования, которые подтвердили предположения вероятностной модели. 


Получение информации о стохастической структуре
телекоммуникационных сетей и наличие программных инструментов для
выявления более или менее стабильных структур позволит понять причины
возникновения неожиданных больших нагрузок, предотвратить такие нагрузки,
а также поможет в будущем в проектировании надежных, оптимальных по
стоимости и уровню сервиса телекоммуникационных сетей нового поколения.

%\vspace*{-15pt} 
{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{9}
\bibitem{1bat}
Teletraffic Engeneering Handbook. International Telecommunication Union, 
Geneva, 2005 {\sf http://www.itu.int}. \vspace*{5pt} 
\bibitem{2bat}
\Au{Севастьянов~Б.\,А.} Курс теории вероятностей и математической статистики. 
М., 2004. \vspace*{5pt} 
\bibitem{3bat}
\Au{Айвазян~C.\,А., Бухштабер~В.\,М., Енюков~И.\,С, Мешалкин~Л.\,Д.} Прикладная 
статистика. Классификация и снижение размерности~// Финансы и статистика. М., 
1989. \vspace*{5pt} 
\bibitem{4bat}
\Au{Bilmes~J.\,A.} A gentle tutorial of the EM algorithm and its application to 
parameter estimation for Gaussian mixture and hidden Markov models. Berkeley, 
CA, USA: International Computer Science Institute,  1998. \vspace*{5pt} 
\bibitem{5bat}
\Au{Шлезингер~М.\,И.} О самопроизвольном различении образов~// Шлезингер~М.\,И. 
Читающие. автоматы. Киев: Наукова думка, 1965. С.~38--45. \vspace*{5pt} 
\bibitem{6bat}
\Au{Hsiao~I.-T., Rangarajan~A., Gindi~G.}. Joint-MAP 
reconstruction/segmentation for transmission tomography using mixture-models as 
priors. Yale University, 1998. \vspace*{5pt} 
\bibitem{7bat}
{\sf http://zedgraph.org}. \vspace*{4pt} 
\bibitem{8bat}
{\sf http://ita.ee.lbl.gov/html/contrib/LBL-PKT.html}. \vspace*{5pt} 
\bibitem{9bat}
{\sf http://www.synterra.ru}.
\end{thebibliography}

} } \label{end\stat}
\end{multicols}