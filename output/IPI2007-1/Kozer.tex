\def\stat{kozer}
\def\tit{
ЛИНГВИСТИЧЕСКОЕ МОДЕЛИРОВАНИЕ ДЛЯ СИСТЕМ
МАШИННОГО ПЕРЕВОДА И ОБРАБОТКИ ЗНАНИЙ}
\def\titkol{
Лингвистическое моделирование для систем
машинного перевода и обработки знаний}
\def\autkol{Е.\,Б.~Козеренко}
\def\aut{Е.\,Б.~Козеренко$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

\footnotetext[1]{ИПИ РАН, kozerenko@mail.ru}

\vskip 24pt plus 9pt minus 6pt


\Abst{Данная работа посвящена актуальным проблемам создания
семантико-синтаксических представлений для  систем машинного перевода и
извлечения знаний из естественно-языковых текстов. Целью наших
исследований является построение целостной лингвистической модели на
основе синергетического подхода, использующего лингвистические знания,
статистические методы  и механизмы машинного обучения для извлечения
новых грамматических правил из текстовых корпусов и разрешения
неоднозначности. Для формализации лингвистических знаний используется
когнитивная трансферная грамматика (КТГ), являющаяся семантически
мотивированным вариантом унификационно-порождающей грамматики. Для
подготовки обучающих компонентов систем и получения статистических
данных о языковых структурах создается многоязычный лингвистический
ресурс, представляющий собой банк синтаксических деревьев (Treebank) и
корпус семантически выровненных параллельных текстов на русском,
английском и ряде других европейских языков.}

\KW{машинный перевод; формальные грамматики;
лингвистическая модель; выравнивание параллельных текстов; семантика;
синтаксис; языковые структуры}

\vskip 24pt plus 9pt minus 6pt

\begin{multicols}{2}

\section{Введение}

Современный период развития исследований и разработок в области
машинного перевода и сис\-тем извлечения знаний из текстов характеризуется
интенсивным процессом <<гибридизации>> подходов и моделей.
Потребность в этом носит объективный характер. Значительные
вычислительные ресурсы современных систем позволяют накапливать и
использовать ранее переведенные текстовые фрагменты, обеспечивать
машинный перевод, основанный на прецедентах (``Example-Based Machine
Translation'')~[1--3], эффективно поддерживать
компоненту <<переводческой памяти>>
(``Translation Memory'')~[4--6].

\label{st\stat}

\thispagestyle{headings}

Создатели систем, основанных на правилах, вводят в правила различные
стохастические модели, которые позволяют отобразить динамику и разнообразие 
языковых форм и значений, по\-рож\-да\-емых в процессе речевой деятельности, а 
сторонники статистических методов построения лингвистических моделей все чаще 
обращаются к подходам, основанным на лингвистических знаниях, 
рас\-смат\-ри\-вая это как средства <<интеллектуализации>> систем~[4--8].

Машинный перевод и извлечение знаний из текстов~--- это разные задачи, каждая 
из которых задает свойственный именно ей фокус внимания к лингвистическим 
объектам. Извлечение знаний (фактографической информации) из текстов и 
построение информационных систем поддержки аналитических решений (ИСПАР) 
требует проработки лексико-семантических представлений, создания развитых 
тезаурусов и онтологий, пред\-мет\-но-ори\-ен\-ти\-ро\-ван\-ных семантических 
словарей.

Для машинного перевода наиболее сложной проблемой является
реализация языковых трансформаций, которые необходимо производить при
переводе с одного языка на другой. Текущий этап развития систем
машинного перевода характеризуется исследованиями в области
когнитивной семантики, вероятностных языковых моделей и разработкой
семантико-синтаксических пред\-став\-ле\-ний, учитывающих многозначность и
неоднозначность синтаксических структур. Новое содержание проблеме
языковых трансформаций придают современные реалии: необходимость
проектировать и развивать обучающие компоненты систем машинного
перевода и обработки текстовых знаний на основе уже существующих и
вновь со\-зда\-ющих\-ся корпусов параллельных текстов.

При создании компьютерных моделей русской грамматики доминировали
подходы, основанные на грамматиках зависимостей~\cite{9koz}  или
локально-синтаксических представлениях, при этом не разрабатывались
грамматики составляющих. Основные причины этого~--- как объективные:
русский язык характеризуется относительно свободным порядком слов в
предложении, так и субъективные:  точка зрения на Хомскианские
грамматики как на грамматики, применимые только для английского языка и
других языков с фиксированным порядком слов.

Предлагаемый нами подход дает возможность компактного представления структуры 
со\-став\-ля\-ющих предложения (грамматика фразовых структур), с одной стороны, 
а с другой стороны~--- учитывает механизмы зависимости между узлами дерева 
предложения. Эта система формальной грамматики, получившая название КТГ, дает 
возможность строить такие алгоритмизируемые представления, которые не ведут к 
экспоненциальному росту правил и вычислительных затрат.

\section{Когнитивная трансферная грамматика}

Основу КТГ составляют
прототипические структуры исследуемых языков (в исходной модели~---
русского и английского), их наиболее вероятные позиции в предложении,
статистические данные о дистрибутивных характеристиках структур (т.е.\
информация о контекстных условиях употребления ис\-сле\-ду\-емых
объектов~---  о структурных контекстах), схемы полного разбора
предложений.

Создание и развитие КТГ предполагает:
\begin{itemize}
\item семантический подход к анализу языкового значения и языковой
формы (форм);
\item построение формально-грамматических представлений с учетом
структур составляющих и механизмов линеаризации, а также отношений
зависимости между узлами синтаксического дерева (подход, имеющий черты
сходства с HPSG~\cite{10koz}: наследование признаков через головные
вершины фразовых структур);
\item  включение вероятностных характеристик языковых объектов;
\item создание пространств когнитивного трансфера (ПКТ),
сформированных в виде экспертных лингвистических правил и
расширяемых посредством выявления  изосемичных языковых структур в
параллельных текстах на различных языках.
\end{itemize}

В отличие от подходов на основе <<переводческой памяти>> (``Translation
Memory''), реа\-ли\-зу\-ющих возможность наращивания языковой компетенции
сис\-те\-мы за счет ранее переведенных текстовых фрагментов и в значительной
степени основанных на аппарате регулярных выражений, КТГ предназначена для 
реализации механизма {\bfseries\textit{структурной памяти}},  который 
моделирует языковую компетенцию взрослого обучаемого (``Adult Learning 
Memory''). Таким образом, \textit{структурная память} предполагает следующие 
компоненты:
\begin{enumerate}[(1)]
\item исходный базовый набор грамматических правил, представленных в
формализованном виде (КТГ);
\item механизмы расширения и уточнения системы правил, которые
реализуются посредством методов машинного обучения на параллельных
текстах.
\end{enumerate}

Наши исследования в значительной степени базируются на концепциях
функционального подхода, который был применен нами для многоязычной ситуации. 
При разработке лингвистического процессора, обеспечивающего англо-русский и 
русско-английский трансфер, нами было предложено понятие полей функционального 
переноса (ПФП)~\cite{11koz, 12koz}, явившихся базисом сегментации языковых 
структур для решения задач машинного перевода. Основная идея такого поля 
состоит в принятии гипотезы о том, что в основе грамматических структур лежат 
структуры когнитивные (ментальные фреймы); функционально-семантическое поле 
отражает взаимодействие элементов разных языковых уровней~\cite{12koz}. В 
результате формализации описания синтаксических и семантических свойств полей 
функционального переноса была разработана грамматика когнитивного переноса, или 
КТГ~\cite{11koz}. В настоящее время понятие  полей функционального переноса 
расширено для многоязычной ситуации, и мы используем понятие ПКТ. Основной 
конструктивной единицей ПКТ является \textit{трансфема}. 
{\looseness=-1

}

{\bfseries\textit{Трансфема}}~--- {\sf это единица когнитивного пе\-рено\-са, 
т.е. переводимое смысловое целое в единстве своих категориальных и 
функциональных характеристик, устанавливающая семантическое соответствие между 
языковыми структурами, принадлежащими различным языковым уровням и языковым 
сис\-те\-мам.}

{\bfseries\textit{Типы трансфем}} определяются {\bfseries\textit{рангом
транс\-фемы}}:
\begin{itemize}
\item ранг 1~--- лексема как структурный знак, т.е. слово, рассматриваемое
как ка\-те\-го\-ри\-аль\-но-функ\-цио\-наль\-ная единица без учета конкретного 
лексического значения данного слова;
\item ранг 2~--- словосочетание, т.е.  синтаксическая структура, состоящая
из двух и более синтаксически связанных слов, но не являющаяся
законченным предложением или клаузой;\\[-10pt]
\item ранг 3~--- клауза, т.е. зависимое (придаточное) предложение;\\[-10pt]
\item ранг 4~--- независимое предложение (простое предложение или
главное предложение сложноподчиненного предложения);\\[-10pt]
\item ранг 5~--- рассеянная структура, т.е. группа слов, обладающая
синтактико-семантическим единством, но не расположенная контактно,
т.е.\ между членами группы появляются другие языковые объекты, не
являющиеся членами этой группы;\\[-10pt]
\item ранг 0~--- морфологические единицы, не яв\-ля\-ющие\-ся
самостоятельными словами, а входя\-щие в состав лексем исходного языка, которые 
на языке перевода могут быть вы\-ра\-жены единицами других рангов, например: 
суффикс\;$\rightarrow$\;клауза 
(\textit{implementable}\;$\rightarrow$\;\textit{который может быть 
реализован}).
\end{itemize}

Построена целостная система межъязыковых соответствий русского и
английского языков как модуль синтактико-семантических структурных
моделей для лингвистического процессора автоматического перевода
методом трансфера~\cite{11koz, 12koz}.

\section{Функциональный подход к~лингвистическому
моделированию}

Разработка понятия функции, являющегося центральным в
функциональной грамматике, связана с широкой проблематикой функций
языка~[13--21]. Функции
связаны со значениями языковых единиц, но они не тождественны им.
Исследование функции некоторой языковой формы включает анализ ее
значения (или ряда значений в случае многозначности).

На современном этапе лингвистических исследований и разработок
необходимо синергетическое сочетание функционального и уровневого
подходов. Функциональный подход интегрирует разноуровневые языковые
средства (синтаксические, лексические, словообразовательные и
словоизменительные) на основе их функционально-семантических
характеристик.

Отношение между понятиями \textit{категория} и \textit{функция} можно иначе 
выразить как \textit{исходное структурное значение} и \textit{реализуемое 
структурное значение}. Подобная концепция была высказана Леонардом Блумфилдом в 
его работе <<Язык>>. Так, с точки зрения Л.~Блумфилда, каждая лексическая форма 
связана с грамматическими формами в двух направлениях. С одной стороны, 
лек\-си\-че\-ская форма, даже когда она взята сама по себе, абстрагированно, 
обнаруживает значимую грамматическую \textit{структуру}. С другой стороны, 
лексическая форма в любом конкретном высказывании, являясь особой языковой 
формой, всегда сопровождается той или иной грамматической формой. Она выступает 
в определенной функции, и случаи, в которых преимущественно данная лексическая 
форма встречается, составляют в совокупности ее грамматическую функцию. 
Лексические формы, выпол\-ня\-ющие какие-либо общие функции, принадлежат к 
одному формальному классу. На основе различных функций могут возникать частично 
совпадающие формальные классы. Так, выполнение функции действующего лица 
характерно для субстантивных выражений и для типично инфинитивных 
словосочетаний (\textit{to scold the boys would be foolish} <<бранить мальчиков 
было бы глупо>>)~\cite{22koz}. {\looseness=1

}

Здесь Блумфилд называет функцией дей\-ст\-ву\-юще\-го лица субъектную
функцию, тем самым подчеркивая ее <<именной>> характер. То есть
функциональная потенция <<быть субъектом предложения>> исходно заложена
в категории имени существительного. Глагольная же единица (в данном
случае инфинитив), исполняя функцию, свойственную имени, как бы
<<надевает>> на себя новую~--- именную форму~--- поверх своей исходной,
глагольной.

Таким образом, получается \textit{композиционная категория}
Глагол--Имя, или VerbNoun в нотации КТГ~\cite{12koz}.

Грамматика данного типа рассматривает в единой системе средства,
относящиеся к разным языковым уровням, но объединенные на основе их
семантических функций; при описании языкового материала используется
подход <<от семантики к ее формальному выражению>> (<<от функций  к
средствам>>) как основной, определяющий построение грамматики, в
сочетании с подходом <<от формы к семантике>> (<<от средств к
функции>>).  Под единицами строя языка подразумеваются, прежде всего,
грамматические формы слова и синтаксические конструкции, а также
единицы <<строевой лексики>> (по Л.\,В.~Щербе)~\cite{23koz}:
модальные и фразовые глаголы, слова типа \textit{вчера, обычно, часто,
прежде, долго} и~т.п.

Степанов~Ю.\,С.~\cite{21koz} вводит понятие функтора как языкового средства 
транспозиции одного множества языковых единиц в другое множество языковых 
единиц того же языка. Функция есть свойство или значение функтора. Приводится 
пример функции: если принять за исходное множество единиц русские глаголы типа 
\textit{сообщать}, \textit{выражать}, \textit{исполнять} и~т.п., а за 
производное множество единиц \textit{сообщение}, \textit{выражение}, 
\textit{исполнение} и нечто \textit{сообщается}, \textit{исполняется}, то 
отношение первого множества ко второму будет функцией, а языковые формы 
\textit{-ение, нечто~---   -(ает)ся} будут языковыми средствами этой функции, 
функторами.

Понятие функции является одним из центральных в коммуникативной
грамматике Г.\,А.~Золотовой. Функция~--- это предназначенность элемента к
определенному способу существования в системе, к определенному
служению этой системе~\cite{24koz}. Если за целое принимаем
предложение в его коммуникативном назначении, то функции его элементов,
его составных частей определяются как их строительные, комбинаторные
потенции, реализуемые в построении предложения.

Функции реализуются при взаимодействии языковых объектов и их
контекстов.

Для рассмотрения семантики способов конфи\-гу\-ри\-ро\-ва\-ния языковых 
структур мы пользуемся понятием структурного знака~\cite{25koz}, предложенным в 
семиотической лингвистике С.\,К.~Шаумяном. При этом слово также рассматривается 
нами не с точки зрения его лексического зна\-чения, а как 
функционально-категориальная единица, мини\-маль\-ный структурный знак. Такой 
подход прини\-ма\-ет\-ся нами как определенный этап исследований структурных 
знаков, продиктованный не\-об\-хо\-ди\-мостью максимально полного извлечения 
семан\-ти\-че\-ской информации из возможных способов конфигурирования языковых 
объектов и изучения когнитивных механизмов линеаризации языковых структур.

Семиотическая лингвистика вводит понятие \textit{суперпозиции
функций}, полагая, что каждый языковой объект обладает исходной
\textit{первичной} функцией, а происходящие в действующем языке сдвиги
значений~--- это наложение вторичной и других функций на исходную.
Таким образом, использование инструмента суперпозиции
категорий~\cite{26koz, 27koz} дает возможность выразить функциональные
свойства языковых объектов.

\section{Изофункциональные трансформации при~переводе}

Функциональный подход, исследующий отношения <<функциональной
синонимии>> разнородных и разноуровневых единиц языка, чрезвычайно
актуален в настоящий момент, когда проводятся эксперименты по
выявлению изофункциональных и изосемичных языковых структур из
параллельных текстовых корпусов. Именно этот подход позволяет найти
соответствия в текстах на разных языках. В самом деле, заранее нельзя с
полной достоверностью определить, каким именно образом была переведена
та или иная языковая структура в текстовом корпусе. Поэтому необходимо
строить и исследовать различные гипотезы при проектировании
лингвистического процессора.

Отсутствие полного совпадения между английскими и русскими
языковыми конструкциями в научно-технических текстах можно обнаружить
при изучении сравнительной частоты употребления в них отдельных частей
речи, что важно для построения систем перевода, использующих машинное
обучение.

Для научного изложения в целом характерен признак номинативности, т.е.\ более 
широкое использование существительных, чем в других функциональных стилях. При 
этом сопоставительный анализ переводов показывает, что в русском языке эта 
тенденция выражена более четко, и при пе\-ре\-воде английские глаголы нередко 
заменяются суще\-ст\-ви\-тель\-ны\-ми. Проведенные нами статистические 
исследования параллельных текстов позволяют сделать вывод о том, что русский 
текст приблизительно на 35\% более номинативен, чем английский. Рассмотрим 
следующие примеры глагольно-именных трансформаций при англо-русском переводе.
\begin{enumerate}[(1)]
\item \textit{The fuel system is designed to store liquid gasoline and to deliver
it to the engine cylinders in the form of vapor mixed with air.}

\textit{Система питания предназначается для заправки жидким
топливом и подачи его в цилиндры в виде смеси паров бензина с
воздухом.}

\textit{to store and to deliver}\;$\rightarrow$\;\textit{для заправки и подачи}
\item \textit{A similar approach has marked the EU's efforts to expand the
current club of 15 countries to embrace former communist countries further
east}.

\textit{Точно таким же подходом характеризуются усилия ЕС по
расширению нынешнего клуба 15 стран дальше на восток путем
присоединения к нему бывших коммунистических стран.}

\textit{to embrace}\;$\rightarrow$\;\textit{по расширению}
\end{enumerate}

Нами были проведены исследования на материале имеющихся в нашем распоряжении 
параллельных переводов научных статей и отдельно взятых примеров высказываний с 
исследуемыми конструкциями, а также мы обращались к опросу 
экспертов-переводчиков. Наиболее продуктивные типы глагольно-именных 
трансформаций при англо-русском переводе коррелируют со сле\-ду\-ющи\-ми 
функциональными значениями.

{\sf Обстоятельства цели и следствия, выраженные инфинитивом (58\% в
письменных переводах и 71\% при опросе
респондентов\,--\,профессиональных переводчиков):}


\begin{enumerate}[(1)]
\setcounter{enumi}{2}
\item  \textit{In order to understand the phenomenon, one should consider
the laws of motion.}

\textit{Для понимания этого явления надо рас\-смот\-реть законы
движения.}

\textit{In order to understand}\;$\rightarrow$\;\textit{Для понимания }
\end{enumerate}

{\sf Составное сказуемое с инфинитивом (be\;+\;ин\-фи\-ни\-тив) (51\% в
письменных переводах и 59\%~--- при опросе
респондентов\,--\,профессиональных переводчиков):}

\begin{enumerate}[(1)]
\setcounter{enumi}{3}
\item \textit{The difficulty will be to obtain the substance in question.}

\textit{Трудность будет состоять в получении рас\-смат\-ри\-ва\-е\-мо\-го 
вещества.}

\textit{to obtain}\;$\rightarrow$\;\textit{в получении}
\end{enumerate}

{\sf Инфинитив после относительных местоимений which и whom с предшествующим 
предлогом час\-то пе\-ре\-во\-дит\-ся отглагольным существительным с предлогом 
\textsl{для}; в этом случае относительное местоимение с предлогом не 
переводится (48\% в письменных переводах и 52\% при опросе 
рес\-пон\-ден\-тов\,--\,про\-фес\-сио\-наль\-ных переводчиков):}
\begin{enumerate}[(1)]
\setcounter{enumi}{4}
\item \textit{In vacuum, molecules have large space in which to move.}

\textit{В вакууме молекулы имеют большое пространство для
движения.}

\textit{in which to move}\;$\rightarrow$\;\textit{для движения}
\end{enumerate}

{\sf Адъективные трансформации инфинитива (существительное\;+\;инфинитив в 
определительной функции) (практически 100\% в обоих случаях):}
\begin{enumerate}[(1)]
\setcounter{enumi}{5}
\item \textit{The amount of polonium to be obtained from a uranium
mineral can be simply calculated.}

\textit{Количество полония, которое должно быть получено из урана,
можно довольно просто подсчитать. }

\textit{to be obtained}\;$\rightarrow$\;\textit{которое должно быть
получено}
\end{enumerate}

{\sf Инфинитив в функции второго дополнения (глаголы} \textit{cause},
\textit{get}, \textit{lead}, \textit{make}\;+\;{\sf инфинитив) (42\% в
письменных переводах и 58\% при опросе 
рес\-пон\-ден\-тов\,--\,про\-фес\-сио\-наль\-ных переводчиков):}
\begin{enumerate}[(1)]
\setcounter{enumi}{6}
\item \textit{Pressure causes ice to melt.}

\textit{Давление приводит к таянию снега.}

\textit{to melt}\;$\rightarrow$\;\textit{к таянию}
\end{enumerate}

{\sf Инфинитив, стоящий в начале предложения и выполняющий функцию подлежащего 
(31\% в письменных переводах и 44\% при опросе 
рес\-пон\-ден\-тов\,--\,про\-фес\-сио\-наль\-ных переводчиков):}
\begin{enumerate}[(1)]
\setcounter{enumi}{7}
\item \textit{То define exactly what is meant by the total heat in a body is
at present still not possible.}

\textit{Точное определение того, что имеется в виду под общим
нагревом тела, в настоящий момент все еще невозможно.}

\textit{То define exactly}\;$\rightarrow$\;\textit{Точное определение}
\end{enumerate}

{\sf Оборот <<for\;+\;существительное\;+\;инфинитив>> выполняет функции 
различных членов предложения (в научной литературе чаще всего функции 
обстоятельства цели или следствия)~--- 32\% в письменных переводах и 43\% при 
опросе рес\-пон\-ден\-тов\,--\,про\-фес\-сио\-наль\-ных переводчиков:}
\begin{enumerate}[(1)]
\setcounter{enumi}{8}
\item \textit{The temperature was too low for the substance to
decompose.}

\textit{Температура была слишком низкой для разложения этого
вещества.}

\textit{to decompose}\;$\rightarrow$\;\textit{для разложения}
\end{enumerate}

Система правил трансфера для англо-русского машинного перевода вначале была 
построена по принципу одновариантных правил, когда соответствие подбиралось как 
наиболее широкий способ перевода некоторой конструкции, пусть не всегда 
совершенно грамматичный, однако же обеспе\-чи\-ва\-ющий <<понятность>> перевода 
в наибольшем числе случаев~\cite{10koz}. При этом подходе предпочтение 
отдавалось всегда тому вари\-ан\-ту, который был по форме ближе всего к 
исходной анг\-лий\-ской конструкции: для того, чтобы избежать трансформаций при 
пе\-ре\-во\-де, которые всегда приводят к появлению <<шумов>> и резкому 
увеличению вычислительных затрат и, соот\-вет\-ст\-вен\-но, программистских 
усилий. Одна\-ко в насто\-ящее время нами разработана систе\-ма многовариантных 
правил трансфера фра\-зовых структур, при этом функциональные значения языковых 
единиц отражены в расширенной сис\-те\-ме  
ка\-те\-го\-ри\-аль\-но-функ\-цио\-наль\-ных атрибутов. Языко\-вые 
струк\-ту\-ры представлены в виде иерар\-хии правил КТГ, которая является 
раз\-но\-вид\-ностью уни\-фи\-ка\-ци\-он\-но-по\-рож\-да\-ющей 
грам\-ма\-ти\-ки. Структуры атрибутов и значений и их преобра\-зо\-ва\-ния 
задаются в виде кон\-тек\-с\-т\-но-сво\-бод\-ных и мягко 
кон\-тек\-с\-т\-но-за\-ви\-си\-мых продукционных правил. Отношения зависимости 
реализуют\-ся через механизм головных вершин фразовых структур, а сами фразовые 
структуры задают линейные последовательности языковых 
объ\-ек\-тов~\cite{28koz}. {\looseness=2

}

\section{Многовариантный перевод\newline и композиционные
категории}

Инструментом задания категориальных и функциональных значений
языковых структур служат композиционные категории. Метод построения
композиционных категорий позволяет реализовать суперпозицию
категориальных значений языковых объектов для осуществления
многовариантного перевода. Так, \textit{герундий} мы относим к категории
``\textit{VerbNounIng}'', инфинитив в субъектной функции~--- к
``\textit{toPlusInfinitiveSubj}'', инфинитив в объектной функции~--- к
``\textit{toPlusInfinitiveObj}'', русское деепричастие и английское Participle~I
в адвербиальной функции~--- к категории ``\textit{ParticipleAdv}'', личные
формы глагола~--- к ``\textit{VerbFinit}'', используются также и другие
категории:

\noindent
$\{$[Category: \textit{VerbNounIng}]: \textit{asking questions}$\}$;

\noindent
$\{$[Category: \textit{toPlusInfinitiveSubj}]: \textit{She} is known \textit{to be a
skilled typist}$\}$;

\noindent
$\{$[Category: \textit{toPlusInfinitiveObj}]: \textit{We feel them to be sensitive
readers}$\}$.

Разработаны многовариантные правила 
функ\-цио\-наль\-но-се\-ман\-ти\-че\-ско\-го переноса, посредством которых 
задаются наиболее вероятные способы перевода рассматриваемых языковых структур. 
Например,  инфинитивные конструкции в функции обстоятельства цели/следствия 
могут переводиться следующим  образом:
\begin{enumerate}[(1)]
\setcounter{enumi}{9}
\item \textit{Hydrogen and oxygen unite to form water.}

\textit{Водород и кислород соединяются, образуя воду.}

\textit{Водород и кислород соединяются и образуют воду.}

\textit{Водород и кислород соединяются с образованием воды.}

Схема многовариантного англо-русского трансфера инфинитивной
конструкции \textit{to form water} будет выглядеть следующим образом.

[Category: \textit{VerbInf}]\;$\rightarrow$\;$\{$\textit{to form water}$\}$

OR

$\{$[Category: \textit{ParticipleAdv}]; $\{$\textit{образуя воду}$\}$

[Category: \textit{VerbFinit}]; $\{$\textit{образуют воду}$\}$

[Category: \textit{VerbNounIng}]$\}$ $\{$\textit{с образованием
воды}$\}$
\end{enumerate}

В следующем примере инфинитивный оборот соотнесен с ранее стоящим наречием 
\textit{too} и выполняет функцию обстоятельства следствия:
\begin{enumerate}[(1)]
\setcounter{enumi}{10}
\item \textit{The temperature was too low for the substance to}
decompose.

\textit{Температура была слишком низкой для разложения этого
вещества.}

\textit{Температура была слишком низка, для того чтобы вещество
разложилось.}

\textit{Температура была слишком низка, для того чтобы вещество
могло разложиться.}

\textit{Температура была слишком низка, и разложения вещества не
произошло.}
\end{enumerate}

Схему трансфера данной инфинитивной конструкции можно представить
в виде следующих правил:

\noindent
[Category: \textit{VerbInf}]\;$\rightarrow$~OR~  $\{$[Category:
\textit{VerbNounIng}];

\noindent
[Category: \textit{VerbFinit}]; [Category:
\textit{VerbModalPhrase}];

\noindent
[Category: \textit{SentenceNeg}]$\}$.

При осуществлении анализа предложений и последующей свертки
сегментов конструкций в узлы для последующего трансфера этим узлам
будут присваиваться соответствующие метки (\textit{VerbNounIng},
\textit{SentenceNeg} и~т.д.), которые запускают необходимые процедуры
трансформаций при переводе.

\section{Исследование транскатегориальных переносов в
существующих системах машинного перевода}

Мы рассмотрели примеры перевода предложений с герундиальными и инфинитивными 
оборотами с английского языка на русский су\-ще\-ст\-ву\-ющи\-ми машинными 
переводчиками. В большинстве систем доминирует подход, состоящий в том, чтобы 
выбирать эквивалент, наиболее близкий по форме к исходной языковой конструкции. 
Однако отчетливо прослеживается тенденция к включению трансформаций, даже если 
это не всегда пока еще улучшает качество перевода. Следует отметить, что имеет 
место большое сходство переводов в системах, основанных на совершенно различных 
принципах, что указывает на ситуацию интенсивной диффузии систем машинного 
перевода и различных подходов к лингвистическому моделированию. Рассмотрим 
примеры перевода предложений с герундиями в сис\-те\-мах, которые в настоящее 
время лидируют в области англо-русского и русско-английского машинного 
перевода. Исходное предложение и его переводы, сделанные 
человеком-переводчиком:
\begin{enumerate}[(12)]
\item \textit{Не could not help joining the discussion.}

\textit{Он не мог не принять участия в обсуждении.}

\textit{Он не мог не выступить в прениях.}
\end{enumerate}

Переводы предложения~(12) существующими системами машинного
перевода:

\noindent
\textit{Он не смог помочь соединить обсуждение. (Babelfish)}

\noindent
\textit{Он не смог помогать соединению дискуссии. (ЭТАП)}

\noindent
\textit{Он не мог сдержать присоединение к обсуждению. (ПроМт)}

\noindent
\textit{Он не мог помочь присоединяясь к обсуждению. (CognitiveTroll)}

\noindent
\textit{Он не мог сдержать присоединение к обсуждению. (SDL)}

\section{Вероятностные методы грамматического разбора
предложений и~выравнивания параллельных текстов}

Истоки стохастической исследовательской парадигмы находятся в
проектах разработки алгоритмов распознавания речи, символов, исправления
орфографии. Основным методом решения многих задач, в частности
определения и разметки час\-тей речи, вероятностного грамматического
разбора,  является правило Байеса. В архитектуре стохастических систем, в
основном, используется алгоритм динамического программирования.

Машинное обучение в значительной степени основано на стохастической
исследовательской парадигме. Алгоритмы обучения могут быть двух типов:
неуправляемые и управляемые. Не\-управ\-ля\-емый алгоритм должен вывести
модель, пригодную для обобщения новых данных, которые ему ранее не
предъявлялись, и этот вывод должен быть основан только на данных. Управляемый 
же алгоритм обучается на множестве правильных ответов на данные из обучающей 
выборки таким образом, что выведенная модель даст более точные решения. Целью 
машинного обучения является автоматический вывод модели для некоторой области 
на основе данных из этой области, таким образом, система, обучаемая, например, 
синтаксическим правилам, должна быть обеспечена базовым набором правил фразовых 
структур. В последнее время больше внимания исследователей было уделено 
построению N-грам\-мов, от\-ра\-жа\-ющих сложности синтаксических и 
семантических структур~\cite{29koz, 30koz}, применению N-грам\-мов переменной 
длины~\cite{31koz}, включению семантической информации в N-грам\-мы: в 
работе~\cite{32koz} дается детальное описание подхода к созданию 
статистического машинного перевода, основанного на N-грам\-мах двуязычных 
единиц, называемых <<кортежами>>, а также четырех специальных атрибутных 
функций. Авторы иллюстрируют свой метод примерами переводов материалов 
заседаний Европарламента с английского языка на испанский и с испанского на 
английский.

Статистические методы обработки естественного языка расширяют схему основных 
су\-ще\-ст\-ву\-ющих подходов к машинному переводу~--- прямого перевода, 
переноса (трансфера) и подхода на основе языка-посредника 
(интерлингвы)~\cite{33koz, 34koz}. Машинный перевод на основе статистики был 
впервые предложен в~\cite{35koz, 36koz}.

Значения вероятностей для каждого возможного варианта грамматического
разбора (т.е.\ развертывания нетерминального узла) вычисляются на основе
частот встречаемости таких вариантов разбора в существующих текстовых
корпусах с синтаксической разметкой (treebanks). Значения вероятностей для
вариантов разбора могут быть также получены и в виде лингвистических
экспертных оценок.

Для любой системы обработки естественного языка необходимо
проектирование модуля определения и разметки частей речи (тэггера).
Стохастические тэггеры появились в 1980-е годы. Их общая идея
заключается в выборе наиболее вероятного тэга (т.е.\ частеречной метки) для
данного слова. Чаще всего для вероятностных тэггеров используются
Марковские модели. Так, например, для некоторого данного предложения
или последовательности слов выбирается последовательность тэгов, которая
максимизирует следующую фор\-мулу:
$$
P(\mbox{\textit{слово}}\vert \mbox{\textit{тэг}}) * P(\mbox{\textit{тэг}}\vert 
\mbox{\textit{предыдущие}}\ n\ \mbox{\textit{тэгов}})\,.
$$

Еще один подход к машинному обучению, основанный на правилах и
стохастическом тэггировании (разметке частей речи), известен как обучение,
основанное на трансформациях (Transformation-Based Learning, TBL).
TBL~--- это метод управ\-ля\-емо\-го обучения с использованием заранее
размеченного обучающего корпуса.

Для вероятностного грамматического разбора применяются
стохастические грамматики.
\begin{itemize}
\item Вероятностная контекстно-свободная грамматика, ее определение:
$$
G = (N,T,P,S,D)\,.
$$

Здесь $N$~--- это множество нетерминальных символов; $T$~---
множество терминальных символов; $P$~--- множество продукций вида
$A\rightarrow b$, где $A$~--- это нетерминальный символ, $b$~--- это
цепочка символов; $S$~--- специальный исходный символ; $D$~---
функция, приписывающая значения вероятности каж\-до\-му правилу из
множества~$P$. Как получить необходимые данные для вероятностной
контекстно-свободной грамматики? Один из путей~--- использование
корпуса синтаксически размеченных предложений. Такой корпус называется
банком синтаксических деревьев (treebank). Например, Penn
Treebank~\cite{37koz}  содержит деревья разбора для ряда текстовых
корпусов (Brown Corpus, Switchboard corpus). Если задан банк деревьев
разбора, то вероятность каж\-дой развертки некоторого нетерминального узла
может быть вычислена путем подсчета числа раз, когда данная развертка
встречается, с последующей нормализацией:
\begin{multline*}
P\left(\alpha\rightarrow \beta \vert \alpha\right) = \fr{Count (\alpha 
\rightarrow \beta
)}{\sum_\gamma Count (\alpha \rightarrow \gamma )} ={}\\
{}= \fr{Count (\alpha\rightarrow \beta )}{Count (\alpha )}\,. 
\end{multline*}
\item Вероятностная грамматика замещения деревьев:
является обобщением вероятностной контекстно-свободной грамматики, при
этом более мощной стохастически, поскольку можно приписывать значения
вероятности фрагментам или даже целым схемам разбора.
\end{itemize}

Статистические подходы к выравниванию параллельных текстов
направлены на то, чтобы найти наиболее вероятный вариант выравнивания
$A$ для двух заданных параллельных текстов $S$ и~$T$:
$$
\mathrm{arg}\ \underset{A}{\max}\  P (A\vert S,\,T) =
\mathrm{arg}\  \underset{A}{\max}\  P(A,S,T)\,.
$$

Для того чтобы оценить значения вероятностей, которые указаны в этом
выражении, чаще всего применяются методы, которые пред\-став\-ля\-ют
параллельные тексты в виде последовательности выравниваемых цепочек
предложений ($B_1, \ldots , B_K$).  При этом предполагается, что вероятность
одной цепочки не зависит от вероятностей других цепочек, а зависит только
от предложений в данной цепочке~\cite{38koz}. Тогда
$$
P(A,S,T) \approx \prod\limits_{k=1}^K P(B_k)\,.
$$

Этот метод просто учитывает длину предложения на исходном языке и на
языке перевода, измеренную в символах. Предполагается, что более длинное
предложение одного языка будет соответствовать более длинному
предложению другого языка. Такой подход дает вполне устойчивые
результаты для сходных языков и буквального перевода.

Более тонкие механизмы сопоставления обеспечиваются методами
лексического выравнивания. Так, в работе~\cite{39koz} представлен
метод выравнивания посредством создания модели последовательного
пословного перевода. Наилучшим результатом выравнивания будет тот,
который максимизирует вероятность порождения корпуса при заданной
модели перевода. Для выравнивания двух текстов $S$ и $T$ необходимо
разбить их и представить в виде последовательности цепочек предложений.
Цепочка содержит ноль или более предложений на каждом из языков, а
последовательность цепочек покрывает весь корпус:
$$
B_k = (S_{a_k},\ldots , S_{b_k};\ t_{c_k},\ldots , t_{d_k})\,.
$$

Затем наиболее вероятное выравнивание $A=$\linebreak
$=B_1,\ldots , B_{m_A}$
данного корпуса определяется следующим выражением (при этом цепочки
предложений не зависят друг от друга):
$$
\mathrm{arg}\ \underset{A}{\max}\ P(S,T,A) = \mathrm{arg}\
\underset{A}{\max}\ P(L)\prod\limits_{k=1}^{m_A} P(B_k)\,,
$$
где $P(L)$ означает вероятность того, что порождается выравнивание~$L$
цепочек. Модель перевода, используемая при этом подходе, предельно
упрощена и не учитывает фактор порядка слов в предложении и возможность
того, что слову в исходном тексте может соответствовать более, чем одно
слово в тексте перевода. В этой модели используются цепочки слов, при этом
они ограничены соответствиями 1:1, 0:1 и 1:0. Суть модели заключается в
том, что, если некоторое слово обычно переводится словом другого языка, то
вероятность соответствия цепочек слов 1:1 будет высокой~--- значительно
выше, чем произведение вероятностей соответствий 1:0 и 0:1 цепочек слов,
использующих это рассматриваемое слово. При этом программа выбирает
наиболее вероятный вариант выравнивания.

Модель перевода, основанная на пословном выравнивании (например,
русского и английского параллельных текстов) будет выглядеть следующим
образом:
$$
P(r\vert e ) = \fr{1}{Z} \sum\limits_{a_1=0}^l\ldots \sum\limits_{a_m=0}^l
\prod\limits_{j=1}^m P(r_j\vert e_{a_j})\,,
$$
где $e$~--- предложение на английском языке; $l$~--- длина $e$, выраженная в 
словах;  $r$~--- предложение на русском языке; $m$~--- длина $r$; $r_j$~--- 
$j$-тое слово в $r$; $a_j$~--- позиция в $e$, с которой выравнивается $r_j$; 
$P(w_r\vert w_e)$~--- \textit{вероятность перевода}, т.е. вероятность того, что 
мы увидим $w_r$ в предложении на русском языке, если мы встретим 
со\-от\-вет\-ст\-ву\-ющее $w_e$ в английском предложении; $Z$~--- константа 
нормализации.

Для конкретного выравнивания перемножаются $m$ вероятностей
переводов, при этом отдельные переводы не зависят один от другого. Так,
например, если необходимо вычислить вероятность:
$$
P(\mbox{\textit{Анна}}\vert \mbox{\textit{Ann}})\times 
P(\mbox{\textit{видела}}\vert \mbox{\textit{saw}})\times 
P(\mbox{\textit{Париж}}\vert \mbox{\textit{Paris}}),
$$
для выравнивания $(\mbox{\textit{Анна}}\vert \mbox{\textit{Ann}})$, 
$(\mbox{\textit{видела}}\vert \mbox{\textit{saw}})$, 
$(\mbox{\textit{Париж}}\vert \mbox{\textit{Paris}})$ следует перемножить 
вероятности этих трех переводных соответствий. При этом для каждого 
выравнивания делаются два упрощающих допущения: каждое русское слово 
порождается ровно одним английским словом (которое может быть нулевым, т.е. 
отсутствовать), и по\-рож\-де\-ние каждого русского слова не зависит от других 
порождаемых слов в русском предложении.

Однако выше описанный подход, основанный на пословном
сопоставлении и никак не учитывающий связи между словами и фразами, не
дает оптимальных результатов при выравнивании русскоязычных и
англоязычных текстов, поскольку между этими языками имеют место
определенные структурные различия и при переводе могут осуществляться
значительные трансформации.

Если рассматриваемые языки структурно отличаются, применяются
методы, ориентированные на привлечение грамматических знаний,
например используются методы выравнивания по словам, относящимся к
значимым частям речи~\cite{40koz}. При этом служебные слова не
учитываются. Для использования этих методов необходимо про\-из\-вес\-ти
разметку параллельных текстов по частям речи.

На современном этапе развития исследований и разработок в области
машинного перевода и обработки текстовых знаний все больше назревает
потребность в подходах, основанных на лингвистических знаниях. Это также
осознается и сторонниками статистических подходов. Так, например, в
работе~\cite{41koz} описан двухступенчатый метод автоматического
извлечения переводных шаблонов из параллельных текстов на английском и
китайском языках. Этот метод основан на алгоритме индукции грамматики и
алгоритме выравнивания с использованием скобочной трансдукционной
грамматики. Однако сами авторы указывают, что, поскольку в данной
модели не заложены предварительные синтаксические знания,
грамматическая правильность результата не может быть гарантирована.

\section{Многовариантная вероятностная модель когнитивного
трансфера}

\subsection{Вероятностная грамматика замещения деревьев}

Рассмотрим, каким образом значения вероятности используются в процессе 
грамматического разбора. Например, вероятностная контекстно-свободная 
грамматика (Probabilistic Context Free Grammar, PCFG) и вероятностная 
грамматика подстановки деревьев  (Probabilistic Tree Substitution Grammar, 
PTSG) присваивают вероятность $P$ каж\-до\-му дереву разбора~$T$ (т.е.\ каждому 
деривату) предложения~$S$. Эта информация является ключевой для разрешения 
неоднозначности синтаксических структур. Вероятность каждого возможного дерева 
разбора~$T$ определяется как произведение вероятностей всех правил~$r$, 
используемых для развертывания каждого узла~$n$ в дереве разбора: 
%\begin{equation} 
$$ 
P(T,S) = \prod\limits_{n\in T} p(r(n))\,.
$$
%\end{equation}

Вероятность однозначного предложения (т.е. предложения, где нам не
надо разрешать неоднозначность) равна  вероятности единственного дерева
разбора для этого предложения, т.е.\ $P(T,S)=$\linebreak
$=P(T)$. Вероятность же
неоднозначного предложения равна сумме вероятностей всех возможных
деревьев разбора ($\tau (S)$) данного предложения:
    $$
P(S) = \sum\limits_{T\in \tau (S)} P(T,S) = \sum\limits_{T\in\tau (S)} P(T)\,.
$$

Вероятность полного разбора предложения вычисляется с учетом категориальной 
информации для каждой головной вершины каждого узла. Пусть $n$~--- 
синтаксическая категория некоторого узла~$n$, $h(n)$~--- головная вершина 
узла~$n$, а $m(n)$~--- материнский узел для узла $n$. Таким образом, мы будем 
вычислять вероятность  $p(r(n)\vert n$, $h(n))$. Для этого мы преобразовываем 
выражение~(1) таким образом, что каждое правило становится обу\-слов\-лен\-ным 
своей головной вершиной:
$$
P(T,S) = \prod\limits_{n\in T} p(r(n)\vert n,\, h(n))\times p(h(n)\vert
n,\,h(m(n))).
$$

В нашей системе грамматики функциональные значения языковых
структур определяются категориальными значениями головных вершин.
Вероятностные характеристики вводятся в правила унификационной
грамматики в виде весов, присваиваемых деревьям разбора. Неоднозначные
и многозначные синтаксические структуры учитываются в многовариантной
грамматике когнитивного трансфера (переноса). Неоднозначность является
коренным свойством естественного языка и вызывает основные затруднения
при создании систем машинного перевода.

\subsection{Многовариантные правила когнитивного трансфера}

В разрабатываемой нами системе грамматики \textit{функциональные}
значения языковых структур определяются \textit{категориальными
значениями головных вершин}. Вероятностные характеристики вводятся в
правила унификационной грамматики в виде весов, присваиваемых деревьям
разбора. Неоднозначные и многозначные синтаксические структуры
учитываются в многовариантной КТГ (МКТГ).

Синтаксис МКТГ-структуры (МКТГС) может быть представлен в общем виде
следующим образом:

\noindent
\textit{МКТГС}\;$\rightarrow$\; МКТГС $<$\textit{идентификатор}$>$
\textit{МКТГС} $<$\textit{вес}$>$ \textit{МКТГС} $<$\textit{метка}$>$
$<$\textit{Входная фразовая структура} \& \textit{набор
атрибутов-значений}$>$ $<$\textit{Схема трансфера, управляемого
головной вершиной}$>$ $<$\textit{Генерируемая фразовая структура} \&
\textit{набор атрибутов-значений~1}$>$ $<$\textit{вес1}$>$
$<$\textit{Генерируемая фразовая структура} \& \textit{набор
атрибутов-значений~2}$>$ $<$\textit{вес2}$>$ \ldots
$<$\textit{Генерируемая фразовая структура} \& \textit{набор
атрибутов-значений}~$N\!>$ $<$\textit{вес}$N\!>$.

В новом варианте МКТГ отражено явление многозначности синтаксических структур и 
предусмот\-ре\-ны некоторые механизмы разрешения не\-од\-нознач\-но\-сти 
посредством включения в систему правил разбора и перевода статистической 
информации о возможных контекстах языковых структур. Многовариантная грамматика 
когнитивного переноса обеспечивает расширяемую платформу для разработки систем 
машинного перевода и извлечения знаний из текста: может применяться для 
большего числа языков. Новый синтетический подход к лингвистическому 
моделированию для систем машинного перевода и обработки знаний предполагает 
семантическое выравнивание структур для ряда европейских языков; установление 
кросс-лингвистических пространств когнитивных соответствий;  разрешение 
неоднозначности с использованием стохастических методов, подготовкой языковых 
структур и шаблонов для машинного обучения систем.

Продолжают формироваться обучающие наборы данных для расширения и модификации 
правил. Для сокращения числа избыточных правил (которые будут неизбежно 
возникать на этапе обуче\-ния) в систему закладываются не только шаблоны 
языковых структур, по аналогии с которыми будут порождаться правила, но и 
правила-фильтры на основе ПКТ.

\section{Заключение}

Актуальность проблемы создания новых гиб\-рид\-ных методов
представления языковых объектов обусловлена тем, что на современном
этапе исследований встает задача оптимального сочетания сильных сторон
двух исследовательских парадигм: логико-лингвистического моделирования,
использующего правила, и стохастического подхода. Особое значение
предлагаемая работа имеет для решения проблемы структурного анализа и
компьютерного моделирования полнотекстовых научных и патентных
документов. Необходимость моделирования языковых трансформаций для
систем машинного перевода и извлечения знаний из текстов обусловлена
тем, что до сих пор эти явления мало исследованы с точки зрения
возможностей их компьютерных реализаций и, соответственно, недостаточно
учтены в действующих системах машинного перевода, а правила, задающие функциональную
синонимию языковых конструкций, позволяют извлечь необходимую
информацию из параллельных текстов и избежать формирования
избыточных правил и <<шумов>>.

При формировании процедур снятия неоднозначности мы используем статистические 
данные, полученные при изучении параллельных текстов научных и патентных 
документов нашего экспериментального корпуса. Так, например, при ранжировании 
предпочтительности вариантов трансфера нами используется статистика соотношения 
<<гла\-голь\-но\-сти-но\-ми\-на\-тив\-но\-сти>> русского и английского научного 
дискурса.

Дальнейшие наши исследования связаны с расширением числа типов трансформаций в 
анг\-ло-рус\-ском и рус\-ско-анг\-лий\-ском переводах и построением 
лингвистических представлений для многоязычной ситуации. Разрабатывается 
многоязычная лингвистическая база знаний, которая основана на сочетании методов 
семантического анализа фразовых структур (с акцентом на функциональной 
семантике) и статистических характеристиках языковых объектов.

Кроме компьютерных реализаций полученные результаты используются
для выработки инновационных подходов к обучению иностранным языкам
на основе семантической грамматики и созданию образовательных программ
по информационным технологиям и компьютерной лингвистике.

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{99}
\bibitem{1koz}
\Au{Brown~R.\,D.}
Example-based machine translation in the Pangloss system~//
16th Conference (International) on Computational
Linguistics, 1996. Copenhagen: Center for Sprogteknologi. P.~169--174.

\bibitem{2koz}
\Au{Knight~K.}
Automating knowledge acquisition for machine translation~// Artificial
Intelligence Magazine, 1997. Vol.~18. P.~81--96.

\bibitem{3koz}
\Au{Козеренко~Е.\,Б.}
Логико-статистические методы представления языковых
структур в машинном переводе~// Труды Международной конференции
Диалог'2005 <<Компьютерная лингвистика и интеллектуальные технологии>>.
М.: Наука, 2005.

\bibitem{4koz}
\Au{Wang~Ye-Yi, Waibel~А.} Modelling with structures in statistical machine 
translation~// 36th Annual Meeting of the Association for Computational 
Linguistics / 17th Conference (International) on Computational Linguistics, 
1998. P.~1357--1363.

\bibitem{5koz}
Hutchins~J., Hartmann~W., Ito~E., eds.
Compendium of translation software~// 7th Ed.
European Association for Machine Translation, 2003.

\bibitem{6koz}
\Au{Lagoudaki~E.}
Translation memories survey 2006: User's perceptions
around TM usage~//  28th Translating and the Computer
28~Conference Proceedings. London: Aslib/IMI, 2006. P.~1--29.

\bibitem{7koz}
\Au{Alshawi~H., Buchsbaum~A.\,L., Fei~Xia}. A comparison of head transducers 
and transfer for a limited domain translation application~// 35th Annual 
Meeting of the Association for Computational Linguistics / 8th European Chapter 
of the Association for Computational Linguistics, 1997. P.~360--365.

\bibitem{8koz}
\Au{Plana~E.}
SIMILIS second-generation translation memory software~//
28th Translating and the Computer Conference Proceedings.
London: Aslib/IMI, 2005.

\bibitem{9koz}
\Au{Mel'cuk~I.\,A.}
Dependency syntax: Theory and practice.
Albany: State University of New York, 1988.

\bibitem{10koz}
\Au{Pollard~C., Sag~I.\,A.}
Head-driven phrase structure grammar. Chicago: University of Chicago Press, 1994.

\bibitem{11koz}
\Au{Kozerenko~E.\,B.}
Cognitive approach to language structure segmentation
for machine translation algorithms~//
International Conference
on Machine Learning, Models, Technologies and Applications Proceedings.
Las Vegas, USA: CSREA Press, 2003. P.~49--55.

\bibitem{12koz}
\Au{Козеренко~Е.\,Б.}
Моделирование переноса функциональных значений для
англо-русского машинного перевода~// Труды Международной конференции
Диалог'2004 <<Компьютерная лингвистика и интеллектуальные технологии>>.
М.: Наука, 2004.

\bibitem{13koz}
\Au{Якобсон~Р.\,О.}
Разработка целевой модели языка в европейской
лингвистике в период между двумя войнами~// Новое в лингвистике. М.,
1965. Вып.~4. С.~372--377.

\bibitem{14koz}
\Au{Якобсон~Р.\,О.}
Шифтеры, глагольные категории и русский глагол~//
Принципы типологического анализа языков различного строя. М., 1972.

\bibitem{15koz}
\Au{Halliday~M.\,A.\,K.}
System and function in language~// In: Halliday~M.\,A.\,K.
Selected Papers. London, 1976.

\bibitem{16koz}
\Au{Звегинцев~В.\,А.}
Функция и цель в лингвистической теории~// Проблемы
теоретической и экспериментальной лингвистики. М., 1977. С.~120--146.

\bibitem{17koz}
\Au{Слюсарева~Н.\,А.}
Проблемы функционального синтаксиса современного
английского языка. М., 1981. 206~с.

\bibitem{18koz}
\Au{Halliday~M.\,A.\,K.}
An introduction to functional grammar. Ed. Arnold~E. London, 1985.

\bibitem{19koz}
\Au{Шведова~Н.\,Ю.}
Один из возможных путей построения функциональной
грамматики русского языка~// Проблемы функциональной грамматики. М.,
1985. С.~30--37.

\bibitem{20koz}
\Au{Гак~В.\,Г.}
К типологии функциональных подходов к изучению языка~//
Проблемы функциональной грамматики. М., 1985. С.~5--15.

\bibitem{21koz}
\Au{Степанов~Ю.\,С.}
Имена, предикаты, предложения (семиологическая
грамматика). М.: Едиториал УРСС, 2004.

\bibitem{22koz}
\Au{Блумфилд~Л.}
Язык. Изд. 2-е, стереотипное.  М.: Едиториал УРСС,
2002.

\bibitem{23koz}
\Au{Щерба~Л.\,В.}
Языковая система и речевая деятельность. Л., 1974.

\bibitem{24koz}
\Au{Золотова~Г.\,А., Онипенко~Н.\,К., Сидорова~М.\,Ю.}
Коммуникативная грамматика русского языка. М., 2004.

\bibitem{25koz}
\Au{Шаумян~С.\,К.}
Семиотическая лингвистика как объяснительная наука~//
Труды Международной конференции Диалог'2005 <<Компьютерная
лингвистика и интеллектуальные технологии>>. М.: Наука, 2005. С.~507--513.

\bibitem{26koz}
\Au{Shaumyan~S.}
A semiotic theory of language. Indiana University Press,
1987.

\bibitem{27koz}
\Au{Shaumyan~S.}
Signs, mind, and reality. USA: John Benjamins Publishing
Company, 2006.

\bibitem{28koz}
\Au{Козеренко~Е.\,Б.}
Лингвистические аспекты информатики~// Системы и
средства информатики. Специальный выпуск <<Научно-методологические
проблемы информатики>>. М.: ИПИРАН, 2006. C.~88--111.

\bibitem{29koz}
\Au{Rosenfeld~R.}
A maximum entropy approach to adaptive statistical language
modeling~// Computer Speech and Language, 1996. Vol.~10. P.~187--228.

\bibitem{30koz}
\Au{Niesler~T.\,R., Woodland~P.\,C.}
Modelling word-pair relations in a
category-based language model~// IEEE Conference
(International) on Acoustics, Speech, and Signal Processing, 1999. P.~795--798.

\bibitem{31koz}
\Au{Ney~H., Essen~U., Kneser~R.}
On structuring probabilistic dependencies
in stochastic language modeling~// Computer Speech and Language, 1994.
Vol.~8. P.~1--38.

\bibitem{32koz}
\Au{Marino~J.\,B., Banchs~R.\,E., Crego~J.\,M., Adria de Gispert,
Lambert~P., Fonollosa~J.\,A.\,R., Costa-jussa M.\,R.}
 N-gram-based machine translation~//
Computational Linguistics, 2006. Vol.~32. No.\,4. P.~527--549.

\bibitem{33koz}
\Au{Voss~C., Dorr~B.\,J.}
Toward a lexicalized grammar for
interlinguas~// Machine Translation, 1995. Vol.~10. No.\,1--2. P.~139--180.

\bibitem{34koz}
\Au{Dorr~B.,  Nizar~H.}
Interlingua approximation: A generation-heavy approach~//
AMTA-2002 Interlingua Reliability Workshop. Tiburon,
California, USA, 2002.

\bibitem{35koz}
\Au{Brown~P.\,F., Cocke~J., Della~Pietra~S.\,A., Della~Pietra~V.\,J.,
Jelinek~F., Lafferty~J.\,D., Mercer~R.\,L., Roossin~P.\,S.}
A statistical approach to machine
translation~// Computational Linguistics, 1990. Vol.~16. P.~79--85.

\bibitem{36koz}
\Au{Brown~P.\,F.,  Della Pietra~S.\,A., Della Pietra~V.\,J., Mercer~R.\,L.}
The mathematics of statistical machine translation: Parameter estimation~//
Computational Linguistics, 1993. Vol.~19. No.\,2. P.~263--311.

\bibitem{37koz}
\Au{Marcus~M.\,P., Santorini~B., Marcinkiewicz~M.\,A.}
Building a large
annotated corpus of English: The Penn Treebank~//
Computational Linguistics, 1993. Vol.~19. No.\,2. P.~313--330.

\bibitem{38koz}
\Au{Gale~W.\,A., Church~K.\,W.}
A program for aligning
sentences in bilingual corpora~// Computational Linguistics, 1993.
Vol.~19. P.~75--102.

\bibitem{39koz}
\Au{Chen~S.\,F.} Aligning sentences in bilingual corpora using lexical 
information~// 31st Annual Meeting of the Association for Computational 
Linguistics, 1993. P.~9--16.
{%\looseness=1

}
\bibitem{40koz}
\Au{Haruno~M.,  Yamazaki~T.} High-performance bilingual text alignment using 
statistical and dictionary information~// 34th Annual Meeting of the 
Association for Computational Linguistics, 1996. P.~131--138. 
{%\looseness=1

}
\bibitem{41koz}
\Au{Hu~Rile, Zong~Chengqing, Xu~Bo}. An approach to automatic acquisition of 
translation templates based on phrase structure extraction and alignment~// 
IEEE Transactions on Audio, Speech and Language Processing, 2006. Vol.~14. 
No.\,5. P.~1656--1663. 
{\looseness=1

}
\end{thebibliography}

}
}


\end{multicols}

\label{end\stat}