\def\stat{kravtsova}

\def\tit{ИСПОЛЬЗОВАНИЕ КРИТЕРИЕВ СТАЦИОНАРНОСТИ ДЛЯ~НАСТРОЙКИ МОДЕЛЕЙ ПРИ~ПРОГНОЗИРОВАНИИ ВРЕМЕННЫХ РЯДОВ}

\def\titkol{Использование критериев стационарности для настройки моделей при~прогнозировании временных рядов}

\def\aut{О.\,А.~Кравцова$^1$}

\def\autkol{О.\,А.~Кравцова}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Кравцова О.\,А.}
\index{Kravtsova O.\,A.}


%{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
%{Работа выполнена при поддержке Министерства науки и~высшего образования Российской Федерации (проект 
%075-15-2020-799).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский государственный университет имени М.\,В.~Ломоносова, \mbox{phd3984@gse.cs.msu.ru}}

\vspace*{-6pt}

     

    
\Abst{Рассматривается возможность использования информации о стационарности 
остатков для совершенствования процедуры прогнозирования нестационарных временных 
рядов. При традиционном подходе данная процедура используется только в~формате 
подтверждения или отвержения гипотезы о~нестационарности остатков. В~настоящей статье 
критерии стационарности предлагается использовать при настройке гиперпараметров для построения 
моделей прогнозирования. Методика основана на концепции коинтеграции Грейнд\-же\-ра для поиска 
статистически значимой связи между временными рядами. Для уменьшения ошибки прогноза моделей в~качестве 
функции потерь используется p-зна\-че\-ние тес\-тов на ста\-ци\-о\-нар\-ность. В~качестве данных для проверки 
использовались экономические и~сгенерированные временные ряды. Проведенные эксперименты показали, 
что нередко такой подход оказывается более эффективным по сравнению с~традиционными способами 
настройки моделей.}
    
\KW{временные ряды; стационарность; деревья решений; регрессионный анализ}

\DOI{10.14357/19922264220202}
  
%\vspace*{-4pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}
    

\section{Введение}

%\vspace*{-5pt}

Прогнозирование временн$\acute{\mbox{ы}}$х рядов является одной из самых исследуемых задач. 
В~общем виде задача прогнозирования состоит в~выборе такого алгоритма, 
который обеспечивает максимальное качество прогноза относительно выбранной функции потерь. 
Оптимальной настройкой для модели считается та, которая позволяет получить минимум для заданного 
функционала качества~\cite{1-kr}.

Если остатки модели нестационарны, то модель имеет неодинаковую точность прогноза в~разные 
периоды времени, т.\,е.\ нуждается в~корректировке. 
В~связи с~этим получил распространение подход, основанный на концепции коинтеграции Грейнд\-же\-ра~\cite{2-kr}, 
в~котором исследование распределения остатков по времени является составляющей оценки качества 
регрессионных моделей. Данная концепция широко используется в~финансовом секторе, например в~парном 
трейдинге для выявления ложных регрессионных связей~\cite{3-kr}.

Для прогнозирования нестационарных вре\-мен\-н$\acute{\mbox{ы}}$х рядов, которые весьма часто пред\-став\-ля\-ют основную 
проб\-ле\-му при прогнозировании экономических вре\-мен\-н$\acute{\mbox{ы}}$х рядов, используются такие\linebreak модели,
 как \mbox{ARIMA} (Autoregressive Integrated\linebreak Moving Average)~\cite{4-kr, 5-kr} и~деревья решений~\cite{6-kr, 7-kr}. 
 Указанные модели обладают ограниченной прогностической спо\-соб\-ностью при использовании на 
 нестационарных временных рядах. Для увеличения прогностической способности используются 
 различные гибридные модели и~ан\-самб\-ле\-вые методы. Модель ARIMA используют в~качестве 
 дополнения к~нейронной сети~\cite{8-kr, 9-kr, 10-kr} и~вместе с~вейвлетами~\cite{11-kr, 12-kr} 
 деревья решений объединяют в~ан\-самб\-ле\-вый метод~\cite{13-kr, 14-kr}.


В настоящей статье для стандартных моделей ARIMA и~ансамблей деревьев решений  
функция\linebreak потерь дополняется информацией о~<<степени>> статистически значимой связи между
 прогнозом и~реальными значениями (p-зна\-че\-ние тес\-тов на ста\-ци\-о\-нар\-ность). 
 Проверка предложенного метода \mbox{проведена} на экономических рядах и~сгенерированных псевдовыборках. 
 В~част\-ности, анализ и~прогнозирование паттернов поведения акций~--- одна из самых исследуемых задач 
 в~сфере фондового рынка. Особый интерес представляет прогнозирование рядов для краткосрочной
  перспективы, так как долгосрочная перспектива, как правило, показывает довольно низкие
   доходности. Большинство инвесторов теряет свой капитал в~краткосрочном периоде прогнозирования, 
   поэтому методы анализа цен акций требуют улучшения~\cite{15-kr}.


\vspace*{-6pt}


\section{Стационарность в~функции~потерь}

 Среди этапов построения модели ARIMA можно выделить 
 сле\-ду\-ющие: идентификация модели, оценка ее параметров и~диагностическая проверка~\cite{16-kr}. 
 Наиболее часто используемый в~про\-грам\-мных пакетах подход к~выбору оптимальных гиперпараметров 
 основан на критерии Акаике (AIC) из~\cite{17-kr}.

Для построения деревьев использовался алгоритм CART (Classification and Regression Trees)~\cite{18-kr}. 
Небольшие модификации могут вызывать сильные изменения в~решении дерева, поэтому необходимо 
тщательно подготавливать данные и~следить за процедурой настройки гиперпараметров~\cite{19-kr}. 
Для тестирования использовалась библиотека Scikit-learn. 
В~качестве способа подбора гиперпараметров был выбран так называемый поиск по сетке (Grid search)~\cite{18-kr}.

Данная работа основана на утверждении, что\linebreak если остатки стационарны, то модель является хорошо 
специфицированной, т.\,е.\ если модель и~совершает ошибки, то эти ошибки происходят 
по большей части из-за шумовой компоненты в~данных, которая не поддается прогнозированию с~по\-мощью 
математических методов.

В качестве первого теста на стационарность был выбран классический тест единичного корня~--- 
тест Ди\-ки--Фул\-ле\-ра~\cite{21-kr}, где использование единичного корня с~дрейфом и~детерминированного 
временн$\acute{\mbox{о}}$го тренда является опциональным:
\begin{equation*}
\Delta y_i = \alpha_0 + \alpha_1  t+\delta y_{i-1}+\varepsilon_i.
\end{equation*}


Для подсчета p-значения используется t-рас\-пре\-де\-ле\-ние (распределение Стьюдента) со ста\-ти\-сти\-кой~$\mathrm{DF}$:
\begin{equation*}
F(x) = \fr{1}{2}+x\Gamma\left(\fr{v+1}{2}\right),\enskip
 \mathrm{DF} = \fr{\bar{\alpha}} {\mathrm{s.\,e.}(\bar{\alpha})}\,,
\end{equation*}
$X \in \mathbf{R} \thicksim \mathrm{St}\left(v\right)$, $v>0$; $\Gamma$~--- гам\-ма-функ\-ция Эйлера; 
$\mathrm{s.\,e.}$ (standard error)~--- 
стандартная ошибка; $\bar{\alpha}$~--- оценка параметра~$\alpha$. 
Тогда функцию потерь можно пред\-ста\-вить с~по\-мощью p-зна\-че\-ния и~итоговая задача 
оптимизации будет выглядеть сле\-ду\-ющим образом:
\begin{equation}
\label{eqloss}
    F \left(\fr{\bar{\alpha}} {\mathrm{s.\,e.}(\bar{\alpha})}\right) \rightarrow \min\,.
\end{equation}

Экономические ряды характеризуются структурными сдвигами, т.\,е.\ 
возникают качественные изменения связей. Такой сдвиг практически невозможно предсказать,
 поэтому тест Ди\-ки--Фул\-ле\-ра покажет отсутствие стационарности даже в~случае правильной 
 спецификации. Тест Зи\-во\-та--Энд\-рю\-са позволяет обработать единичное изменение среднего и~единичное 
 изменение наклона тренда~\cite{22-kr}:
 
 \noindent
\begin{multline*}
\Delta y_i =c + \alpha y_{t-1}+\beta t  +\gamma \mathrm{DU}_t+ \theta \mathrm{DT}_t+{}\\
{} +\sum\limits_{j=1}^{k}d_j\Delta y_{t-j} + \varepsilon_t.
\end{multline*}

Функция потерь для данного теста аналогична случаю теста Ди\-ки--Фул\-ле\-ра в~формуле~(\ref{eqloss}). 
Если в~обуча\-ющих данных наблюдается структурное изменение, т.\,е.\ 
меняется тренд или среднее для одного участка выборки сильно отличается от 
среднего другого участка, будем использовать тест Зи\-во\-та--Энд\-рю\-са, 
в~противном случае используем тест Ди\-ки--Фул\-лера.

\vspace*{-2pt}

\section{Алгоритмы улучшения моделей прогнозирования}

В качестве данных для подтверждения гипотезы о релевантности использования остатков 
в~функции потерь для моделей прогнозирования были использованы следующие: курс рубля, цена на нефть, 
индекс Мосбиржи, цена на золото~\cite{23-kr}, сгенерированные ряды. Динамика этих данных напрямую 
отражается на издержках во всех отраслях экономики~\cite{24-kr}, поэтому прогнозирование данных рядов 
является актуальной задачей. Для рядов использовались средние показатели за неделю. 
Под сгенерированными рядами понимаются ряды, полученные с~по\-мощью метода бутстрепа из 
исходных (в~итоге получаем~50~различных рядов). Для каждого такого ряда строился прогноз с~по\-мощью 
модели ARIMA. В~качестве регрессоров для деревьев решений использовались лаговые значения 
и~--- для деревьев решений~--- остатки от оценок ARIMA. Все прогнозы строились на периоды от~4 до~12~недель. 
Хорошим прогнозом будем считать модель с~прогнозом с~наименьшей ошибкой, высокой корреляцией 
между спрогнозированными значениями и~действительными, стационарными остатками.

В общем виде рассмотрим алгоритм для улучшения модели ARIMA с~помощью использования
 p-зна\-че\-ния тес\-тов на ста\-цио\-нар\-ность.
\ %%<-- этот пробел для того, чтобы первый элемент перечня был

%% на следующей строке, а не в~подбор к~заголовку окружения

\vspace*{2pt}

\textbf{Алгоритм 1} (ARIMA) %\label{alg:1}
    
        \noindent
        \begin{enumerate}[1.]

       
        \item
        Используем метод поиска по сетке для различных гиперпараметров 
        модели прогнозирования для разных размеров обучающей и~тестовой выборки.
        
        \item
        Для каждой комбинации считаем величину среднеквадратичной ошибки (MSE), 
        p-зна\-че\-ние теста на стационарность для остатков модели (разница 
        между оцененными значениями обучающей выборки и~значениями обучающей выборки) и~критерий AIC.
        
        
        \item
        Отсортируем комбинации по метрике MSE для фиксированной длины тестовой выборки.
        \item
        
        Посчитаем разность между показателями \mbox{p-зна}\-че\-ния для первой настройки и~второй настройки, 
        аналогично посчитаем разность для критерия AIC.
        
        
        \item
        Если разность для p-зна\-че\-ния оказалась положительной и~эта разница превышает~0,001, 
        то переходим к~сле\-ду\-юще\-му шагу. Иначе выбираем настройку с~минимальным AIC.
        
        \item
        
        Повторяем процесс сравнения для второй и~трет\-ьей настройки и~т.\,д., пока не выполнятся оба условия.
        \end{enumerate}

\noindent
Таким образом, для обучающей выборки считаем MSE, p-зна\-че\-ние и~AIC, а~для тестовой~--- только MSE.
Для деревьев решений нет необходимости в~оценке сложности модели, однако, чтобы 
лучше контролировать процесс обучения, рассмотрим корреляции. Показатель корреляции 
Пирсона для фиксированной длины тестовой выборки высчитаем сле\-ду\-ющим образом.

\vspace*{2pt}

\textbf{Алгоритм 2} (Корреляции) % \label{alg:11}
    
        \noindent
        \begin{enumerate}[1.]
        
        \item
        Из исходного ряда выберем фиксированный размер обучающей выборки для 
        фиксированной даты последнего наблюдения.

        
        \item
        Из обучающей выборки исключим последние наблюдения размером с~тестовую выборку, 
        на этих значениях будем вычислять коэффициент корреляции. Назовем их валидационной 
        выборкой. Объединим оставшиеся значения из обучающей выборки с~предшествующими ей 
        значениями из исходной выборки
        
        \item
        Для разных размеров обучающей выборки (т.\,е.\ различных подвыборок из <<пред\-шест\-ву\-ющие 
        значения исходной вы\-бор\-ки\;+\;обуча\-ющая вы\-бор\-ка\;$-$\;раз\-мер тес\-то\-вой выборки>>) 
        используем поиск по сетке гиперпараметров, построим прогнозы для валидационной выборки. 
        Посчитаем корреляцию прогноза валидационной выборки с~истинными значениями
        
        \item
        Для каждого набора гиперпараметров для изначальной фиксированной даты 
        последнего наблюдения из п.~1 и~изначально заданной длины тестовой выборки сохраним 
        значения корреляций.
        

    \end{enumerate}


Теперь рассмотрим общий алгоритм для де\-ревь\-ев решений.

\vspace*{2pt}

\textbf{Алгоритм 3} (Деревья решений)

    \noindent
    \begin{enumerate}[1.]
    

        \item Используем метод поиска по сетке для различных гиперпараметров модели 
        прогнозирования для разных размеров обучающей и~тес\-то\-вой выборки.

        
        \item

        Для каждой комбинации считаем величину MSE и~p-зна\-че\-ние 
        теста на ста\-ци\-о\-нар\-ность для остатков модели.

        
        
        \item

        Отсортируем комбинации по метрике MSE для фиксированной длины тес\-то\-вой выборки.

        \item

        Посчитаем разность между показателями \mbox{p-зна}\-че\-ния для первой настройки и~второй настройки.

        
        \item

        Если разность для p-зна\-че\-ния оказалась положительной и~эта разница превышает~0,001, 
        то переходим к~следующему шагу. Иначе выбираем настройку с~наибольшим показателем корреляции. 
        Показатель корреляции выбирается из сохраненных значений из алгоритма~2 для выбранной длины 
        обуча\-ющей и~тес\-то\-вой выборок.

        
        \item

        Повторяем процесс сравнения для второй и~треть\-ей настройки и~т.\,д., пока не выполнятся оба условия.

        
        
    \end{enumerate}




\section{Вычислительный эксперимент}

 Вначале рассмотрим возможность использования величины p-зна\-че\-ния тес\-тов 
 на стационарность и~среднеквадратичной ошибки для отбора размера тренировочной 
 выборки при прогнозировании с~по\-мощью алгоритма построения модели ARIMA на основе 
 критерия Акаике из~\cite{17-kr}.

В качестве примера на рис.~1 продемонстрирована величина ошибки прогноза (MSE) 
 цены на нефть для разных промежутков ряда, где размер обуча\-ющей выборки подбирался 
 на основании критерия стационарности остатков~--- p\_val и~на критерии величины среднеквадратичной ошибки~--- 
 mse.  Чем меньше оцененные значения отличаются от действительных, 
 тем лучше получится результат прогноза. График показывает, что использование 
 стационарности остатков в~качестве критерия отбора размера обуча\-ющей выборки в~ряде случаев 
 уже позволяет уменьшать ошибку прогноза.
 


На рис.~2 для выбранного оптимального размера обучающей выборки показана 
разница между величиной ошибки алгоритма, основанного на популярном подходе к~настройке ARIMA из~\cite{17-kr}, 
mse(auto\_arima),  и~на критерии стационарности для различных рядов, mse(p\_val). 
Итоговая разница никогда не становится меньше нуля, что говорит о~том, что  метод 
как минимум не хуже, а~в~ряде случае и~лучше, чем классический подход подбора.



Для деревьев решений рассмотрим анализ одного конкретного нестационарного ряда фиксированной длины на рис.~3 
(в~данном случае ряд индекса\linebreak\vspace*{-12pt}

\pagebreak

\end{multicols}


\begin{figure*} %fig1
\vspace*{1pt}
  \begin{center}  
    \mbox{%
\epsfxsize=99.747mm
\epsfbox{kra-1.eps}
}

\end{center}
\vspace*{-9pt}
\Caption{Величина ошибки прогноза (MSE) цены на нефть для двух критериев 
    отбора размера обучающей выборки: \textit{1}~--- критерий стационарности остатков~--- p\_val; \textit{2}~--- 
    критерий величины среднеквадратичной ошибки~--- mse}
    \label{pinki}
\end{figure*}

\begin{figure*} %fig2
\vspace*{9pt}
  \begin{center}  
    \mbox{%
\epsfxsize=102.865mm
\epsfbox{kra-2.eps}
}

\end{center}
\vspace*{-9pt}
\Caption{Разница между величиной ошибки прогноза алгоритма, основанного на 
    критерии Акаике~(\textit{1}) и~на критерии стационарности~(\textit{2})}
    \label{pic2}
\end{figure*}

\begin{multicols}{2}

\noindent
 Мосбиржи). На этом рисунке p\_val~--- 
отбор на основе стационарности остатков, min mse train~--- на основе величины ошибки mse, min mse test~--- 
минимально возможная ошибка при лучшем подборе гиперпараметров для заданного размера тренировочной выборки. 
На некоторых участках графики p\_val~(\textit{1}) и~min mse train~(\textit{2}) пересекаются. 

Каждый из графиков показывает, 
насколько минимальной может быть ошибка прогноза на тестовой выборке для конкретного временн$\acute{\mbox{о}}$го 
ряда при фиксированной длине прогноза для разных размеров обучающей выборки, т.\,е.\ 
перебираем различные комбинации гиперпараметров для разных размеров обуча\-ющей выборки и~выбираем те, 
которые на тестовой выборке продемонстрировали наименьшую ошибку прогноза. Таким образом, задача~--- 
приблизиться к~минимуму графика  min mse train.



Однако, в~отличие от ARIMA, использование \mbox{p-зна}\-че\-ния для деревьев не всегда позволяет 
улучшить результат. Использование такого алгоритма релевантно только в~том случае, если прогноз 
дела-\linebreak\vspace*{-12pt}

\pagebreak

\end{multicols}

\begin{figure*} %fig3
\vspace*{1pt}
  \begin{center}  
    \mbox{%
\epsfxsize=100.047mm
\epsfbox{kra-3.eps}
}

\end{center}
\vspace*{-9pt}
\Caption{Подбор размера обучающей выборки деревьев решений для одного из рядов: \textit{1}~--- p\_val; \textit{2}~--- min mse train; \textit{3}~--- min mse test}
    \label{pic3}
\end{figure*}

\begin{figure*} %fig4
\vspace*{9pt}
  \begin{center}  
    \mbox{%
\epsfxsize=103.065mm
\epsfbox{kra-4.eps}
}

\end{center}
\vspace*{-9pt}
\Caption{Разница между величиной ошибки прогнозов алгоритмов, основанных на 
    величине ошибки MSE~(\textit{1}) и~на критерии стационарности~(\textit{2})}
    \label{pic4}
\end{figure*}

\begin{multicols}{2}

\noindent
ется
 на период от~8 до~12~недель. На рис.~4 пред\-став\-ле\-ны только результаты прогноза для~8 и~12~недель.
  Как и~в~случае с~\mbox{ARIMA}, график позволяет говорить о~том, 
что метод с~учетом стационарности остатков как минимум не хуже  (разность между величиной 
ошибки традиционного подхода и~метода с~учетом стационарности никогда не меньше нуля).



Основываясь на эмпирических результатах исследования, 
мож\-но сделать вывод, что использование информации о стационарности остатков
 представляется релевантным для уменьшения ошибки прогноза.

Однако данный метод обладает рядом минусов. Во-пер\-вых, это высокая вычислительная слож\-ность, 
так как необходимо рассматривать множество различных комбинаций гиперпараметров. Во-вто\-рых, 
для деревьев решений результат работы алгоритма нестабилен для разных размеров периода 
прогнозирования. В~связи с~этим следует довести метод до более компактного итеративного процесса, 
который бы обеспечивал статистически значимое улучшение прогноза моделей.


\section{Заключение}

Для выбора корректной настройки гиперпараметров моделей прогнозирования 
существует большое разнообразие подходов. В~данной статье рассматривались наиболее популярные 
подходы\linebreak к~построению прогнозов нестационарных вре\-мен\-н$\acute{\mbox{ы}}$х рядов с~по\-мощью \mbox{ARIMA} и~деревьев решений. 
В~качестве подхода к~настройке гиперпараметров был выбран метод из~\cite{17-kr} 
для ARIMA и~алгоритм поиска по сетке для метода CART построения деревьев решений. 
В~статье проверяется возможность использования p-зна\-че\-ния тестов на стационарность в~функции 
потерь для улучшения прогнозов данных алгоритмов.

Наибольшую эффективность тесты на стационарность для остатков модели продемонстрировали 
для модели ARIMA, для деревьев решений использование p-зна\-че\-ния нерелевантно при слишком 
малом или слишком большом периоде прогнозирования.

{\small\frenchspacing
 {%\baselineskip=10.8pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}

\bibitem{1-kr}
\Au{Khmelnitskaya A.\,B.}
Social welfare functions for different subgroup utility scales~// 
Constructing and applying objective functions~/ Eds. A.~Tangian, J.~Gruber.~--- 
Lecture notes in economics and mathematical systems ser.~---
 Berlin, Heidelberg: Springer-Verlag, 2002. 
Vol.~510. P.~515--530.  doi: 10.1007/978-3-642-56038-5.


\bibitem{2-kr}
\Au{Engle R.\,F., Granger~C.\,W.\,J.} 
Co-integration and error correction: Representation, estimation, and testing~//  
Econometrica, 1987. Vol.~55. No.\,2. P.~251--276.  doi: 10.2307/ 1913236.


\bibitem{3-kr}
\Au{Hatemi-J A.}
Tests for cointegration with two unknown regime shifts with an application to financial market integration~//  
Empir. Econ., 2008. Vol.~35. P.~497--505. doi: 10.1007/s00181-007-0175-9.

\bibitem{5-kr} %4
\Au{Ariyo A.\,A., Adewumi~A.\,O., Ayo~C.\,K.}
Stock price prediction using the ARIMA model~// 16th 
 Conference (International) on Computer Modeling and Simulation Proceedings.~--- Piscataway, NJ, USA: IEEE, 2014. P.~106--112. 
 doi: 10.1109/UKSim.2014.67.

\bibitem{4-kr} %5
\Au{Li T., Zhong~J., Huang~Z.}
Potential dependence of financial cycles between emerging and developed countries: Based on ARIMA-GARCH 
copula model~// Emerg. Mark. Financ. Tr., 2019. Vol.~56. No.\,6. P.~1--14. doi: 10.1080/ 1540496X.2019.1611559.


\bibitem{7-kr} %6
\Au{Gepp A., Kumar~K., Bhattacharya~S.}
Business failure prediction using decision trees~//
J.~Forecasting, 2010. Vol.~29. No.\,6. P.~536--555. doi: 10.1002/for.1153.

\bibitem{6-kr} %7
\Au{Aggarwal C.\,C.}
Mining time series data~// Data mining.~--- Springer, 2015. P.~457--491. 
doi: 10.1007/978-3-319-14142-8.


\bibitem{8-kr}
\Au{Namini S.\,S., Tavakoli~N., Namin~A.\,S.}
A~comparison of ARIMA and LSTM in forecasting time series~//  17th Conference 
(International) on Machine Learning and Applications Proceedings.~--- Piscataway, NJ, USA: IEEE, 2018. 
P.~536--555. doi: 10.1109/ICMLA.2018.00227.


\bibitem{9-kr}
\Au{Temur A.\,S., Akgun~M., Temur~G.}
Predicting housing sales in Turkey using ARIMA, LSTM and hybrid models~//  J.~Bus. Econ. 
Manag., 2019. Vol.~20. No.\,5. P.~920--938.
doi: 10.3846/jbem.2019.10190.

\bibitem{10-kr}
\Au{Wang Z., Lou~Y.}
 Hydrological time series forecast model based on wavelet de-noising and ARIMA-LSTM~//  
 3rd Information Technology, Networking, Electronic and Automation Control Conference Proceedings.~--- 
 Piscataway, NJ, USA: IEEE, 2019. P.~1697--1701. doi: 10.1109/\linebreak ITNEC.2019.8729441.




\bibitem{12-kr} %11
\Au{Ye T.}
Stock forecasting method based on wavelet analysis and ARIMA-SVR model~// 3rd Conference 
(International) on Information Management Proceedings.~--- Piscataway, NJ, USA: IEEE, 2017. P.~102--106. 
doi: 10.1109/\mbox{INFOMAN}.2017.7950355.

\bibitem{11-kr} %12
\Au{Singh S., Parmar K.\,S., Kumar~J., Makkhan~S.\,J.\,S.}
Development of new hybrid model of discrete wavelet decomposition and autoregressive integrated 
moving average\linebreak (\mbox{ARIMA}) models in application to one month forecast the casualties cases of COVID-19~// 
Chaos Soliton. Fract., 2020. Vol.~135. Art.~109866.  doi: 10.1016/ j.chaos.2020.109866.

\bibitem{14-kr} %13
\Au{Zhou F., Zhang Q., Sornette~D., Jiang~L.}
Cascading logistic regression onto gradient boosted decision trees for forecasting and trading stock 
indices~//  Appl. Soft Comput., 2019. Vol.~84. No.\,2. Art.~105747. 13~p. doi: 10.1016/ j.asoc.2019.105747.

\bibitem{13-kr} %14
\Au{Ribeiro M.\,H.\,D.\,M., Coelho~L.}
Ensemble approach based on bagging, boosting and stacking for short-term prediction in 
agribusiness time series~// Appl. Soft Comput., 2020. Vol.~86. Art.~105837. 17~p.
 doi: 10.1016/j. asoc.2019.105837.




\bibitem{15-kr}
\Au{Elder A.}
The new trading for a living: Psychology, discipline, trading tools and systems, risk control, 
trade management.~--- 
Wiley Trading ser.~--- New York, NY, USA: John Wiley \& Sons Ltd., 2014. 304~p.

\bibitem{16-kr}
\Au{Tabachnick B.\,G., Fidell L.\,S.}
 Using multivariate statistics.~--- 6th ed.~--- London: Pearson Education, 2013. 983~p.


\bibitem{17-kr}
\Au{Hyndman R., Khandakar Y.}
Automatic time series forecasting: The forecast package for~R~// J.~Stat. Softw., 2008. Vol.~27. 
No.\,3. P.~1--22. doi: 10.18637/jss.v027.i03.

\bibitem{18-kr}
\Au{Pedregosa F., Varoquaux~G., Gramfort~A.,  \textit{et al.}} Scikit-learn: Machine learning in Python~// J.~Mach. Learn. Res., 
2011. Vol.~12. P.~2825--2830. %Decision Trees.
%{\sf https://scikit-learn.org/stable/modules/tree.html.}

\bibitem{19-kr}
\Au{Singh S., Gupta P.}
Comparative study Id3, Cart and C4.5 decision tree algorithm: A~survey~// Int. J.~Advanced Information 
Science Technology, 2014. Vol.~3. No.\,7. P.~47--52. doi: 10.15693/ijaist/2014.v3i7.


%\bibitem{20-kr}
%\Au{Pedregosa F., \textit{et al.}} Scikit-learn: Machine learning in Python~// J.~Machine 
%Learning Research, 2011. Vol.~12. P.~2825-2830. GridSearchCV.
%{\sf https://scikit-learn.org/\linebreak stable/modules/generated/sklearn.model\_selection.GridSearchCV.html}

\bibitem{21-kr} %20
\Au{Dickey D.\,A., Fuller W.\,A.}
Distribution of the estimators for autoregressive time series with a unit root~// 
J.~Am. Stat. Assoc., 1979. Vol.~74. No.\,366. P.~427--431. doi: 10.2307/ 2286348.

\bibitem{22-kr}
\Au{Zivot E., Andrews~D.}
Further evidence on the great crash, the oil-price shock, and the unit-root hypothesis~// J.~Bus. 
Econ. Stat., 2002. Vol.~10. No.\,3. P.~251--270. doi: 10.2307/ 1391541.

\bibitem{23-kr}
Финам. Данные от 01.01.2005 до 20.11.2020. {\sf https:// www.finam.ru}.

\bibitem{24-kr}
\Au{Литвинова Я.\,С.} Цена на нефть как ключевой фактор воздействия на российскую валюту~// 
Проб\-ле\-мы и~перспективы экономики и~управ\-ле\-ния: Мат-лы I~Междунар. на\-учн. конф.~--- 
СПб.: Реноме, 2012. С.~19--21. {\sf  https://moluch.ru/conf/econ/ archive/15/2170}.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-8pt}

\hfill{\small\textit{Поступила в~редакцию 26.10.21}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{-2pt}

\def\tit{MODEL SETTING USING STATIONARITY CRITERIA\\ FOR~TIME SERIES FORECASTING}


\def\titkol{Model setting using stationarity criteria for time series forecasting}


\def\aut{O.\,A.~Kravtsova}

\def\autkol{O.\,A.~Kravtsova}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-8pt}


\noindent
M.\,V.~Lomonosov Moscow State University, 1-52~Leninskie Gory, GSP-1, Moscow 119991, Russian Federation

\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2022\ \ \ volume~16\ \ \ issue\ 2}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2022\ \ \ volume~16\ \ \ issue\ 2
\hfill \textbf{\thepage}}}

\vspace*{3pt} 







\Abste{The article discusses the possibility of using the information on the stationarity 
of residuals to improve the procedure of forecasting nonstationary time series.
 In the traditional approach, this procedure is used only to confirm or reject 
 the hypothesis of nonstationarity of residuals. In this article, the stationarity 
 test is used for fine-tuning of hyperparameters of the forecasting models. The technique 
 is based on the Granger cointegration approach property to find a~statistically 
 significant relationship between time series. The author used the p-value of stationarity 
 tests as a~loss function. Economic and generated time series were used as data for verification. 
 The experiments have shown that this approach is often more effective in comparison with the traditional 
 methods of tuning models.}

\KWE{time series; stationarity; decision trees; regression analysis}

\DOI{10.14357/19922264220202}

%\vspace*{-16pt}

%\Ack
%\noindent




%\vspace*{4pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
\bibitem{1-kr-1}
\Aue{Khmelnitskaya, A.\,B.} 2002. Social welfare 
functions for different subgroup utility scales. \textit{Constructing and applying objective functions}. 
Eds. A.~Tangian, and J.~Gruber. Lecture notes in economics and mathematical systems ser.
Berlin, Heidelberg: Springer-Verlag. 510:515--530. 
doi: 10.1007/978-3-642-56038-5.
\bibitem{2-kr-1}
\Aue{Engle, R.\,F., and C.\,W.\,J.~Granger.}
 1987. Co-integration and error correction: Representation, estimation, and testing. 
 \textit{Econometrica} 55(2):251--276. doi: 10.2307/ 1913236.
\bibitem{3-kr-1}
\Aue{Hatemi-J, A.} 2008. Tests for cointegration with two unknown regime shifts with an 
application to financial market integration. \textit{Empir. Econ.} 35:497--505. 
doi: 10.1007/ s00181-007-0175-9.

\bibitem{5-kr-1} %4
\Aue{Ariyo, A.\,A., A.\,O.~Adewumi, and C.\,K.~Ayo.} 2014. 
Stock price prediction using the ARIMA model. \textit{16th  Conference
(International) on Computer Modeling and Simulation Proceedings}. Piscataway, NJ: IEEE. 106--112. 
doi: 10.1109/UKSim.2014.67.

\bibitem{4-kr-1} %5
\Aue{Li, T., J.~Zhong, and Z.~Huang.} 2019. Potential dependence
 of financial cycles between emerging and developed countries: Based on ARIMA-GARCH copula model.
 \textit{Emerg. Mark. Financ. Tr.} 56(6):1--14. 
 doi: 10.1080/ 1540496X.2019.1611559.


\bibitem{7-kr-1} %6
\Aue{Gepp, A., K.~Kumar, and S.~Bhattacharya.} 2010. Business failure prediction using decision trees. 
\textit{J.~Forecasting} 29(6):536--555. doi: 10.1002/for.1153.

\bibitem{6-kr-1} %7
\Aue{Aggarwal, C.\,C.} 2015. Mining time series data. \textit{Data mining}. Springer. 457--491.

\bibitem{8-kr-1}
\Aue{Namini, S.\,S., N.~Tavakoli, and A.\,S.~Namin.} 2018. A~comparison of ARIMA and LSTM 
in forecasting time series. 
\textit{17th Conference (International) on Machine Learning and Applications Proceedings}. 
Piscataway, NJ: IEEE. 536--555. doi: 10.1109/ICMLA.2018.00227.
\bibitem{9-kr-1}
\Aue{Temur, A.\,S., M.~Akgun, and G.~Temur.} 2019. Predicting housing sales in Turkey using ARIMA, 
LSTM and hybrid models. \textit{J.~Bus. Econ. Manag.} 20(5):920--938. doi: 10.3846/jbem.2019.10190.
\bibitem{10-kr-1}
\Aue{Wang, Z., and Y.~Lou.} 2019. Hydrological time series forecast model based on wavelet de-noising 
and ARIMA-LSTM. \textit{3rd Information Technology, Networking, Electronic and Automation Control 
Conference Proceedings}. Piscataway, NJ: IEEE. 1697--1701. doi: 10.1109/\linebreak ITNEC.2019.8729441.


\bibitem{12-kr-1} %11
\Aue{Ye, T.} 2017. Stock forecasting method based on wavelet analysis and ARIMA-SVR model. 
\textit{3rd Conference (International)  on Information Management Proceedings}.
Piscataway, NJ: IEEE. 102--106. 
doi: 10.1109/ \mbox{INFOMAN}.2017.7950355.

\bibitem{11-kr-1} %12
\Aue{Singh, S., K.\,S.~Parmar, J.~Kumar, and S.\,J.\,S.~Makkhan.}
 2020. Development of new hybrid model of discrete wavelet decomposition and autoregressive 
 integrated moving average (ARIMA) models in application to one month forecast the casualties cases 
 of COVID-19. \textit{Chaos Soliton. Fract.} 135(1):109866. doi: 10.1016/j.chaos.2020.109866. 8~p.
 

\bibitem{14-kr-1} %13
\Aue{Zhou, F., Q.~Zhang, D.~Sornette, and L.~Jiang.}
 2019. Cascading logistic regression onto gradient boosted decision trees for forecasting and 
 trading stock indices. \textit{\mbox{Appl}. Soft Comput.} 84(2):105747. 13~p. 
 doi: 10.1016/j.asoc. 2019.105747. 
 
 \bibitem{13-kr-1} %14
\Aue{Ribeiro, M.\,H.\,D.\,M., and L.~Coelho.}
 2020. Ensemble approach based on bagging, boosting and stacking for short-term prediction in
  agribusiness time series. \textit{Appl. Soft Comput.} 86:105837. 17~p. 
  doi: 10.1016/j.asoc.2019.105837. 
  
\bibitem{15-kr-1}
\Aue{Elder, A.} 2014. \textit{The new trading for a~living: Psychology, discipline, trading tools and systems, 
risk control, trade management}. 
Wiley Trading ser.
New York, NY: John Wiley \& Sons Ltd. 304~p.
\bibitem{16-kr-1}
\Aue{Tabachnick, B.\,G., and L.\,S.~Fidell.}
2013. \textit{Using multivariate statistics}. 6th ed. London: Pearson Education. 983~p.
\bibitem{17-kr-1}
\Aue{Hyndman, R., and Y.~Khandakar.} 2008. Automatic time series forecasting: The forecast package for 
R. \textit{J.~Stat. Softw.} 27(3):1--22. doi: 10.18637/jss.v027.i03.
\bibitem{18-kr-1}
\Aue{Pedregosa, F., G.~Varoquaux, A.~Gramfort, \textit{et al.}}
 2011. Scikit-learn: Machine learning in Python. Decision Trees. 
 \textit{J.~Mach. Learn. Res.} 12:2825--2830.
\bibitem{19-kr-1}
\Aue{Singh, S., and P.~Gupta.}
 2014. Comparative study Id3, cart and C4.5 decision tree algorithm: A~survey. 
 \textit{Int. J.~Advanced Information Science Technology} 3(7):47--52. doi: 10.15693/ijaist/2014.v3i7.
%\bibitem{20-kr-1}
%\Aue{Pedregosa, F., \textit{et al.}} 2011. Scikit-learn: Machine learning in Python. 
%GridSearchCV. \textit{J.~Machine Learning Research} 12:2825--2830.
\bibitem{21-kr-1}
\Aue{Dickey, D.\,A., and W.\,A.~Fuller.}
 1979. Distribution of the estimators for autoregressive time series with a~unit root. 
 \textit{J.~Am. Stat. Assoc.} 74(366):427--431. doi: 10.2307/ 2286348.
\bibitem{22-kr-1}
\Aue{Zivot, E., and D.~Andrews.} 2002. Further evidence on the great crash, the oil-price shock,
 and the unit-root hypothesis. \textit{J.~Bus. Econ. Stat.} 10(3):251--270. 
 doi: 10.2307/ 1391541.
\bibitem{23-kr-1}
Finam. Dannye ot 01.01.2005 do 20.11.2020 [Data from 01.01.2005 to 20.11.2020]. Available at: 
{\sf https://www.\linebreak finam.ru/} (accessed April~6, 2022). 
\bibitem{24-kr-1}
\Aue{Litvinova, Ya.\,S.} 2012. Tsena na neft' kak klyuchevoy faktor vozdeystviya na rossiyskuyu valyutu 
[Oil price as a~key factor affecting the Russian currency]. 
\textit{Mat-ly I Mezhdunar. nauchn. konf. ``Problemy i~perspektivy ekonomiki i~upravleniya''}
 [I Scientific Conference (International) ``Problems and Prospects of Economics and Management'' Proceedings]. 
 St.\ Petersburg: Renome. 19--21. Available at: 
 {\sf  https://moluch.ru/conf/econ/archive/15/ 2170} (accessed June~3, 2022).
 \end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received October 26, 2021}}

\Contrl

\noindent
\textbf{Kravtsova Olga A.} (b.\ 1996)~--- 
PhD student, Faculty of Computational Mathematics and Cybernetics, M.\,V.~Lomonosov Moscow State University, 
1-52~Leninskie Gory, GSP-1, Moscow 119991, Russian Federation; \mbox{phd3984@gse.cs.msu.ru}



   

\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература}    