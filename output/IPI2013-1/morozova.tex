\def\stat{morozova}

\def\tit{ПОСТРОЕНИЕ СЕМАНТИЧЕСКИХ ВЕКТОРНЫХ 
ПРОСТРАНСТВ РАЗЛИЧНЫХ ПРЕДМЕТНЫХ 
ОБЛАСТЕЙ$^*$}

\def\titkol{Построение семантических векторных 
пространств различных предметных 
областей}

\def\autkol{Ю.\,И.~Морозова}

\def\aut{Ю.\,И.~Морозова$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
{Работа выполнена при частичной поддержке РФФИ (проект 11-06-00476-а).}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Институт проблем информатики Российской академии наук, yulia-ipi@yandex.ru}


\Abst{Данная работа посвящена актуальным проблемам исследования семантики 
лингвистических единиц с использованием корпусных методов. В~работе дается 
описание нового направления лингвистических исследований~--- дистрибутивной 
семантики. Предлагается расширение существующих моделей дистрибутивной 
семантики за счет перехода от описания лексем к описанию значимых словосочетаний. 
Описывается методика построения семантических векторных пространств (СВП) для 
различных предметных областей.}

\KW{дистрибутивная семантика; векторные пространства; значимые словосочетания; 
коллокации}

\vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}

\section{Обзор моделей дистрибутивной семантики}

Дистрибутивная семантика~--- об\-ласть научных исследований, 
занимающаяся вычислением степени семантической близости между 
лингвистическими единицами на основании их дистрибутивных 
(контекстных) признаков в больших массивах лингвистических данных. 
Модели векторных пространств находят все более широкое применение в 
исследованиях, связанных с семантическими моделями естественного 
языка, и имеют разнообразный спектр потенциальных и действующих 
приложений. Основными сферами применения дистрибутивных моделей 
являются: разрешение лексической неоднозначности, информационный 
поиск,\linebreak кластеризация документов, автоматическое формирование словарей 
(словарей семантических отноше\-ний, двуязычных словарей), создание 
семантических карт, моделирование перифраз, определение тематики 
документа, определение тональности высказывания, биоинформатика. 

Теоретические основы данного направления восходят к дистрибутивной 
методологии З.~Харриса~[1, 2]. Близкие идеи выдвигали 
основоположники структурной лингвистики Ф.~де~Сос\-сюр и 
Л.~Витгенштейн. Дистрибутивная семантика основывается на 
дистрибутивной гипотезе о том, что лингвистические элементы со схожей 
дистрибуцией имеют близкие значения~[3, 4]. 

В качестве вычислительного инструмента и спосо\-ба представления 
моделей используется линейная алгебра. Информация о дистрибуции 
лингви\-сти\-че\-ских единиц представляется в виде многоразрядных векторов, 
а семантическая близость между лингви\-сти\-че\-ски\-ми единицами 
вы\-чис\-ля\-ет\-ся как расстояние между векторами. Много\-разрядные векторы 
образуют матрицу, где каждый\linebreak вектор соответствует лингвистической 
единице (слово или словосочетание), а каждое измерение вектора 
соответствует контексту (документ, параграф, предложение, 
словосочетание, слово).

Для вычисления меры близости между векторами могут использоваться 
различные формулы: расстояние Минковского, расстояние Манхеттена, 
евклидово расстояние, расстояние Чебышёва, скалярное произведение, 
косинусная мера. Наиболее популярной является косинусная мера:
$$
\fr{x\bullet y}{\vert x\vert\bullet\vert y\vert }= \fr{\sum\limits_{i=1}^n 
x_i\bullet y_i}{\sqrt{\sum\limits_{i=1}^n 
x_i^2}\bullet\sqrt{\sum\limits_{i=1}^n y_i^2}}\,.
$$

Существует множество разновидностей моделей дистрибутивной 
семантики, которые различаются по следующим параметрам:
\begin{itemize}
\item тип контекста (размер контекста, правый или левый контекст, 
ранжирование);
\item количественная оценка частоты встречаемости слова в данном 
контексте (абсолютная частота, энтропия, совместная информация и~пр.); 
\item метод вычисления расстояния между векторами (косинус, скалярное 
произведение, расстояние Минковского и~пр.);
\item метод уменьшения размерности матрицы (случайная проекция, 
сингулярное разложение и~пр.).
\end{itemize}

Наиболее известными моделями дистрибутивной семантики являются 
латентный семантический анализ, разработанный для решения проблемы 
синонимии при информационном поиске~[5], и модель языка как 
гиперпространства, разработанная как модель семантической памяти 
человека~[6].

Концепция СВП впервые была 
реализована в ин\-фор\-ма\-ци\-он\-но-поиско\-вой системе SMART~[7].\linebreak 
Идея СВП состоит в представлении каждого документа из коллекции в 
виде точки в пространстве, т.\,е.\ вектора в векторном пространстве. Точки,\linebreak 
расположенные ближе друг к другу в этом пространстве, считаются более 
близкими по смыслу. Пользовательский запрос рассматривается как 
псевдодокумент и тоже представляется как точка в этом же пространстве. 
Документы сортируются в порядке возрастания расстояния, т.\,е.\ в 
порядке уменьшения семантической близости от запроса, и в таком виде 
предоставляются пользователю. 

Впоследствии концепция СВП была успешно применена для других 
семантических задач. Например, в работе~[8] контекстное векторное 
пространство было использовано для оценки семантической близости 
слов. Данная сис\-те\-ма достигла результата 92,5\% на тесте по выбору 
наиболее подходящего синонима из стандартного теста английского языка 
TOEFL, в то время как средний результат при прохождении теста 
человеком был 64,5\%.

В настоящее время ведутся активные исследования по унификации модели 
СВП и выработке общего подхода к различным задачам выявления 
семантических связей из корпусов текстов~[9].

\section{Выделение значимых словосочетаний}

Целью данной работы является применение модели СВП для построения 
концептуальных моделей различных предметных областей. Развитие 
существующих подходов к построению СВП заключается в использовании 
значимых словосочетаний (ЗС) вместо отдельных лексем. Под ЗС
 понимаются лексические последовательности, 
имеющие тенденцию к совместной встречаемости. 
     
     В лингвистике для обозначения ЗС
используется также термин <<коллокация>>. Этот термин был впервые 
введен в <<Словаре лингвистических терминов>> О.\,С.~Ахмановой~[10]. 
Исследованиям коллока\-ций русского языка посвящено большое 
количество литературы, например монография Е.\,Г.~Борисовой~[11]. 
В~теоретической лингвистике под коллокациями понимают 
словосочетания из двух или более слов, которые обусловливают друг друга 
семантически и грамматически~[12]. В~корпусной лингвистике 
коллокациями называют статистически устойчивые словосочетания, 
причем они могут быть как фразеологизированными, так и свободными.
     
     Для выделения значимых словосочетаний в компьютерной 
лингвистике используются различные статистические меры (меры 
ассоциации, меры ассоциативной связанности, \textit{англ.}\ association measures), 
вычисляющие силу связи между элементами в составе коллокации. 
В~литературе упоминается несколько десятков мер ассоциативной 
свя\-зан\-ности. Чаще других используются MI, t-score и log-likelihood~[13].

Мера MI (mutual information), введенная в работе~\cite{14-mor}, сравнивает 
зависимые кон\-текст\-но-свя\-зан\-ные час\-то\-ты с независимыми 
частотами слов в тексте. Если значение MI превосходит определенное 
пороговое значение, то словосочетание считают статистически значимым. 
Мера MI вычисляется по следующей формуле:
$$
\mathrm{MI}=\log_2\fr{f(n,c)\times N}{f(n)\times f)c)}\,,
$$
где $n$~--- первое слово словосочетания; $c$~--- второе слово 
словосочетания; $f(n,c)$~--- частота совместной встречаемости двух слов; 
$f(n)$, $f(c)$~--- абсолютные частоты встречаемости каждого слова по 
отдельности; $N$~--- общее число словоупотреблений в корпусе.

Мера t-score также используется при ответе на вопрос, насколько не 
случайным является сочетание двух или более слов в тексте. Для 
вычисления t-score используется следующая формула:
$$
\mathrm{t}\mbox{-}\mathrm{score}=\fr{f(n,c)-f(n)\times 
f(c)/N}{\sqrt{f(n,c)}}\,.
$$

     Также достаточно часто применяется мера, известная под названием 
log-likelihood, или логарифмическая функция правдоподобия, введенная в\linebreak 
работе~\cite{15-mor}. Для вычисления log-likelihood применяется 
следующая формула:
     $$
     \mathrm{log}\mbox{-}\mathrm{likelihood}=2\sum f(n,c)\times 
\log_2\fr{f(n,c)\times N}{f(n)\times f(c)}\,.
     $$

Применив различные меры ассоциативной связанности слов к материалам 
научных патентов, авторы составили частотный словарь значимых 
словосочетаний для предметной области научных\linebreak патентов. Примеры 
выделенных значимых словосочетаний: \textit{благородный металл}, 
\textit{вспомогательное устройство}, \textit{жесткий элемент}, 
\textit{измерительная ячейка}, \textit{опорный карниз}, \textit{оптический 
луч}, \textit{система охлаж\-де\-ния}, \textit{тяжелая фракция}.

\section{Построение семантического векторного пространства}

Модель семантического векторного пространства, которую планируется 
построить в ходе данного исследования, обладает следующими 
характеристиками:
\begin{itemize}
\item тип изучаемых единиц: значимые словосочетания;
\item тип контекста: лексемы и словосочетания, размер контекста~--- 
предложение, ранжирование контекста~--- нет;
\item количественная оценка частоты встречаемости изучаемой единицы в 
данном контексте: абсолютная частота;
\item метод вычисления расстояния между векторами: косинусная мера.
\end{itemize}

Приведем пример использования методики построения СКП на основе 
следующего текстового фрагмента:

\noindent
\textit{Искусственный интеллект~--- наука и технология создания 
интеллектуальных машин, особенно интеллектуальных компьютерных 
программ.}

\noindent
\textit{Компьютерная лингвистика~--- направление искусственного 
интеллекта, которое ставит своей целью использование математических 
моделей для описания естественных языков}. 

\noindent
\textit{Дискретная математика~--- область математики, занимающаяся 
изучением дискретных структур, которые возникают как в пределах 
самой математики, так и в ее приложениях.}
\noindent
\textit{Конструктивная математика~--- близкое к интуиционизму течение 
в математике, изучающее конструктивные построения.}

Построим контекстные векторы для ЗС <<\textit{искусственный 
интеллект}>>, <<\textit{компьютерная лингвистика}>>, 
<<\textit{дискретная математика}>>, <<\textit{конструктивная 
математика}>> и слов, встречающихся в текстовом фрагменте более 
одного раза. В~таблице используются сокращенные обозначения: 
$c_1$~--- искусственный интеллект;  $c_2$~--- компьютерная 
лингвистика; $c_3$~--- дискретная математика; $c_4$~--- конструктивная 
математика; $c_5$~--- интеллект, интеллектуальный; $c_6$~--- 
математика, математический; $c_7$~--- изучать, изучение.

    Применив формулу вычисления косинусной меры между 
контекстными векторами, получим\linebreak\vspace*{-12pt}


\begin{center}
\vspace*{1pt}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
&$c_1$&$c_2$&$c_3$&$c_4$&$\ldots$\\
\hline
$c_1$&0&1&0&0&$\ldots$\\
$c_2$&1&0&0&0&$\ldots$\\
$c_3$&0&0&0&0&$\ldots$\\
$c_4$&0&0&0&0&$\ldots$\\
$\ldots$&$\ldots$&$\ldots$&$\ldots$&$\ldots$&$\ldots$\\
\hline
\end{tabular}
\vspace*{6pt}
\end{center}

\noindent
 следующие коэффициенты 
семантической бли\-зости между рассматриваемыми ЗС:

<<\textit{дискретная математика}>> и <<\textit{конструктивная 
математика}>>~--- 0,95;

<<\textit{искусственный интеллект}>> и <<\textit{компьютерная 
лингвистика}>>~--- 0,7;

<<\textit{компьютерная лингвистика}>> и <<\textit{дискретная 
математика}>>~--- 0,52;

<<\textit{компьютерная лингвистика}>> и <<\textit{конструктивная 
математика}>>~--- 0,4;

<<\textit{искусственный интеллект}>> и <<\textit{дискретная 
математика}>>~--- 0,36;

<<\textit{искусственный интеллект}>> и <<\textit{конструктивная 
математика}>>~--- 0,29.

\section{Заключение}

В работе были рассмотрены основные направления и модели нового 
направления исследований в компьютерной лингвистике~--- 
дистрибутивной семантики. На основании автоматической обработки 
больших массивов лингвистических данных возможно создавать 
различные лингвистические ресурсы: семантические словари, 
многоязычные словари, семантические карты предметных областей. 
В~качестве математической модели используются многоразрядные 
векторы и мат\-ри\-цы линейной ал\-геб\-ры, что представляет собой 
удобный формализм для компьютерной реализации. В~рамках данного 
направления предлагается разработать методику построения 
семантических векторных пространств для различных предметных 
областей, где в качестве изучаемых единиц будут выступать значимые 
словосочетания, выделенные из текстов с использованием мер 
ассоциативной связанности слов. 

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{99}

\bibitem{1-mor}
\Au{Harris Z.\,S.} Papers in structural and transformational linguistics.~--- 
Dordrecht: Reidel, 1954.
\bibitem{2-mor}
\Au{Harris Z.\,S.} Mathematical structures of language.~--- New York: John 
Wiley \& Sons, 1968.
\bibitem{3-mor}
\Au{Sahlgren M.} The distributional hypothesis~// From context to meaning: 
Distributional models of the lexicon in linguistics and cognitive science (Special 
issue of the Italian Journal of Linguistics).~--- Pisa: Pacini Editore, 2008. 
Vol.~20. No.\,1. P.~33--53.
\bibitem{4-mor}
\Au{Turney P.\,D., Pantel P.} From frequency to meaning: Vector space models 
of semantics~// J.~Artificial Intelligence Research.~--- Menlo Park, California: 
AAAI Press, 2010. No.\,37. P.~141--188.
\bibitem{5-mor}
\Au{Landauer Th.\,K., McNamara D.\,S., Dennis~S., Kintsch~W.} Handbook of 
Latent Semantic Analysis.~--- Mahwah, NJ: Lawrence Erlbaum, 2007.
\bibitem{6-mor}
\Au{Lund K., Burgess C.} Producing high-dimensional semantic spaces from 
lexical co-occurrence~// Behavior Research Methods, Instruments \& 
Computers.~--- New York: Psychonomic Society, 1996. Vol.~28. No.\,2. 
P.~203--208.
\bibitem{7-mor}
\Au{Salton G.\,M.} The SMART retrieval system: Experiments in automatic 
document processing.~--- Eaglewood Cliffs, NJ: Prentice-Hall, 1971.
\bibitem{8-mor}
\Au{Rapp R.} Word sense discovery based on sense descriptor dissimilarity~// 
9th MT Summit Proceedings.~--- New Orleans, LA, 2003. P.~315--322. {\sf 
http://www.amtaweb.org/ summit/MTSummit/FinalPapers/19-Rapp-final.pdf}.
\bibitem{9-mor}
\Au{Turney P.} A~uniform approach to analogies, synonyms, antonyms and 
associations~// 22nd Conference (International) on Computational Linguistics 
(\mbox{COLING}) Proceedings, 2008. P.~905--912. {\sf 
http://www.aclweb. org/anthology-new/C/C08/C08-1114.pdf}.
\bibitem{10-mor}
\Au{Ахманова О.\,С.} Словарь лингвистических терминов.~--- М.: 
Советская энциклопедия, 1966.
\bibitem{11-mor}
\Au{Борисова Е.\,Г.} Коллокации. Что это такое и как их изучать.~--- 2-е 
изд., стер.~--- М.: Филология, 1995.
\bibitem{12-mor}
\Au{Иорданская Л.\,Н., Мельчук И.\,А.} Смысл и сочетаемость в 
словаре.~--- М.: Языки славянских культур, 2007.
\bibitem{13-mor}
\Au{Захаров В.\,П., Хохлова М.\,В.} Анализ эффективности статистических 
методов выявления коллокаций в текстах на русском языке~// 
Компьютерная лингвистика и интеллектуальные технологии: Труды 
Междунар. конф. Диалог'2010.~--- М.: РГГУ, 2010.
\bibitem{14-mor}
\Au{Church K., Hanks P.} Word association norms, mutual information, and 
lexicography~// Computational Linguistics,
1996. Vol.~16. No.\,1. P.~22--29.

\label{end\stat}

\bibitem{15-mor}
\Au{Dunning T.} Accurate methods for the statistics of surprise and 
coincidence~// Computational Linguistics,
1993. Vol.~19. No.\,1. P.~61--74.
\end{thebibliography}
}
}

\end{multicols}