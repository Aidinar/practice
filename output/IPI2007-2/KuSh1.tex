%%файл макросов для Латеха.Сотавил Шиоков Б. Март 1995.
\newcommand{\il}[2]{\int\limits_{#1}^{#2}}%интеграл с пределами #1 и #2
\font\aj=msbm10   %ажурнай шрифт
\font\got=eufm10   %готический шрифт
\newcommand{\p}{{\sf P}}  %вероятность
\newcommand{\e}{{\sf E}}  % матожидание
\newcommand{\D}{{\sf D}}  % дисперсия
%\renewcommand{\labelenumi}{\theenumi)}%метка в enumarate: n)
%\renewcommand{\pd}{\p(N_k=n)}%дискретная функций распределения
\newcommand{\frr}[4]{\p(#1_1#2#3_1,\ldots,#1_{#4}#2#3_{#4})}
\newcommand{\eql}[1]{\openup1\jot
\tabskip=0pt plus1fil\halign to \textwidth{
\tabskip=0pt$\hfil\displaystyle##\hfil$\tabskip =0pt plus1fil&
{\rm##}\tabskip=0pt\crcr#1\crcr}}%многострочные формулы с номерами
\renewcommand{\r}{\hbox{\aj R}}  % поле дуйствительных чисел
\renewcommand{\a}{\alpha} % греческий
\newcommand{\be}{\beta}
\newcommand{\lam}{\lambda} %..........
\newcommand{\La}{\Lambda} %..........
\renewcommand{\t}{\theta} %..........
\newcommand{\T}{\Theta}  %..........
\renewcommand{\d}{\delta} % алфавит
\newcommand{\de}{\Delta} %.....
\newcommand{\G}{\Gamma}%.....
%\renewcommand{\g}{\gamma}   %греч.
\newcommand{\kp}{\mathop{\rm\ae{}}} %каппа
\newcommand{\om}{\omega}
%\newcommand{\si}{\sigma}  %алфавит
\newcommand{\pto}{\stackrel{P}{\to}}
\newcommand{\ff}[2]{\left({#1\over#2}\right)}% дробь с круглами скобками
\newcommand{\eqd}{\stackrel{d}{=}} % равество с буквой d
\newcommand{\vct}[2]{{#1}_1+\ldots+{#1}_{#2}} % сумма #2 чисел #1
\newcommand{\vc}[2]{{#1}_1,\ldots,{#1}_{#2}}
\newcommand{\gr}{\!\ge\!}
\newcommand{\li}{\!\le\!}
\newcommand{\seq}[2]{\{#1_{#2}\}_{#2\ge1}} % пос-сть чисел #1 с инд.#2
\newcommand{\ex}[1]{\exp\left\{it#1\right\}}
\newcommand{\sqn}[2]{\{#1_{n,#2}\}_{#2\ge1}}
\newcommand{\n}{{\cal N}}% каллиграфические буквы
\renewcommand{\k}{{\cal K}}% --''--
\newcommand{\m}{{\cal M}}% --"--
\renewcommand{\c}{{\sf C}}%--"--
\renewcommand{\b}{{\sf B}}%--"--
\newcommand{\h}{{\cal H}} %--"--
\newcommand{\x}{{\cal X}} %.....
\renewcommand{\u}{{\cal U}} %.....
\newcommand{\I}{\hbox{\sf\bf I}}
%\renewcommand{\V}{\hbox{\sf V}}
%\let\ln=\log


\def\stat{kush}

\def\tit{БАЙЕСОВСКИЙ ПОДХОД К~АНАЛИЗУ СИСТЕМ МАССОВОГО 
ОБСЛУЖИВАНИЯ И~ПОКАЗАТЕЛЕЙ НАДЕЖНОСТИ$^*$}
\def\titkol{Байесовский подход к анализу систем массового обслуживания и показателей надежности}
\def\autkol{А.\,А.~Кудрявцев, С.\ Я.\ Шоргин}
\def\aut{А.\,А.~Кудрявцев$^1$, С.\ Я.\ Шоргин$^2$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
{Работа выполнена при поддержке РФФИ, проект \No 05-07-90103.}

\renewcommand{\thefootnote}{\arabic{footnote}}}
 \footnotetext[1]{Факультет вычислительной математики и кибернетики МГУ им. М.\,В.~Ломоносова,
nubigena@hotmail.com} 
\footnotetext[2]{Институт проблем информатики Российской академии наук, sshorgin@ipiran.ru}


%\input macros.tex

\Abst{В данной работе рассматривается байесовский подход к постановке определенных задач теории массового обслуживания и теории
надежности. Соответствующий метод предусматривает рандомизацию характеристик систем относительно некоторых априорных
распределений их параметров. Данный подход может использоваться, в частности, для вычисления моментных
характеристик для вероятностно-временных и надежностных характеристик больших групп систем или устройств. В работе
приведена сводка результатов, полученных ранее; представлены новые результаты для случая, когда в качестве априорного
рассматривается распределение Эрланга.}

\KW{байесовский подход; системы массового обслуживания; надежность; смешанные
распределения; моделирование}

\vskip 24pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}


\label{st\stat}


\section{Введение и основные предположения}

Теория массового обслуживания~--- весьма развитая математическая дисциплина. 
В рамках этой теории получено огромное количество глубоких с точки зрения 
математики и важных с прикладной точки зрения результатов, относящихся к
исследованию систем и сетей массового обслуживания (СМО), представляющих 
собой модели широкого класса реальных систем, прежде
всего информационно-телекоммуникационных систем и сетей. 
В настоящее время развитие теории массового обслуживания
ведется, в основном, в на\-прав\-ле\-нии рас\-смот\-ре\-ния все более сложных по вероятностным характеристикам входящих потоков и
распределений времени обслуживания, все более сложных дис\-цип\-лин обслуживания, в интересах более адекватного отражения
реальных процессов.

Одним из направлений обобщения и усложнения постановок является усложнение 
вероятностной структуры тех или иных входных параметров СМО. В частности,  
вместо традиционных входящих потоков рассматриваются потоки Кокса, самоподобные 
потоки, марковские и полумарковские потоки и~т.\,п. Аналогичные обобщения 
осуществляются и по отношению к распределениям времен %\linebreak 
обслу\-жи\-ва\-ния. В 
определенной степени эти обобщения могут интерпретироваться как результат 
рандомизации тех или иных параметров более <<прос\-тых>> потоков и 
распределений обслуживания. Так, процесс Кокса получается в результате 
специальной рандомизации интенсивности пуассоновского потока и~т.\,п.

Все эти обобщенные современные постановки предполагают, что стохастический механизм рандомизации <<влияет>> на
параметры системы непосредственно в период ее функционирования, то есть мы изначально знаем, с какой системой <<имеем
дело>>, пусть даже эта система достаточно сложна, и исследуем характеристики функционирования именно этой <<изначально
фиксированной>> системы. 

Однако в реальной практике часты ситуации, при которых сама исследуемая система задана в
определенном смысле <<неточно>>. 

Например, если даже говорить о простейших системах типа M$\vert$G$\vert$1, исследователю могут быть
априори не известны параметр входящего потока $\lambda$ и параметры обслуживания $\mu$ и $\sigma^2$. Такие ситуации
возникают, скажем, в случае, когда рассматривается целый класс однотипных СМО, относительно которых известны только
типы входящего потока и распределения обслуживания, а также дисциплина обслуживания, но конкретные параметры этих
потоков и распределений, вообще говоря, различны для разных СМО данного класса. Исследователь априори не знает, с
какой СМО из данного класса он имеет дело (это может иметь место, например, при исследовании серии однотипных устройств
коммутации или передачи, выпускаемых одним и тем же производителем, для которых разброс значений тех или иных
показателей обусловливается естественными технологическими вариациями при производстве; возможны и другие примеры). В
этом случае, поскольку неизвестными являются именно <<исходные>> параметры потоков и времени обслуживания, естественным
является рандомизационный подход, при котором элементами вероятностного пространства становятся (если рассматривать
приведенный выше пример) значения $\lambda$, $\mu$ и $\sigma^2$ (а в общем случае можно говорить о вероятностном
пространстве, элементами которого являются сами однотипные СМО). При этом подлежащие вычислению характеристики такой
<<рандомизированной>> СМО, естественно, являются рандомизацией аналогичных характеристик <<обычной>> СМО того же
типа~--- с учетом того априорного распределения входных параметров СМО, которое взято исследователем за основу.

Таким образом, в том же примере с системой типа M$\vert$G$\vert$1 возникают задачи рандомизации <<обычных>> характеристик таких систем с
учетом априорных распределений входных па\-ра\-мет\-ров. Скажем, может приниматься предположение о показательном, равномерном
или каком-то другом распределении одной или нескольких из величин $\lambda$, $\mu$ и $\sigma^2$ (которые при таком
подходе становятся случайными величинами), об их независимости или зависимости и~т.\,п. Полученные результаты могут
применяться, например, для вы\-чис\-ле\-ния средних значений, построения доверительных интервалов для тех или иных
характеристик рассматриваемого класса СМО <<в целом>>. Такой подход к построению моделей массового обслуживания
естественно назвать байесовским. Впервые он сформулирован в~\cite{Shorgin05}.

Другим направлением применения байесовского подхода является оценка надежности. Как известно~\cite{Kozlov70},
коэффициент готовности восстанавливаемого устройства в стационарном режиме может быть вычислен по формуле
$$
k=\fr{\lambda^{-1}}{\lambda^{-1}+\mu^{-1}}=\fr{\mu}{\lambda+\mu}\,,
$$
где $\lambda^{-1}$~--- среднее время безотказной работы, $\mu^{-1}$~--- среднее время восстановления. Если мы примем
сформулированное выше предположение, в соответствии с которым любое изучаемое устройство выбирается случайным образом
из некоторого множества сходных устройств, различающихся средними величинами показателей надежности, то, %\linebreak
соглас\-но
приведенным выше рассуждениям, значения $\lambda$ и $\mu$ можно рассматривать в качестве случайных.
Следовательно, при таких предположениях коэффициент готовности $k$ также является случайной величиной, и его
распределение зависит от распределений величин $\lambda$ и $\mu$. Результаты, получаемые в рамках такой постановки,
могут использоваться, в частности, для вычисления средних значений и построения доверительных интервалов для
надежностных характеристик всей изучаемой группы устройств.

Данная работа является логическим продолжением статьи~\cite{Apice06}, в которой авторы рассматривали вероятностные
характеристики коэффициента загрузки $\rho$, вероятности потерь $1-\pi$ (здесь $\pi$~--- вероятность того, что входящий
в СМО вызов не будет потерян) и коэффициента готовности $k$ в системе M$\vert$M$\vert$1$\vert$0 в предположении об экспоненциальном и
равномерном распределении параметров $\lambda$ и $\mu$. В работе будет рассмотрен еще один вид зависимости
вероятностных и моментных характеристик случайных величин $\rho$, $\pi$ и $k$ в предположении, что параметр входящего
потока $\lambda$ и параметр обслуживания~$\mu$ независимы и имеют вырожденное распределение и распределение Эрланга
соответственно.

%Авторы предполагают расширить рассматриваемый класс распределений, по которым производится рандомизация параметров
%$\lambda$ и $\mu$. В таблице 1 отображены этапы рассмотрения предложенной задачи. Буквы D, M, R, E, P обозначают
%вырожденное, экспоненциальное, равномерное, Эрланга, Парето распределения соответственно, символ <<$*$>> относится к
%классической постановке задачи, символ <<$+$>> соответствует распределениям, о которых пойдет речь в данной работе, а
%символом <<$-$>> обозначаются распределения, для которых авторы планируют получить аналогичные результаты в дальнейшем.

%\begin{center}
%\begin{tabular}{|c||c|c|c|c|c|}
%\hline
%\vspace{-2.5mm}&&&&&\\
%$\lambda, \mu$&D&M&R&E&P\\
%\vspace{-4mm}&&&&&\\
%\hline
%\hline
%\vspace{-2.5mm}&&&&&\\
%D&*&$+$&$+$&$+$&$-$\\
%\vspace{-4mm}&&&&&\\
%\hline
%\vspace{-2.5mm}&&&&&\\
%M&&$+$&$-$&$-$&$-$\\
%\vspace{-4mm}&&&&&\\
%\hline
%\vspace{-2.5mm}&&&&&\\
%R&&&$+$&$-$&$-$\\
%\vspace{-4mm}&&&&&\\
%\hline
%\vspace{-2.5mm}&&&&&\\
%E&&&&$-$&$-$\\
%\vspace{-4mm}&&&&&\\
%\hline
%\vspace{-2.5mm}&&&&&\\
%P&&&&&$-$\\
%\hline
%\end{tabular}

%\bigskip

%{\footnotesize Таблица 1.}
%\end{center}

%\smallskip

%Для того, чтобы лучше объяснить суть постановки задачи приведем следующий несложный пример.


\section{Вводный пример}


Рассмотрим ситуацию, когда некий наблюдатель (исследователь) имеет дело с достаточно большой серией систем обслуживания
M$\vert$M$\vert$1$\vert$0, различающихся только параметром распределения %\linebreak 
обслу\-жи\-ва\-ния. В частности, это могут быть некие станки,
коммутаторы, маршрутизаторы или другие обслуживающие средства, о которых заранее известно, что их функционирование
описывается системой вышеуказанного типа. То есть эти сис\-те\-мы идентичны по дисциплине обслуживания и по типам входящего
потока и распределения времени обслуживания. В рассматриваемом примере характеристики входящего потока также предполагаются
идентичными для всех систем данной серии; различаются только численные характеристики обслуживания (то есть параметры
показательного распределения).

Разброс характеристик обслуживания обуслов\-ли\-ва\-ет\-ся технологическими (конструктивными) причинами. И главным аспектом
рассматриваемой постановки является то, что исследователю не известно, каково конкретное значение параметра
обслуживания рассматриваемой им <<взятой наугад>> системы из данной серии. Известно лишь <<априорное>> распределение
этого параметра (поскольку серия систем мыслится большой, то можно в рамках этой серии рассматривать стохастические
явления и вводить вероятностные распределения). Исследователя интересуют характеристики обслуживания для серии в целом
(или характеристики <<наугад взятой>> системы). Очевидно, что помимо традиционных факторов стохастичности, имеющих
место в СМО (стохастичность поступающего потока и процессов обслуживания), появляется еще один фактор, связанный со
случайностью выбора рассматриваемой системы.

Пусть, скажем, параметр обслуживания $\mu$ у рассматриваемых систем может принимать только два значения $\mu_1$ и
$\mu_2$ с вероятностями соответственно $p_1$ и $p_2$. <<Физически>> это означает, что среди рассматриваемой серии
систем (маршрутизаторов, станков и~т.\,п.) встречаются только две <<разновидности>> обслуживающих приборов: приборы
первой разновидности осуществляют обслуживание с параметром $\mu_1$, приборы второй разновидности~--- с параметром
$\mu_2$. Тогда у <<взятой наугад>> системы коэффициент загрузки становится случайной величиной, принимающей значения
$\lambda/\mu_1$ с ве\-ро\-ятностью~$p_1$ и $\lambda/\mu_2$ с вероятностью $p_2$. Ста\-ци\-о\-нар\-ная вероятность блокировки
<<выбранной>> системы в связи с вмешательством случайного фактора выбора конкретной системы сама становится
<<случайной>> и принимает значения $\lambda/(\lambda+\mu_1)$ с вероятностью~$p_1$ (это вероятность того, что
исследователю <<попалась>> система первой <<разновидности>>) и $\lambda/(\lambda+\mu_2)$ с вероятностью $p_2$
(<<попалась>> система второй <<разновидности>>). Естественно, <<усредненная>> вероятность блокировки в такой
<<байесовской>> СМО равна $p_1\lambda/(\lambda+\mu_1)+p_2\lambda/(\lambda+\mu_2)$.

Как видим, для исследования байесовских СМО нет необходимости проводить анализ сис\-те\-мы %\linebreak
ме\-то\-да\-ми теории массового
обслуживания. Байесов\-ская система является <<рандомизацией>> не\-ко\-торой <<обычной>> СМО, и, соответственно, %\linebreak
характеристики байесовской СМО вычисляются путем рандомизации последующего усреднения (по априорному распределению
параметра или параметров) уже вычисленных ранее методами теории массового обслуживания характеристик <<обычной>> СМО.
То есть математическая часть работы сводится именно к этой рандомизации и усреднению. При этом как с технической, так и
с концептуальной точек зрения целесообразно осуществлять рандомизацию стационарных характеристик  
<<обычных>> СМО,
получая стационарные характеристики байесовских СМО.
{\looseness=1

}

Отметим еще одну содержательную модель, математическим описанием которой может служить байесовская СМО. Предположим,
что исследователь рассматривает не серию систем, а некоторую одну систему, количественные параметры которой меняются со
временем. Например, имеется обслуживающее устройство, один из элементов которого в заранее не известные моменты
заменяется на другой, потом на третий и~т.\,п. Скажем, такой системой является пограничный пост в аэропорту, пограничник
на котором иногда сменяется~--- в моменты времени, не известные наблюдателю (пассажиру); наблюдатель знает лишь
вероятность того, что он <<наткнется>> на некоторого конкретного пограничника, и среднее время проверки паспорта каждым
из возможных пограничников.

При таком подходе структура системы и дис\-цип\-ли\-на обслуживания не изменяются со временем, а изменяется только
количественный параметр распределения обслуживания (например, интенсивность). Аналогичным образом может меняться и
параметр поступающего потока. О том, когда происходят изменения, информации нет. Исследователю известно только
распределение значений <<изменчивых>>, случайных параметров, с которыми он <<сталкивается>>, рассматривая систему в
<<случайный>> момент времени.

Поскольку предполагается, что информации о моментах <<перестройки>> системы или хотя бы о распределении этих моментов у
исследователя нет, описание переходных процессов в системе такого рода невозможно. Следовательно, возможен анализ (и
последующая рандомизация) только стационарных распределений рассматриваемой СМО. Для того чтобы такая постановка имела
смысл, необходимо ввести предположение, что система изменяется достаточно <<редко>>~--- так, чтобы на каждом интервале
постоянства параметров СМО <<успевала>> достичь стационарного состояния. Естественно, результаты такого анализа будут
приближенными, поскольку в реальной жизни стационарное состояние, строго говоря, не достигается.

\section{Обзор полученных ранее результатов}

Напомним, что данная работа посвящена рассмотрению системы M$\vert$M$\vert$1$\vert$0. Для большей полноты картины приведем вкратце
результаты, опубликованные в~\cite{Apice06}.

Рассмотрим произвольную СМО, в которой интенсивность входящего потока $\lambda$ и
интенсивность обслуживания $\mu$ независимы и имеют равномерное распределение. Такая модель приемлема для описания
ситуации, когда для обоих значений~$\lambda$ и~$\mu$ (или для любого из них) задан допустимый интервал значений, но
реальная величина~$\lambda$ и/или $\mu$ может варьироваться в этих пределах.

Загрузка рассматриваемой системы $\rho=\lambda/\mu$. Как известно, от значения $\rho$ зависит наличие стационарного
режима у рассматриваемой системы; величина $\rho$ входит во многие формулы, опи\-сы\-ва\-ющие характеристики разнообразных
СМО. В связи с этим рассмотрение величины $\rho$ представляется одной из первоочередных задач, которые следует
исследовать в рамках байесовской теории СМО.

Пусть носителем случайной величины $\lambda$ является некоторый отрезок $[a_\lambda,\ b_\lambda]$, носителем случайной
величины $\mu$~--- некоторый отрезок $[a_\mu,\ b_\mu]$, причем $0\le a_\lambda\le b_\lambda$, $0\le a_\mu\le b_\mu$.

При этом функция распределения случайной величины $\rho$ может быть записана таким образом:
$$\p(\rho<x)=\int\!\!\!\!\!\!\il{\!\!\!\!\lambda/\mu<x}{}\fr{1}{(b_\lambda-a_\lambda)(b_\mu-a_\mu)}\
d\lambda d\mu.$$

Дальнейшие выкладки существенно зависят от соотношения между величинами $a_\lambda/a_\mu$ и $b_\lambda/b_\mu$.
Предположим для определенности, что $a_\lambda/a_\mu\le$\linebreak $\le  b_\lambda/b_\mu$. Обозначим
$$
K=\fr{1}{(b_\lambda-a_\lambda)(b_\mu-a_\mu)}\,.
$$
Тогда при $x< a_\lambda/b_\mu$
$$
\p(\rho<x)=0\,,
$$
при $a_\lambda/b_\mu\le x\le a_\lambda/a_\mu$
$$
\p(\rho<x)=K\fr{(b_\mu x-a_\lambda)^2}{2x}\,,
$$
при $a_\lambda/a_\mu\le x\le b_\lambda/b_\mu$
$$
\p(\rho<x)=K\left(\fr{a_\mu+b_\mu}{2}x-a_\lambda\right)\left(b_\mu-a_\mu\right)\,,
$$
при $b_\lambda/b_\mu\le x\le b_\lambda/a_\mu$
$$
\p(\rho<x)=1-K\fr{(b_\lambda-a_\mu x)^2}{2x}\,,
$$
при $x>b_\lambda/a_\mu$
$$
\p(\rho<x)=1\,.
$$

Выпишем плотность случайной величины $\rho$. При $x< a_\lambda/b_\mu$
$$
f_\rho(x)=0\,,
$$
при $a_\lambda/b_\mu\le x\le a_\lambda/a_\mu$
$$
f_\rho(x)=K\left(\fr{b_\mu^2}{2}-\fr{a_\lambda^2}{2x^2}\right)\,,
$$
при $a_\lambda/a_\mu\le x\le b_\lambda/b_\mu$
$$
f_\rho(x)=K\fr{b_\mu^2-a_\mu^2}{2}\,,
$$
при $b_\lambda/b_\mu\le x\le b_\lambda/a_\mu$
$$
f_\rho(x)=K\left(\fr{b_\lambda^2}{2x^2}-\fr{a_\mu^2}{2}\right)\,,
$$
при $x>b_\lambda/a_\mu$
$$
f_\rho(x)=0\,.
$$

Проведя элементарные выкладки, получаем, что среднее значение и второй момент случайной величины $\rho$
равны соответственно:
\begin{align*}
\e\rho&=\fr{b_\lambda+a_\lambda}{2(b_\mu-a_\mu)}\, \ln\fr{b_\mu}{a_\mu}\,;\\
\e\rho^2&=\fr{a_\lambda^2+a_\lambda b_\lambda+b_\lambda^2}{3a_\mu b_\mu}\,.
\end{align*}

Очевидно, что при ($b_\lambda-a_\lambda)\rightarrow0$ и при ($b_\mu-a_\mu)\rightarrow$\linebreak $\rightarrow 0$, то есть при стягивании носителя
случайной величины $\lambda$ к некоторой фиксированной точке $\lambda_0$ и при стягивании носителя случайной 
величины~$\mu$ к некоторой фиксированной точке $\mu_0$ значение $\e\rho$, как это и должно быть, стремится к $\lambda_0/\mu_0$,
а значение $\e\rho^2$~--- к $\lambda_0^2/\mu_0^2$. Такая постановка задачи соответствует случаю, когда один или оба
параметра $\lambda$ и/или $\mu$ имеют вырожденное распределение.

Заметим также, что зависимость среднего значения величины $\rho$ от распределения $\lambda$ сводится к зависимости от
математического ожидания $\lambda$. В то же время зависимость $\e\rho$ от параметров распределения $\mu$ носит более
сложный вид.

В случае $a_\lambda/a_\mu\ge b_\lambda/b_\mu$ формулы для функции распределения и плотности случайной величины~$\rho$
аналогичны (здесь они опущены для сокращения объема изложения). Математическое ожидание и второй момент случайной
величины~$\rho$ в указанном случае совпадают с выписанными выше зна\-че\-ниями.

На основании полученных результатов нетрудно вычислить другие необходимые характеристики величины $\rho$.

Заметим, что рассмотренная модель позволяет изучать важную ситуацию, в которой $\lambda<\mu$ с вероятностью 1. При этом
$\rho<1$, что является условием эргодичности систем с одним обслуживающим прибором. В силу постулируемой независимости
случайных величин $\lambda$ и $\mu$ обеспечить выполнение условия $\lambda<\mu$ может только соответствующее взаимное
расположение отрезков $[a_\lambda,\ b_\lambda]$ и $[a_\mu,\ b_\mu]$, то есть выполнение условия $0\le a_\lambda\le
b_\lambda\le a_\mu\le b_\mu$.

Теперь рассмотрим случай показательной распределенности параметров $\lambda$ и $\mu$ в системе M$\vert$M$\vert$1$\vert$0. Подобную модель
целесообразно рассматривать в качестве <<первого приближения>> в ситуациях, когда никакой априорной информации о
значениях $\lambda$ и $\mu$ нет, за исключением данных об их средних значениях (пусть они равны соответственно $1/l$ и
$1/m$). Предположение о независимости $\lambda$ и~$\mu$ сохраняется.

В целях сокращения объема изложения остановимся лишь на конечных выражениях ин\-те\-ре\-су\-ющих нас характеристик.

Несложно показать, что при $x\ge0$
$$
\p(\rho<0)=\fr{lx}{m+lx}\,.
$$
Отсюда, в частности, следует, что случайная величина $\rho=\lambda/\mu$ в данном случае, в отличие от ситуации,
рассмотренной в предыдущем примере, не имеет моментов первого и более высоких порядков. Однако некоторые другие
характеристики байесовских СМО, зависящие от случайного $\rho$, могут иметь конечные моменты.

Рассмотрим, например, вероятность того, что поступивший в систему вызов не будет потерян. В~стационарном режиме эта
вероятность равна, в соответствии с формулами Эрланга, $\pi=1/(1+\rho)$. В~<<байесовской>> постановке эта вероятность,
как было отмечено выше, сама становится <<случайной>>. Рассмотрим распределение случайной величины $\pi$ в условиях
рассматриваемой модели.

При $0\le x\le1$ функция распределения и плотность случайной величины $\pi$  имеют вид соответственно
\begin{align*}
F_\pi(x)&=\fr{mx}{mx+l(1-x)}\,;\\
f_\pi(x)&=\fr{ml}{(mx+l(1-x))^2}\,,
\end{align*}
а усредненная вероятность непотери вызова~---
$$
\e\pi=\fr{ml}{(m-l)^2}\left(\ln\fr{m}{l}+\fr{l}{m}-1\right)\,.
$$
Нетрудно вычислить также второй момент случайной величины $\pi$ и другие ее характеристики. Заметим, что при $m=l$
$$
\e\pi=\fr{l}{2}\,.
$$

Значение
$$
\pi=\fr{1}{1+\rho}=\fr{\mu}{\lambda+\mu}
$$
совпадает с величиной коэффициента готовности~$k$. Следовательно, распределение случайного коэффициента готовности в
случае, когда величины~$\lambda$ и $\mu$ имеют показательное распределение, пред\-став\-ле\-но выше в качестве распределения
случайной величины $\pi$.

\section{Основные результаты}

Итак, рассмотрим, как и ранее, систему M$\vert$M$\vert$1$\vert$0. Пусть параметр входящего потока~$\lambda$ имеет вырожденное
распределение, а параметр обслуживания $\mu$ имеет распределение Эрланга с параметрами $n$ и $\alpha$. Нашей первой
целью является нахождение функции распределения и плотности случайных величин
$$
\rho=\fr{\lambda}{\mu}\ \ \ \ \mbox{и}\ \ \ \ k=\pi=\fr{1}{1+\rho}\,.
$$

Найдем функцию распределения $F_\rho(x)$ случайной величины $\rho$. Имеем
\begin{multline*}
F_\rho(x)=1-\p\left(\mu<\fr{\lambda}{x}\right)={}\\
{}=1-\il{0}{\lambda/x}\fr{t^{n-1}\alpha^n e^{-\alpha t}}{(n-1)!}\,dt={}\\
{}=1-\fr{1}{(n-1)!}\il{0}{\alpha\lambda/x}z^{n-1}e^{-z}\,dz={}\\
{}= e^{-\alpha\lambda/x}\sum_{k=0}^{n-1}\fr{(\alpha\lambda)^k}{x^k k!}\,,\ \ \ \ x>0\,.
\end{multline*}

Продифференцировав последнее выражение по $x$, найдем плотность величины $\rho$:
$$
f_\rho(x)=
e^{-\alpha\lambda/x}\sum_{k=0}^{n-1}\fr{(\alpha\lambda)^k(\alpha\lambda-kx)}{k!x^{k+2}},\ \ \ \ x>0\,.
$$

Очевидно, что при данной постановке задачи величина $\rho$ не имеет моментов первого и более высоких порядков:
$$
\e\rho=\il{0}{\infty}e^{-\alpha\lambda/x}
\sum_{k=0}^{n-1}\fr{(\alpha\lambda)^k(\alpha\lambda-kx)}{k!x^{k+1}}\,dx=\infty\,.
$$

Рассмотрим вероятностные характеристики вероятности <<непотери>> вызова $\pi$. Для функции распределения имеем
\begin{multline*}
F_\pi(x)=1-\p\left(\rho<\fr{1-x}{x}\right)={}\\
{}= 1-e^{-\alpha\lambda x/ (1-x)}\sum_{k=0}^{n-1}\fr{(\alpha\lambda)^k x^k}{(1-x)^k k!}\,,
\ x\in(0,\ 1)\,.
\end{multline*}

В этом случае плотность $\pi$ вычисляется по формуле
%\end{multicols}

\noindent
%\fbox{\parbox{164.5mm}
{\begin{multline*}
f_\pi(x)={}\\
%e^{-\alpha\lambda x/ (1-x)}\,\fr{\alpha\lambda}{(1-x)^2}
%\sum_{k=0}^{n-1}\fr{(\alpha\lambda)^k x^k}{(1-x)^k k!}-
% e^{-\alpha\lambda x /(1-x)}
%\sum_{k=0}^{n-1}\fr{(\alpha\lambda)^k} {k!}
%\fr{k x^{k-1}(1-x)^k+k x^k (1-x)^{k-1}}{(1-x)^{2k}}={}\\[1pt]
{}=e^{-\alpha\lambda x / (1-x)}
\sum_{k=0}^{n-1}\fr{(\alpha\lambda)^k x^{k-1}(\alpha\lambda x-k
x+k)}{k!(1-x)^{k+2}}\,,\\
x\in(0,\ 1)\,.
\end{multline*}
%}
}

%\bigskip

%\begin{multicols}{2}
Найдем математическое ожидание и дисперсию случайной величины $\pi$. Имеем
\begin{multline*}
\e\pi={}\\[5pt]
{}=\il{0}{1}e^{-\alpha\lambda x /(1-x)} \sum_{k=0}^{n-1}\fr{(\alpha\lambda)^k x^k(\alpha\lambda x -k x
+k)}{k! (1-x)^{k+2}}\,dx={}\\[5pt]
{}=\il{0}{\infty}e^{-z} \sum_{k=0}^{n-1}\fr{z^k(z+k)}{k!(\alpha\lambda+z)}\, dz={}\\[5pt]
{}=\sum_{k=0}^{n-1}\fr{1}{k!}\left[\il{0}{\infty}\fr{e^{-z}z^{k+1}}{\alpha\lambda+z}\,
dz+k\il{0}{\infty}\fr{e^{-z}z^k}{\alpha\lambda+z}\, dz\right]\,.
\end{multline*}

Для упрощения дальнейших выкладок введем следующее обозначение. Пусть $Ei(x)$~--- интегральная показательная функция:
$$
Ei(x)=-\il{-x}{\infty}\fr{e^{-t}}{t}\,dt\,.
$$

Используя~[4] (формула~567.9) и~[5] (формула~3.351), вычислим при $k\ge1$ интеграл
\begin{multline*}
\il{0}{\infty}\fr{e^{-z}z^k}{\alpha\lambda+z}\,dz={}\\[5pt]
{}=\il{\alpha\lambda}{\infty}\fr{e^{\alpha\lambda}e^{-t}(t-\alpha\lambda)^k}{t}\,dt=
e^{\alpha\lambda}(-\alpha\lambda)^k\il{\alpha\lambda}{\infty}\fr{e^{-t}}{t}\,dt+{}\\[5pt]
{}+e^{\alpha\lambda}\il{\alpha\lambda}{\infty}e^{-t}\sum_{l=1}^k C_k^l t^{l-1}(-\alpha\lambda)^{k-l}\, dt={}\\[5pt]
{}=-e^{\alpha\lambda}(-\alpha\lambda)^k Ei(-\alpha\lambda)+{}\\[5pt]
{}+e^{\alpha\lambda}\sum_{l=1}^k
C_k^l(-\alpha\lambda)^{k-l}\il{\alpha\lambda}{\infty}e^{-t}t^{l-1}\,dt={}\\[5pt]
{}=-e^{\alpha\lambda}(-\alpha\lambda)^k
Ei(-\alpha\lambda)+{}\\[5pt]
{}+\sum_{l=1}^k\sum_{m=0}^{l-1}(-1)^{k-l}(\alpha\lambda)^{k-l+m}\fr{k!}{l(k-l)!m!}\,.
\end{multline*}
%
Таким образом,
%\noindent
%\fbox{\parbox{164.5mm}
{\begin{multline*}
\e\pi=  1+e^{\alpha\lambda}\alpha\lambda Ei(-\alpha\lambda)-{}\\[4pt]
{}-\sum_{k=1}^{n-1}\fr{e^{\alpha\lambda} (-\alpha\lambda)^{k}
Ei(-\alpha\lambda)(k-\alpha\lambda)}{k!}+{}\\[4pt]
{}+\sum_{k=1}^{n-1}\sum_{l=1}^{k+1}\sum_{m=0}^{l-1}(-1)^{k-l+1}(\alpha\lambda)^{k-l+m+1}\times{}\\[4pt]
{}\times \fr{k+1}
{l(k-l+1)!m!}+{}\\[4pt]
{}+
\sum_{k=1}^{n-1}\sum_{l=1}^k\sum_{m=0}^{l-1}(-1)^{k-l}(\alpha\lambda)^{k-l+m}\fr{k}{l(k-l)!m!}\,.
\end{multline*}
}
%}
%
Найдем второй момент случайной величины $\pi$:
\begin{multline*}
\e\pi^2={}\\
{}=\!\il{0}{1}\!e^{-\alpha\lambda x /(1-x)}\sum_{k=0}^{n-1}\fr{(\alpha\lambda)^k x^{k+1}(\alpha\lambda
x-kx+k)}{k!(1-x)^{k+2}}\,dx\!={}\\%[6pt]
{}=\sum_{k=0}^{n-1}\fr{1}{k!}\left[\il{0}{\infty}\fr{e^{-z}z^{k+2}}{(\alpha\lambda+z)^2}\,dz
+k\il{0}{\infty}\fr{e^{-z}z^{k+1}}{(\alpha\lambda+z)^2}\ dz\right]\,.
\end{multline*}
%
Вычислим при $k\ge1$ интеграл
\begin{multline*}
\il{0}{\infty}\fr{e^{-z}z^{k+2}}{(\alpha\lambda+z)^2}\,dz=
\il{\alpha\lambda}{\infty}\fr{e^{\alpha\lambda}e^{-t}(t-\alpha\lambda)^{k+2}}{t^2}\,dt={} \\[4pt]
{}=e^{\alpha\lambda}\Bigg[\il{\alpha\lambda}{\infty}\fr{e^{-t}(-\alpha\lambda)^{k+2}}{t^2}\,dt+{}\\
{}+\il{\alpha\lambda}{\infty}\fr{e^{-t}(k+2)(-\alpha\lambda)^{k+1}}{t}\ dt+{} \\[4pt]
{}+\sum_{l=2}^{k+2}C_{k+2}^l(-\alpha\lambda)^{k-l+2}\il{\alpha\lambda}{\infty}e^{-t}t^{l-2}\ dt\Bigg]={} \\[4pt]
{}=(-1)^{k+2}(\alpha\lambda)^{k+1}+e^{\alpha\lambda}(-\alpha\lambda)^{k+2}
Ei(-\alpha\lambda)-{}\\[4pt]
{}- e^{\alpha\lambda}(k+2)(-\alpha\lambda)^{k+1}Ei(-\alpha\lambda)+{}\\[4pt]
{}+\sum_{l=2}^{k+2}C_{k+2}^l(-\alpha\lambda)^{k-l+2}
(l-2)!\sum_{m=0}^{l-2}\fr{(\alpha\lambda)^m}{m!}\,.
\end{multline*}
%
Таким образом,
\begin{multline*}
\e\pi^2=
\sum_{k=0}^{n-1}\fr{1}{k!}\Bigg[(-1)^{k+1}(\alpha\lambda)^{k}(k-\alpha\lambda)+{}\\
{}+e^{\alpha\lambda}(-\alpha\lambda)^{k}Ei(-\alpha\lambda)((\alpha\lambda)^{2}+2\alpha\lambda-k(k+1))+{} %\\
\end{multline*}

\noindent
\begin{multline*}
{}+\sum_{l=2}^{k+2}C_{k+2}^l(-\alpha\lambda)^{k-l+2}(l-2)!\sum_{m=0}^{l-2}\fr{(\alpha\lambda)^m}{m!}+{}\\
{}+k\sum_{l=2}^{k+1}C_{k+1}^l(-\alpha\lambda)^{k-l+1}(l-2)!\sum_{m=0}^{l-2}\fr{(\alpha\lambda)^m}{m!}\Bigg]\,.
\end{multline*}

Зная первые два момента случайной величины~$\pi$, легко вычислить дисперсию рассматриваемой характеристики.

Заметим, что, несмотря на громоздкий вид момен\-тов вероятности <<непотери>> вызова, по\-лу\-чен\-ные формулы допускают
несложную компьютерную реализацию, которая дает возможность %\linebreak
вычис\-лять моменты $\pi$ для любого натурального значения
параметра $n$. Однако, очевидно, особый интерес вызывает частный случай распределения Эрланга при $n=1$, а именно,
экспоненциальное распределение параметра обслуживания. Приведем формулы для полученных выше характеристик в этом
частном случае:
\begin{align*}
F_\rho(x)&=e^{-\alpha\lambda /x}\,, \\ 
f_\rho(x)&=\fr{\alpha\lambda e^{-\alpha\lambda / x}} {x^2}\,,& x>0\,;\ \ \ \ \ \ \ \ \\
\e\rho  &=\il{0}{\infty}\fr{\alpha\lambda e^{-\alpha\lambda y}}{y}\, dy=\infty\,;\\ 
F_\pi(x) &=1-e^{-\alpha\lambda x /(1-x)}\,,\\
f_\pi(x)&=\fr{\alpha\lambda e^{-\alpha\lambda x /(1-x)}}{(1-x)^2}\,,& x\in(0,\,1)\,;\\
\e\pi &=1+\alpha\lambda e^{\alpha\lambda} Ei(-\alpha\lambda)\,;\\ 
\e\pi^2&=\e\pi(2+\alpha\lambda)-1\,.
\end{align*}

Представленные в статье результаты не являются полными в рамках проблематики байесовских СМО и байесовских моделей
надежности даже в рамках рассмотрения систем типа M$\vert$M$\vert$1$\vert$0. Очевидно, что дальнейшее продвижение в рамках
данной проблематики требует рассмотрения и других априорных распределений величин $\lambda$, $\mu$ и других
традиционных входных параметров для СМО и восстанавливаемых устройств, которые могут представлять интерес для практики.
При этом должны быть определены соответствующие распределения показателей функционирования и надежности различных типов систем (в том
числе систем вида M$\vert$G$\vert$1, M$\vert$M$\vert$n$\vert$0 и~др.) после их рандомизации с учетом наиболее важных для практики априорных
распределений параметров.

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{9}
\bibitem{Shorgin05}
\Au{Шоргин С.\,Я.}
О байесовских моделях массового обслуживания~// 
II~Научная сессия Института проблем информатики РАН: тезисы докладов.~---  
М.: ИПИ РАН. 2005. С.~120--121.

\bibitem{Kozlov70}
\Au{Kozlov~B.\,A., Ushakov~I.\,A.}
Reliability Handbook.~---  Holt, Rinehart  Winston, 1970.

\bibitem{Apice06}
\Au{D`Apice~C., Manzo~R., Shorgin~S.}
Some Bayesian queueing and reliability models~// 
Electronic J. ``Reliability: Theory \& Applications''. Vol.\ 1. No.\,4. 
December, 2006.

\bibitem{Dwhite66}
\Au{Двайт~Г.}
Таблицы интегралов и другие математические формулы~/ Пер. с англ.~---  
М.: Наука, 1966. 228~с.

\bibitem{GR71}
\textit{Градштейн~И.\,С., Рыжик~И.\,М.}
Таблицы интегралов, сумм, рядов и произведений.~---  М.: Наука, 1971.  1108~с.


\end{thebibliography}

}
}

\end{multicols}


\label{end\stat}