\def\stat{bosov}

\def\tit{ПРИМЕНЕНИЕ САМООРГАНИЗУЮЩИХСЯ НЕЙРОННЫХ СЕТЕЙ К~ПРОЦЕССУ 
ФОРМИРОВАНИЯ ИНДИВИДУАЛЬНОЙ ТРАЕКТОРИИ ОБУЧЕНИЯ$^*$}

\def\titkol{Применение самоорганизующихся нейронных сетей к~процессу 
формирования индивидуальной траектории обучения}

\def\aut{А.\,В.~Босов$^1$}

\def\autkol{А.\,В.~Босов}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Босов А.\,В.}
\index{Bosov A.\,V.}


{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Исследование выполнено при финансовой поддержке Российского научного фонда (проект 
 22-28-00588). Работа проводилась с~использованием инфраструктуры Центра коллективного 
пользования <<Высокопроизводительные вычисления и~большие данные>> (ЦКП 
<<Информатика>> ФИЦ ИУ РАН, Москва).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии 
\mbox{наук, avbosov@ipiran.ru}}


\vspace*{-3pt}


  

\Abst{Рассмотрена задача динамической классификации обучающихся в~рамках 
поддержки процесса формирования индивидуальной траектории пользователя 
электронной обучающей системы. Модель обучения рассчитана на смешанную 
форму ведения образовательной деятельности с~частичной самостоятельной 
работой и~периодическими контрольными мероприятиями в~форме тестов, 
частичной очной работой с~выполнением контрольных работ и~сдачей зачетов. 
Целью классификации ставится определение категории обучаемого по 
результатам очередного контрольного мероприятия. Семантика категорий 
предполагает возможность индивидуального выбора разного уровня сложности 
заданий на очередном шаге обучения. Направлением совершенствования 
существующих методик классификации определен отказ от накопления 
и~использования статистики предыдущих (других) групп обучающихся. Отсутствие 
образцов правильной классификации обосновало применение 
самоорганизующихся нейронных сетей. Для решения использованы карты 
Кохонена, стандартный вариант которых адаптирован к~имеющейся модели 
обучения и~к задаче учета субъективной оценочной политики преподавателя. 
Описаны три варианта алгоритма самообучения. Выполнены экспериментальные 
исследования, их результаты проиллюстрированы.}

\KW{электронное средство обучения; самоорганизующаяся нейронная сеть; 
карта Кохонена; задача классификации; индивидуальная траектория обучения}

\DOI{10.14357/19922264220302} 
  
%\vspace*{-3pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}

\section{Введение}

     Типовым инструментом современных электронных обучающих систем, 
используемых как дистанционно, так и~в дополнение к~традиционным 
формам занятий, является средство построения\linebreak \mbox{индивидуальных} траекторий 
обучаемых. Как правило, такое средство учитывает промежуточные\linebreak 
результаты обучения и~формирует рекомендации для настройки контента 
системы, например для определения уровня сложности контрольных 
заданий. %\linebreak 
Реализуемые этими средствами методы и~алгоритмы составляют 
значимую часть тео\-рии тестирования (Item Response Theory). Чаще всего для 
описания результативности процесса обучения \mbox{используют} вероятностные 
модели, которые позволяют адаптировать процесс тестирования под уровень 
знаний пользователей~[1--6]. Результатом\linebreak адаптации является 
индивидуальная траектория обучения (тестирования), которая представляет 
собой привязанную ко времени последовательность решений задачи 
классификации обучаемых~--- отнесение их к~различным категориям 
успешности обучения. По результатам проведенной классификации разным 
категориям пользователей предлагаются разные траектории дальнейшего 
тестирования или обучения.
     
     Поставленная перед обучающей системой задача классификации 
относится к~типовым, поэтому для ее решения применяются самые 
распространенные средства. Так, классический байесовский 
классификатор~[7] успешно реализован в~системе дистанционного обучения, 
использующей рейтинг пользователя, который рассчитывается в~процессе 
обучения как свертка показанных промежуточных результатов~[8]. 
Недостаток этого варианта категоризации обучающихся и~других средств 
формирования индивидуальной траектории, основанных на статистике, 
состоит в~том, что для реализации соответствующих алгоритмов требуется 
знание некоторых вероятностных характеристик. В~[8] это условные 
вероятности со\-хра\-не\-ния/из\-ме\-не\-ния рейтинга после выполнения 
очередного контрольного мероприятия. Точно знать эти характеристики 
нель\-зя, поэтому их заменяют статистическими оценками, рассчитанными по 
имеющимся или накопленным данным. Соответственно, к~недостаткам или 
трудностям применения байесовского классификатора при категоризации 
обучающихся можно отнести следующее:
     \begin{itemize}
\item частотные оценки вероятностей требуют наличия большого объема 
достоверной статистики;
\item любые изменения количества, порядка, характера контрольных 
мероприятий приводят к~искажению накопленной статистики, 
невозможности ее использования;
\item предполагается совпадение вероятностных характеристик разных групп 
обучающихся.
\end{itemize}

     Цель данной статьи состоит в~том, чтобы предложить способ 
классификации обучающихся по результатам использования электронного 
средства\linebreak обучения, свободной от перечисленных недостатков. Для этого 
байесовский классификатор предлагается заменить не менее типовым 
инструментом~--- самообучающейся искусственной \mbox{нейронной} \mbox{сетью}. 
Поскольку решаемая задача классификация типична, то и~вариант сети был 
выбран самый распространенный~--- карта самоорганизации Кохонена~[9]. 
Наиболее известные финансовые приложения~[10] этих карт к~настоящему 
времени пополнились за счет самых разных сфер применения. Фактически 
к~приложениям самообучающихся карт надо относить практически любой 
технический анализ, связанный с~классификацией. Так, общепринята 
практика категоризации зачисленных студентов, сотрудников, прошедших 
обучение, действующих инженеров~[11--14]. Вклад этих работ и~многих 
других состоит не столько в~развитии самой технологии 
самоорганизующихся карт и~средств кластеризации, сколько в~расширении 
сферы применения известных алгоритмов, подтверждения их эффективности в~новых приложениях. Данная статья представляет результаты исследования 
такого же характера. Цель работы~--- применить существующий механизм 
классификации с~помощью карт Кохонена в~действующей сис\-те\-ме 
дистанционного обучения CLASS.NET~\cite{15-bos}. Для этого предложены 
несколько вариантов адап\-та\-ции модели процесса обучения и~алгоритма 
самоорганизации карты Кохонена, проведены практические эксперименты.
     
\section{Модель процесса обучения и~задача категоризации 
обучающихся}

     Модель процесса обучения предполагает смешанное дистанционно-очное обучение и~включает~$T$ контрольных мероприятий. Типичная схема 
обучения для предлагаемой модели состоит в~том, что имеющийся по 
изучаемому предмету курс разбит на несколько частей, каждая часть 
завершается очными мероприятиями (промежуточный зачет и/или 
контрольная работа), а~в~промежутках учащиеся выполняют по 
нескольку заочных мероприятий (тестирование). После очередного 
контрольного мероприятия (шага обучения) для каждого студента 
определяется категория, например: <<неуспевающий>>~(1); <<низкий 
уровень>>~(2); <<средний уровень>>~(3); <<высокий уровень>>~(4). 
В~рамках данной работы будут использованы указанные четыре категории 
студентов, которые обозначаются номером $k\hm\in K\hm= \{1,2,3,4\}$. 
Ограничений общности это предположение не влечет, а~для приведенных 
ниже иллюстративных расчетов надо зафиксировать чис\-ло категорий 
и~наделить их ясным содержанием.
     
     Итак, на каждом шаге обучения должна решаться задача 
классификации: каждый студент должен быть отнесен к~одной из категорий 
на основании продемонстрированных им результатов. \mbox{Соответствующие} 
моменты времени обозначаются $t\hm= 1,\ldots , T$. Типовое использование 
таких категорий в~электронных обучающих системах состоит в~определении 
уровня сложности следующего этапа/шага обучения и/или контрольного 
мероприятия. Таким образом обеспечивается соответствие контрольного 
контента уровню подготовки студента и~формирование индивидуальной 
траекторию обучения.
     
     Будем предполагать, что для каждого~$t$ задано значение $x_t\hm\in 
\{\mathrm{т}, \mathrm{з}, \mathrm{к}\}$, определяющее тип контрольного 
мероприятия: $\mathrm{т}$~--- тест; $\mathrm{з}$~--- зачет;  
$\mathrm{к}$~--- контрольная работа. Каждый из $S$ обучающихся\linebreak 
в~момент~$t$ получает очередную отметку $e_t^s$, $s\hm= 1,\ldots , S$, 
которая в~зависимости от~$x_t$ характеризуется своей областью значений. 
Для определенности будем предполагать, что для $x_t\hm= \mathrm{т}$ 
\mbox{значения} $e_t^s\hm\in \{0,1,\ldots , 100\}$, для $x_t\hm= \mathrm{з}$ значения 
$e_t^s\hm\in \{0,1\}$, для $x_t\hm= \mathrm{к}$ значения $e_t^s\hm\in 
\{2,3,4,5\}$; т.\,е.\ тестирование оценивается по 100 балльной шкале, зачет~--- 
традиционно за\-чет/не\-за\-чет, контрольная работа~--- отметками 
неудовлетворительно, удовлетворительно, хорошо, отлично. Соответственно, 
задача классификации обучающихся в~момент~$t$ состоит в~определении 
категории $k_\tau^s\hm\in K$ для каждого $s$-го студента.
     
     Вариант решения этой задачи, предложенный в~[8], состоит в~том, 
чтобы свернуть текущий вектор оценок $(e_1^s, \ldots , e_t^s)^\prime$, $x^\prime$~--- 
транспонированный вектор, в~некоторую скалярную величину~--- текущий 
рейтинг, решение об отнесении студента с~этим рейтингом к~категории~$k$ 
обеспечивается байесовским правилом, в~котором применяются 
статистические характеристики (частотные оценки апостериорных 
вероятностей), вычисленные по результатам, продемонстрированным 
предыдущими\linebreak группами обуча\-ющих\-ся. Принципиальное предложение 
данной работы состоит в~том, чтобы для классификации использовать только 
результаты, демонстрируемые одной небольшой группой\linebreak \mbox{обуча\-ющих\-ся}, 
и~классифицировать студентов, сравнивая результаты обуче\-ния между 
собой. Формально такая задача состоит в~определении отображения
     \begin{equation}
     \left\{\!\left\{ e_\tau^s\right\}^t_{\tau=1} \right\}^S_{s=1}\!\! \to \left\{ 
k_t^s\right\}^S_{s=1},\enskip k_t^s\in K,\ t=1,\ldots , T.\!
     \label{e1-bos}
     \end{equation}
     
     Если не учитывать масштабы и~семантику входного набора данных 
     $\{\{ e_\tau^s\}^t_{\tau=1} \}^S_{s=1}$, т.\,е.\ величин $\{ 
x_\tau\}^t_{\tau=1}$ типов контроля, то задача~(1) становится типичной 
постановкой для построения одномерной самоорганизующейся карты 
Кохонена~[9]. Необходимость учета порядка и~типов контрольных 
мероприятий требует небольшой адаптации стандартного алгоритма 
самообучения. Кроме того, требуется еще учесть динамический характер 
модели обучения, что классификация выполняется вместе с~очередными 
шагами обучения и~контроля. Эта особенность также требует учета при 
по\-стро\-ении карты.
     
\section{Варианты реализации карт Кохонена}

     \textbf{Первый} из предлагаемых вариантов алгоритма 
самообучения отличается от классического только тем, что для определения 
расстояния между входными векторами и~нейронами карты вместо 
евклидовой нормы $\vert x\vert^2\hm= x x^\prime$ используется функция 
нормировки $\| x\|^2_{Q} \hm= x^\prime Qx$ для 
симметричной не\-от\-ри\-ца\-тель\-но определенной мат\-ри\-цы~$Q$, т.\,е.\ единичной 
матрице $Q\hm=\mathbf{1}$ соответствует евклидова норма $\| 
x\|^2_{\mathbf{1}} \hm= \vert x\vert^2$. Матрица~$Q$ будет использована 
с~разными целями. В~первом варианте ее задача~--- масштабировать отметки. 
Во всех вариантах эта матрица будет диагональной, в~первом~--- на 
диагонали будут $100^{-2}$, если соответствующая величина $x_t\hm= 
\mathrm{т}$; $\mathrm{1}$, если $x_t\hm= \mathrm{з}$; $5^{-2}$, если 
$x_t\hm= \mathrm{к}$. Поясним это на примере, воспользовавшись 
следующим распределением видов контрольных мероприятий: 
     \begin{equation}
     \left.
    \! \begin{array}{c}
   \!\!   \! x_1, x_2, x_3, x_4=\mathrm{т}\,;\enskip x_5=\mathrm{з}\,;\enskip
     x_6=\mathrm{к}\,;\enskip \\[6pt]
    \!\!  \! x_7, x_8, x_9=\mathrm{т}\,;\enskip x_{10}=\mathrm{з}\,;\enskip 
x_{11}=\mathrm{к}\,;\\[6pt]
  \!\!  \! x_{12}, x_{13} =\mathrm{т}\,;\enskip x_{14}=\mathrm{з}\,;\enskip
     x_{15}=\mathrm{к}\,;\enskip x_{16}, x_{17}=\mathrm{т}\,,
     \end{array}\!
     \right\}\!\!
     \label{e2-bos}
     \end{equation}
т.\,е.\ в~первой части курса четыре теста, зачет, контрольная; во второй 
части~--- три теста, зачет, контрольная; в~третьей части~--- два теста, зачет, 
контрольная, два теста. Этот порядок соответствует примерам, 
рассмотренным в~[8]. Таким образом, для~17~указанных видов контрольных 
мероприятий матрица нормировки $Q\hm= Q^{1/2}Q^{1/2}$:
\begin{multline}
Q^{1/2}= \mathrm{diag} \left\{
\fr{1}{100}, \fr{1}{100},
\fr{1}{100}, \fr{1}{100},1, \fr{1}{5}, \fr{1}{100}, \fr{1}{100},\right.\\ 
\left.\fr{1}{100}, 1,
\fr{1}{5}, \fr{1}{100}, \fr{1}{100}, 1, \fr{1}{5}, \fr{1}{100}, 
\fr{1}{100}\right\}.
\label{e3-bos}
\end{multline}
     
     Выбираем момент~$t$ и~отвечающую ему матрицу нормировки 
$Q_t\hm= \mathrm{diag} \left\{ Q_{1,1}, \ldots , Q_{t,t}\right\}$. Далее следуем 
обычному алгоритму. Обозначим~$W$ матрицу весов карты размера $4\times 
t$, $W_k$~--- $k$-ю строку этой мат\-ри\-цы, т.\,е.\ вектор весов $k$-го нейрона, 
$k\hm= 1,2,3,4$. Выполняем последовательность итераций, нумеруя их 
$i\hm= 1, \ldots , I$. На $i$-й итерации последовательно для каждого $s$-го 
студента, $s\hm= 1, \ldots , S$, находится ближайший нейрон
     $$
     k^i_{\min}(s)= \argmin\limits_{k=1,2,3,4} \left\| E_t^s -
W_k(i)\right\|^2_{Q_t}\,,
     $$
где $E_t^s=\left( e_1^s, \ldots , e_t^s\right)^\prime$~--- вектор, составленный из 
отметок $s$-го студента к~текущему моменту~$t$; $W_k(i)$~--- $k$-я строка 
матрицы~$W$, отвечающая $i$-й итерации.
     
     Далее для каждого $k$-го нейрона вычисляется значение функции 
соседства $h \left(k, k^i_{\max}(s)\right)$ и~корректируется вектор весов:
     \begin{equation}
     \left.
     \begin{array}{c}
     h\left( k, k^i_{\min} (s)\right) =\exp \left\{ -\fr{\vert k-
k^i_{\min}(s)\vert^2}{2\sigma_i^2}\right\},\\[6pt]
     \!\!W_k(i)\!=\! W_k(i)+\eta_i h \left( k, k^i_{\min}(s)\right) \left( E_t^s \!-\!
W_k(i)\right),\\[6pt]
     \hspace*{-23mm}s=s+1, \ \mbox{если } s<S\,,\\[6pt]
     \hspace*{10mm}\mbox{иначе } (s=S)\ i=i+1\,,\ s=1\,.
          \end{array}\!\!
     \right\}\!\!
     \label{e4-bos}
     \end{equation}

     Отметим, что в~(\ref{e4-bos}), в~отличие от обычного алгоритма, 
в~рамках одной итерации обрабатываются все входные воздействия (отметки 
всех студентов), причем с~одинаковыми параметрами обучения $\sigma_i$ 
и~$\eta_i$. Такая организация алгоритма самообучения позволяет 
гарантированно учитывать отметки всех студентов с~одинаковыми весами, 
уравнивая вклад в~классификацию всех обучающихся.  
Переход\linebreak к~($i\hm+1$)-й итерации выполняется, когда матрица весов 
скорректировалась всеми имеющимися~$S$~от\-мет\-ками.
     
     Выбор параметров обучения выполнен согласно самым 
распространенным рекомендациям~[16--18]:
     $$
     \sigma_i= \sigma_0\exp \left\{-\fr{i}{\delta}\right\},\
     \delta= \fr{1000}{\ln \sigma_0}\,,\
     \eta_i= \eta_0 \exp \left\{-\fr{i}{\Delta}\right\}.
     $$
     
      Более того, в~расчетах даже 
не использовалась величина~$\delta$ и~полагалось $\sigma_i\hm= const 
\hm=1$. Осталь-\linebreak\vspace*{-12pt}

\pagebreak

\noindent
ные значения ($\eta_0\hm=0{,}1$ и~$\Delta\hm= 1000$)~--- 
обычные рекомендации для $I\hm=1000$ итераций.
     
     В рамках этого же варианта алгоритма са\-мо\-обуче\-ния можно добавить 
возможность назначения весов значимости для разных типов контрольных 
мероприятий. Например, с~учетом очного характера можно отметку за зачет 
учесть с~двойным весом, а~отметку за контрольную работу~--- с~тройным. 
Для этого~(\ref{e3-bos}) заменяется на
     \begin{multline}
     Q^{1/2} = \mathrm{diag}\left\{ \fr{1}{100}, \fr{1}{100}, \fr{1}{100},\fr{1}{100}, 
2, \fr{3}{5}, \fr{1}{100}, \fr{1}{100}, \right.\\ 
     \left. \fr{1}{100},
      2, \fr{3}{5}, \fr{1}{100}, 
\fr{1}{100}, 2, \fr{3}{5}, \fr{1}{100}, \fr{1}{100}\right\}.
 \label{e5-bos}
\end{multline}
     
     Характер влияния этой и~последующих модификаций алгоритма 
иллюстрируется в~следующем разделе на примерах.
     
     Следующий, \textbf{второй}, вариант алгоритма или, точнее говоря, 
модели классификации устраняет два возможных недостатка первого 
варианта.\linebreak Во-пер\-вых, нужно обеспечить корректную с~точки зрения 
преподавателя категоризацию студентов в~группе, в~которой нет четко 
представленных всех четырех категорий обучаемых. Например, в~группе без 
<<неуспевающих>> категория~1 долж\-на остаться пус\-той, в~то время как 
применение алгоритма~(\ref{e4-bos}),\linebreak вполне возможно, все равно даст 
четыре категории, распределив студентов без учета оценочного кон\-текс\-та, 
вложенного в~категории. В~связи с~этим можно увидеть второй  
недостаток~--- вкла\-ды\-ва\-емый в~категории преподавателем кон\-текст 
<<неуспе\-ва\-ющий>>, <<низкий уровень>>, <<средний уровень>> и~<<высокий 
уровень>> может не гарантироваться алгоритмом~(\ref{e4-bos}). Другая 
формулировка этой же проб\-ле\-мы со\-сто\-ит в~отсутствии учета 
алгоритмом~(\ref{e4-bos}) экспертного (преподавательского) пред\-став\-ле\-ния 
о~содержании понятий <<неуспевающий>>, <<низкий уровень>>, <<средний 
уровень>> и~<<высокий уровень>>.
     
     Модифицируя~(\ref{e4-bos}) для устранения указанных недостатков, 
введем <<экспертные>> траектории $(\mathrm{IE}_T^s)^k$, $k\hm\in K$, смысл 
которых состоит в~том, чтобы представить <<идеальный>> экземпляр $k$-й 
категории:
     \begin{equation}
     \left.
     \begin{array}{l}
     \left( \mathrm{IE}^s_{17}\right)^1 = (30, 30, 30, 30, 0, 2, 30, 30, 30,\\[3pt]
     \hspace*{30mm} 0, 2, 30, 30, 0, 2, 30, 30)^\prime\,;\\[6pt]
     \left( \mathrm{IE}^s_{17}\right)^2 = (50, 50, 50, 50, 0, 3, 50, 50, 50,\\[3pt]
           \hspace*{30mm}0, 3, 50, 50, 0, 3, 50, 50)^\prime\,;\\[6pt]
     \left( \mathrm{IE}^s_{17}\right)^3 = (70, 70, 70, 70, 0, 4, 70, 70, 70,\\[3pt]
           \hspace*{30mm}0, 4, 70, 70, 0,4,70,70)^\prime\,;\\[6pt]
     \left( \mathrm{IE}^s_{17}\right)^4 = (90, 90, 90, 90, 0, 5, 90, 90, 90,\\[6pt]
          \hspace*{30mm} 0, 5, 90, 90, 0, 5, 90, 90)^\prime\,.
\end{array}
\right\}
\label{e6a-bos}
     \end{equation}
     
     Отметим, что эти <<идеальные>> траектории решают вопрос 
с~начальными условиями, так как их можно использовать в~(\ref{e4-bos}) 
для начала итерирования, т.\,е.\ для величин~$W_k(0)$. Во втором варианте 
траектории~(\ref{e6a-bos}) используются в~качестве входных векторов:
     \begin{equation}
     \left.
     \!\!\begin{array}{l}
     \!W_k(i)=W_k(i)+\eta_i h \left( k, k^i_{\min}(s)\right) \left( E_t^s \!-\!
W_k(i)\right),\\[3pt]
 \hspace*{50mm}s=1, \ldots , S\,;\\[3pt]
     \!W_k(i)= W_k(i)+{}\\[3pt]
     \hspace*{10mm}{}+\eta_i h \left( k, k^i_{\min}(s)\right)\left( 
\left(\mathrm{IE}_t^s\right)^k -W_k(i)\right)\,,\\[6pt]
\hspace*{25mm}k=1,\ldots , K\,,\ s=1, \ldots, \left[\fr{S}{k}\right];\\[3pt]
     \!W_k(i+1)= W_k(i)\,,\ \mbox{если } s=S\,,\ k=K\,.
     \end{array}\!\!
     \right\}\!\!
     \label{e6-bos}
     \end{equation}
     
     Таким образом, для рассматриваемого случая $k\hm= 1,2,3,4$ каждая из 
четырех <<идеальных>> траекторий $(\mathrm{IE}^s_{17})^k$ участвует в~$i$-й 
итерации алгоритма, повторяясь в~качестве входа в~количестве 25\%, 
     $[S/k]\cdot 100\%$, от числа имеющихся траекторий, т.\,е.\ числа 
студентов.
     
     Наконец, последний, \textbf{третий}, вариант модели классификации 
учитывает фактор устаревания полученных студентом отметок или большей 
актуальности (приоритетности) последних, старших по времени результатов. 
Максимально просто добиться учета этого фактора можно, ограничившись 
числом учитываемых оценок, положив $Q_t\hm= \mathrm{diag} \left\{0, \ldots , 0, 
Q_{t,t-\varepsilon+1}, \ldots , Q_{t,t}\right\}$, т.\,е.\ учитывая 
только~$\varepsilon$ последних по времени отметок. Более гибкий способ 
состоит в~использовании параметра устаревания~$\alpha$, $0\hm< \alpha\hm\leq 1$,  и~матрицы 
нормировки
     \begin{multline}
     Q^{1/2}_t =\mathrm{diag} \left\{ \alpha^{t-1} Q^{1/2}_{1,1}, \ldots\right. \\
   \left.  \ldots, \alpha^2
Q^{1/2}_{t-2, t-2}, \alpha Q^{1/2}_{t-1, t-1}, Q^{1/2}_{t,t}\right\}.
     \label{e7-bos}
     \end{multline}
     
     Такая нормировка означает динамическое изменение входных 
данных~--- умножение отметок до текущего контрольного мероприятия~$t$ 
на величину~$\alpha$.

\begin{table*}\small %tabl1
\begin{center}
\Caption{Примеры траекторий результатов обучения}
\vspace*{2ex}

      \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
$s$&$e_1^s$&$e_2^s$&$e_3^s$&$e_4^s$&$e_5^s$&$e_6^s$&$e_7^s$&$e_8^s$&$e_9^s$&$e^s_{1
0}$&$e^s_{11}$&$e^s_{12}$&$e^s_{13}$&$e^s_{14}$&$e^s_{15}$&$e^s_{16}$&$e_{17}^s$\\
\hline
\hphantom{9}2&35&20&25&20&1&2&34&24&20&0&2&34&25&0&2&34&14\\
\hphantom{9}7&58&73&54&49&1&3&56&58&69&0&2&45&67&1&3&51&72\\
13&54&69&55&65&1&4&71&69&69&1&4&67&55&1&4&66&61\\
17&69&67&74&68&1&4&99&91&92&1&5&87&93&1&5&94&87\\
18&89&94&78&98&1&5&89&88&89&1&5&97&94&1&3&77&65\\
\hline
\end{tabular}
\end{center}
%\end{table*}
%\begin{table*}\small %tabl2
\begin{center} 
\Caption{Результаты классификации~--- вариант~1, матрица нормировки~(\ref{e3-bos})}
\vspace*{2ex}

      \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
$s$&$k_1^s$&$k_2^s$&$k_3^s$&$k_4^s$&$k_5^s$&$k_6^s$&$k_7^s$&$k_8^s$&$k_9^s$&$k^s_{10}
$&$k^s_{11}$&$k^s_{12}$&$k^s_{13}$&$k^s_{14}$&$k^s_{15}$&$k^s_{16}$&$k_{17}^s$\\
\hline
\hphantom{9}2&1&1&1&1&2&2&2&1&1&1&1&1&1&1&1&1&1\\
\hphantom{9}7&2&3&2&2&3&3&2&2&2&2&2&2&2&2&2&2&2\\
13&2&2&2&2&3&3&3&3&3&3&3&3&3&3&3&3&3\\
17&3&3&3&3&3&3&4&4&4&4&4&4&4&4&4&4&4\\
18&4&4&4&4&4&4&4&4&4&4&4&4&4&4&4&4&4\\
\hline
\end{tabular}
\end{center}
%\end{table*}
%
%\begin{table*}\small %tabl3
\begin{center}
\Caption{Результаты классификации~--- вариант~1, матрица нормировки~(\ref{e5-bos})}
\vspace*{2ex}

      \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
$s$&$k_1^s$&$k_2^s$&$k_3^s$&$k_4^s$&$k_5^s$&$k_6^s$&$k_7^s$&$k_8^s$&$k_9^s$&$k^s_{10}
$&$k^s_{11}$&$k^s_{12}$&$k^s_{13}$&$k^s_{14}$&$k^s_{15}$&$k^s_{16}$&$k_{17}^s$\\
\hline
\hphantom{9}2&1&1&1&1&3&2&2&2&2&2&2&2&2&1&1&1&1\\
\hphantom{9}7&2&3&2&2&3&3&3&3&3&2&2&2&2&2&2&2&2\\
13&2&2&2&2&3&3&3&3&3&4&4&4&3&4&4&4&3\\
17&3&3&3&3&4&4&4&4&4&4&4&4&4&4&4&4&4\\
18&4&4&4&4&4&4&4&4&4&4&4&4&4&4&4&4&4\\
\hline
\end{tabular}
\end{center}
\vspace*{-3pt}
\end{table*}
                                   
     
                                   

     
\section{Результаты практических экспериментов}

     Для иллюстрации результатов работы предложенных классификаторов 
использовалась немного адаптированная модель обучения, реализованная 
в~системе дистанционного обучения CLASS.NET~\cite{15-bos} и~тот же 
набор данных, что и~в~\cite{8-bos}. В~расчетах были использованы отметки 
по схеме контроля~(\ref{e2-bos}) для $S\hm=36$ студентов, характерные 
траектории для 5 студентов приведены в~табл.~1.

\pagebreak
     
     
     Выбранные для таблицы траектории субъективно оценивались как 
типичные для классов <<неуспевающий>> ($s\hm=2$), <<низкий уровень>> 
($s\hm=7$), <<средний уровень>> ($s\hm=13$) и~<<высокий уровень>> 
($s\hm=17$ и~$18$). Причем траектории $s\hm=17$ и~$18$ 
иллюстрируют явно выраженные переходы между классами $k\hm=4$ 
в~класс $k\hm=3$ и~наоборот, они должны помочь иллюстрировать разницу 
предложенных классификаторов. В~электронном представлении, в~частности в~программной реализации, данные (строки таблиц) дополнительно 
выделяются цветом, который также используется на рисунках для 
визуализации траекторий. Результаты классификации первым вариантом 
алгоритма~(\ref{e4-bos}) с~матрицей нормировки~(\ref{e3-bos}) приведены 
в~табл.~2, с~матрицей нормировки~(\ref{e5-bos})~--- в~табл.~3.
     

     В целом назначаемые классификатором категории вполне 
соответствуют ожидаемым. Причем более <<лояльными>> оказались 
результаты табл.~2. Это очевидная реакция на увеличение веса зачета (см.\ 
$k_5^2$, $k_5^7$ и~$k_{10}^{13}$). Также можно отметить <<правильную>> 
динамику траектории $s\hm=17$, а именно переход из класса $k\hm=3$ 
в~класс $k\hm=4$, и~отсутствие обратного перехода для траектории $s\hm=18$. 
В~последнем случае классификатор не отреагировал на ухудшение 
результатов, здесь сработал эффект <<старых заслуг>>. Наконец, в~табл.~3 
еще выделяются изменения в~траектории $s\hm=13$: классификатор явно 
завышает результаты. Но это субъективная оценка. На самом деле по 
имеющимся данным классификатор не имеет возможности оценить верхнюю 
границу отметок, <<помочь>> ему в~этом должен второй вариант алгоритма. 


\begin{table*}[b]\small %tabl4
%\vspace*{-12pt}
\begin{center}
\Caption{Результаты классификации~--- вариант~2}
\vspace*{2ex}

      \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
$s$&$k_1^s$&$k_2^s$&$k_3^s$&$k_4^s$&$k_5^s$&$k_6^s$&$k_7^s$&$k_8^s$&$k_9^s$&$k^s_{10}
$&$k^s_{11}$&$k^s_{12}$&$k^s_{13}$&$k^s_{14}$&$k^s_{15}$&$k^s_{16}$&$k_{17}^s$\\
\hline
\hphantom{9}2&1&1&1&1&2&2&2&2&2&1&1&1&1&1&1&1&1\\
\hphantom{9}7&2&3&2&2&3&3&3&2&2&2&2&2&2&2&2&2&2\\
13&2&2&2&2&3&3&3&3&3&3&3&3&3&3&3&3&3\\
17&3&3&3&3&3&3&3&3&4&4&4&4&4&4&4&4&4\\
18&4&4&4&4&4&4&4&4&4&4&4&4&4&4&4&4&4\\
\hline
\end{tabular}
\end{center}
%\end{table*}
%\begin{table*}\small  %tabl5
\begin{center}
\Caption{Результаты классификации~--- вариант~3}
\vspace*{2ex}

      \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
    $s$&$k_1^s$&$k_2^s$&$k_3^s$&$k_4^s$&$k_5^s$&$k_6^s$&$k_7^s$&$k_8^s$&$k_9^s$&$k^s_{10}
$&$k^s_{11}$&$k^s_{12}$&$k^s_{13}$&$k^s_{14}$&$k^s_{15}$&$k^s_{16}$&$k_{17}^s$\\
      \hline
  \multicolumn{18}{|c|}{$\alpha=0{,}75$}\\
\hline
\hphantom{9}2&1&1&1&1&3&2&2&1&1&1&1&1&1&1&1&1&1\\
\hphantom{9}7&2&3&2&2&3&3&2&2&2&1&1&1&1&3&3&3&3\\
13&2&3&2&3&3&3&4&3&3&3&3&3&3&3&4&3&3\\
17&3&3&4&3&4&4&4&4&4&4&4&4&4&4&4&4&4\\
18&4&4&4&4&4&4&4&4&4&4&4&4&4&4&3&4&3\\
\hline
      \multicolumn{18}{|c|}{$\alpha=0{,}5$}\\
     \hline
\hphantom{9}2&1&1&1&1&3&2&1&1&1&1&1&1&1&1&1&1&1\\
\hphantom{9}7&2&3&2&2&3&2&2&2&3&1&1&1&2&4&3&2&3\\
13&2&3&2&3&4&3&4&3&3&4&3&3&2&4&4&3&3\\
17&3&3&4&3&4&3&4&4&4&4&4&4&4&4&4&4&4\\
18&4&4&4&4&4&4&4&4&4&4&4&4&4&4&3&3&3\\
\hline
      \multicolumn{18}{|c|}{$\alpha=0{,}25$}\\
      \hline
\hphantom{9}2&1&1&1&1&3&1&1&1&1&1&1&1&1&1&1&1&1\\
\hphantom{9}7&2&3&2&2&4&2&2&2&3&1&1&1&3&4&2&1&3\\
13&2&3&2&3&4&3&3&3&3&4&3&3&2&4&3&2&2\\
17&3&3&4&3&4&3&4&4&4&4&4&4&4&4&4&4&4\\
18&4&4&4&4&4&4&4&4&4&4&4&4&4&4&2&3&3\\
\hline
\end{tabular}
\end{center}
\end{table*}


     
     Визуализировать в~удобной для преподавателя форме результаты 
классификации предлагается следующими двумя схемами. На рис.~1 
иллюстрируется зависимость от времени (номера контрольного мероприятия) 
результатов и~обучения, и~классификации. Для каждого студента траектория 
оформлена серией кругов. Центр каждого круга расположен
 на высоте, 
соответствующей полученной отметке\linebreak\vspace*{-12pt}

{ \begin{center}  %fig1
 \vspace*{12pt}
    \mbox{%
\epsfxsize=79mm
\epsfbox{bos-1.eps}
}

\end{center}

\vspace*{-2pt}

\noindent
{{\figurename~1}\ \ \small{
Динамика результатов обучения~--- категории и~отметки
}}}

%\vspace*{6pt}

{ \begin{center}  %fig2
 \vspace*{-3pt}
     \mbox{%
\epsfxsize=77.444mm
\epsfbox{bos-2.eps}
}

\vspace*{6pt}

\noindent
{{\figurename~2}\ \ \small{
Индивидуальные результаты обучения
}}\end{center}
}

\vspace*{9pt}

\noindent
 (шкала слева), а~размер~--- 
категории: круг самого маленького диаметра отвечает категории~1, самого 
большого~--- категории~4. В~электронном представлении круг 
дополнительно окрашивается цветом, назначенным соответствующей 
траектории (как и~в~табл.~1--3). Такая форма визуализации хорошо 
характеризует ситуацию в~целом. Если же важно более точно 
визуализировать совокупность отметок и~категорий каждого студента, то 
лучше использовать представление типа фазового портрета, т.\,е.\ линии, 
отображающие только отметки и~категории. Этот вариант визуализации 
результата классификации показан на рис.~2. Категории на этом рисунке 
представляет шкала слева, отметки отображаются точками, которые 
соединены линиями, свя\-зы\-ва\-ющи\-ми соседние по времени отметки $e_t^s$ 
и~$e^s_{t+1}$. Оба рисунка соответствуют результатам табл.~1.





     Результаты расчетов для второго варианта алгоритма~(\ref{e6-bos}) 
приведены в~табл.~4. Здесь для расчетов к~имеющимся данным табл.~1 были 
добавлены 36~траекторий~(\ref{e6a-bos}), по 9~каждого предложенного типа.
     

     
     Этот вариант оправдывает ожидания, разделяя высокие категории 
$k\hm= 3$ и~$4$. Так, траектория $s\hm=13$ относится к~<<правильной>> 
категории $k\hm=3$. Такой же эффективный учет субъективного 
представления~(\ref{e6a-bos}) демонстрируют и~остальные траектории, не 
представленные в~табл.~1. Видимый недостаток здесь остается у траектории 
$s\hm=18$, так как избавиться от эффекта <<старых заслуг>> не получается.

 \begin{table*}\small %tabl6
     \begin{center}
     \Caption{Результаты классификации~--- смешанный вариант 2--3, $\alpha\hm= 
0{,}75$}
      \vspace*{2ex}
      
      \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
$s$&$k_1^s$&$k_2^s$&$k_3^s$&$k_4^s$&$k_5^s$&$k_6^s$&$k_7^s$&$k_8^s$&$k_9^s$&$k^s_{10}
$&$k^s_{11}$&$k^s_{12}$&$k^s_{13}$&$k^s_{14}$&$k^s_{15}$&$k^s_{16}$&$k_{17}^s$\\
\hline
\hphantom{9}2&1&1&1&1&3&3&2&1&1&1&1&1&1&1&1&1&1\\
\hphantom{9}7&2&3&2&2&3&3&3&2&3&1&1&1&1&3&3&2&3\\
13&2&3&2&3&3&3&3&3&3&4&3&3&3&3&3&3&3\\
17&3&3&3&3&4&3&4&4&4&4&4&4&4&4&4&4&4\\
18&4&4&4&4&4&4&4&4&4&4&4&4&4&4&3&3&3\\
\hline
\end{tabular}
\end{center}
%\vspace*{-12pt}
\end{table*}
     
     Последнюю группу расчетов представляет табл.~5~--- результаты 
расчетов для третьего варианта алгоритма, т.\,е.\ с~матрицей 
нормировки~(\ref{e7-bos}) и~значениями параметра устаревания 
$\alpha\hm=0{,}75$, 0,5 и~0,25.  

    
                                   
     
     Параметр устаревания весьма эффективно справился с~недостатком 
предыдущего примера. Помимо траектории $s\hm=18$, для который этот 
вариант алгоритма обеспечил понижение категории из-за ухудшения 
результатов на последних этапах обучения, алгоритм обнаружил 
аналогичную ситуацию и~для траектории $s\hm=13$, к~которой ранее в~такой 
связи внимания не было. Относительно значений параметра представляется, 
что $\alpha\hm= 0{,}25$ не имеет смысла, так как классифицируется 
фактически последняя отметка. Значения $\alpha\hm= 0{,}5$ 
и~$0{,}75$ работают хорошо; на данном наборе примеров лучше 
выглядит $\alpha\hm=0{,}75$, поскольку в~целом демонстрирует более 
<<гладкий>> результат. 

\vspace*{-6pt}

\section{Заключение}

\vspace*{-2pt}

     Полученные результаты можно подытожить рекомендацией 
использовать комбинацию второго и~третьего вариантов алгоритма, полагая 
$\alpha\hm= 0{,}75$, а~возможность использования матрицы нормировки 
первого варианта оставить на усмотрение преподавателя. Такой расчет 
с~имеющимися данными иллюстрируется в~табл.~6, и~его результаты выглядят 
наиболее предпочтительными для рекомендации к~практическому 
применению.
     

\vspace*{-6pt}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
 
 \vspace*{-2pt}

\bibitem{2-bos} %1
\Au{Rasch G.} Probabilistic models for some intelligence and attainment tests.~--- Chicago, IL, USA: The 
University of Chicago Press, 1980. 199~p. 

\bibitem{1-bos} %2
\Au{Van der Linden W.\,J., Scrams~D.\,J., Schnipke~D.\,L., \textit{et al.}} Using response-time 
constraints to control for differential speededness in computerized adaptive testing~// Appl. 
Psych. Meas., 1999. Vol.~23. No.\,3. P.~195--210.

\bibitem{3-bos}
\Au{Кибзун А.\,И., Иноземцев~А.\,О.} Оценивание уровней сложности тестов на основе 
метода максимального правдоподобия~// Автоматика и~телемеханика, 2014. №\,4.  
С.~20--37.

\bibitem{5-bos} %4
\Au{Куравский~Л.\,С., Мармалюк~П.\,А., Юрьев~Г.\,А., Думин~П.\,Н., Панфилова~А.\,С.} 
Вероятностное моделирование процесса выполнения тестовых заданий на основе 
модифицированной функции Раша~// Вопросы психологии, 2015. №\,4. С.~109--118.

\bibitem{4-bos} %5
\Au{Наумов А.\,В., Мхитарян~Г.\,А.} О~задаче вероятностной оптимизации для 
ограниченного по времени тестирования~// Автоматика и~телемеханика, 2016. №\,9. 
С.~124--135.

\bibitem{6-bos}
\Au{Kuravsky~L.\,S., Margolis~A.\,A., Marmalyuk~P.\,A., Panfilova~A.\,S., Yuryev~G.\,A., 
Dumin~P.\,N.} A~probabilistic model of adaptive training~// Applied Mathematical Sciences, 
2016. Vol.~10. No.\,48. P.~2369--2380.
\bibitem{7-bos}
\Au{Callan R.} The essence of neural networks.~--- Prentice Hall Europe, 1999. 232~p.
\bibitem{8-bos}
\Au{Босов А.\,В., Мартюшова~Я.\,Г., Наумов~А.\,В., Сапунова~А.\,П.} Байесовский подход 
к~построению индивидуальной траектории пользователя в~системе дистанционного 
обучения~// Информатика и~её применения, 2020. Т.~14. Вып.~3. С.~89--96.
\bibitem{9-bos}
\Au{Kohonen T.} Self-organizing maps.~--- 3rd ed.~--- Berlin, Heidelberg: Springer, 
2001. 501~p.
\bibitem{10-bos}
\Au{Deboeck G., Kohonen~T.} Visual explorations in finance.~--- London: Springer-Verlag, 
1998. 258~p.

\bibitem{13-bos} %11
\Au{Ахтеров А.\,В., Лезина~О.\,В., Шастина~А.\,Е.} Диагностика развития  
ор\-га\-ни\-за\-ци\-он\-но-управ\-лен\-че\-ских компетенций инженеров с~помощью 
самоорганизующихся карт Кохонена~// Автоматизация и~управление в~технических 
системах, 2013. №\,42. С.~35--45.

\bibitem{11-bos} %12
\Au{Зарубина Н.\,К., Овчинкин~О.\,В., Пыхтин~А.\,И.} Разведочный анализ результатов 
приема в~вуз с~применением нейронной сети Кохонена для планирования контингента 
студентов~// Ин\-фор\-ма\-ци\-он\-но-из\-ме\-ри\-тель\-ные и~управ\-ля\-ющие сис\-те\-мы, 
2016. Т.~14. №\,6. С.~65--69.
\bibitem{12-bos} %13
\Au{Сябренко А.\,П., Тынченко~В.\,С., Бочарова~О.\,А., Орешенко~Т.\,Г.} 
Анализ результатов аттестации сотрудников предприятий 
с~применением карт Кохонена~// На\-уч\-но-тех\-ни\-че\-ский вестник Поволжья, 2018. 
№\,6. С.~159--162.

\bibitem{14-bos}
\Au{Tynchenko V.\,S., Tynchenko~V.\,V., Bukhtoyarov~V.\,V., Kukartsev~V.\,V., 
Kukartsev~V.\,A., Eremeev~D.\,V.} Application of Kohonen self-organizing maps to the analysis 
of enterprises' employees sertification results~// IOP Conf. Ser.~--- Mat. Sci., 2019. Vol.~537. Iss.~4. Art.~4042010. 5~p.
\bibitem{15-bos}
\Au{Наумов А.\,В., Джумурат~А.\,С., Иноземцев~А.\,О.} Сис\-те\-ма дистанционного 
обучения математическим дисциплинам CLASS.NET~// Вестник компьютерных 
и~информационных технологий, 2014. №\,10. С.~36--44.

\bibitem{18-bos} %16
\Au{Kohonen T.} Self-organized formation of topologically correct feature maps~// Biol. 
Cybern., 1982. Vol.~43. P.~59--69.

\bibitem{16-bos} %17
\Au{Ritter H., Martinetz~T., Schulten~K.} Neural computation and self-organizing maps: An 
introduction.~--- Reading, MA, USA: Addison-Willey, 1992. 306~p.
\bibitem{17-bos} %18
\Au{Kohonen T.} Exploration of very lage database by self-organizing maps~//  Conference 
(International) on Neutral Networks Proceedings.~--- Piscataway, NJ, USA: IEEE, 1997. Vol.~1. 
P.~PL1--PL6. doi: 10.1109/ICNN.\linebreak 1997.611622.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 20.04.22}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{-2pt}

\def\tit{APPLICATION OF~SELF-ORGANIZING NEURAL NETWORKS TO~THE~PROCESS 
OF~FORMING AN~INDIVIDUAL LEARNING PATH}


\def\titkol{Application of~self-organizing neural networks to~the~process 
of~forming an~individual learning path}


\def\aut{A.\,V.~Bosov}

\def\autkol{A.\,V.~Bosov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-8pt}


\noindent
Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, 
44-2~Vavilov Str., Moscow 119333, Russian Federation


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2022\ \ \ volume~16\ \ \ issue\ 3}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2022\ \ \ volume~16\ \ \ issue\ 3
\hfill \textbf{\thepage}}}

\vspace*{3pt} 
    

\Abste{The problem of dynamic classification of students within the framework of supporting 
the process of forming an individual trajectory of the user of an electronic learning system is 
considered. The training model is designed for a mixed form of educational activities with partial 
independent work and periodic control events in the form of distance tests, partial full-time work 
with offline tests, and offset tests. The purpose of the classification is to determine the category of 
the student based on the results of the next control event. The semantics of the categories 
suggests the possibility of an individual task of different levels of task complexity at the next 
step of learning. The direction of improving the existing methods of classification is the rejection 
of the accumulation and use of statistics from previous (other) groups of students. The absence 
of samples of correct classification justified the use of self-organizing neural networks. For the 
solution, Kohonen's maps were used, the standard version of which is adapted to the existing 
learning model and to the task of taking into account the subjective evaluation policy of the 
teacher. Three variants of the self-learning algorithm are described. Experimental research was 
carried out, its results are illustrated.}

\KWE{electronic learning tool; self-organizing neural network; Kohonen's map; classification; 
individual learning path}



\DOI{10.14357/19922264220302} 

%\vspace*{-16pt}

\Ack
\noindent
The research was prepared with the support of the Russian Science Foundation according to the 
research project No.\,22-28-00588. The research was carried out using the infrastructure of the 
Shared Research Facilities ``High Performance Computing and Big Data'' (CKP ``Informatics'') 
of FRC CSC RAS (Moscow).




%\vspace*{4pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}

\bibitem{2-bos-1}
\Aue{Rasch, G.} 1980. \textit{Probabilistic models for some intelligence and attainment tests}. 
Chicago, IL: The University of Chicago Press. 199~p. 

\bibitem{1-bos-1} %2
\Aue{Van der Linden, W.\,J., D.\,J.~Scrams, D.\,L.~Schnipke, \textit{et al.}} 1999. Using response-time 
constraints to control for differential speededness in computerized adaptive testing. \textit{Appl. 
Psych. Meas.} 23(3):195--210.

\bibitem{3-bos-1}
\Aue{Kibzun, A.\,I., and A.\,O.~Inozemtsev.} 2014. Using the maximum likelihood method to 
estimate test complexity levels. \textit{Automat. Rem. Contr.} 75(4):607--621.

\bibitem{5-bos-1} %4
\Aue{Kuravsky, L.\,S., P.\,A.~Marmalyuk, G.\,A.~Yuryev, P.\,N.~Dumin, and A.\,S.~Panfilova.} 
2015. Veroyatnostnoe mo\-de\-li\-ro\-va\-nie protsessa vypolneniya testovykh zadaniy na osno\-ve 
modifitsirovannoy funktsii Rasha [Probabilistic modeling of the process of carrying out test tasks 
on the basis of the modified function Rush]. \textit{Voprosy psihologii} [Problems of 
Psychology] 4:109--118.

\bibitem{4-bos-1} %5
\Aue{Naumov, A.\,V., and G.\,A.~Mkhitaryan.} 2016. On the problem of probabilistic 
optimization of time-limited testing. \textit{Automat. Rem. Contr.} 77(9):1612--1621.

\bibitem{6-bos-1}
\Aue{Kuravsky, L.\,S., A.\,A.~Margolis, P.\,A.~Marmalyuk, A.\,S.~Panfilova, G.\,A.~Yuryev, 
and P.\,N.~Dumin.} 2016. A~probabilistic model of adaptive training. \textit{Applied 
Mathematical Sciences} 10(48):2369--2380.
\bibitem{7-bos-1}
\Aue{Callan, R.} 1999. \textit{The essence of neural networks}. Prentice Hall Europe. 232~p.
\bibitem{8-bos-1}
\Aue{Bosov, A.\,V., Ya.\,G.~Martyushova, A.\,V.~Naumov, and A.\,P.~Sapunova.} 2020. 
Bayesovskiy podkhod k~postroeniyu individual'noy traektorii pol'zovatelya v~sisteme 
dis\-tan\-tsi\-on\-no\-go obucheniya [Bayesian approach to the construction of an individual user 
trajectory in the system of distance learning]. \textit{Informatika i~ee Primeneniya~--- Inform. 
Appl.} 14(3):89--96.
\bibitem{9-bos-1}
\Aue{Kohonen, T.} 2001. \textit{Self-organizing maps}. 3rd ed. Berlin, Heidelberg: Springer. 
501~p.
\bibitem{10-bos-1}
\Aue{Deboeck, G., and T.~Kohonen.} 1998. \textit{Visual explorations in finance}. London: 
Springer-Verlag. 258~p.

\bibitem{13-bos-1} %11
\Aue{Akhterov, A., O.~Lezina, and A.~Shastina.} 2013. Diagnostika razvitiya  
organizatsionno-upravlencheskikh kompetentsiy inzhenerov s~pomoshch'yu 
samoorganizuyushchikhsya kart Kokhonena [Diagnostics of development of organizational and 
managerial competencies of the engineers using the self-organizing Kohonen maps]. 
\textit{Avtomatizatsiya i~upravlenie v~tekhnicheskikh sistemakh} [Automation and Control in 
Technical Systems] 42:35--45.

\bibitem{11-bos-1} %12
\Aue{Zarubina, N.\,K., O.\,V.~Ovchinkin, and A.\,I.~Pykhtin.} 2016. Razvedochnyy analiz 
rezul'tatov priema v~vuz s~primeneniem neyronnoy seti Kokhonena dlya planirovaniya 
kontingenta studentov [Exploratory data analysis of foster campaigns' results using 
Kohonen's neural network when planning the number of students].  
\textit{Informatsionno-izmeritel'nye i~upravlyayushchie sistemy} [Information-Measuring and 
Control Systems] 14(6):65--69.
\bibitem{12-bos-1} %13
\Aue{Syabrenko, A.\,P., V.\,S.~Tynchenko, O.\,A.~Bocharova, and T.\,G.~Oreshenko.} 
2018. Analiz rezul'tatov attestatsii sotrudnikov 
predpriyatiy s~primeneniyem kart Kokhonena [Analysis of the enterprises employees attestation results based on the Kohonen maps]. 
\textit{Nauchno-tekhnicheskiy vestnik 
Povolzh'ya} [Scientific and Technical Volga Region Bulletin] 6:159--162.

\bibitem{14-bos-1}
\Aue{Tynchenko, V.\,S., V.\,V.~Tynchenko, V.\,V.~Bukhtoyarov, V.\,V.~Kukartsev, 
V.\,A.~Kukartsev, and D.\,V.~Eremeev.} 2019. Application of Kohonen self-organizing maps to 
the analysis of enterprises' employees certification results. \textit{IOP Conf. Ser.~--- 
Mat. Sci.} 537(4):4042010. 5~p.
\bibitem{15-bos-1}
\Aue{Naumov, A.\,V., A.\,S.~Dzhumurat, and A.\,O.~Inozemtsev.} 2014. Sistema 
distantsionnogo obucheniya ma\-te\-ma\-ti\-che\-skim distsiplinam CLASS.NET [Distance learning 
system for mathematical disciplines CLASS.NET]. \textit{Vestnik komp'yuternykh 
i~informatsionnykh tekhnologiy} [Herald of Computer and Information Technologies]  
10:36--44.

\bibitem{18-bos-1} %16
\Aue{Kohonen, T.} 1982. Self-organized formation of topologically correct feature maps. 
\textit{Biol. Cybern.} 43:59--69.
\bibitem{16-bos-1} %17
\Aue{Ritter, H., T.~Martinetz, and K.~Schulten.} 1992. \textit{Neural computation and  
self-organizing maps: An introduction}. Reading, MA: Addison-Willey. 306~p.
\bibitem{17-bos-1} %18
\Aue{Kohonen, T.} 1997. Exploration of very lage database by self-organizing maps.  \textit{Conference 
(International) on Neutral Networks Proceedings}. Piscataway, NJ: IEEE. 1:PL1--PL6. doi: 
10.1109/ICNN.1997.611622.


\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received April 20, 2022}}

\Contrl

\noindent
\textbf{Bosov Alexey V.} (b.\ 1969)~--- Doctor of Science in technology, principal scientist, 
Institute of Informatics Problems, Federal Research Center ``Computer Science and Control'' of 
the Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, Russian Federation; 
\mbox{avbosov@ipiran.ru}

\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература}    