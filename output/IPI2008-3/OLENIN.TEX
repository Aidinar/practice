
\def\stat{olenin}

\def\tit{СТРУКТУРНАЯ ДЕКОМПОЗИЦИЯ МАТРИЧНЫХ СИСТЕМ}
\def\titkol{Структурная декомпозиция матричных систем}
\def\autkol{А.\,С. Оленин}
\def\aut{А.\,С. Оленин$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

%{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
%{Работа выполнена при поддержке РФФИ, грант
%08-01-00567.}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Институт проблем информатики Российской академии наук,
aolenin@yandex.ru}

\Abst{Рассматривается один из возможных подходов к распараллеливанию
матричных систем путем их структурной декомпозиции на совокупность подсистем,
независимых на определенном этапе вычислений. Сформулирован конструктивный
алгоритм декомпозиционного метода и дана оценка его вычислительных затрат.}

\KW{матричная система, ленточная матрица; полная матрица; треугольная матрица;
блочная трехдиагональная матрица; декомпозиция; вектор разбиения, отрезок разбиения;
факторизация; LU-раз\-ло\-же\-ние; распараллеливание}

      \vskip 36pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

      \label{st\stat}


     Развитие современных информационных технологий вряд ли возможно
без разработки рациональных подходов к структурной организации вычис\-ли\-тель\-ных 
задач и алгоритмов. От этого %\linebreak 
напрямую зависит производительность и 
эффективность вычислительных процессов параллельных средств 
обработки. Если задачи на уровне алгоритмов не обладают достаточной 
степенью параллелизма, то не следует ожидать высокой производительности при их 
решении на параллельных\linebreak вычислительных системах. То же самое относится и к 
векторной обработке.

     Нередко эффективные, обоснованные теоретически по точности,
устойчивости и тщательно отработанные на практике вычислительные
алгоритмы~\cite{1ol, 2ol} в своей обычной формулировке могут при
некоторых условиях терять свойства параллельности и становиться
преимущественно последовательными. Именно в таких ситуациях важно
предпринимать шаги по структурной модификации алгоритмов, с тем чтобы
повысить их степень параллелизма. Иногда эта цель достигается за счет
некоторого увеличения общего числа операций, но при этом наращивание
параллельных свойств позволяет создать весьма значительный потенциал
производительности.

     Следует отметить, что проблема структурной модификации исходного
алгоритма с целью придания ему более высокой степени параллелизма
является весьма непростой и, по существу, равносильна созданию нового
алгоритма, в котором сохранены черты старого в специфических условиях.
Подходы к решению этой проблемы разнообразны~\cite{3ol} и сильно зависят
от характера вычислительных задач. При этом по большей части
осуществляется выявление и реализация параллельных свойств алгоритмов в
рамках их исходной структуры. Далее будет изложен один из возможных
подходов, связанный со структурной декомпозицией матричных систем, и
обсуждены его особенности.

     Будем рассматривать линейное уравнение с мат\-ри\-цей ленточного типа,
где матрица имеет размер ($N\times N$) и ширину ленты $2m + 1$, где $m$~---
число диагоналей над (под) главной диагональю
     \begin{align}
     \sum\limits_{j=-m}^m a_{i,i+j}x_{i+j} & = f_i\,,\quad i=1, 2, \ldots , N\,,
     \label{e1ol}\\
     x_{1-m} & =0\,,\quad x_{2-m} =0\,,\ \ldots ,\  x_0 =0\,,\notag\\
     x_{N+1} & = 0\,, \quad x_{N+2} =0\,,\ \ldots ,\  x_{N+m}=0\,.\notag
     \end{align}

     В том случае, когда значение $m$ по величине сравнимо с $N$, матрица
близка к полной, и для ее решения широко используются, например, методы,
основанные на процедуре факторизации. Однако анализ показывает, что
типичный процесс вы\-чис\-ле\-ний вдоль главной диагонали в подобных методах
является последовательным, а параллелизм обусловлен наличием побочных
диагоналей, причем параллеллизм тем выше, чем больше задействованных
диагоналей, т.\,е.\ чем больше ширина ленты матрицы. Поэтому при малой
ширине ленты процесс факторизации становится преимущественно
последовательным и малопригодным для счета на параллельных средствах.
Между тем матричные системы с малой шириной ленты часто применяются в
реальных вычислениях, и их параллельная реализация весьма актуальна.

     Предлагаемый подход заключается в декомпозиции (разбиении)
исходной системы на совокупность подсистем, независимых друг от друга на
определенном этапе вычислений. Связь этих подсистем осуществляется путем
формулирования отдельной задачи, которая позволяет выполнить расчет
подсистем в параллельном режиме, а затем вычислить окончательный
результат для исходной сис\-те\-мы.

     
     Итак, разобьем всю последовательность неизвестных на $n + 1$
отрезков с помощью $n$ векторов $X_k = \{ x_i | i = i_k, i_k + 1,\ldots , i_k + m -
1\}$,  $k = 1, 2,\ldots , n$, $X_0 = 0$, $X_{n+1} = 0$. Отрезок с номером $k$
ограничен слева вектором $X_{k-1}$, справа~--- вектором~$X_k$.


     Решение системы~(\ref{e1ol}) будем искать в виде
     \begin{equation}
        x_i = y_i +\sum\limits_{k=1}^n\sum\limits_{p=1}^m v_{ip}^{(k)}
x_{i_k+p-1}\,,\quad i=1, 2, \ldots , N\,.
     \label{e2ol}
     \end{equation}
 
     Запишем это выражение в векторно-матричной форме для
произвольного вектора разбиения $X_t$:
     \begin{equation}
     X_t = Y_t +\sum\limits_{k=1}^n V_t^{(k)} X_k\,.
     \label{e3ol}
     \end{equation}
     Здесь векторы имеют размер $m$, матрицы~--- размер ($m\times m$):
     \begin{align*}
     X_t &= \begin{pmatrix}
     x_{i_t}\\ x_{i_t+1}\\ \ldots\\ x_{i_t+m-1}
     \end{pmatrix}\,;\quad
     Y_t = \begin{pmatrix}
     y_{i_t}\\ y_{i_t+1}\\ \ldots\\ y_{i_t+m-1}
     \end{pmatrix}\,;\\[6pt]
     V_t^{(k)} & =
     \begin{pmatrix}
     v^{(k)}_{i_t,1} & v^{(k)}_{i_t,2} & \ldots & v^{(k)}_{i_t,m}\\
     v^{(k)}_{i_t+1,1} & v^{(k)}_{i_t+1,2} & \ldots & v^{(k)}_{i_t+1,m}\\
     \ldots & \ldots & \ldots & \ldots\\
     v^{(k)}_{i_t+m-1,1} & v^{(k)}_{i_t+m-1,2} & \ldots & v^{(k)}_{i_t+m-
1,m}\\
     \end{pmatrix}
     \,.
     \end{align*}
         
     Для того чтобы равенство~(\ref{e3ol}) тождественно %\linebreak
      удов\-ле\-тво\-ря\-лось на
векторе $X_k$, необходимо выполнение условий:
     \begin{equation}
     Y_k = 0\,;\quad
     V_t^{(k)} =
     \begin{cases}
     E\,, & t=k\,;\\
     0\,, & t\not= k\,,
     \end{cases}
     \label{e4ol}
     \end{equation}
где     $E$~--- единичная матрица размера ($m\times m$).

     Подставляя выражение (\ref{e2ol}) в систему~(\ref{e1ol}), получаем
серию задач:
     \begin{align}
     \sum\limits_{j=-m}^m a_{i,i+j} y_{i+j} & = f_i\,;\notag\\
     \sum\limits_{j=-m}^m a_{i,i+j} v^{(k)}_{i+j,p} & = 0\,,\quad p=1, 2, \ldots ,
m\,,\label{e5ol}\\ &i=1, 2, \ldots , N\,,\ k=1, 2, \ldots , n\,.\notag
     \end{align}

     Далее примем во внимание, что на границах отрезка $k$, т.\,е.\ на
векторах $X_{k-1}$ и $X_k$, согласно условиям~(\ref{e4ol}), имеют место
граничные равенства:
     \begin{align*}
     Y_{k-1} & =0\,;\quad Y_k=0\,;\\[4pt]
     V_{k-1}^{(k-1)} & =E\,;\quad V_k^{(k-1)} =0\,;\\[4pt]
     V_{k-1}^{(k)} & =0\,;\quad V_k^{(k)} =E\,.
     \end{align*}

     Из этих равенств следует, что на отрезке $k$ только две функции
     ($v^{(k-1)}$ и $v^{(k)}$) из систем~(\ref{e5ol}) будут иметь ненулевые
решения, поскольку только они имеют ненулевые значения на границах (при
нулевой правой части систем). Для удобства обозначим функцию $v^{(k-1)}$ на
отрезке $k$ через $u^{(k)}$. Придем к следующей совокупности систем на
отрезке~$k$:
     \begin{align}
     \sum\limits_{j=-m}^m a^{(k)}_{i,i+j} y^{(k)}_{i+j} & = f_i^{(k)}\,;\ \
Y_{k-1} =0\,;\ \ Y_k=0\,;\label{e6ol}\\
     \sum\limits_{j=-m}^m a^{(k)}_{i,i+j} u_{i+j,p}^{(k)} & = 0\,;\quad
U^{(k)}_{k-1} =E\,;\quad U_k^{(k)} =0\,,\notag\\[-6pt]
&\label{e7ol}\\[-6pt]
& p=1, 2, \ldots , m\,;\notag\\
     \sum\limits_{j=-m}^m a_{i,i+j}^{(k)}v^{(k)}_{i+j, p} & =0\,;\quad
V^{(k)}_{k-1} =0\,;\quad V_k^{(k)} =E\,,\notag\\[-6pt]
&\label{e8ol}\\[-6pt]
&p=1, 2, \ldots , m\,.\notag
     \end{align}

     Вследствие условий на границах неизвестных значений
системы~(\ref{e1ol}), $u^{(1)} = 0$ на первом отрезке, $v^{(n)} = 0$~--- на
отрезке $n + 1$.

     С учетом задач (\ref{e6ol})--(\ref{e8ol}) выражение~(\ref{e2ol}) на
отрезке~$k$ принимает вид
     \begin{multline}
     x_i^{(k)} = y_i^{(k)} +\sum\limits_{p=1}^m u_{ip}^{(k)} x_{i_{k-1}+p-1}+{}\\
{}+\sum\limits_{p=1}^m v_{ip}^{(k)}x_{i_k+p-1}\,.
     \label{e9ol}
     \end{multline}

     Теперь запишем систему~(\ref{e1ol}) на векторе $X_k$, учитывая, что
слева от него расположен отрезок~$k$, а справа~--- отрезок $k + 1$:
     \begin{equation}
     A^{(k)} X^{(k)} +B_k X_k +C^{(k+1)} X^{(k+1)} = F_k\,.
     \label{e10ol}
     \end{equation}
Здесь верхние индексы относятся к отрезкам, а нижние~--- к векторам
разбиения,
\end{multicols}
\begin{align*}
A^{(k)} &=
\begin{pmatrix}
a_{i_k, i_k-m} & a_{i_k, i_k-m+1} & \ldots & a_{i_k, i_k-1}\\
0 & a_{i_k+1, i_k-m+1} & \ldots & a_{i_k+1, i_k-1}\\
\ldots &\ldots &\ddots&\ldots\\
0 & 0 & \ldots & a_{i_k+m-1,i_k-1}
\end{pmatrix}\,;\\
B_k & =
\begin{pmatrix}
a_{i_k, i_k} & a_{i_k, i_k+1} & \ldots & a_{i_k, i_k+m-1}\\
a_{i_k+1, i_k} & a_{i_k+1, i_k+1} & \ldots & a_{i_k+1, i_k+m-1}\\
\ldots &\ldots &\ddots&\ldots\\
a_{i_k+m-1, i_k}& a_{i_k+m-1,i_k+1} & \ldots & a_{i_k+m-1,i_k+m-1}
\end{pmatrix}\,;\\
C^{(k+1)} & =
\begin{pmatrix}
a_{i_k, i_k+m} & 0 & \ldots &0\\
a_{i_k+1,i_k+m} & a_{i_k+1, i_k+m+1} & \ldots & 0\\
\ldots &\ldots &\ddots&\ldots\\
a_{i_k+m-1,i_k+m} & a_{i_k+m-1,i_k+m+1} & \ldots & a_{i_k+m-1,i_k+2m-1}
\end{pmatrix}\,;
\end{align*}
\begin{multicols}{2}
\noindent
\begin{align*}
X^{(k)}& = \{x_i| i = i_{k-m},\ldots ,i_{k-1}\}\,;\\
X_k &= \{x_i| i = i_k\,,\ldots ,i_{k+m-1}\}\,;\\
X^{(k+1)} & = \{x_i| i = i_{k+m}\, ,\ldots ,i_{k+2m-1}\}\,;\\
F_k &= \{f_i| i = i_k\,, \ldots ,i_{k+m-1}\}\,,
\end{align*}
где
$A^{(k)}$~--- верхняя треугольная матрица, связанная с отрезком~$k$;
$B_k$~--- полная матрица, связанная с вектором~$k$;
$C^{(k+1)}$~--- нижняя треугольная матрица, связанная с отрезком $k + 1$.

     Выразим векторы $X^{(k)}$, $X^{(k+1)}$ в системе~(\ref{e10ol}) через
векторы разбиения, используя формулу~(\ref{e9ol}):
     \begin{align*}
     X^{(k)} & = Y^{(k)}+U^{(k)} X_{k-1} +V^{(k)} X_k\,;\\
     X^{(k+1)} & = Y^{(k+1)}+U^{(k+1)} X_{k} +V^{(k+1)} X_{k+1}\,.
     \end{align*}

     Вид введенных здесь векторов и матриц ясен из выражения~(\ref{e9ol}).
После подстановки этих соотношений в систему~(\ref{e10ol}), получим
     \begin{multline}
    \overline{A}_k X_{k-1} +\overline{B}_k X_k +\overline{C}X_{k+1} =
\overline{F}_k\,,\\
\ \ \ \ \ \ \ \ \ k=1, 2, \ldots , n\,,\label{e11ol}
\end{multline}
где
\begin{gather*}
\overline{A}_k  = A^{(k)}U^{(k)}\,;\\
\overline{B}_k  = A^{(k)}V^{(k)}+B_k+C^{(k+1)}U^{(k+1)}\,;\\
\overline{C}_k  = C^{(k+1)}V^{(k+1)}\,;\\
\overline{F}_k  = F_k - A^{(k)}Y^{(k)} - C^{(k+1)}
Y^{(k+1)}\,.
\end{gather*}

     Система~(\ref{e11ol}) имеет блочную трехдиагональную матрицу и
является связующей для под\-сис\-тем~\mbox{(\ref{e6ol})--(\ref{e8ol}).}

     Итак, для решения задачи~(\ref{e1ol}) в соответствии с изложенной
схемой декомпозиции необходимо выполнить следующие действия:
     \begin{enumerate}[1.]
\item Решить задачи~(\ref{e6ol})--(\ref{e8ol}) на отрезках разбиения.
\item Найти решение связующей задачи~(\ref{e11ol}) на векторах разбиения.
\item Вычислить неизвестные значения системы~(\ref{e1ol}) по
формуле~(\ref{e9ol}).
     \end{enumerate}

     Далее займемся оценкой вычислительных затрат декомпозиционной
схемы. Вначале вспомним, что, непосредственно применяя для решения
заданной системы~(\ref{e1ol}) такой широко распространенный метод, как
$LU$-разложение, требуется выполнить порядка $m^2N$ операций. Следует
выяснить, приводит ли декомпозиционная схема к увеличению объема
вычислений и если приводит, то на какую величину по сравнению с
     $LU$-разложением.

     Будем полагать, что отрезки разбиения примерно равны и имеет место
обычное рабочее соотношение параметров: $m \ll n \ll N$, где $n \gg 1$. Для
решения линейных систем на отрезках используем алгоритм
     $LU$-разложения. Тогда для системы~(\ref{e6ol}) по порядку величины
имеем $n$ задач по $m^2(N/n)$ операций каждая, т.\,е.\ всего $m^2N$ операций.
Сис\-те\-мы~(\ref{e7ol}) и~(\ref{e8ol}), если в них граничные величины
перенесены в правые части, дают в совокупности порядка $m^3N$ операций.
Связующая система~(\ref{e11ol}) может быть решена за $m^3n$ операций. И,
наконец, формула~(\ref{e9ol}) содержит примерно $mN$ операций. Очевидно,
что в приведенной оценке определяющей является величина $m^3N$, которая
при достаточно больших значениях ширины ленты может существенно
превосходить оценку $m^2N$, име\-ющую место при решении исходной
системы~(\ref{e1ol}) без применения декомпозиции. И здесь возникает
правомерный вопрос: не является ли дополнительная вычислительная
нагрузка, связанная с декомпозицией, слишком чрезмерной? Однако эту
нагрузку можно значительно снизить, если обратить внимание на то, что
матрицы систем~(\ref{e7ol}) и~(\ref{e8ol}) не меняются по
индексу~$p$, поскольку граничные величины, как указывалось выше,
перенесены в правые части. Это обстоятельство позволяет использовать
специфику $LU$-разложения, которая состоит в том, что этап разложения на
треугольные множители для каждой из систем~(\ref{e7ol}) и~(\ref{e8ol}) может
быть выполнен однократно. А поскольку этот этап является доми\-ни\-ру\-ющим
по затратам, то оценку числа операций для него благодаря указанному
свойству можно снизить с $m^3N$ до $m^2N$. При этом на этапе решения
треугольных систем алгоритма $LU$-разложения затраты остаются на уровне
$m^2N$ операций. До\-бав\-ляя сюда число операций $m^2N$ для
системы~(\ref{e6ol}), получаем оценку вычислительных затрат
декомпозиционного метода порядка $Cm^2N$ операций, где $C$~---
небольшая по величине константа, точное определение которой требует более
детального рассмотрения. Принципиально важно то, что оценку,
совпадающую с точностью до константы (т.\,е.\ независимую от ширины
ленты) с оценкой исходного алгоритма, удалось получить, используя именно
специфику $LU$-разложения. В случае алгоритмов, в которых отсутствует
подобная специфика, затраты на декомпозицию значительно возрастают.
Указанное обстоятельство наглядно демонстрирует важную для приложений
ситуацию, когда структурная декомпозиция задач на подзадачи требует
внимательного отношения к алгоритмам реализации.

     Итак, применив декомпозиционный метод, можно приблизительно в $C$
раз увеличить объем вычис\-ле\-ний, но одновременно получить существенный
потенциал распараллеливания. Действительно, самая затратная часть метода,
связанная с %\linebreak
 сис\-те\-ма\-ми~(\ref{e6ol})--(\ref{e8ol}), распадается на $n + 1$
независимых подзадач и может выполняться как в параллельном, так и в
векторном режиме. Решение связующей задачи~(\ref{e11ol}) сводится к
векторно-матричным операциям, которые естественно распараллеливаются и
векторизуются. Формула~(\ref{e9ol}) вносит менее значительный вклад в
общий объем вычислений и также обладает параллельными свойствами.

     Отметим, что характерная степень параллелизма схемы декомпозиции
определяется числом полученных независимых подзадач, т.\,е.\
па\-ра\-мет\-ром~$n$. Следовательно, неравенство $n > C$ устанав\-ли\-ва\-ет
приближенный критерий, показывающий, когда эффект по времени
вычислений за счет параллелизма схемы декомпозиции может стать выше, чем
потери из-за большего числа операций. И~этот эффект будет усиливаться с
ростом~$n$.

     Сделаем несколько замечаний о качестве вы\-чис\-ле\-ний по
декомпозиционной схеме. Не ухудшится ли оно по сравнению с
непосредственным счетом? Качество решения линейной системы зависит, как
известно, от свойств ее матрицы. Если для матрицы заданной
системы~(\ref{e1ol}) выполнены локальные условия устойчивости (например,
диагональное преобладание), то эти условия справедливы и для под\-мат\-риц,
которые участвуют в подзадачах~(\ref{e6ol})--(\ref{e8ol}). Поэтому качество
вычислений в подзадачах остается на уровне принятого алгоритма решения.
Что касается связующей системы~(\ref{e11ol}), то условия ее устойчивости
также являются производными от свойств исходной матрицы и не оказывают
сколько-нибудь существенного самостоятельного влияния на качество
вычислительного процесса. И все же, приводя теоретические соображения,
следует иметь в виду, что качество вычислительных процессов, особенно в
сложных задачах, наиболее надежно обеспечивается с помощью практических
вычислений.

     Приведем формулировку метода декомпозиции для распространенного в
реальных задачах случая $m = 1$, т.\,е.\ для системы с трехдиагональной
мат\-ри\-цей. Такая система обычно записывается сле\-ду\-ющим образом:
     \begin{align*}
     &a_i x_{i-1} +b_ix_i +c_ix_{i+1} = f_i\,,\quad i=1, 2, \ldots , N\,;
     \\
&x_0 =0 \,; \quad x_{N+1} =0\,.
     \end{align*}

     В этом случае вид структурной декомпозиции из векторно-матричной
формы переходит в скалярную (векторы разбиения становятся скалярными
величинами):
     \begin{align}
&     a_i^{(k)} y_{i-1}^{(k)} +b_i^{(k)}y_i^{(k)} +c_i^{(k)} y_{i+1}^{(k)}  =
f_i^{(k)}\,,\notag\\[-6pt]
     & \label{e13ol}\\[-6pt]
 &    y^{(k)}_{i_k-1}  =0\,,\quad y_{i_k}^{(k)} =0\,;\notag\\[6pt]
&     a_i^{(k)} u_{i-1}^{(k)} +b_i^{(k)}u_i^{(k)} +c_i^{(k)} u_{i+1}^{(k)}  =
0\,,\notag\\[-6pt]
     & \label{e14ol}\\[-6pt]
&     u^{(k)}_{i_k-1}  =1\,,\quad u_{i_k}^{(k)} =0\,;\notag\\[6pt]
 &    a_i^{(k)} v_{i-1}^{(k)} +b_i^{(k)}v_i^{(k)} +c_i^{(k)} v_{i+1}^{(k)}  =
0\,,\notag\\[-6pt]
     & \label{e15ol}\\[-6pt]
&     v^{(k)}_{i_k-1}  =0\,,\quad v_{i_k}^{(k)} =1\,.\notag
     \end{align}

     Связующая система приобретает вид:
     \begin{equation}
     \overline{a}_k \overline{x}_{k-1} +\overline{b}_k\overline{x}_k
+\overline{c}_k\overline{x}_{k+1} = \overline{f}_k\,,\ k=1, 2, \ldots , n\,;
     \label{e16ol}
     \end{equation}
     \vspace*{-9pt}
     
     \noindent
     \begin{gather*}
        \overline{x} =0\,;\quad \overline{x}_{n+1} =0\,;\\[2pt]
        \overline{x}_{k-1} = x_{i_k-1}\,;\quad \overline{x}_k = x_{i_k}\,;\quad \overline{x}_{k+1} = x_{i_k+1}\,;\\[2pt]
        \overline{a}_k = a_{i_k-1}u_{i_k-1}^{(k)}\,;\\[2pt]
     \overline{b}_k = a_{i_k-1} v^{(k)}_{i_k-1} +b_{i_k} +c_{i_k+1}
u^{(k+1)}_{i_k+1}\,;\\[2pt]
     \overline{c}_k = c_{i_k+1} v^{(k+1)}_{i_k+1}\,;\\[2pt]
     \overline{f}_k =  f_{i_k} -a_{i_k-1} y^{(k)}_{i_k-1} - c_{i_k+1}
y^{(k+1)}_{i_k+1}\,.
     \end{gather*}

     Неизвестные значения на отрезках вычисляются по формуле:
     \begin{equation}
     x_i^{(k)} = y_i^{(k)} +u_i^{(k)} x_{i_k-1} +v_i^{(k)} x_{i_k}\,.
     \label{e17ol}
     \end{equation}

     В схеме (\ref{e13ol})--(\ref{e17ol}) вычислительные затраты по
сравнению со случаем, когда ширина ленты велика, минимальны, и,
соответственно, роль специфики применяемых алгоритмов (в рассмотренном
выше смысле) также минимальна. 

Отметим, что обычно алгоритмы решения
\mbox{таких} систем имеют существенно ограниченные %\linebreak 
возможности для
распараллеливания, поэтому применение декомпозиционных подходов для их
распа\-рал\-ле\-ли\-ва\-ния, когда это необходимо, является особен\-но полезным.
Например, системы с ленточными матрицами весьма часто встречаются при
численном решении задач математической фи\-зики. 
{\looseness=1

}

Возможно также
приложение метода в задачах построения канонических разложений
случайных функций~\cite{4ol} (проблема распараллеливания таких задач
обсуждалась с академиком В.\,С.~Бурцевым и к.\ ф-м. н. А.\,М.~Степановым).

     В заключение подчеркнем, что методы структурной декомпозиции,
несмотря на разнообразие всевозможных приложений и реализаций,
со\-став\-ля\-ют по сути единый, весьма мощный фундаментальный инструмент
распараллеливания задач и поэтому представляют значительный интерес для
вычислительных аспектов информатики и информационных технологий.

\vspace*{-6pt}
{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{9}
\bibitem{1ol}
\Au{Марчук Г.\,И.}
Методы вычислительной математики.~--- М.: Наука, 1989.

\bibitem{2ol}
\Au{Фаддеев Д.\,К., Фаддеева~В.\,Н.}
Вычислительные методы линейной алгебры.~--- СПб.: Лань, 2002.

\bibitem{3ol}
\Au{Воеводин В.\,В., Воеводин~Вл.\,В.}
Параллельные вычисления.~--- СПб.: БХВ-Петербург, 2002.

\label{end\stat}

\bibitem{4ol}
\Au{Пугачев В.\,С., Синицын~И.\,Н.}
Теория стохастических систем. 2-е изд.~--- М.: Логос, 2004.
\end{thebibliography}
}
}
\end{multicols}