
\def\stat{konovalov}

\def\tit{ОБ АДАПТИВНЫХ СТРАТЕГИЯХ И~УСЛОВИЯХ~ИХ~СУЩЕСТВОВАНИЯ$^*$}

\def\titkol{Об адаптивных стратегиях и~условиях их 
существования}

\def\autkol{М.\,Г.~Коновалов}

\def\aut{М.\,Г.~Коновалов$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
{Работа выполнена при поддержке РФФИ, грант № 11-07-00112.}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Институт проблем информатики Российской академии наук, mkonovalov@ipiran.ru}



\Abst{Рассматривается задача оптимального управления в отсутствие априорной 
информации об управляемом объекте. Решением задачи является построение адаптивных 
стратегий на основе наблюдений, доступных в процессе управления. Изучаются 
некоторые условия адаптивной управляемости объекта. В~качестве математической 
модели используются управляемые случайные последовательности.}

\KW{управляемые случайные последовательности; адаптивные стратегии; условия 
существования}

\vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}


\section{Введение}

  Тема статьи относится к области адаптивных методов обработки информации с целью 
принятия оптимальных решений. Потребность в адаптивном\linebreak
подходе возникает в задачах 
с большой информационной неопределенностью, что наиболее характерно для 
телекоммуникационных систем, автоматизированных производственных процессов, 
робототех\-ни\-ки и других сфер, неразрывно связанных с компьютерной обработкой 
информации. Понятие неопределенности многозначно и связано с отсутствием априорных 
сведений, недетерминированностью, а также с неполнотой наблюдений. 
К~перечисленным факторам в нарастающей степени добавляется <<избыточность>> 
информации, которая порождается чрезмерно прогрессирующими объемами 
передаваемой и хранимой информации и обусловлена экспоненциальным ростом 
пропускной способности телекоммуникационных сетей, а также емкостей носителей 
информации.
  
  Идея адаптации (приспособления, самоорганизации), заимствованная из 
биологического мира, начала активно эксплуатироваться в науке примерно с середины 
прошлого века. Кратко, она заключается в том, чтобы, целенаправленно взаимодействуя с 
окружающей средой, отбирать и использовать поступающую информацию, необходимую 
для принятия оптимальных решений с точки зрения поставленной цели.
  
  Данная статья посвящена теоретическим аспектам адаптации. В~качестве исходного 
пред\-став\-ле\-ния использована схема, которая опирается на пред\-став\-ление о паре 
  <<объект--субъект>>, взаимодействующей в дискретном времени путем 
попеременного обмена сигналами. При этом субъект воздействует на объект с помощью 
управлений, получая в ответ сигналы, называемые наблюдениями. Действия субъекта 
преследуют цель, выраженную в наличии определенных свойств у траектории 
наблюдений.
  
  Основная отличительная особенность заключается в предположении, что действия 
субъекта происходят при недостаточной информации об объекте. В~качестве 
математической модели объекта взята конструкция управляемой случайной 
последовательности. В~терминах этого аппарата легко очерчиваются четыре аспекта 
информационной неопределенности:
  \begin{enumerate}[(1)]
\item недетерминированность понимается как стохастичность;
\item недостаток информации об объекте трактуется как неполное знание вероятностного 
распределения, задающего процесс;
  \item неполнота наблюдений означает, что состояния процесса наблюдаются лишь 
частично;
  \item недостаток знаний выражается в неумении \mbox{найти} или рассчитать ту или иную 
характеристику, связанную со случайной последовательностью, даже при наличии 
априорной информации о распределении процесса и полной его наблюдаемости.
  \end{enumerate}
  
  Субъект ассоциируется с алгоритмом, согласно которому выбираются управления, 
регулирующие траекторию случайной последовательности. Такой алгоритм принято 
называть стратегией управ\-ле\-ния. Задача заключается в том, чтобы выбрать стратегию, 
достигающую цели в ситуации, когда информация субъекта об объекте ограничена. 
По-дру\-го\-му можно сказать, что речь идет о построении стратегии, достигающей цели (в 
данном случае~--- максимизации предельного среднего дохода) для любого процесса из 
некоторого заданного класса объектов. Такие стратегии называют адаптивными по 
отношению к заданному классу объектов~[1].
  
  В разд.~2 даются формальные определения объекта, цели и адаптивной стратегии 
управления.
  
  В разд.~3 анализируются условия существования адаптивной стратегии. В~качестве 
необходимых условий обсуждаются два требования, которые, как представляется, должны 
выполняться из интуитивных соображений.
  
  Первое из необходимых условий связано с принципиальной особенностью адаптивных 
стратегий, которые, прежде чем выйти на <<оптимальный режим>>, должны затратить 
некоторое время на <<обуче\-ние>>. (На самом деле в рассматриваемой постановке процесс 
обучения для адаптивных стратегий длится даже неограниченно долго.) Естественно 
предположить, что подобные стратегии могут реализоваться, только если в процессе 
обучения не будут совершены <<непоправимые ошибки>>. Это соображение 
раскрывается на примерах и получает формальное описание.
  
  Второе необходимое условие является менее очевидным. Оно связано с гипотезой о 
том, что адаптивная стратегия управления классом случайных последовательностей 
существует лишь тогда, когда для данного класса возможно построение так называемой 
адаптивной стратегии перебора. Это выражается в том, что существует и заранее известно 
некоторое счетное множество вариантов поведения, среди которого для данного класса 
обязательно найдется оптимальный или близкий к нему вариант. Данное соображение 
также иллюстрировано примерами и приведена теорема о критерии существования 
адаптивной стратегии для определенного класса объектов.
  
  Подход, использованный в статье, а также полученные результаты являются 
продолжением направления, представленного в работе~[2].
  
\section{Постановка задачи адаптивного управления}
  
  Пусть  время $t$ пробегает значения 0, 1, \ldots\ и пусть заданы измеримые 
пространства $(X,\mathbf{X})$, $(Y,\mathbf{Y})$, $(Z,\mathbf{Z})$ (соответственно 
пространства \textit{состояний}, \textit{управлений} и \textit{наблюдений}).
  
  Общая траектория процесса упорядочена в виде последовательности $x_0, y_1, 
z_1,x_1,\ldots$\linebreak $\ldots , x_{t-1},y_t,z_t,x_t,\ldots$ Предыстория процесса до момента~$t$ 
включительно обозначается как

\noindent
  \begin{gather*}
 \! x^t=x_0^t=(x_0,\ldots , x_{t-1});\ \ \ y^t=y_1^t=(y_1, \ldots , y_{t-1});\\
  z^t=z_1^t=(z_1,  \ldots , z_{t-1})\,.
  \end{gather*}
  
  Траектории процесса определяются последовательностями условных вероятностных 
распределений~$\mu$, $\nu$ и~$\sigma$.
  
  Последовательность $\mu\hm=(\mu_0,\mu_1,\ldots ,\mu_t, \ldots)$ задает механизм 
смены состояний. В~этой последовательности $\mu_0$~--- вероятностное распределение 
на $(X,\mathbf{X})$; $\mu_t=\mu_t(A\vert x^{t-1},y^t)$, $t\hm>0$~---  условная 
(переходная) вероятность, которая при любых наборах $(x^{t-1},y^t)$ является 
вероятностной мерой на $(X,\mathbf{X})$ и при любом $A\hm\in X$ является измеримой 
функцией относительно $x^{t-1},y^t$.
  
  Последовательность $\nu\hm=(\nu_1, \ldots , \nu_t, \ldots)$ задает механизм появления 
наблюдений. В~этой последовательности каждый элемент $\nu_t\hm=\nu_t(C\vert x^{t-1}, 
y^t)$, $t\hm>0$, представляет собой условное распределение, которое при любом условии 
является вероятностной мерой на $(Z,\mathbf{Z})$ и для любого $C\hm\in Z$ является 
измеримой функцией относительно переменных, стоящих в условии. Пара $o\hm= 
(\mu,\nu)$ называется объектом.
  
  Последовательность $\sigma\hm= (\sigma_1, \ldots , \sigma_t. \ldots)$ называется 
(допустимой) \textit{стратегией} и определяет выбор управлений. В~этой 
последовательности:
%\smallskip
   $\sigma_1\hm=\sigma_1(\cdot)$~--- вероятностная мера на $(Y,\mathbf{Y})$; 
      $\sigma_{t+1}\hm=\sigma_{t+1}(B\vert y^t,z^t)$, $t\hm>0$,~--- условная вероятность, 
которая при любых $y^t,z^t$ является вероятностной мерой на $(Y,\mathbf{Y})$ и при 
любом $B\hm\in Y$ является измеримой функцией относительно $y^t,z^t$. Элементы 
последовательности~$\sigma$ называются (допустимыми) \textit{правилами}.

%\smallskip
  
  Введем обозначение для прямых произведений множеств:
  $$
  \Omega_0=X\,;\enskip \Omega_t=X^{t+1}\times Y^t\times Z^t\,,\enskip t>0\,,
  $$
а также для наименьших $\sigma$-ал\-гебр, порожденных соответствующими 
$\sigma$-ал\-геб\-рами:
$$
\mathbf{F}_0=\mathbf{X}\,;\enskip \mathbf{F}_t=\mathbf{X}\otimes \mathbf{Y}\otimes 
\mathbf{Z}\otimes \mathbf{X}\otimes \cdots \otimes \mathbf{Y}\otimes \mathbf{Z}\otimes 
\mathbf{X}
$$
($\mathbf{X}$ повторяется $t+1$ раз, $\mathbf{Y}$ и $\mathbf{Z}$~--- $t$ раз, $t\hm>0$).
  
  Положим
  
  \vspace*{3pt}
  
  \noindent
  $$
  \Omega =\prod\limits_{t\geq 0}\Omega_t\,;\enskip 
\mathbf{F}=\mathop{\otimes}\limits_{t\geq0}\mathbf{F}_t\,.
  $$ 
  
  Согласно общей теории~\cite{3-kon} последовательности $o\hm=(\mu,\nu)$ и~$\sigma$ 
порождают на пространстве $(\Omega, \mathbf{F})$ вероятностную меру $\mathbf{P}\hm= 
\mathbf{P}_{o,\sigma}\hm=\mathbf{P}_{\mu,\nu,\sigma}$, которая согласована с 
элементами этих последовательностей следующим образом. Случайные 
последова\-тель\-ности

\vspace*{-3pt}

\noindent
  \begin{gather*}
  x_t=x_t(\omega)\,;\enskip  
  y_{t+1}=y_{t+1}(\omega)\,;\\
  z_{t+1}= z_{t+1}(\omega)\,,\enskip  \omega\in \Omega\,,\  t\geq 0\,,
  \end{gather*}
удовлетворяют соотношениям:

\pagebreak

\noindent
$$
\mathbf{P}(x_0(\omega)\in A_0)=\int\limits_{A_0} \mu_0(dx_0)\,;
$$

\vspace*{-12pt}

\noindent
\begin{multline*}
\mathbf{P}\left(x_0(\omega)\in A_0\,,\  y_1(\omega)\in B_1\,,\ 
z_1(\omega)\in C_1, \ldots \right.\\[1pt]
\left.{}\ldots\,,
y_t(\omega)\in B_t\,,\  z_t(\omega)\in C_t\,,\  x_t(\omega)\in A_t\right)={}\\[1pt]
{}=\int\limits_{A_0}\mu_0(dx_0)\int\limits_{B_1}\sigma_1(dy_1)\int\limits_{C_1}\nu_1(dz_1
\vert x_0, y_1)\cdots{}\\[1pt]
{}\cdots
\int\limits_{B_t}\sigma_t\left(dy_t\vert y^{t-1},z^{t-1}\right) 
\int\limits_{C_t} \nu_t\left( dz_t\vert x^{t-
1},y^t\right) \times{}\\[1pt]
{}\times
\int\limits_{A_t} \mu_t\left( dx_t\vert x^{t-1},y^t\right)
\end{multline*}
для любых $A_t\in X$, $B_{t+1}\hm\in Y$, $C_{t+1}\hm\in Z$, $t\hm\geq 0$.
  
  По определению стратегии, ее правила зависят от предыдущих управлений и 
наблюдений, но не от предыдущих состояний. Это соответствует предположению о том, 
что состояния объекта не наблюдаемы в ходе процесса управления. В~частных случаях 
объект $o\hm=(\mu,\nu)$ может, конечно, описывать полностью наблюдаемый процесс. 
Например, если все множества $X_t$ содержат один и тот же единственный элемент. 
Другой простой пример~--- когда наблюдения тождественны состояниям. Однако на 
самом деле, как показывает лемма~1, с формальной точки зрения рассмотрение объекта с 
<<ненаблюдаемой>> компонентой всегда можно заменить изучением полностью 
наблюдаемого процесса.
  
  \medskip
  
  \noindent
  \textbf{Лемма 1.} \textit{Для любого объекта $o\hm=(\mu,\nu)$ условная вероятность 
$\mathbf{P}\left(dz_t\vert y^t,z^{t-1}\right)$ не зависит от стратегии~$\sigma$ при любых 
$t\hm>0$.}
  
  \medskip
  
  \noindent
  Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ Согласно отмеченной выше согласованности 
условных распределений $\mu,\nu,o$ и порождаемой ими меры~\textbf{P} имеем 
соотношения:
  \begin{multline*}
  I_1=\mathbf{P}\left(
  y_1(\omega)\in B_1,\ z_1(\omega)\in C_1\right) ={}\\[1pt]
  {}=
  \mathbf{P}\left( x_0(\omega)\in X_0\,,\ y_1(\omega)\in B_1\,,\ z_1(\omega)\in 
C_1\right)={}\\[1pt]
  {}=\int\limits_{X_0} \int\limits_{B_1} \int\limits_{C_1} \mu_0\left(dx_0\right) 
\sigma_1\left(dy_1\right) \nu_1\left(dz_1\vert x_0,y_1\right)={}\\[1pt]
  {}= \int\limits_{B_1}\int\limits_{C_1}\sigma_1\left(dy_1\right) \int\limits_{X_0}\mu_0\left( 
dx_0\right) \nu_1\left( dz_1\vert x_0,y_1\right)\,,
  \end{multline*}
справедливые при любых $B_1\hm\in Y$ и $C_1\in Z$. Кроме того, по определению 
условной вероятности
$$
I_1=\int\limits_{B_1}\int\limits_{C_1}\sigma_1\left(dy_1\right) \mathbf{P}\left(dz_1\vert 
y_1\right)\,.
$$
  
  Сравнивая оба выражения для~$I_1$, получаем, что
  $$
  \mathbf{P}\left( dz_1\vert 
y_1\right)=\int\limits_{X_0}\mu_0\left(dx_0\right)\nu_1\left(dz_1\vert x_0, y_1\right)\,,
  $$
т.\,е.\ утверждение леммы справедливо для $t\hm=1$. Пусть оно верно для $n\hm=1, 2, 
\ldots , t\hm-1$. Для любых $B_1\hm\in Y$, $C_1\hm\in Z$, \ldots , $B_{t-1}\hm\in Y$, 
$C_t\hm\in Z$ имеем:

\noindent
\begin{multline*}
I_t=\mathbf{P}\left( y_1(\omega)\in B_1\,,\ z_1(\omega)\in C_1, \ldots{}\right.\\[1pt]
\left.{}\ldots , y_t(\omega)\in B_t\,,\ 
z_t(\omega) \in C_t\right)={}\\[1pt]
{}=
\mathbf{P}\left( x_0(\omega)\in X\,,\ y_1(\omega)\in B_1\,,\ z_1(\omega)\in C_1\,, \ldots\right.\\[1pt]
\left.{}\ldots , x_{t-
1}(\omega)\in X\,,\ y_t(\omega)\in B_t\,,\ z_t(\omega)\in C_t\right)={}\\[1pt]
{}=
\int\limits_X \int\limits_{B_1} \int\limits_{C_1}\ldots \\[1pt]
\ldots\int\limits_X \int\limits_{B_t} 
\int\limits_{C_t} \mu_0\left( dx_0\right) \sigma_1\left( dy_1\right) \nu_1\left( dz_1\vert 
x_0,y_1\right)\cdots{}\\[1pt]
\cdots \mu_{t-1}\left( dx_{t-1}\vert x^{t-2} y^{t-1}\right) \sigma_t \left( dy_t\vert y^{t-
1},z^{t-1}\right)\times{}\\[1pt]
{}\times \nu_t\left( dz_t\vert x^{t-1},y^t\right)={}\\[1pt]
{}=\int\limits_{B_1} \sigma_1\left( dy_1\right) \int\limits_{C_1} \int\limits_{B_2} 
\sigma_2\left( dy_2\vert z_1\right)\cdots\\[1pt]
\cdots \int\limits_{C_{t-1}}\int\limits_{B_t} \sigma_t \left( 
dy_t\vert y^{t-1},z^{t-1}\right)\times{}\\[1pt]
{}\times \int\limits_X \mu_0\left(dx_0\right) \nu_1\left( dz_1\vert 
x_o,y_1\right)\cdots{}\\[1pt]
{}\cdots \int\limits_{X_{t-1}}\mu_{t-1}\left( dx_{t-1}\vert x^{t-2} y^{t-1}\right) \nu_t \left( 
dz_t\vert x^{t-1}, y^t\right)={}\\[1pt]
{}=\int\limits_{B_1} \sigma_1\left( dy_1\right) \int\limits_{C_1} 
\int\limits_{B_2}\sigma_2\left( dy_2\vert z_1\right)\cdots\\[1pt]
\cdots \int\limits_{C_{t-1}} 
\int\limits_{B_t} \sigma_t\left( dy_t\vert y^{t-1},z^{t-1}\right) \int\limits_{C_t} 
\mathbf{P}\left( dz_1\vert y_1\right)\ldots{}\\[1pt]
{}\cdots \mathbf{P}\left( dz_{t-1}\vert y^{t-1},z^{t-2}\right) \mathbf{P}\left( dz_t\vert y^t, 
z^{t-1}\right)\,.
\end{multline*}
Отсюда получаем, что

\noindent
  \begin{multline*}
\hspace*{-6.95218pt}\mathbf{P}\left( dz_1\vert y_1\right)\cdots \mathbf{P}\left( dz_{t-1}\vert y^{t-1},z^{t-
2}\right) \mathbf{P}\left( dz_t\vert y^t,z^{t-1}\right)={}\\[1pt]
  {}=\int\limits_X \mu_0\left( dx_0\right) \nu_1\left( dz_1\vert x_o,y_1\right)\cdots \\[1pt]
  \cdots
\int\limits_X \mu_{t-1}\left( dx_{t-1}\vert x^{t-2}y^{t-1}\right) \nu_t\left( dz_t\vert x^{t-
1},y^t\right)\,.
  \end{multline*}
  
  Следовательно, по предположению индукции $\mathbf{P}\left( dz_t\vert y^t,z^{t-
1}\right)$ не зависит от~$\sigma$.
  
  Таким образом, не уменьшая общности, можно ограничиться (что и будет сделано в 
оставшейся части текста) рассмотрением полностью наблюда-\linebreak\vspace*{-12pt}

\pagebreak

\noindent
емых объектов $o\hm=\mu$, 
управляемых (допустимыми) стратегиями~$\sigma$ c правилами вида
  $$
  \sigma_1=\sigma_1\left(\cdot\right)\,;\enskip \sigma_{t+1}=\sigma_{t+1}\left( \cdot \vert 
y^t,x^t\right)\,,\enskip t>0\,.
  $$
(Множество всех таких стратегий при заданных пространствах состояний и управлений 
далее обозначается через~$\Sigma$.) В~этом случае вероятностная мера 
$\mathbf{P}\hm=\mathbf{P}_{\mu,\sigma}$ определена на пространстве $(\Omega, 
\mathbf{F})$, в котором $\Omega\hm=\prod\limits_{t\geq0} X^{t+1}\times Y^t$, 
$\mathbf{F}\mathop{\otimes}\limits_{t\geq0} \mathbf{F}_t$, где $\mathbf{F}_0\hm=\mathbf{X}$; 
$\mathbf{F}_t=\mathbf{X}\otimes \mathbf{Y}\otimes \mathbf{X}\otimes \cdots \otimes 
\mathbf{Y}\otimes \mathbf{X}$ и согласована с последовательностями~$\mu$ и~$\sigma$. 
Через $\mathbf{F}_t$ обозначена $\sigma$-ал\-геб\-ра, порожденная предысторией 
$(x^t,y^t)$ до момента~$t$ включительно.
  
  В то же время необходимо заметить, что предположение о наличии 
<<двухступенчатой>> структуры у объектов (со\-сто\-яние--наблю\-де\-ние) может 
принести пользу при их изучении. Так происходит, например, в теории частично 
наблюдаемых управляемых марковских процессов.
  
  Предположим далее, что на наблюдаемой части траектории процесса задан 
одношаговый доход (в момент~$t$), и будем считать, что этот доход имеет вид 
$g_t\hm=g(x_t)$, где $g:\ X\rightarrow (0,\,1)\subset \mathbb{R}$~--- измеримая числовая 
функция со значениями из интервала (0,\,1).
  
  Обозначим через $v_{t,s}\hm=s^{-1}\sum\limits_{n=1}^s g_{t+n}$ среднее 
арифметическое доходов на промежутке от $t+1$ до $t\hm+s$ ($t\hm\geq0$, $s\hm\geq 1$).
  
  Если объект~$\mu$ управляется согласно стратегии~$\sigma$, то число
  $$
  w_t(\mu,\sigma) =\sup \left\{ c:\ \mathbf{P}_{\mu,\sigma} \left( 
\lim\limits_{\overline{s\rightarrow\infty}} v_{t,s}>c\right) =1\right\}
  $$
характеризует получаемый при этом гарантированный предельный средний доход 
начиная с момента $t=1$. Поскольку $\lim\limits_{\overline{s\rightarrow\infty}} v_{t,s}$ не 
зависит от~$t$, то $w_0(\mu,\sigma)\hm=w_1(\mu,\sigma)\hm=w_2(\mu,\sigma)\hm=\cdots$. 
Величина $w(\mu,\sigma)\hm=w_0(\mu,\sigma)$ играет в дальнейшем роль целевой 
функции и называется просто \textit{доходом} (при управлении объектом~$\mu$ с 
помощью стратегии~$\sigma$).
  
  Из определения дохода следует, что для любого $t>0$ выполняется условие
  $$
  \mathbf{P}_{\mu,\sigma}\left( \lim\limits_{\overline{s\rightarrow\infty}} v_{t,s}\geq 
w(\mu,\sigma)\vert \mathbf{F}_{t-1}\right)=1
  $$
почти наверное.
  Столь общее определение дохода, без предположений об эргодичности, оказывается 
полезным в теоретических рассмотрениях, однако на практике все же среднее 
арифметическое ведет себя более или менее регулярным образом. Поэтому введем 
следующее определение.
{ %\looseness=1

}
  
  Стратегия~$\sigma$ называется \textit{эргодической} по отношению к классу~$M$, 
если для любого объекта $\mu\hm\in M$ и любого $\varepsilon\hm>0$ выполняется 
условие $\sum\limits_{s=1}^\infty a_s\hm<\infty$, где $a_s\hm= 
a_s(\mu,\sigma,\varepsilon)\hm=\sup\limits_{t\geq0} \mathbf{P}_{\mu,\sigma}\left( \left\vert 
v_{t,s}-w(\mu,\sigma)\right\vert >\varepsilon\vert \mathbf{F}_t\right)$. Обозначим еще
  $$
  W=W(\mu) =\sup\limits_\sigma w(\mu,\sigma)\,,
  $$
где точная верхняя грань берется по всем допустимым стратегиям. Стратегия~$\sigma$ 
называется $\varepsilon$-\textit{оп\-ти\-маль\-ной}, если выполняется неравенство
$$
w(\mu,\sigma)\geq W-\varepsilon\,,\enskip \varepsilon\geq 0\,.
$$
  
  Далее объекты будут объединяться в множества объектов (классы объектов). При этом 
без дополнительных оговорок всюду предполагается, что
  \begin{itemize}
  \item все объекты из класса имеют одинаковые пространства состояний, управлений (и 
наблюдений);
  \item в качестве множества допустимых стратегий берется определенное выше 
множество~$\Sigma$;
  \item функция одношаговых доходов~$g$ одна и та же для всех объектов.
  \end{itemize}
  
  Пусть $M$~--- класс объектов. Стратегия~$\sigma$ является равномерно 
  $\varepsilon$-оп\-ти\-маль\-ной относительно этого класса, если последнее неравенство 
выполняется для всех $\mu\hm\in M$. Такую стратегию будем называть также 
  $\varepsilon$-\textit{адап\-тив\-ной} по отношению к классу~$M$. Класс объектов, для 
которого существует $\varepsilon$-адап\-тив\-ная стратегия, называется 
  $\varepsilon$-\textit{адап\-тив\-но управ\-ля\-емым}. (Если $\varepsilon\hm=0$, то 
приставка <<$\varepsilon$->> в этих определениях опускается.)
  
  Основная задача адаптивного управления заключается в построении адаптивных 
стратегий для различных классов объектов. 

К~настоящему вре\-ме\-ни получено много 
решений для многочисленных вариантов этой задачи. Подобные результаты являются 
фактически достаточными условиями адаптивной управ\-ля\-емости. Ниже, однако, будет 
уделено внимание также необходимым условиям существования адаптивных стратегий. 
Подчеркнем, что рассматриваемая постановка задачи предполагает, по сути, наличие 
лишь минимальной априорной информации об объекте управления~--- необходимо знать 
множество управлений~$Y$.

\section{Некоторые условия адаптивной управляемости}

  Пусть $\mu\in M$~--- фиксированный объект, а $\sigma\hm\in \Sigma$~--- 
фиксированная стратегия из некоторой среды. Набор, состоящий из первых $t$ правил 
стратегии~$\sigma$, будем обозначать через $\sigma^t\hm=(\sigma_1, \ldots , \sigma_t)$. 
Таким образом, $\sigma\hm=(\sigma^t, \sigma_{t+1},\sigma_{t+2}, \ldots)$. Положим
  $$
  w_t^*(\mu,\sigma) =w_t^*(\mu,\sigma^t)=\sup\limits_{\sigma_{t+1},\sigma_{t+2}, \ldots} 
w_t(\mu,\sigma)\,,
  $$
где верхняя грань берется по всем допустимым правилам начиная с момента $t\hm+1$. В 
этих обозначениях $w_0^*(\mu,\sigma) \hm=W(\mu)$. Ясно, что $W(\mu)\hm\geq 
w_1^*(\mu,\sigma)\hm\geq w_2^*(\mu,\sigma)\geq \cdots$
  
  Стратегию~$\sigma$ назовем $\varepsilon$-\textit{по\-вреж\-да\-ющей} для 
объекта~$\mu$, если
  $$
  \inf\left\{ t:\ w_t^*(\mu,\sigma)<W(\mu)-\varepsilon\right\} <\infty\,,\enskip \varepsilon>0\,.
  $$
  
  Пример~1 показывает, что существуют объекты, для которых каждая стратегия~--- 
$\varepsilon$-по\-вреж\-да\-ющая (с разными значениями~$\varepsilon$).
  
  \medskip
  
  \noindent
  \textbf{Пример~1.} Множество~$X$ состояний объекта~$\mu$ образовано точками с 
неотрицательными целочисленными координатами на плоскости, $X\hm=\{ (i,j), 
i\hm\geq0,\ j\hm\geq0\}$. Множество управлений $Y\hm=\{1;2\}$. Начальное состояние 
$x_0=(0,\,0)$. Детерминированные переходы между состояниями заданы следующим 
образом ($t\hm>0$, $i\hm\geq0$):
  \begin{align*}
  \mu_t\left( x_t=(i+1{,}0)\vert x_{t-1}=(i,0),y_t=1\right)&=1\,;\\
  \mu_t\left( x_t=(i,j+1)\vert x_{t-1}=(i,j),y_t=1\right)&=1\,,\ j>0\,;\\
  \mu_t\left( x_t=(i,j+1)\vert x_{t-1}=(i,j),y_t=2\right)&=1\,, j\geq 0\,.
  \end{align*}
  
  Одношаговые доходы определены как $g(i,0)\hm=0$, $g(i,j)\hm=1-2^{-i}$ для $i\geq 0$, 
$j\hm>0$.
  
  Стратегия, состоящая из бесконечного повторения управления~1, приносит доход~0. 
Стратегия, в которой управление~2 первый раз применяется (детерминировано) в 
момент~$t$, приносит доход $1\hm-2^{t-1}$, что меньше максимально возможного 
на~$2^{t-1}$. Рандомизация правил и их зависимость от предыстории не вносит 
принципиальных изменений~--- каждая стратегия остается 
  $\varepsilon$-по\-вреж\-да\-ющей относительно предельно наибольшего, но 
недостижимого значения~1.
  
  В примере~2 оптимальная стратегия для любого объекта из класса является 
повреждающей для остальных объектов.
  
  \medskip
  
  \noindent
  \textbf{Пример~2.} Пусть $X\hm= \{0, 1, 2, \ldots\}\cup \{a,b\}$; $Y\hm=\{0;\,1\}$; 
$g(a)\hm=1$; $g(b)\hm=g(i)\hm=0$, $i\hm\geq0$. Зададим счетное множество объектов 
$M\hm=\{\mu^{(k)},\ k\hm=0, 1, \ldots\}$. Пусть для всех~$k$:
  \begin{align*}
  \mu^{(k)}(x_0=0)&=1\,;\\
  \mu^{(k)}(x_{t+1}=i+1\vert x_t=i, y_t=0)&=1\,,\enskip i\geq0\,;\\
     \mu^{(k)}(x_{t+1}=a\vert x_t=k,y_t=1)&=1\,;\\
     \mu^{(k)}(x_{t+1}=b\vert x_t=i,y_t=1) &=1\,,\enskip i\not=k\,;\\
     \mu^{(k)}(x_{t+1}=a\vert x_t=a,y_t=j)&={}\\
&\hspace*{-45mm}{}=\mu^{(k)}(x_{t+1}=b\vert 
x_t=b,y_t=j)=1\,,\enskip j=0\vee 1\,.
     \end{align*}
  
  Таким образом, состояния $a$ и $b$~--- погло\-ща\-ющие, причем в состояние~$a$, 
приносящее максимальный доход, объект~$\mu^{(k)}$ может попасть, только если 
применить управление~1, находясь в со\-сто\-янии~$k$. Первые (существенные) правила 
оптимальной стратегии для объекта~$\mu^{(k)}$ требуют применения управления~0 до 
достижения состояния~$k$, а затем применения в этом состоянии управления~1. Однако 
такая стратегия является повреждающей для всех остальных объектов. Следовательно, для 
класса~$M$ не существует равномерно оптимальной стра\-тегии.
{\looseness=1

}
  
  Пусть $M$~--- класс объектов. Обозначим через $\Sigma_\varepsilon(\mu)$ множество 
$\varepsilon$-по\-вреж\-да\-ющих стратегий для объекта~$\mu$, $\mu\hm\in M$. Положим 
$\Sigma_\varepsilon(M)\bigcap\limits_{\mu\in M}\left( \Sigma\backslash 
\Sigma_\varepsilon(\mu)\right)$.
  
  \medskip
  
  \noindent
  \textbf{Лемма~2.} \textit{Для того чтобы существовала $\varepsilon$-адап\-тив\-ная 
стратегия, необходимо, чтобы $\Sigma_\varepsilon(M)\not=\emptyset$.}
  \medskip
  
  \noindent
  Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ Если $\Sigma_\varepsilon\not= \emptyset$, то любая 
допустимая стратегия хотя бы для одного из объектов является 
  $\varepsilon$-по\-вреж\-да\-ющей и, следовательно, не является 
  $\varepsilon$-оп\-ти\-маль\-ной, а потому не может быть равномерно 
  $\varepsilon$-оп\-ти\-маль\-ной по отношению к классу~$M$.
  
  В примере~3, несмотря на наличие по\-вреж\-да\-ющих стратегий, адаптивная стратегия 
существует.
  
  \medskip
  
  \noindent
  \textbf{Пример~3.} Пусть $X\hm=Y\hm=\{1, \ldots , K\}$ и пусть задана 
детерминированная функция~$f:\ X\hm\rightarrow X$, которая представляет собой 
циклическую подстановку на множестве~$X$,  т.\,е.\ $f(i)\not= f(j)$, если $i\not= j$; 
$i,j\hm=1, \ldots , K$. Рассмотрим следующий неоднородный во времени 
детерминированный объект. Положим
  \begin{align*}
  \mu_0(x_0=1)&=1\,;\\
  \mu_t(x_t=f(k)\vert x^{t-1},y^t) &= I_{\{y_t=k\}}\,,\ 0<k\,,\ t\leq K\,;\\
  \mu_t(x_t=f(k)\vert x^{t-1},y^t) &=I_{\{y_{K+1}=k}\,,\\
  & \hspace*{10mm}0<k\leq K\,,\enskip t>K
  \end{align*}
($I_A$~--- индикатор события~$A$).
  
  Одношаговые доходы определим как $g(i)\hm=i$, $i\hm\in X$.
  
  Так определенный объект обозначим через~$\mu^f$. Ясно, что для этого объекта 
траектория управ\-ля\-емо\-го процесса, начиная с момента $K+1$, и, следовательно, доход 
зависят исключительно от управ\-ле\-ния, примененного в момент $K+1$. Доход будет 
максимален (и равен~$K$) тогда и только тогда, когда $y_{K+1}\hm= k^\prime \hm= 
k^*(f)\hm=\argmax\limits_{1\leq k\leq K} f(k)$.
  
  Пусть $M=\{\mu^f\}$~--- совокупность всех объектов данного вида (которая содержит 
$K!$ элементов). Очевидно, для класса~$M$ существует равномерно оптимальная 
стратегия, доставляющая доход, равный~$K$. Например, достаточно вначале в моменты 
$t\hm=1, \ldots , K$ по одному разу применить каждое из управлений, а затем в момент 
$K+1$ применить управление~$k^*$, которое будет выявлено путем наблюдения за 
полученными одношаговыми доходами. Таким образом, на первых тактах необходимо совершить 
<<обучение>>~--- выявить управление, приносящее наибольший одношаговый доход. 
В~то же время существуют и повреждающие стратегии. Например, стратегия, в которой 
первые $K$ правил заключаются в применении управления~1. Правило~$\sigma_{K+1}$ 
такой стратегии может быть построено только в виде зависимости от управления~1 и от 
значения $f(1)$, поэтому при любом его определении найдется объект~$\mu^f$, для 
которого в момент $K+1$ будет с положительной вероятностью предписано применение 
неоптимального управления, и, следовательно, доход будет меньше~$K$.
  
  В примере 3 <<обучение>> оказалось возможным только благодаря знанию структуры 
процессов. Если бы заранее не было известно, что необходимо на первых тактах по разу 
<<испробовать>> все управ\-ле\-ния, то легко можно было пропустить период, когда 
возможно обучение, и совершить тем самым <<непоправимую ошибку>>. Следовательно, 
для того чтобы конструктивно построить равномерно оптимальную стратегию, 
необходима дополнительная информация. Это противоречит избранному принципу 
постановки задачи~--- минимальности априорной информации об объекте. 

Введем более 
жесткое определение адаптивной стратегии, которое, в част\-ности, устраняет указанное 
несоответствие.
  
  Пусть $M$~--- некоторый класс объектов. Эргодическая стратегия~$\sigma$ (ее 
определение дано в конце разд.~2) называется \textit{устойчивой} по отношению к 
классу~$M$, если для любого объекта $\mu\hm\in M$ стратегия~$\tilde{\sigma}$, 
полученная из стратегии~$\sigma$ путем произвольной (допустимой) замены конечного 
числа правил, (1)~имеет одинаковый со стратегией доход 
$w(\mu,\sigma)\hm=w(\mu,\tilde{\sigma})$ и (2)~является эргодической по отношению к 
классу~$M$.

%\columnbreak
  
  Адаптивная стратегия для класса~$M$ называется \textit{строго адаптивной}, если она 
устойчивая по отношению к этому классу.
  
  \medskip
  
  \noindent
  \textbf{Пример~4.} Легко показать, что строго адаптивными являются 
многочисленные адаптивные стратегии для класса управляемых конечных связных 
марковских цепей~[1, 2].
  
  Рассмотрим еще один мотив, выдвигаемый в качестве необходимого условия 
адаптивной управ\-ля\-емости.
  
  \medskip
  
  \noindent
  \textbf{Пример~5.} Пусть класс объектов состоит из функций вещественного 
аргумента~$u$ вида $\mu^y\hm=\mu^y(u)\hm=I_{\{u=y\}}$, $y\hm\in [0,\,1]$. (В~терминах 
управляемых случайных последовательностей: $X\hm= \{0;1]\}$, $Y\hm=[0,1]$; 
$\mu_t(x_t\vert x^{t-1},y^t)\hm=x_t I_{\{y_t=y\}}+ (1-x_t)I_{\{y_t=y\}}$; $g(x)\hm=x$, 
$x\hm\in X$.) Интуитивно представляется очевидным, что невозможно найти максимум 
такой функции за счетное число шагов, если не знать значение, в котором она обращается 
в единицу. В~то же время формально для каждого объекта~$\mu^y$ существует 
оптимальная стратегия. Например, можно постоянно повторять управление~$y$. Однако 
не существует стратегии, равномерно оптимальной по отношению к классу 
$M\hm=\{\mu^y\}$. В~такой стратегии для каждого $y\hm\in [0,\,1]$ необходимо должно 
было бы выполняться следующее условие: $\sigma_t(y_t=y\vert \cdot)>0$ хотя бы для 
одного значения~$t$. Но это невозможно, поскольку для фиксированного значения~$t$ 
данное неравенство может быть выполнено лишь для счетного множества значений~$y$, а 
$t$ также пробегает счетное множество значений. Счетное объединение счетных 
множеств само счетно, поэтому необходимое неравенство не может быть выполнено для 
всех точек на отрезке [0,\,1].
  
  Аналогичные рассуждения показывают, что в данном примере не существует счетного 
множества стратегий, обладающего тем свойством, что для любого объекта найдется 
$\varepsilon$-оп\-ти\-маль\-ная стратегия из этого множества.
  
  Конечное или счетное множество стратегий $\Sigma\hm=\{\sigma(1),\sigma(2), \ldots \}$ 
назовем \textit{базовым} по отношению к классу объектов $M\hm\in \mathcal{M}$, если:
  \begin{enumerate}[(1)]
  \item для любого объекта из $M$ и любого $\varepsilon\hm>0$ существует оптимальная 
стратегия из множества~$\Sigma$;
  \item любая стратегия $\sigma(i)$ является устойчивой по отношению к классу~$M$.
  \end{enumerate}
  
  \smallskip
  
  \noindent
  \textbf{Теорема.} \textit{Строго адаптивная стратегия для класса объектов~$M$ 
существует тогда и только тогда, когда для этого класса существует базовое 
множество стратегий~$\Sigma$.}


%\hfill {\large Приложение~1}

\bigskip

%\pagebreak

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\ \ теоремы.

Необходимость условий в данном случае является тривиальной, поскольку строго 
адаптивная стратегия, если она существует, образует базовое множество 
стратегий~$\Sigma$, состоящее из одного элемента.
  
  Докажем достаточность. Определим с по\-мощью стратегий из~$\Sigma$ новую 
стратегию $a$ следующим образом. Обозначим
  $$
  \theta_{t,n}=\mathrm{Int}\left(\left( 1-v_{t,n}\right)^{-n}\right)\,,
  $$
где $\mathrm{Int}\left(a\right)$ означает целую часть числа~$a$, и зададим 
последовательность марковских моментов $\tau\hm=\{\tau_n\}$ с помощью рекуррентных 
соотношений

\pagebreak

\noindent
$$
\tau_0=0\,,\enskip \tau_n=\tau_{n-1}+n+\theta_n\,,
$$
где $\theta_n\hm=\theta_{\tau_{n-1},n}$. Соответствующие $\sigma$-ал\-геб\-ры обозначим 
$\mathbf{F}_{(n)}\hm=\mathbf{F}_{\tau_{n-1}}$.
  
  Будем считать, что на пространстве $(\Omega,\mathbf{F})$ задана последовательность 
случайных величин $\beta\hm=\{\beta_n\}$, независимых 
относительно~$\mathbf{F}_{(n)}$. Каждая случайная величина имеет одно и то же 
невырожденное распределение $\{b_i\}$ на множестве номеров стратегий из~$\Sigma$.
  
  Определим правила стратегии $a\hm=a(\Sigma,\beta)$ формулой
  $$
  a_t=\sum\limits_{n=1}^\infty \sigma_t(\beta_n) I_{\{\tau_{n-1}<t\leq \tau_n\}}\,,
  $$
где $\sigma_t(\beta_n)$~--- правило стратегии $\sigma(i)\hm\in\Sigma$ в момент~$t$, если 
$\beta_n\hm=i$.
  
  Наглядно работа стратегии~$a$ выглядит следующим образом. Процесс управления 
разбивается на этапы. Этап с номером $n$ начинается в момент $\tau_{n-1}+1$ и 
оканчивается в момент~$\tau_n;\tau_0\hm=0$. В~момент, предшествующий началу 
очередного этапа, определяется номер стратегии в множестве~$\Sigma$, из которой будут 
взяты правила для применения на данном этапе. Этот номер равен значению случайной 
величины~$\beta_n$. Продолжительность $n$-го этапа равна $n\hm+\theta_n$ и зависит, 
следовательно, от номера этапа и от оценки качества применяемой стратегии, полученной 
в течение первых $n$ тактов этапа. Стратегия~$a$ называется стратегией перебора~[2]. 
Таким образом, последовательность~$\beta$ определяет на каждом этапе выбор стратегии 
из множества~$\Sigma$, правила из которой применяются на этом этапе.
  
  Пусть задан объект $\mu\hm\in M$ и пусть $W\hm=W(\mu)$~--- точная верхняя грань 
доходов для этого объекта, взятая по всем допустимым стратегиям, и пусть %также
  \begin{alignat*}{2}
  W_i&=w(\mu,\sigma(i))\,; &\enskip v_n^{(1)}&=v_{\tau_{n-1},n}\,;\\
  v_n^{(2)}&=v_{\tau_{n-1},n+\theta_n}\,; &\enskip \Delta_n&=\tau_n-\tau_{n-1}=n+\theta_n\,.
  \end{alignat*}
  
  Для произвольного $\varepsilon>0$ определим множества
  $$
  A_n^{(k)}(\varepsilon)=\left\{ v_n^{(k)}\geq W-\varepsilon\right\}\,,
  $$
обозначая их дополнения $\overline{A_n^{(k)}(\varepsilon)}$, $k=1, 2$.
  
  Обозначим
  \begin{align*}
  s_n^{(1)} &= \sum\limits_{l=1}^n I_{A_l^{(1)}(\varepsilon)\cap 
{A_l^{(2)}(2\varepsilon)}} \Delta_l\,;\\
  s_n^{(2)} &= \sum\limits_{l=1}^n I_{A_l^{(1)}\cap 
\overline{A_l^{(2)}(2\varepsilon)}}\Delta_l\,;\\
  s_n^{(3)} &= \sum\limits_{l=1}^n I_{\overline{A_l^{(1)}(\varepsilon)}}\Delta_l\,,
  \end{align*}
так что $\tau_n\hm=\sum\limits_{l=1}^n \Delta_l\hm= s_n^{(1)}\hm+ s_n^{(2)}\hm+ 
s_n^{(3)}$.

\columnbreak

  
  С~помощью введенных обозначений запишем оценку для усредненного дохода к 
моменту~$\tau_n$:
  \begin{multline}
  w_n=\fr{1}{\tau_n}\sum\limits_{t=1}^{\tau_n} g_t=\fr{\sum\limits_{l=1}^n 
v_l^{(2)}\Delta_l} {\sum\limits_{l=1}^n \Delta_l}\geq{}\\
{}\geq (W-2\varepsilon) \fr{s_n^{(1)}} 
{s_n^{(1)}+s_n^{(2)}+s_n^{(3)}}\,.
  \label{e1-kon}
  \end{multline}
  
  Для оценки суммы $s_n^{(1)}$ запишем неравенство
  $$
  s_n^{(1)}\geq \Delta_{v_n}\,,
  $$
в котором обозначено
$$
v_n=\max\left\{ l:\ l\leq n,\ A_l^{(1)}(\varepsilon)\cap A_l^{(2)}(2\varepsilon)\right\}\,.
$$
  
  Оценим вероятность события $B_n\hm=\{v_n\hm\leq n-\ln n\}$, для которого выполняется 
включение
  $$
  B_n\subset \bigcap\limits_{n-\ln n<l\leq n} 
  \overline{A_l^{(1)}(\varepsilon)}\cap \overline{A_l^{(2)}(2\varepsilon)}\,.
  $$
  
  Согласно определениям эргодической стратегии, базового множества стратегий и 
семейства случайных величин~$\beta$ имеем:
  \begin{multline*}
  \mathbf{P}_{a} \left( \overline{A_l^{(1)}(\varepsilon)}\cup\overline{A_l^{(2)} 
(2\varepsilon)}\,\Big\vert \mathbf{F}_{(l)}\right)\leq{}\\
  {}\leq
  \sum\limits_{\substack{{i\in \mathcal{I};}\\ {W_i\leq W-\varepsilon/2}}}\!\!\!\!
   \mathbf{P}_{a}\left(\beta_l=i\vert 
\mathbf{F}_{(l)}\right)+{}\\
{}+  %\substack{{i=\overline{1,n}}\\ {j=\overline{1,l}}}
\sum\limits_{\substack{{i\in \mathcal{I};}\\ {W_i\leq W-\varepsilon/2}}}\!\!\!\!
\mathbf{P}_{a}\left( \overline{A_l^{(1)}(\varepsilon)}, \ \beta_l=i
\vert \mathbf{F}_{(l)}\right)\leq{}\\
  {}\leq \sum\limits_{\substack{{i\in \mathcal{I};}\\ {W_i\leq W-\varepsilon/2}}}\!\!\!\!
  \mathrm{P}_{a}(\beta_l=i)+{}\\
{}+\sum\limits_{\substack{{i\in \mathcal{I};}\\ {W_i> W-
\varepsilon/2}}}
\!\!\!\!\mathbf{P}_{a}\left( v_l^{(1)}\leq W_i-\fr{\varepsilon}{2}, \beta_l=i\vert 
\mathbf{F}_{(l)}\right) \leq{}\\
  {}\leq \sum\limits_{\substack{{i\in \mathcal{I};}\\ {W_i\leq W-\varepsilon/2}}}\!\!\!\!
   b_i+a_l\left( 
\fr{\varepsilon}{2}\right) \leq q<1
  \end{multline*}
при всех достаточно больших~$l$. Отсюда следует, что для всех достаточно больших 
значений~$n$ выполняется неравенство
$$
\mathbf{P}_a(B_n)\leq q^{n-\ln n}\,.
$$
  
  Следовательно, согласно лемме Бо\-ре\-ля--Кан\-тел\-ли
  \begin{equation}
  \mathbf{P}_{a}\left( \overline{\lim\limits_{n\rightarrow\infty}} B_n\right)=0\,.
  \label{e2-kon}
  \end{equation}
  
  Это означает, что
  $$
  s_n^{(1)}\geq \Delta_{v_n}\geq (1-W-\varepsilon)^{-n+\ln n}\,.
  $$
  
  Оценим сумму $s_n^{(2)}$. Обозначив 
$C_n\hm=A_n^{(1)}(\varepsilon)\cap$\linebreak 
$\cap\overline{A_n^{(2)}(2\varepsilon)}$ и $W_{(n)}\hm=\sum\limits_{i\in 
I} W_i I_{\{\beta_n=i\}}$, получим:
  \begin{multline*}
  \mathrm{P}_{a}\left(C_n\vert \mathrm{ F}_{(n)}\right)=
  \mathrm{P}_{a|} \left( C_n, W_{(n)}<W-\fr{3\varepsilon}{2}\vert \mathrm{
  F}_{(n)}\right) +{}\\
  {}+ \mathrm{P}_{a}\left( 
  C_n, W_{(n)}\geq W-\fr{3\varepsilon}{2}\vert \mathrm{
  F}_{(n)}\right)\leq{}\\
  {}\leq \mathrm{P}_{a}\left( v_n^{(1)}>W-\varepsilon,\, W_{(n)}<W-\fr{3\varepsilon}{2}\vert \mathrm{
  F}_{(n)}\right)+{}\\
  {}+
  \mathrm{P}_{a} \left( v_n^{(2)}\leq W-2\varepsilon,\, W_{(n)}\geq W-
\fr{3\varepsilon}{2}\vert \mathrm{
  F}_{(n)}\right)\leq{}\\
  {}\leq \sum\limits_{i\in \mathcal{I}; W_i\leq W- \varepsilon/2} \mathrm{P}_{a}\left(
  v_{\tau_n,n}>W_i+\fr{\varepsilon}{2},\, \beta_l=i\vert\mathrm{F}_{(n)}\right)+{}\\
  {}+\sum\limits_{\substack{{i\in \mathcal{I};}\\ {W_i> W- 3\varepsilon/2}}}\!\!\!\!
   \mathbf{P}_{a} \left( 
v_{\tau_n,n+\theta_n}\leq W_i-\fr{\varepsilon}{2},\,\beta_l=i\vert\mathbf{F}_{(n)}\right)\leq {}\\
{}\leq
a_n\left( \fr{\varepsilon}{2}\right)\,.
  \end{multline*}
  
  Из определения базового множества стратегий следует, что
  $$
  \sum\limits_{n=1}^\infty \mathbf{P}_{a} (C_n)<\infty\,,
  $$
поэтому согласно лемме Бо\-ре\-ля--Кан\-тел\-ли полу\-чаем:
\begin{equation}
\mathbf{P}_{a}\left( \overline{\lim\limits_{n\rightarrow\infty}} C_n\right) =0\,.
\label{e3-kon}
\end{equation}
  
  Отсюда следует, что
  $$
  \sup\limits_n s_n^{(2)}\leq c<\infty\,.
  $$
  
  Для суммы $s_n^{(3)}$ имеем следующую оценку:
  $$
  s_n^{(3)}\geq \sum\limits_{l=1}^n \left(n+(1-W+\varepsilon)^{-l}\right)< n^2+n(1-
W+\varepsilon)^{-n}.
  $$
  
  Подставляя оценки, полученные для сумм $s_n^{(k)}$, в неравенство~(\ref{e1-kon}), 
получаем:
  \begin{multline*}
  w_n\geq (W-\varepsilon) \left( 1+\fr{s_n^{(2)}+s_n^{(3)}}{s_n^{(1)}}\right)^{-1}\geq 
{}\\
  {}\geq (W-\varepsilon)\left( 1+\fr{c+n^2+n(1-W+\varepsilon)^{-n}}{(1-W-\varepsilon/2)^{-
n+\ln n}}\right)^{-1}\geq{}\\
{}\geq W-3\varepsilon
  \end{multline*}
для всех достаточно больших значений~$n$. Отсюда
\begin{equation}
\lim\limits_{\overline{n\rightarrow\infty}} w_n\geq W\,.
\label{e4-kon}
\end{equation}
  
  Рассмотрим далее множество
  $$
  \Omega^\prime =\left\{ \lim\limits_{n\rightarrow\infty} w_n =W\right\}\cap 
\overline{B}\cap\overline{C}\,,
  $$
где $\overline{B}$ и $\overline{C}$ означают соответственно дополнения к множествам 
$B\hm= \overline{\lim\limits_{n\rightarrow\infty}} B_n$ и $C\hm= 
\overline{\lim\limits_{n\rightarrow\infty}} C_n$.
  
  Согласно формулам~(\ref{e2-kon})--(\ref{e4-kon})
  $$
  \mathbf{P}_{a}\left(\Omega^\prime\right) =1\,.
  $$
  
  Определим следующие события:
  
  \noindent
  \begin{align*}
  D_{n,t}^{(1)} &= \left\{ \tau_{n-1}<t\leq \tau_{n-1}+n\right\} \cap \Omega^\prime\,;\\
  D_{n,t}^{(2)} &= \left\{\tau_{n-1}+n<t\leq \tau_n\right\}\cap \Omega^\prime\,;\\
  D_{n,t}^{(3)} &= \left\{ \tau_{n-1}<t\leq \tau_n\right\} \cap \Omega^\prime\,.
  \end{align*}
  
  На множестве $D_{n,t}^{(1)}$ усредненный доход $v_t\hm=v_{0,t}\hm=
  t^{-1}\sum\limits_{s=1}^t g_s$ оценивается с помощью формулы~(\ref{e1-kon}) как
  
    \noindent
  $$
  v_t\geq \fr{\tau_{n-1} w_n}{\tau_{n-1}+n+\theta_n}\geq W-\varepsilon_n^{(1)}\,,
  $$
где $\varepsilon_n^{(1)}\hm\rightarrow0$ при $n\hm\rightarrow\infty$.
  
  Пусть событие $D_{n,t}^{(2)}$ имеет место. Тогда $\theta_n\geq (1\hm- 
W\hm+\varepsilon)^{-n}$. Кроме того, из определения событий $B_n$, $B$, 
$D_{n,t}^{(2)}$ следует, что для всех достаточно больших значений~$n$ выполняется 
неравенство $v_n\hm> n-\ln n$. Следовательно, на множестве~$D_n^{(2)}$ справедлива 
оценка

  \noindent
  $$
  v_t\geq \fr{\tau_{n-1} w_n}{\tau_{n-1}+n+\theta_n}\geq W-\varepsilon_n^{(2)}\,,
  $$
где $\varepsilon_n^{(2)}\hm\rightarrow0$ при $n\hm\rightarrow\infty$.
  
  Из определения событий $C_n$, $C$, $D_{n,t}^{(3)}$ вытекает, что
  
    \noindent
  $$
  D_{n,t}^{(3)} \subset \left\{ \min\limits_{n<m\leq n+\theta_n} v_{n,m}\geq W-
2\varepsilon\right\}\,,
  $$
поэтому на множестве $D_n^{(3)}$ справедливы неравенства:

  \noindent
\begin{multline*}
\!\!v_t\geq \fr{\tau_{n-1} w_n}{t}+\left(1- \fr{\tau_{n-1}}{t}\right) \left( 1-\tau_n\right)^{-1} 
\!\!\sum\limits_{s=\tau_{n-1}+1}^t \!\!\!\!g_s\geq{}\\
{}\geq \fr{\tau_{n-1} w_n}{t}+\left( 1-\fr{\tau_{n-1}}{t}\right)\left( W-2\varepsilon\right) \geq 
W-2\varepsilon -\varepsilon_n^{(3)},
\end{multline*}
где $\varepsilon_n^{(3)}\rightarrow0$ при $n\hm\rightarrow\infty$.

\pagebreak
  
  Таким образом, на множестве
  $$
  D_{n,t}=\bigcup\limits_{k=1}^3 D_{n,t}^{(k)} = \left\{ \tau_{n-1}<t\leq \tau_n\right\} \cap 
\Omega^\prime
  $$
имеет место оценка $v_n\hm\geq W-\varepsilon-\varepsilon_n$, где 
$\varepsilon_n\hm\rightarrow 0$ при $n\hm\rightarrow\infty$. Достаточность утверждения 
теоремы следует из соотношений $\Omega\hm= \bigcup\limits_{n=1}^\infty \left\{ \tau_{n-
1}\hm<t\hm\leq \tau_n\right\}$ и $\lim\limits_{t\rightarrow\infty} I_{D_{n,t}}\hm=0$.

\section{Заключение}

  Адаптивные стратегии, позволяющие достигать цели в условиях информационной 
неопреде\-лен\-ности, основываясь на <<обучении>> в процессе взаимодействия с объектом, 
находят все более широкое практическое применение. 

В~этой работе было уделено 
внимание теоретическим аспектам адаптивного подхода. Сформулированы определения 
адаптивных стратегий и приведена формальная постановка задачи адаптивного 
управления. Сформулированы и доказаны некоторые утверждения о необходимых 
условиях и достаточных условиях адап\-тив\-ной управляемости. 

Продолжение исследований 
в данном на\-прав\-ле\-нии позволит найти ответы на принципиальные вопросы, в каких 
ситуациях можно рассчитывать на <<приспособление к неизвестной среде>> и сколь 
универсальными могут быть <<обучающиеся>> алгоритмы.



{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{9}


  \bibitem{1-kon}
  \Au{Sragovich~V.\,G.}
  Mathematical theory of adaptive control.~--- Singapore: World Scientific, 2006.
  \bibitem{2-kon}
  \Au{Коновалов~М.\,Г.}
  Методы адаптивной обработки информации и их приложения.~--- М.: ИПИ РАН, 2007.
  
  \label{end\stat}
  
  \bibitem{3-kon}
  \Au{Неве~Ж.}
  Математические основы теории вероятностей.~--- М.: Мир, 1969.
\end{thebibliography}
}
}


\end{multicols}