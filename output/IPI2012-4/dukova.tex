\def\stat{dukova}

\def\tit{ОБ ОПТИМАЛЬНОМ КОРРЕКТНОМ ПЕРЕКОДИРОВАНИИ ЦЕЛОЧИСЛЕННЫХ ДАННЫХ В~РАСПОЗНАВАНИИ$^*$}

\def\titkol{Об оптимальном корректном перекодировании целочисленных 
данных в~распознавании}

\def\autkol{Е.\,В.~Дюкова, А.\,В.~Сизов, Р.\,М.~Сотнезов}

\def\aut{Е.\,В.~Дюкова$^1$, А.\,В.~Сизов$^2$, Р.\,М.~Сотнезов$^3$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1]
{Работа выполнена при финансовой поддержке РФФИ
(проект №~10-01-00770) и гранта Президента РФ по поддержке ведущих
научных школ НШ-7950.2010.1.}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Вычислительный центр Российской академии
наук им.\ А.\,А.~Дородницына, edjukova@mail.ru}
\footnotetext[2]{Московский государственный университет
им.~М.\,В.~Ломоносова, box.sizov@gmail.com}
\footnotetext[3]{Вычислительный центр Российской академии
наук им.~А.\,А.~Дородницына, rom.sot@gmail.com}


\Abst{Исследуются вопросы применения
логических процедур распознавания по прецедентам в случае
вещественнозначной информации и целочисленной информации высокой
значности. Рас\-смот\-ре\-на задача корректного понижения значности
данных. Разработаны генетические алгоритмы поиска оптимальной
корректной перекодировки исходной информации. Проведено тестирование
алгоритмов на реальных данных.}

\KW{распознавание образов; корректная
перекодировка; покрытие булевой матрицы}

\vspace*{6pt}


\vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}

\section{Введение}

Один из подходов к решению задачи распознавания по прецедентам
сводится к комбинаторному (логическому) анализу исходных признаковых
описаний объектов. При данном подходе для каждого признака
определяется бинарная функция близости между его значениями,
позволяющая различать объекты и их подописания. Особенно эффективен
комбинаторный подход в случае целочисленной информации низкой
значности, например бинарной. Поэтому актуальной является задача
корректного понижения значности исходных данных.

Пусть $\{x_1,\ldots ,x_n\}$~--- сис\-те\-ма признаков и $\epsilon_j,
\epsilon_j\hm\geq0,$~---  точность измерения признака $x_j$, $j \in
\{1,2,\ldots ,n\}$. Пусть далее $S_{i_1}\hm=(a_{i_11},\ldots ,a_{i_1n})$ и
$S_{i_2}\hm=(a_{i_21}, \ldots ,a_{i_2n})$~--- обучающие объекты (здесь
$a_{i_tj}$~--- значение признака $x_j$ для объекта $S_{i_t}$, $t \hm\in
\{1,2\}$, $j\hm=1,2,\ldots ,n$). Положим
$$
    \delta_j(S_{i_1},S_{i_2})=
    \begin{cases}
        1, &  \mbox{если }|a_{i_1j}-a_{i_2j}|\leq\epsilon_j\,;  \\
        0 &  \mbox{иначе}\,.
    \end{cases}
$$
Функция $\delta_j(S_{i_1},S_{i_2})$ называется функцией бли\-зости
объектов $S_{i_1}$ и $S_{i_2}$ по признаку $x_j$. Предполагается,
что обучающие объекты из разных классов имеют разные описания, т.\,е.\
для любых $S_{i_1}$ и $S_{i_2}$, принадлежащих разным классам,
существует хотя бы один признак $x_j$ такой, что
$\delta_j(S_{i_1},S_{i_2})\hm=1$. В~случае бинарной информации полагают
$\epsilon_j\hm=0$, $j\hm\in\{1,2,\ldots ,n\}$.

Один из способов понижения значности данных состоит в преобразовании
исходной выборки путем разбиения множества значений каждого признака
на интервалы порогами. Значения признаков, попавших в один интервал,
считаются близкими и кодируются одним числом. Однако при
произвольном выборе порогов обучающие объекты, принадлежащие разным
классам, могут стать неразличимыми. При данном способе
преобразования информации важным является понятие корректной
перекодировки данных, т.\,е.\ такого преобразования обучающей
информации, при котором объекты из разных классов остаются
различимыми.

Ю.\,И.~Журавлевым предложена методика корректного перекодирования
исходных данных. Показано, что задача построения корректной
перекодировки может быть сведена к построению специаль\-но\-го вида
покрытия булевой матрицы, которая строится по обучающей выборке. 

В~\cite{a1,a2} предложен подход, позволяющий выбирать наилучшую в
смысле качества распознавания корректную перекодировку. Недостаток
подхода~--- его большая вычислительная сложность.

Целью данной работы является развитие методов корректного
перекодирования данных и снижение вычислительной сложности этих
методов. В~работе предложены более эффективные способы оценки
качества перекодировок. Для сокращения перебора при поиске
оптимальной корректной перекодировки использован генетический
подход. Приведены результаты тестирования генетических алгоритмов
поиска оптимальной корректной перекодировки на реальных прикладных
задачах из репозитория системы <<Распознавание>>, описанной в~$\cite{a3}$.

\section{Основные обозначения}

Рассмотрим задачу распознавания по прецедентам с двумя
непересекающимися классами $K_{1} $ и $K_{2}$~\cite{a4}. Пусть
$T=(a_{ij })_{m \times n}$~--- обучающая таб\-ли\-ца, $a_{ij} \hm\in
\mathbb{R}$, $\mathbb{R}$~--- множество действительных чисел.
Столбцам таблицы $T$ соответствуют признаки $x_1,x_2, \ldots ,x_n$, а
каждая строка является набором значений признаков, описывающим один
из обучающих объектов. Предполагается, что в таблице~$T$ нет
столбцов, состоящих из одинаковых чисел.

Пусть $S_{i_1}$ и $S_{i_2}$~--- обучающие объекты, принадлежащие
разным классам, $j\hm\in \{1,2,\ldots ,n\}$.

\smallskip

\noindent
\textbf{Определение 1.} Число $(a_{i_{2}j} + {a_{i_{1}j}})/2$
назовем порогом для признака $x_j$, если в $T$ не существует
элемента $a_{ij}$ такого, что $a_{ij} \in (a_{i_{1}j}, a_{i_{2}j})$.

\smallskip

Через $D^{(j)}$ обозначим множество всех порогов для признака $x_j$,
$j\in \{1,2,\ldots ,n\}$. Суммой двух элементов $a_{i_{1}j}$ и
$a_{i_{2}j}$ таб\-ли\-цы~$T$ по порогу $d \hm\in D^{(j)}$,
$j\hm\in\{1,2,\ldots ,n\}$, назовем число $(a_{i_1j}\oplus a_{i_2j}|_d)$,
равное~1, если $a_{i_{1}j}$ и $a_{i_{2}j}$ лежат по разные стороны
от порога~$d$, и равное~0 в противном случае. Пусть
$D^{(j)}\hm=\{d^{(j)}_1,\ldots ,d^{(j)}_{u_j}\}$.

Через $\prod$ будем обозначать последовательность всех порогов
$d^{(1)}_1,\ldots ,d^{(1)}_{u_1}, d^{(2)}_1,\ldots ,d^{(2)}_{u_2},\ldots , 
d^{(n)}_1,\ldots$\linebreak $\ldots ,d^{(n)}_{u_n},$ 
где 
$u_j = |D^{(j)}|$ при $j\hm=1,2,\ldots ,n$. Суммой двух строк таблицы~$T$ 
с номерами $i_1$ и $i_2$ по последовательности порогов
$\prod$ назовем строку
%\begin{gather*}
$(a_{{i_1}1} \oplus$\linebreak $\oplus\;a_{{i_2}1} |_{d^{(1)}_1},\ \ldots ,\ a_{{i_1}1} \oplus 
a_{{i_2}1} |_{d^{(1)}_{u_1}},\
a_{{i_1}2} \oplus a_{{i_2}2} |_{d^{(2)}_1},\ \ldots$\linebreak 
$\ldots ,\ a_{{i_1}2} \oplus a_{{i_2}2} |_{d^{(2)}_{u_2}},\
\ldots ,\
a_{{i_1}n} \oplus a_{{i_2}n} |_{d^{(n)}_{1}},\ \ldots ,\ a_{{i_1}n} \oplus $\linebreak
$\oplus\;a_{{i_2}n} |_{d^{(n)}_{u_n}})$.
%\end{gather*}

Пусть $m_1$ и $m_2$~--- число обучающих объектов из классов $K_1$ и
$K_2$ соответственно. Построим булеву матрицу $L$. Матрица $L$ имеет
размеры $h \times N$, где $h \hm= m_1m_2$, $N\hm=|D^{(1)}|+\ldots +|D^{(n)}|$.
Каждая ее строка образуется в результате попарного сложения строк
таблицы~$T$, описывающих объекты из разных классов, по
последовательности порогов~$\prod$. Порядок выбора пар может быть
задан произвольным образом. Множеству порогов $D^{(j)}$, $j \hm\in
\{1,2,\ldots ,n\}$, по построению соответствует группа из $u_j$ столбцов
мат\-ри\-цы~$L$, обозначаемая через~$G_j$.

\smallskip

\noindent
\textbf{Определение 2.} Набор столбцов $H$ матрицы $L$ назовем
кодирующим покрытием, если выполнены следующие два условия: 1)~$H$
является покрытием~$L$, т.\,е.\ для любой строки матрицы~$L$ в наборе~$H$ 
можно указать хотя бы один столбец, имеющий~1 на пересечении с
этой строкой; 2)~$H \cap G_j \hm\neq \varnothing$ при $j\hm=1,2,\ldots ,n$.

\smallskip

\noindent
\textbf{Определение 3.} Кодирующее покрытие назовем неприводимым,
если никакое его собственное подмножество кодирующим покрытием не
является.

\smallskip

\noindent
\textbf{Определение 4.} Число $\max\limits_{j\in\{1,2,\ldots ,n\}} |H \cap
G_j|+1$ назовем значностью кодирующего покрытия~$H$.

\smallskip

Кодирующее покрытие $H$ задает очевидным образом преобразование
таблицы~$T$ в таблицу~$T^H$ на основе замены элементов $T$ числами
из $\{0,1,\ldots ,k-1\}$, где $k$~--- знач\-ность~$H$. Действительно, пусть
$a_{pj}$~--- произвольный элемент таблицы $T$ и пусть
$\{d_1,\ldots ,d_v\}$~--- пороги, соответствующие столбцам из $H \cap
G_j$, причем $d_1<\ldots <d_v$ и $v\hm<k$. Возможны три случая:
\begin{enumerate}[1)]
\item $a_{pj}\leq d_1$;
\item
    $d_t<a_{pj}\leq d_{t+1}$, $t\hm\in\{1,2,\ldots ,v-1\}$;
\item
    $d_v<a_{pj}$.
    \end{enumerate}

В случае~1 элемент $a_{pj}$ кодируется числом 0, в случае~2~---
числом $t$ , в случае~3~--- числом $v$. Легко видеть, что в таблице
$T^H$ описания объектов из разных классов различны. В дальнейшем
$T^H$ будем называть корректной перекодировкой таблицы~$T$.

Таким образом, каждому кодирующему покрытию матрицы~$L$
соответствует корректная перекодировка. Мощность множества
кодирующих покрытий матрицы~$L$ экспоненциально растет с ростом
размеров задачи. Поэтому сложной в вычислительном плане является
задача выбора наилучшей по качеству распознавания корректной
перекодировки. Данная задача рассмотрена в~$\cite{a1}$. В~указанной
работе построен алгоритм КОД1 поиска оптимальной корректной
перекодировки.

\section{Алгоритм поиска оптимальной корректной перекодировки КОД1}

Введем понятие типичного элемента $b_{ij}$ в таблице $T^H \hm=
(b_{ij})_{m \times n}$. Пусть $b_{ij}\hm=a$ и $q_t$, $t\hm\in \{1,2\}$,~---
число строк в $T^H$, имеющих $a$ в пересечении со столбцом с номером
$j$ и описывающих объекты из класса $K_t$. Элемент $b_{ij}$ назовем
типичным в $T^H$ для класса $K_1$, если
$$
    \fr{q_1}{|K_1|} - \fr{q_2}{|K_2|} > \mu_j\,,
$$
где $\mu_j, \mu_j \geq 0,$~--- заданный порог типичности значений
признака $x_j$. Аналогично вводится понятие типичного элемента для
класса~$K_2$.

Положим
$$
    I_{ij}(a)=
    \begin{cases}
        1, &  \mbox{ если } b_{ij}=a\,;\\
        0 &  \mbox{ иначе}\,.
    \end{cases}
$$

Пусть $D \subseteq D^{(j)}$, $Q_j$~--- множество всех типичных элементов $j$-го столбца $T^H$.

Для каждого признака $x_j$ зададим целое число $k_j$, $0\hm<k_j\hm\leq u_j$,
и для каждого $p$, $p\hm\in \{1,\ldots ,k_j\},$ поставим задачу максимизации
функционала
$$
    F(D)=\fr{1}{m} \sum\limits^m_{i=1} \sum\limits_{a\in Q_j} I_{ij}(a)\,, 
    \enskip |D|=p, D \subseteq D^{(j)}\,.
$$

Таким образом, для каждого признака $x_j$ и для каждого $p$, $p\hm\in
\{1,\ldots ,k_j\},$ выбираем подмножество порогов $D^*_{pj}$ такое, что
$F(D^*_{pj})\hm=\max F(D)$, $|D|\hm=p$, $D \subseteq D^{(j)}$. Множество
перекодировок признака $x_j$ упорядочиваем по убыванию значений
$F(D^*_{pj})$. Будем считать, что перекодировка
$H_1\hm=\{D^*_{p_11},D^*_{p_22},\ldots ,D^*_{p_nn}\}$ следует за
перекодировкой $H_2\hm=\{D^*_{q_11},D^*_{q_22},\ldots ,D^*_{q_nn}\}$, если
$$
    \sum\limits^n_{j=1}F(D^*_{q_jj})\geq \sum\limits^n_{j=1}F(D^*_{p_jj})\,.
$$

В заданном порядке последовательно просматриваем всевозможные
перекодировки таблицы $T$. Первая по порядку корректная
перекодировка считается оптимальной.

Сложность алгоритма КОД1 быстро растет с\linebreak рос\-том размеров задачи. 
В~следующем разделе построены алгоритмы, в которых используются другие
критерии оптимальности кодирующего покрытия. Для сокращения
вычислительной сложности рассмотрен генетический подход.

\vspace*{-9pt}

\section{Однокритериальные генетические алгоритмы поиска оптимальной корректной 
перекодировки КОД2, КОД3, КОД4}

\vspace*{-2pt}

Пусть $c_j$, $j \hm\in \{1,2,\ldots ,N\}$,~--- число единиц в $j$-м столбце
матрицы $L_{h \times N}$, $R_1(H)$~--- множество номеров столбцов
$L$, входящих в кодирующее покрытие $H$, $R_2(H)$~--- множество
номеров столбцов матрицы $L$, не входящих в кодирующее покрытие $H$.
Тогда
\begin{align*}
    f_1(H) &= \sum\limits_{j \in R_2(H)} c_j\,;
\\
    f_2(H) &= \fr{1}{|H|}\sum\limits_{j \in R_1(H)}\fr{1}{c_j}\,.
\end{align*}

Построены алгоритмы КОД2, КОД3 и КОД4. В~генетическом алгоритме КОД4
особям соответствуют кодирующие покрытия, а в алгоритмах КОД2 и КОД3
особям соответствуют неприводимые кодирующие покрытия. Роль функции
приспособленности играет один из двух функционалов: $f_1(H)$ для
КОД2 и $f_2(H)$ для КОД3 и КОД4. Функция приспособленности особи
является критерием качества кодирующего покрытия в перечисленных
алгоритмах.

Для реализации генетических алгоритмов взята схема генетического
алгоритма из~\cite{a5}, которая адаптирована к условиям задачи.
Основной особенностью задачи поиска кодирующего покрытия является
условие включения в покрытие хотя бы одного столбца из набора
столбцов $G_j$, $j\hm=1,2,\ldots ,n$, матрицы~$L$. Для выполнения этого
условия внесены соответствующие изменения в процедуру восстановления
допустимости решения.

В работе использован оригинальный оператор мутации c переменным
числом мутирующих генов, что позволяет минимизировать влияние
данного оператора на особь на ранних этапах работы и усиливать его
влияние с увеличением числа итераций.

\vspace*{-6pt}

\section{Двухкритериальный генетический алгоритм 
поиска оптимальной корректной перекодировки КОД5}

\vspace*{-1pt}

Разработан двухкритериальный генетический алгоритм, основанный на
схеме однокритериального генетического подхода. Отличия заключаются
в процедуре вычисления функции приспособленности и процедуре
добавления особи в популяцию.

На каждом этапе для каждой особи вычисляются значения функционалов
$f_1(H)$ и $f_3(H)$, где $f_3(H)$~--- значность перекодировки. На
основе полученных векторов значений $v(f_1(H), f_3(H))$ производится
вычисление рангов. Пусть $V$~--- множество векторов~$v$, вычисленных
для каждой особи популяции. Рангом вектора $rg(v)$, $v\hm\in V,$
называется величина, равная числу векторов, строго доминирующих
данный вектор. В~случае если таких векторов нет, ранг вектора~$v$
принимается равным~1. В~качестве функции приспособленности
используется 
$$
f(v)=\max\limits_{w\in V}(rg(w)-rg(v))+1\,.
$$
В~процедуре
обновления популяции заменяется особь, име\-ющая самый низкий ранг.
Алгоритм рассматривает только неприводимые покрытия.

\vspace*{-6pt}

\section{Результаты экспериментов}

\vspace*{-1pt}

Построенные в настоящей работе генетические алгоритмы были
протестированы на реальных данных и сравнивались с алгоритмами КОД1
и градиентным алгоритмом. В~качестве распознающего\linebreak\vspace*{-12pt}

\pagebreak

%\vspace*{9pt}
\begin{center}
{{\tablename~1}\ \ \small{Характеристики задач}}
\end{center}
%\begin{table*}
{\small
      \begin{center}
      \tabcolsep=12pt
\begin{tabular}{|c|c|c|}
\hline
$N$ & $m_1, m_2, n$ & Z\\
\hline
1 & 90, 42, 9\hphantom{9} & 112\hphantom{9}\\
2 & 60, 71, 13 & 97\\
3 & 30, 30, 33 & 51\\
4 & 50, 50, 19 & 78\\
5 & 70, 80, 24 & 133\hphantom{9}\\
\hline
\end{tabular}
\end{center}}
%\end{table*}
\addtocounter{table}{1}


\vspace*{5pt}
\begin{center}
{{\tablename~2}\ \ \small{Значность оптимальных перекодировок}}
\end{center}
{\small
      \begin{center}
      \begin{tabular}{|c|c|c|c|c|c|}
\hline
$N$ & КОД1 & КОД2 & КОД3 & КОД4 & КОД5 \\
\hline
1 & 39 & 31 & 27 & 30 & 24 \\
2 & 26 & 24 & 12 & 22 & 11 \\
3 & 24 & 20 & 11 & 18 & 10 \\
4 & 29 & 23 & 17 & 23 & 15 \\
5 & ---  & 21 & 15 & 20 & 13 \\
\hline
\end{tabular}
\end{center}}
%\end{table*}
\addtocounter{table}{1}


\vspace*{5pt}
\begin{center}
{{\tablename~3}\ \ \small{Качество распознавания}}
\end{center}
{\small
      \begin{center}
      \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
$N$ & $A_0$ &$A^*_0$ & $A_1$ & $A_2$ & $A_3$ & $A_4$ & $A_5$ \\
\hline
1 & 54& 66 & 67 & 67 & \textbf{76} & 72 & 73 \\
2 & 63& 83 & 88 & 92 & 93 & 92 & \textbf{94} \\
3 & 58& 70 & 72 & 72 & \textbf{82} & 80 & 81 \\
4 & 53& 68 & 71 & 73 & \textbf{79} & 72 & 75\\
5 & 57& 66 & --- & 67 & 76 & 74 & \textbf{78}\\
\hline
\end{tabular}
\end{center}}
%\end{table*}
\addtocounter{table}{1}


\vspace*{5pt}
\begin{center}
{{\tablename~4}\ \ \small{Время счета}}
\end{center}
{\small
      \begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
$N$ & $m_1, m_2, n$ & $A^*_0$ & $A_1$ & $A_3$ \\
\hline
1 & 90, 42, 9\hphantom{9} &  6 &  \hphantom{9}59 & 10 \\
2 & 60, 71, 13 &  8 & 244 & 17 \\
3 & 30, 30, 33 & 13\hphantom{9} & 415 & 29 \\
4 & 50, 50, 19 &  9 & 194 & 17 \\
5 & 70, 80, 24 & 24\hphantom{9} & --- & 67 \\
\hline
\end{tabular}
\end{center}}
%\end{table*}

\vspace{12pt}

\addtocounter{table}{1}



\noindent
 алгоритма
использовалась процедура голосования по представительным наборам с
ограничением по длине набора. Сравнение проводилось на реальных
задачах из репозитория программной системы <<Распознавание>>,
описанной в~\cite{a3}.

Результаты счета представлены в табл.~1--4. В~этих таблицах введены
следующие обозначения:

$N$~--- номер задачи;

$m_1, m_2$~--- число объектов в классах;

$n$~--- число признаков;

$A_0$~--- алгоритм голосования по представительным наборам, построенным по исходной 
обуча\-ющей выборке;

$A^*_0$~--- распознающий алгоритм, примененный к данным,
перекодированным градиентным алгоритмом поиска неприводимых
кодирующих покрытий;

$A_1$~--- распознающий алгоритм, примененный к перекодированным алгоритмом КОД1 данным;

$A_2$~--- распознающий алгоритм, примененный к перекодированным алгоритмом КОД2 данным;

$A_3$~--- распознающий алгоритм, примененный к перекодированным алгоритмом КОД3 данным;

$A_4$~--- распознающий алгоритм, примененный к перекодированным алгоритмом КОД4 данным;

$A_5$~--- распознающий алгоритм, примененный к перекодированным алгоритмом КОД5 данным;

$Z$~--- значность исходных данных.

В табл.~1 приведены характеристики задач: чис\-ло обучающих объектов в
классах и число признаков. В~случае вещественнозначной информации
значность определяется по числу различных значений признаков в
обучающей выборке.



Таблица~2 содержит значность полученных алгоритмами перекодировок.
Прочерк означает, что алгоритм был исключен из эксперимента из-за
слишком большого времени выполнения (более одного часа). Нетрудно
заметить, что наименьшая значность достигнута алгоритмом КОД5.
Данный результат обусловлен использованием функционала $f_3(H)$ в
этом алгоритме.

В табл.~3 приведено качество распознавания в процентах, полученное
алгоритмами на скользящем контроле.

Из приведенных в табл.~3 результатов следует, что все предложенные
способы перекодирования данных улучшают качество распознавания. Из
тех же результатов следует, что решения алгоритмов $A_2$ и $A_4$ не
хуже по качеству распознавания, чем решения алгоритмов $A_0$,
$A^*_0$ и $A_1$, а алгоритмы $A_3$ и $A_5$ превосходят другие
алгоритмы по качеству распознавания.

Нетрудно заметить, что условие неприво\-ди\-мости кодирующего покрытия
оказывает существенное влияние как на значность перекодировки, так и
на качество распознавания. Согласно данным, приведенным в табл.~3,
лучшими функционалами оценки качества перекодировки являются
$f_2(H)$ и пара функционалов $f_1(H)$ и $f_3(H)$, так как результаты
алгоритмов $A_3$ и $A_5$ оказались лучшими во всех рассмотренных
задачах.

Алгоритм $A_3$ превзошел алгоритм $A_5$ в задачах~1, 3, 4, поэтому
можно сделать вывод, что меньшая значность перекодировки (функционал
$f_3(H)$) не всегда означает, что перекодировка лучше по ка\-честву
распознавания.

В табл.~4 приведено время счета алгоритмов в секундах.



Прочерк означает, что алгоритм был исключен из эксперимента из-за
слишком большого времени выполнения (более одного часа). В таблице
не представлены алгоритмы $A_2, A_4$ и $A_5$ по той причине, что
вычислительная сложность этих алгоритмов аналогична вычислительной
сложности алгоритма $A_3$, а следовательно, время счета практически
не отличается.

Из результатов следует, что распознающие алгоритмы, полученные на
основе алгоритмов КОД2, КОД3, КОД4 и КОД5, по сравнению с
рас\-по\-зна\-ющим алгоритмом, основанным на алгоритме КОД1, выигрывают не
только по качеству решения, но и по скорости выполнения. Кроме того,
качество решения полученных алгоритмов существенно лучше, чем
качество решения алгоритма голосования по представительным наборам,
примененного к неперекодированным данным.


{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{9}

\bibitem{a1}
\Au{Дюкова Е.\,В., Журавлев Ю.\,И., Песков~Н.\,В., Сахаров~А.\,А.} Обработка вещественнозначной информации логическими
процедурами распознавания~// Искусственный интеллект, 2004. №\,2.
С.~80--85.
\bibitem{a2}
\Au{Djukova~E., Inyakin~A., Peskov~N., Sakharov~A.}
Combinatorial (logical) data analysis in pattern recognition
problems~// Pattern Recognition and Image Analysis, 2005. Vol.~15.
No.\,1. P.~46--48.
\bibitem{a3}
\Au{Журавлев~Ю.\,И., Рязанов~В.\,В., Сенько~О.\,В.}
<<Распознавание>>. Математические методы. Программная система.
Практические применения.~--- М.: Фазис, 2006. 176~с.
\bibitem{a4}
\Au{Журавлев~Ю.\,И.} Об алгебраическом подходе к решению задач
распознавания и классификации~// Проб\-ле\-мы кибернетики, 1978.
Вып.~33. С.~5--68.
\bibitem{a5}
\Au{Sotnezov~R.\,M.} Genetic algorithms for problems of logical
data analysis in discrete optimization and image recognition~//
Pattern Recognition and Image Analysis, 2009. Vol.~19. No.\,3.
P.~469--477.

\label{end\stat}

%\bibitem{a6}
%\Au{Дюкова~Е.\,В., Карнеева~И.\,Л.} Модели распознающих
%алгоритмов, основанные на различных способах перекодировки исходной
%информации~// Математические методы в распознавании образов и
%дискретной оптимизации.~--- М.: ВЦ АН СССР, 1990. С.~43--56.
\end{thebibliography}
}
}

\end{multicols}