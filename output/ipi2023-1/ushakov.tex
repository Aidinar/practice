\def\stat{ushakovi}

\def\tit{КРИТЕРИИ НОРМАЛЬНОСТИ ВЕРОЯТНОСТНОГО РАСПРЕДЕЛЕНИЯ ПРИ~ОКРУГЛЕННЫХ ДАННЫХ$^*$}

\def\titkol{Критерии нормальности вероятностного распределения при~округленных данных}

\def\aut{В.\,Г.~Ушаков$^1$, Н.\,Г.~Ушаков$^2$}

\def\autkol{В.\,Г.~Ушаков, Н.\,Г.~Ушаков}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Ушаков В.\,Г.}
\index{Ушаков Н.\,Г.}
\index{Ushakov V.\,G.}
\index{Ushakov N.\,G.}


{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Работа выполнена при поддержке Министерства науки и~высшего образования
Российской федерации, грант №\,075-15-2020-799.}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Факультет вычислительной математики и~кибернетики Московского государственного университета им. М.\,В.\,Ломоносова; 
Федеральный исследовательский центр <<Информатика и~управление>>\  Российской академии наук, 
\mbox{vgushakov@mail.ru}}
\footnotetext[2]{Институт проблем технологии микроэлектроники и~особочистых материалов Российской академии наук;
Норвежский на\-уч\-но-тех\-но\-ло\-ги\-че\-ский университет, \mbox{nikolai.ushakov@ntnu.no}}

%\vspace*{-10pt}


\Abst{Критерии нормальности менее чувствительны к~округлению данных, чем, например, критерии на экспоненциальность,
но среди критериев нормальности чувствительность сильно различается. В~данной статье определено, какие критерии
более, а~какие менее чувствительны к~округлению. Показано, что критерии, основанные на выборочных моментах, гораздо
более устойчивы к~округлению данных, чем критерии, основанные на порядковых статистиках (в отличие от
устойчивости к~выбросам, где порядковые статистики значительно более устойчивы, чем выборочные моменты).
Это, однако, относится только к~вероятности ошибки первого рода. Вероятность ошибки второго рода мало
чувствительна к~округлению данных для всех критериев нормальности.}


\KW{нормальное распределение; критерий нормальности распределения; округленные данные; уровень значимости;
моделирование  методом Мон\-те-Карло}

\DOI{10.14357/19922264230103} 
  
%\vspace*{-4pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}


\section{Введение}

Предположение о нормальности распределения\linebreak
 выборки  важно для многих статистических методов.
Статистические процедуры, такие как $t$-кри\-те\-рий Стьюдента, критерии, связанные a~коэффициентом регрессии,
F-кри\-те\-рий однородности \mbox{дисперсии} и~т.\,д., основаны на предположении, что наблюдения имеют нормальное
распределение. Если предположение о~нормальности не выполняется, то это может повлиять на точ\-ность результата
и правильность выводов. Поэтому проблема проверки того, что выборка была взята из некоторого нормального
распределения с~неизвестными средним и~дисперсией,~--- одна из наиболее распространенных проблем
в~критериях согласия. По этой причине в~литературе было предложено много критериев нормальности. Сюда
входят критерии, основанные на эмпирической функции распределения, эмпирической характеристической функции,
выборочных моментах и~др. Проб\-ле\-ма, тем не менее, еще не закрыта, и~новые критерии продолжают появляться.
Это связано с~тем, что не существует наилучшего критерия, т.\,е.\ наиболее мощного
критерия для всех условий.

Сравнение различных критериев нор\-маль\-ности проводилось во многих работах (см., в~част\-ности,~[1--5] 
и~приведенные там ссылки). В~указанных работах предполагалось, что наблюдения
регистрируются точно. Однако данные обычно регистрируются в~округленном виде и~содержат как случайную
ошибку измерения, так и~ошибку округления. Округление может возникать в~результате ограниченной
чувствительности измерительной аппаратуры или может быть искусственным с~целью сжатия данных.

Статистические критерии для округленных данных изучались рядом авторов (см.\ ссылки в~[6]). В~частности, в~[7--9]
исследовались влияние округления на уровень значимости и~мощность четырех параметрических критериев
($t$-кри\-те\-рий, двойной $t$-кри\-те\-рий, $\chi^2$-кри\-те\-рий и~$F$-кри\-те\-рий).

\begin{table*}[b]\small %tabl1
\begin{center}
\Caption{Исследуемые критерии и~используемые R-пакеты и~функции}
\vspace*{2ex}

\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{Критерий}&\multicolumn{1}{c|}{Обозначение}&
\multicolumn{1}{c|}{Пакет}&\multicolumn{1}{c|}{Функция}\\
\hline
Пирсона&\hspace*{7mm}P&{\tt nortest}&{\tt pearson.test(x)}\\
Колмогорова--Смирнова&\hspace*{7mm}KS&{\tt nortest}&{\tt lillie.test(x)}\\
Крамера -- фон Мизеса&\hspace*{7mm}CvM&{\tt nortest}&{\tt cvm.test(x)}\\
Андерсона--Дарлинга&\hspace*{7mm}AD&{\tt nortest}&{\tt ad.test(x)}\\
Шапиро--Уилка&\hspace*{7mm}SW&&{\tt shapiro.test(x)}\\
Шапиро--Франция&\hspace*{7mm}SF&{\tt nortest}&{\tt sf.test(x)}\\
Харке--Бера&\hspace*{7mm}JB&{\tt normtest}&{\tt jb.norm.test(x)}\\
Скорректированный Харке--Бера&\hspace*{7mm}AJB&{\tt normtest}&{\tt ajb.norm.test(x)}\\
Фрозини&\hspace*{7mm}F&{\tt normtest}&{\tt frosini.norm.test(x)}\\
Гири&\hspace*{7mm}G&{\tt normtest}&{\tt geary.norm.test(x)}\\
Хегази--Грина (1)&\hspace*{7mm}HG1&{\tt normtest}&{\tt hegazy1.norm.test(x)}\\
Хегази--Грина (2)&\hspace*{7mm}HG2&{\tt normtest}&{\tt hegazy2.norm.test(x)}\\
Эксцесса&\hspace*{7mm}K&{\tt normtest}&{\tt kurtosis.norm.test(x)}\\
Асимметрии&\hspace*{7mm}S&{\tt normtest}&{\tt skewness.norm.test(x)}\\
Шпигельхальтера&\hspace*{7mm}Sp&{\tt normtest}&{\tt spiegelhalter.norm.test(x)}\\
Вайсберга--Бингема&\hspace*{7mm}WB&{\tt normtest}&{\tt wb.norm.test(x)}\\
\hline
\end{tabular}
\end{center}
\end{table*}

Критерии нормальности, хотя менее чувствительны к~округлению данных, чем, например, критерии
экспоненциальности, однако сильно различаются по чувствительности между собой. В~данной работе выясняется,
какие критерии более, а~какие менее робастны по отношению к~округлению. Оказывается, что критерии, основанные
на выборочных моментах, предпочтительнее, чем критерии, основанные на порядковых статистиках (в~отличие от
робастности по отношению к~выбросам, где порядковые статистики робастнее, чем выборочные моменты).
Это, впрочем, относится только к~вероятности ошибки первого рода. Вероятность ошибки второго рода нечувствительна
к округлению данных для всех критериев нормальности. Исследование основано на предварительном теоретическом
анализе и~интенсивном моделировании методом Мон\-те-Кар\-ло. Исследуются все критерии R-па\-ке\-тов nortest и~normtest.
Краткое описание каждого критерия приведено в~следующем разделе.

Существуют различные виды округления. Для определенности будет рассматриваться округление до ближайшего.
Имеется множество $\{x': x'\hm=kh, k\hm=0,\pm1,\pm2,\ldots\}$ (решетка или сетка округления), где $h\hm>0$. Для
вещественного числа~$x$ его округление есть ближайшая к~$x$ точка этой решетки. Обозначим его через~$r_h(x)$.
Для непрерывной случайной величины~$X$ ее округлением (или дискретизацией) является дискретная случайная
величина~$r_h(X)$; $h$ называется шагом дискретизации. Значения~$r_h(X)$ называются округленными данными.
Пусть~$\sigma$~--- стандартное отклонение
случайной величины~$X$. Уровень округления измеряется соотношением $r\hm=h/\sigma$.

В статье  используются следующие обозначения. Разность между~$r_h(x)$ и~$x$ обозначается~$d_h(x)$, 
т.\,е.\ $d_h(x)\hm=r_h(x)\hm-x$. Заметим, что $|d_h(x)|\hm\leqslant h/2$. Кумулятивная функция
распределения нормального распределения с~математическим ожиданием~$\mu$ и~дисперсией~$\sigma^2$
обозначается $\Phi_{\mu,\sigma}(z),\ \Phi(z)\hm=\Phi_{0,1}(z)$.


\vspace*{-9pt}


\section{Краткое описание тестов нормальности и~их~предварительный анализ}

\vspace*{-2pt}

Критерии нормальности, которые изучаются в~данной работе, перечислены в~табл.~1.
В~ней указано, какие R-па\-кет и~функция используются для каж\-до\-го критерия. Пусть $X_1,\ldots,X_n$~---
случайная выборка. Положим $Y_i\hm=X_i/\overline X$. Эмпирические функции распределения выборок
$X_1,\ldots ,X_n$ и~$Y_1,\ldots ,Y_n$ обозначим соответственно~$F_n(x)$ и~$G_n(x)$.

\textbf{Критерий хи-квадрат Пирсона}. Диапазон переменных, образующих выборку, разбит на~$m$~ячеек. Пусть~$O_j$
обозначает число наблюдений в~ячейке~$j$. Пусть~$p_j$~--- вероятность того, что случайное наблюдение
окажется в~ячейке~$j$ при условии, что нулевая гипотеза верна. Определим $E_j\hm=p_jn$~--- ожидаемое
число наблюдений в~ячейке~$j$. Статистика критерия:
$$
T_{\mathrm{P}}=\sum\limits_{j=1}^m \fr{(O_j-E_j)^2}{E_j}\,.
$$

\textbf{Критерий Колмогорова--Смир\-но\-ва}. Статистика критерия:
$$
T_{\mathrm{KS}}=\sup\limits_x \left\vert F_n(x)-\Phi_{\mu,\sigma}(x)\right\vert.
$$

Статистика \textbf{критерия Крамера\,--\,фон Мизеса}:
$$
T_{\mathrm{CvM}}=\int\limits_{-\infty}^\infty \left(F_n(x)-\Phi_{\hat\mu,\hat\sigma}(x)\right)^2d\Phi_{\hat\mu,\hat\sigma}(x).
$$

\textbf{Критерий Андерсона--Дар\-лин\-га}. Тестовая статистика:
$$
T_{\mathrm{AD}}=n\int\limits_{-\infty}^\infty\left(F_n(x)-\Phi_{\hat\mu,\hat\sigma}(x)\right)^2w(x)\,d\Phi_{\hat\mu,\hat\sigma}(x),
$$
где $w(x)$~--- весовая функция:
$$
w(x)=\fr{1}{\Phi_{\hat\mu,\hat\sigma}(x)(1-\Phi_{\hat\mu,\hat\sigma}(x))}\,.
$$

\textbf{Критерий Шапиро--Уил\-ка} основан на сле\-ду\-ющей тестовой статистике:
$$
T_{\mathrm{SW}}=
\fr{\left(\sum\nolimits_{i=1}^ka_iX_{(i)}\right)^2}{\sum\nolimits_{i=1}^n(X_i-\bar X)^2}\,.
$$
Здесь  $(a_1,\ldots ,a_n)$~--- вектор весов:
$$
\left(a_1,\ldots ,a_n\right)=m V^{-1}\left(m  V^{-1} V^{-1}  m^{t}\right)^{-1/2},$$
где $m$ и~$V$~--- средний вектор и~ковариационная матрица порядковой статистики стандартного нормального распределения.

\textbf{Критерий Шапиро--Фран\-ция}. Статистика критерия является
коэффициентом корреляции Пирсона между вектором наблюдений и~вектором~$m$, т.\,е.
$$
T_{\mathrm{SF}}=
\fr{\sum\nolimits_{i=1}^n(X_i-\bar X)(m_i-\bar m)}
{\sqrt{\left(\sum\nolimits_{i=1}^n\left(X_i-\bar X\right)^2\right)\left(\sum\nolimits_{i=1}^n\left(m_i-\bar m\right)^2\right)}}.
$$

\textbf{Критерий Харке--Бе\-ра} основан на статистике
$$
T_{\mathrm{JB}}=\fr{n}{6}\left(b_1+\fr{(b_2-3)^2}{4}\right),
$$
где $b_1$ и~$b_2$~--- квадраты выборочной асимметрии и~выборочного эксцесса соответственно.

\textbf{Скорректированный критерий Хар\-ке--Бе\-ра}. Статистика критерия:
\begin{multline*}
T_{\mathrm{AJB}}=\fr{(n+1)(n+3)}{6(n-2)}\times{}\\
{}\times\left(
b_1+\fr{(n+1)(n+5)}{4n(n-3)}\left(b_2-3\fr{n-1}{n+1}\right)^2\right),
\end{multline*}
где $b_1$ и~$b_2$ определены выше.

Статистика \textbf{критерия Фрозини}:
$$
T_{\mathrm{F}}=\fr{1}{\sqrt n}\sum\limits_{i=1}^n
\left| \Phi\left(\fr{X_{(i)}-\bar X}{S}\right)
-\fr{i-1/2}{n} \right|.
$$

Для \textbf{критерия Гири} в~качестве статистики критерия используется сле\-ду\-ющая мера эксцесса:
$$
T_{\mathrm{G}}=\fr{\sum\nolimits_{i=1}^n|X_i-\bar X|}{\sqrt{n\sum\nolimits_{i=1}^n(X_i-\bar X)^2}}\,.
$$

Два \textbf{критерия Хе\-га\-зи--Гри\-на} основаны на сле\-ду\-ющих статистиках:
\begin{align*}
T_{\mathrm{HG1}} &=\fr{1}{n}\sum\limits_{i=1}^n\left|
\fr{X_{(i)}-\bar X}{S}-\Phi^{-1}\left(\fr{i}{n+1}\right)\right|;\\
T_{\mathrm{HG2}}&=\fr{1}{n}\sum\limits_{i=1}^n\left( \fr{X_{(i)}-\bar X}{S}-\Phi^{-1}\left(\fr{i}{n+1}\right)\right)^2.
\end{align*}

\textbf{Критерии эксцесса и~асимметрии}.
Статистики критериев имеют следующий вид:
\begin{align*}
T_{\mathrm{K}}&=\fr{n\sum\nolimits_{i=1}^n\left(X_i-\bar X\right)^4}{\left(\sum\nolimits_{i=1}^n\left(X_i-\bar X\right)^2\right)^2}\,;
\\
T_{\mathrm{S}}&=\fr{\sqrt n\sum\nolimits_{i=1}^n\left(X_i-\bar X\right)^3}{\left(\sum\nolimits_{i=1}^n\left(X_i-\bar X\right)^2\right)^{3/2}}
\end{align*}
соответственно.

\textbf{Критерий Шпигельхальтера} основан на статистике
\begin{multline*}
T_{\mathrm{Sp}}=
\left[\fr{1}{n!}\left(\fr{2n}{X_{(n)}-X_{(1)}}\right)^{n-1}+{}\right.\\
\left.{}+
\left(
\fr{\sqrt{n(n-1)}}{\sum\nolimits_{i=1}^n|X_i-\bar X|}\right)^{n-1}
\right]^{1/(n-1)}S\,.
\end{multline*}

Статистика \textbf{критерия Вайс\-бер\-га--Бин\-гема}:
$$
T_{\mathrm{WB}}=\fr{\left(\sum\nolimits_{i=1}^nm_iX_{(i)}\right)^2}{\left(\sum\nolimits_{i=1}^nm_i^2\right)\sum\nolimits_{i=1}^n\left(X_i-\bar X\right)^2}\,,
$$
где
$$
m_i=\Phi^{-1}\left(\fr{i-3/8}{n+1/4}\right).
$$

Рассмотрим подробнее перечисленные критерии и~их тестовые статистики. Одно свойство выделяет группу из следующих 
5~критериев: Хар\-ке--Бе\-ра, скорректированного Хар\-ке--Бе\-ра, Гири, эксцесса и~асимметрии. Статистики этих
критериев зависят только от выборочных моментов (не выше четвертого порядка). Эти критерии выделены жирным шрифтом
в~табл.~2--6. Статистики остальных критериев включают в~себя более сложные функции, которые прямо или косвенно
основаны на порядковых статистиках или на эмпирической функции распределения.
Эмпирическая функция распределения может быть записана в~\mbox{виде}
$$
F_n(x)=\begin{cases}
0 &\ \mbox{при}\ x<X_{(1)}\,;\\
\fr{k}{n} &\ \mbox{при}\ X_{(k)}\leqslant x<X_{(k+1)},\\
&\hspace*{10mm}k=1,2,\ldots,n-1\,;\\
1 &\ \mbox{при}\ x\geqslant X_{(n)},
\end{cases}
$$
т.\,е.\ это функция порядковых статистик. Поэтому свойства критериев, основанных на эмпирической функции
распределения, аналогичны свойствам критериев, основанных непосредственно на порядковых статистиках.

\end{multicols}

\begin{table*}\small  %tabl2
\begin{center}
\Caption{Оцененная вероятность ошибки первого рода, $n=50$}
\vspace*{2ex}

\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Критерий}}& \multicolumn{6}{c|}{$r$}\\
\cline{2-7}
&\multicolumn{1}{c|}{0}&\multicolumn{1}{c|}{0,01}&
\multicolumn{1}{c|}{0,03}&\multicolumn{1}{c|}{0,07}&\multicolumn{1}{c|}{0,1}&\multicolumn{1}{c|}{0,2}\\
\hline
\hspace*{4mm}P&0,0406&0,0417&0,0478&0,0744&{\bf 0,0991}&{\bf 0,2457}\\
%\hline
\hspace*{4mm}KS&0,0457&0,0414&0,0419&0,0548&0,0711&{\bf 0,1518}\\
%\hline
\hspace*{4mm}CvM&0,0442&0,0421&0,0546&0,0578&0,0542&{\bf 0,0859}\\
%\hline
\hspace*{4mm}AD&0,0488&0,0463&0,0578&0,0481&0,0571&{\bf 0,0859}\\
%\hline
\hspace*{4mm}SW&0,0525&0,0469&0,0517&0,0422&0,0601&0,0651\\
%\hline
\hspace*{4mm}SF&0,0587&0,0492&0,0521&0,0449&0,0689&0,0621\\
%\hline
\hspace*{4mm}{\bf JB}&0,0477&0,0464&0,0485&0,0433&0,0643&0,0441\\
%\hline
\hspace*{4mm}{\bf AJB}&0,0494&0,0482&0,0463&0,0438&0,0581&0,0447\\
%\hline
\hspace*{4mm}F&0,0467&0,0463&0,0534&0,0543&0,0482&{\bf 0,0783}\\
%\hline
\hspace*{4mm}{\bf G}&0,0558&0,0429&0,0433&0,0501&0,0444&0,0532\\
%\hline
\hspace*{4mm}HG1&0,0543&0,0548&0,0511&0,0487&0,0577&0,0743\\
%\hline
\hspace*{4mm}HG2&0,0564&0,0463&0,0472&0,0433&0,0568&0,0629\\
%\hline
\hspace*{4mm}{\bf K}&0,0551&0,0487&0,0557&0,0442&0,0546&0,0397\\
%\hline
\hspace*{4mm}{\bf S}&0,0526&0,0454&0,0484&0,0513&0,0585&0,0482\\
%\hline
\hspace*{4mm}Sp&0,0656&0,0311&0,0433&0,0343&0,0551&0,0384\\
%\hline
\hspace*{4mm}WB&0,0561&0,0478&0,0449&0,0435&0,0628&0,0609\\
\hline
\end{tabular}
\end{center}
\vspace*{-12pt}
\end{table*}


\begin{table*}\small %tabl3
\begin{center}
\Caption{Оцененная вероятность ошибки первого рода, $n=100$}
\vspace*{2ex}

\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Критерий}}& \multicolumn{6}{c|}{$r$}\\
\cline{2-7}
&\multicolumn{1}{c|}{0}&\multicolumn{1}{c|}{0,01}&
\multicolumn{1}{c|}{0,03}&\multicolumn{1}{c|}{0,07}&\multicolumn{1}{c|}{0,1}&\multicolumn{1}{c|}{0,2}\\
\hline
\hspace*{4mm}P&0,0486&0,0498&0,0541&{\bf 0,1048}&{\bf 0,1228}&{\bf 0,2857}\\
%\hline
\hspace*{4mm}KS&0,0383&0,0413&0,0601&{\bf 0,0849}&{\bf 0,1308}&{\bf 0,3626}\\
%\hline
\hspace*{4mm}CvM&0,0501&0,0463&0,0463&0,0581&0,0664&{\bf 0,1398}\\
%\hline
\hspace*{4mm}AD&0,0451&0,0458&0,0479&0,0595&0,0708&{\bf 0,1418}\\
%\hline
\hspace*{4mm}SW&0,0436&0,0478&0,0463&0,0566&0,0594&{\bf 0,0828}\\
%\hline
\hspace*{4mm}SF&0,0418&0,0456&0,0491&0,0634&0,0630&{\bf 0,0909}\\
%\hline
\hspace*{4mm}{\bf JB}&0,0386&0,0449&0,0489&0,0559&0,0478&0,0473\\
%\hline
\hspace*{4mm}{\bf AJB}&0,0372&0,0426&0,0505&0,0534&0,0453&0,0456\\
%\hline
\hspace*{4mm}F&0,0492&0,0441&0,0478&0,0557&0,0645&{\bf 0,1098}\\
%\hline
\hspace*{4mm}{\bf G}&0,0525&0,0517&0,0488&0,0521&0,0482&0,0416\\
%\hline
\hspace*{4mm}HG1&0,0503&0,0444&0,0505&0,0586&0,0622&{\bf 0,1058}\\
%\hline
\hspace*{4mm}HG2&0,0423&0,0429&0,0508&0,0593&0,0582&{\bf 0,0876}\\
%\hline
\hspace*{4mm}{\bf K}&0,0450&0,0384&0,0393&0,0556&0,0472&0,0449\\
%\hline
\hspace*{4mm}{\bf S}&0,0419&0,0503&0,0533&0,0471&0,0561&0,0499\\
%\hline
\hspace*{4mm}Sp&0,0544&0,0419&0,0524&0,0504&0,0499&0,0520\\
%\hline
\hspace*{4mm}WB&0,0439&0,0437&0,0456&0,0508&0,0514&{\bf 0,0859}\\
\hline
\end{tabular}
\end{center}
\vspace*{-9pt}
\end{table*}

\begin{multicols}{2}


\section{Неравенства}


Связь между моментами (теоретическими или выборочными) непрерывных случайных величин и~их дискретизаций
изучалась в~ряде работ (см., в~част\-ности,~\cite{6-us, 10-us, 11-us, 12-us, 13-us, 14-us} и~ссылки в~этих работах).
Коротко говоря, моменты близки, если шаг дискретизации не слишком велик. В~этом разделе приведены
новые количественные оценки этой близости.

%\smallskip

\noindent
\textbf{Теорема 1.}\ \textit{Пусть $h<1$. Тогда для любого натурального~$m$}

\vspace*{-2pt}

\noindent
\begin{multline*}
|\mathbf{E}\,[r_h(X)]^m-\mathbf{E}\, X^m|\leqslant{}\\
{}\leqslant
\left[\left(\fr{3}{2}\right)^m-1\right]\max\left\{1,\mathbf{E}\,|X|^{m-1}\right\}h\,.
\end{multline*}


\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \ Поскольку
\begin{multline*}
\mathbf{E}\,\left[r_h(X)\right]^m=\mathbf{E}\,\left[X+d_h(X)\right]^m={}\\
{}=\mathbf{E}\,X^m+\sum\limits_{j=1}^m
\begin{pmatrix}
m\\j
\end{pmatrix}
\mathbf{E}\,\left[X^{m-j}d_h(X)^j\right],
\end{multline*}
используя неравенство Ляпунова, получаем
\begin{multline*}
\mathbf{E}\,\left[r_h(X)\right]^m-\mathbf{E}\, X^m|={}\\
{}=\left|\sum\limits_{j=1}^m \begin{pmatrix}
m\\ j
\end{pmatrix}
\mathbf{E}\,\left[X^{m-j}d_h(X)^j\right]\right|\leqslant{}\\
{}\leqslant
\sum\limits_{j=1}^m
\begin{pmatrix}
m\\ j
\end{pmatrix}
\mathbf{E}\,|X^{m-j}d_h(X)^j|\leqslant{}
\end{multline*}

\end{multicols}

\begin{table*}\small %tabl4
\begin{center}
\Caption{Оцененная вероятность ошибки первого рода, $n=500$}
\vspace*{2ex}

\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Критерий}}& \multicolumn{6}{c|}{$r$}\\
\cline{2-7}
&\multicolumn{1}{c|}{0}&\multicolumn{1}{c|}{0,01}&
\multicolumn{1}{c|}{0,03}&\multicolumn{1}{c|}{0,07}&\multicolumn{1}{c|}{0,1}&\multicolumn{1}{c|}{0,2}\\
\hline
\hspace*{4mm}P&0,0453&0,0531&{\bf 0,1928}&{\bf 0,9360}&{\bf 0,8721}&{\bf 1}\\
%\hline
\hspace*{4mm}KS&0,0503&0,0599&{\bf 0,0991}&{\bf 0,2897}&{\bf 0,5114}&{\bf 1}\\
%\hline
\hspace*{4mm}CvM&0,0578&0,0516&0,0547&{\bf 0,0959}&{\bf 0,1618}&{\bf 1}\\
%\hline
\hspace*{4mm}AD&0,0563&0,0491&0,0512&{\bf 0,0919}&{\bf 0,1538}&{\bf 1}\\
%\hline
\hspace*{4mm}SW&0,0486&0,0512&0,0489&{\bf 0,0919}&{\bf 0,1008}&{\bf 0,6383}\\
%\hline
\hspace*{4mm}SF&0,0497&0,0536&0,0501&{\bf 0,0786}&{\bf 0,0986}&{\bf 0,5644}\\
%\hline
\hspace*{4mm}{\bf JB}&0,0514&0,0479&0,0478&0,0535&0,0438&0,0457\\
%\hline
\hspace*{4mm}{\bf AJB}&0,0510&0,0506&0,0481&0,0574&0,0457&0,0459\\
%\hline
\hspace*{4mm}F&0,0542&0,0532&0,0505&{\bf 0,0799}&{\bf 0,1138}&{\bf 1}\\
%\hline
\hspace*{4mm}{\bf G}&0,0447&0,0409&0,0477&0,0575&0,0546&0,0362\\
%\hline
\hspace*{4mm}HG1&0,0573&0,0554&0,0511&{\bf 0,0819}&{\bf 0,1178}&{\bf 0,9960}\\
%\hline
\hspace*{4mm}HG2&0,0469&0,0471&0,0486&{\bf 0,0751}&{\bf 0,0829}&{\bf 0,4325}\\
%\hline
\hspace*{4mm}{\bf K}&0,0329&0,0443&0,0494&0,0539&0,0429&0,0519\\
%\hline
\hspace*{4mm}{\bf S}&0,0572&0,0495&0,0469&0,0518&0,0608&0,0499\\
%\hline
\hspace*{4mm}Sp&0,0551&0,0485&0,0486&0,0552&0,0313&0,0544\\
%\hline
\hspace*{4mm}WB&0,0491&0,0543&0,0487&{\bf 0,0784}&{\bf 0,0961}&{\bf 0,5494}\\
\hline
\end{tabular}
\end{center}
\vspace*{-12pt}
\end{table*}


\begin{table*}\small %tabl5
\begin{center}
\Caption{Оцененная вероятность ошибки первого рода, $n=1000$}
\vspace*{2ex}

\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Критерий}}& \multicolumn{6}{c|}{$r$}\\
\cline{2-7}
&\multicolumn{1}{c|}{0}&\multicolumn{1}{c|}{0,01}&
\multicolumn{1}{c|}{0,03}&\multicolumn{1}{c|}{0,07}&\multicolumn{1}{c|}{0,1}&\multicolumn{1}{c|}{0,2}\\
\hline
\hspace*{4mm}P&0,0498&{\bf 0,0957}&{\bf 0,5254}&{\bf 1}&{\bf 1}&{\bf 1}\\
%\hline
\hspace*{4mm}KS&0,0526&0,0695&{\bf 0,1428}&{\bf 0,5274}&{\bf 0,8961}&{\bf 1}\\
%\hline
\hspace*{4mm}CvM&0,0604&0,0533&0,0639&{\bf 0,1618}&{\bf 0,5154}&{\bf 1}\\
%\hline
\hspace*{4mm}AD&0,0611&0,0562&0,0553&{\bf 0,1648}&{\bf 0,4755}&{\bf 1}\\
%\hline
\hspace*{4mm}SW&0,0594&0,0695&0,0626&{\bf 0,1088}&{\bf 0,1718}&{\bf 1}\\
%\hline
\hspace*{4mm}SF&0,0529&0,0699&0,0649&{\bf 0,1038}&{\bf 0,1538}&{\bf 1}\\
%\hline
\hspace*{4mm}{\bf JB}&0,0597&0,0638&0,0529&0,0548&0,0339&0,0468\\
%\hline
\hspace*{4mm}{\bf AJB}&0,0589&0,0619&0,0509&0,0539&0,0319&0,0509\\
%\hline
\hspace*{4mm}F&0,0580&0,0591&0,0533&{\bf 0,1208}&{\bf 0,3756}&{\bf 1}\\
%\hline
\hspace*{4mm}{\bf G}&0,0515&0,0506&0,0547&0,0498&0,0479&0,0448\\
%\hline
\hspace*{4mm}HG1&0,0620&0,0627&0,0548&{\bf 0,1158}&{\bf 0,2907}&{\bf 1}\\
%\hline
\hspace*{4mm}HG2&0,0522&0,0633&0,0554&{\bf 0,0899}&{\bf 0,1328}&{\bf 1}\\
%\hline
\hspace*{4mm}{\bf K}&0,0553&0,0429&0,0528&0,0495&0,0329&0,0519\\
%\hline
\hspace*{4mm}{\bf S}&0,0561&0,0702&0,0453&0,0514&0,0425&0,0506\\
%\hline
\hspace*{4mm}Sp&0,0577&0,0469&0,0419&0,0550&0,0489&0,0627\\
%\hline
\hspace*{4mm}WB&0,0527&0,0615&0,0639&{\bf 0,09521}&{\bf 0,1478}&{\bf 1}\\
\hline
\end{tabular}
\end{center}
\vspace*{-6pt}
\end{table*}

\begin{multicols}{2}

\noindent
\begin{multline*}
\leqslant
\sum\limits_{j=1}^m \begin{pmatrix}
m\\ j
\end{pmatrix}
\mathbf{E}\,\left|X^{m-j}\left(\frac{h}{2}\right)^j\right|
\leqslant{}\\
{}\leqslant
h\sum\limits_{j=1}^m
\begin{pmatrix}
m\\ j
\end{pmatrix}
\fr{1}{2^j}\mathbf{E}\,|X|^{m-j}
\leqslant{}\\
{}\leqslant
h\sum\limits_{j=1}^m
\begin{pmatrix}
m\\ j
\end{pmatrix}
\fr{1}{2^j}\left(\mathbf{E}\,|X|^{m-1}\right)^{(m-j)/(m-1)}
\leqslant{}\\
{}\leqslant
\left[\left(\fr{3}{2}\right)^m-1\right]\max\left\{1,\mathbf{E}\,|X|^{m-1}\right\}h.
\end{multline*}
Здесь использовано, что
$$
\sum\limits_{j=1}^m
\begin{pmatrix}
m\\ j
\end{pmatrix}
\fr{1}{2^j}=\left(\fr{3}{2}\right)^m-1
$$
и что если $\mathbf{E}\,|X|^{m-1}\hm>1$, то
$$
\left(\mathbf{E}\,|X|^{m-1}\right)^{(m-j)/(m-1)}<\mathbf{E}\,|X|^{m-1}
$$
для каждого $j\hm>1$.
%\square

\smallskip

\noindent
\textbf{Теорема 2.}\ \textit{Пусть~$X$ имеет симметричное, абсолютно непрерывное, унимодальное распределение
с~конечным моментом порядка $m\hm+1$, где~$m$~--- натуральное число,
и пусть $h\hm<1$. Тогда}
$$
\left\vert \mathbf{E}\,\left[r_h(X)\right]^m-\mathbf{E}\, X^m \right\vert \leqslant
Ch^m,
$$
\textit{где $C$ не зависит от}~$h$ $($\textit{но}, \textit{возможно}, \textit{зависит от $m$ и~распределения случайной величины~$X$}).

\begin{table*}\small %tabl6
\begin{center}
\Caption{Оцененная вероятность ошибки первого рода, $n\hm=2000$}
\vspace*{2ex}

\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Критерий}}& \multicolumn{6}{c|}{$r$}\\
\cline{2-7}
&\multicolumn{1}{c|}{0}&\multicolumn{1}{c|}{0,01}&
\multicolumn{1}{c|}{0,03}&\multicolumn{1}{c|}{0,07}&\multicolumn{1}{c|}{0,1}&\multicolumn{1}{c|}{0,2}\\
\hline
\hspace*{4mm}P&0,0419&{\bf 0,1278}&{\bf 0,8901}&{\bf 1}&{\bf 1}&{\bf 1}\\
%\hline
\hspace*{4mm}KS&0,0470&0,0652&{\bf 0,2487}&{\bf 0,9181}&{\bf 1}&{\bf 1}\\
%\hline
\hspace*{4mm}CvM&0,0581&0,0533&{\bf 0,0849}&{\bf 0,5054}&{\bf 1}&{\bf 1}\\
%\hline
\hspace*{4mm}AD&0,0572&0,0528&{\bf 0,0819}&{\bf 0,4635}&{\bf 1}&{\bf 1}\\
%\hline
\hspace*{4mm}SW&0,0508&0,0547&0,0678&{\bf 0,1798}&{\bf 0,5904}&{\bf 1}\\
%\hline
\hspace*{4mm}SF&0,0522&0,0574&0,0719&{\bf 0,1718}&{\bf 0,5694}&{\bf 1}\\
%\hline
\hspace*{4mm}{\bf JB}&0,0541&0,0572&0,0534&0,0593&0,0626&0,0478\\
%\hline
\hspace*{4mm}{\bf AJB}&0,0572&0,0563&0,0564&0,0601&0,0604&0,0458\\
%\hline
\hspace*{4mm}F&0,0601&0,0489&0,0727&{\bf 0,3796}&{\bf 1}&{\bf 1}\\
%\hline
\hspace*{4mm}{\bf G}&0,0552&0,0534&0,0478&0,0469&0,0343&0,0254\\
%\hline
\hspace*{4mm}HG1&0,0631&0,0518&{\bf 0,0799}&{\bf 0,3016}&{\bf 0,9990}&{\bf 1}\\
%\hline
\hspace*{4mm}HG2&0,0537&0,0541&0,0648&{\bf 0,1568}&{\bf 0,4475}&{\bf 1}\\
%\hline
\hspace*{4mm}{\bf K}&0,0587&0,0612&0,0404&0,0489&0,0509&0,0539\\
%\hline
\hspace*{4mm}{\bf S}&0,0459&0,0507&0,0562&0,0541&0,0527&0,0408\\
%\hline
\hspace*{4mm}Sp&0,0580&0,0539&0,0512&0,0519&0,0521&{\bf 0,0938}\\
%\hline
\hspace*{4mm}WB&0,0488&0,0567&0,0651&{\bf 0,1658}&{\bf 0,5414}&{\bf 1}\\
\hline
\end{tabular}
\end{center}
\end{table*}



\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \ 
Без ограничения общности предположим, что распределение~$X$ симметрично относительно нуля. Пусть $f(x)$~---
плот\-ность распределения случайной величины~$X$. Обозначим
\begin{multline*}
p_{j,h}=\mathbf{P}\left(jh<X<(j+1)h\right)=\int\limits_{jh}^{(j+1)h}f(x)\,dx,\\
 j=0,1, 2,\ldots,
\end{multline*}
и рассмотрим следующие распределения: сим\-мет\-рич\-ное относительно нуля дис\-крет\-ное рас\-пре\-де\-ле\-ние~$G$,
да\-ющее вероятности~$p_{j,h}$ точкам~$jh$, где $j\hm=0,1,2,\ldots$; симметричное относительно нуля абсолютно
непрерывное распределение~$H$ с~ку\-соч\-но-по\-сто\-ян\-ной плот\-ностью, равной $p_{j,h}/h$ на каж\-дом интервале
$(jh,(j+1)h)$. Обозначим $m$-е моменты этих распределений~$\nu_m$ и~$\mu_m$ соответственно. Лег\-ко видеть,
что
$\nu_m<\mathbf{E}\, X^m<\mu_m$ и~$\nu_m<|\mathbf{E}\,[r_h(X)]^m<\mu_m$,
поэтому
$$
\left\vert \mathbf{E}\,\left[r_h(X)\right]^m-\mathbf{E}\, X^m \right\vert \leqslant\mu_m-\nu_m.
$$
Оценим правую часть этого неравенства. Имеем
\begin{align*}
\nu_m&=2\sum\limits_{j=0}^\infty(jh)^mp_{j,h}=2h^m\sum\limits_{j=0}^\infty j^mp_{j,h};
\\
\mu_m&=2\sum\limits_{j=0}^\infty\int\limits_{jh}^{(j+1)h}x^m
\fr{p_{j,h}}{h}\,dx={}&\\
&{}=
2h^m\sum\limits_{j=0}^\infty\fr{(j+1)^{m+1}-j^{m+1}}{m+1}\,p_{j,h}.
\end{align*}
Следовательно,

\vspace*{-6pt}

\noindent
\begin{multline*}
\mu_m-\nu_m={}\\
{}=2h^m\sum\limits_{j=0}^\infty\left(\fr{(j+1)^{m+1}-j^{m+1}}{m+1}-j^m\right)p_{j,h}
\leqslant{}\\
{}\leqslant
2h^m\sum\limits_{j=0}^\infty\fr{(j+1)^{m+1}}{m+1}\,p_{j,h}
\leqslant{}\\
{}\leqslant 2h^m\sum\limits_{j=0}^\infty\fr{(j+1)^{m+1}}{m+1}\,p_{j,1}=Ch^m.
\end{multline*}

%\square

\vspace*{-4pt}

Близость моментов по точным и~по округленным данным позволяет надеяться, что 5~критериев первой группы
(JB, AJB, G, K и~S) будут более стабильными по отношению к~округлению данных, чем критерии второй группы.
Это предположение проверяется с~по\-мощью метода статистического моделирования Мон\-те-Карло.

\begin{table*}[b]\small %tabl7
\vspace*{-3pt}
\begin{center}
\parbox{370pt}{\Caption{Эмпирическая мощность для неокругленных и~округленных данных
для четырех распределений ($n\hm=50$)}
}

\vspace*{2ex}

\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
 & \multicolumn{8}{c|}{Распределение}\\
\cline{2-9}
\multicolumn{1}{|c|}{Критерий}&\multicolumn{2}{c|}{Лапласа}&\multicolumn{2}{c|}{Стьюдента}&\multicolumn{2}{c|}{Равномерное}&\multicolumn{2}{c|}{Вейбулла}\\
\cline{2-9}
&$r=0$&$r=0{,}1$&$r=0$&$r=0{,}1$&$r=0$&$r=0{,}1$&$r=0$&$r=0{,}1$\\
\hline
\hspace*{4mm}P&0,2645&0,3576&0,1791&0,2462&0,1940&0,2284&0,1318&0,1789\\
%\hline
\hspace*{4mm}KS&0,4281&0,5265&0,2889&0,3803&0,2561&0,3546&0,2163&0,2572\\
%\hline
\hspace*{4mm}CvM&0,5494&0,582&0,3695&0,4041&0,4352&0,4762&0,2696&0,2759\\
%\hline
\hspace*{4mm}AD&0,5453&0,5836&0,4038&0,4436&0,5732&0,6058&0,3124&0,3313\\
%\hline
\hspace*{4mm}SW&0,5164&0,5417&0,4597&0,4875&0,7499&0,7655&0,4077&0,4290\\
%\hline
\hspace*{4mm}SF&0,5892&0,6153&0,5225&0,5454&0,4697&0,5075&0,3627&0,3724\\
%\hline
\hspace*{4mm}JB&0,5532&0,5721&0,5381&0,5425&0,0091&0,0124&0,2545&0,2714\\
%\hline
\hspace*{4mm}AJB&0,5673&0,5885&0,5457&0,5516&0,0001&0,0002&0,2235&0,2383\\
%\hline
\hspace*{4mm}F&0,5181&0,5535&0,3562&0,3875&0,5284&0,5525&0,2783&0,2855\\
%\hline
\hspace*{4mm}G&0,0009&0,0017&0,0025&0,0031&0,7604&0,7566&0,0895&0,0874\\
%\hline
\hspace*{4mm}HG1&0,5523&0,5911&0,4193&0,4475&0,5824&0,5975&0,3335&0,3457\\
%\hline
\hspace*{4mm}HG2&0,6182&0,6364&0,5456&0,5663&0,2217&0,2375&0,302&0,3148\\
%\hline
\hspace*{4mm}K&0,5795&0,5967&0,5446&0,554&0,7114&0,7224&0,1175&0,1338\\
%\hline
\hspace*{4mm}S&0,3577&0,3516&0,3915&0,3971&0,0019&0,0021&0,3657&0,3686\\
%\hline
\hspace*{4mm}Sp&0,6918&0,6945&0,5261&0,5283&0,8955&0,9027&0,0752&0,0782\\
%\hline
\hspace*{4mm}WB&0,5874&0,6095&0,5172&0,5383&0,4551&0,4947&0,3521&0,3656\\
\hline
\end{tabular}
\end{center}
\end{table*}

\vspace*{-9pt}

\section{Вероятность ошибки первого рода}

\vspace*{-4pt}


В этом разделе изучено, насколько хорошо\linebreak рассматриваемые критерии контролируют вероятность ошибки первого
рода. Показано, что критерии первой группы намного надежнее, чем критерии второй группы. Вероятность ошибки
\mbox{первого} рода оценивается для разных объемов выборки и~разных уровней округления. Методом
Мон\-те-Кар\-ло 10\,000~случайных выборок генерируются из нормального распределения для каждого объема выборки
$n\hm=50$, $100$, $500$, $1000$ и~$2000$. Наблюдения округлены. Все критерии применяются к~одним\linebreak\vspace*{-12pt}

\pagebreak

\noindent
 и~тем же
выборкам. Уровень значимости --- 5\%. Для каждой выборки и~каждого из~16~критериев гипотеза о~нормальности
отклоняется, если полученное P-зна\-че\-ние меньше~0,05. Для заданного критерия и~фиксированных $r$ и~$n$ доля
10\,000~выборок, для которых гипотеза отвергнута, служит оценочной вероятностью ошибки первого рода.
Результаты представлены в~табл.~2--6. Чтобы упростить анализ результатов моделирования в~этих таб\-ли\-цах,
примем следующее соглашение. Выберем определенное пороговое значение вероятности ошибки первого рода и~выделим
жирным шрифтом вероятности, превышающие этот порог. Такие значения могут рассматриваться как неприемлемые. Для
определенности считаем критерий неприемлемым, если оцениваемая вероятность ошибки первого рода на~50\%
выше уровня зна\-чи\-мости, т.\,е.~0,075 (так как уровень значимости равен~0,05).
Это соглашение весьма условно и~сделано только для удобства.
{ %\looseness=1

}




Из табл.~2--6 видно, что при большом объеме выборки критерии первой группы существенно более устойчивы 
не только к~грубому округлению, но и~к достаточно мягкому округлению. Критерий Шпигельхальтера~--- 
специальный случай. Он не
принадлежит к~первой группе, но его робастность почти не уступает робастности критериев первой группы. С~одной
стороны, это связано a~тем, что тестовая статистика критерия основана на сочетании выборочных моментов 
и~порядковых статистик и~зависимость от порядковых статистик очень слабая: только от разницы между максимальной
и~минимальной статистиками. С~другой стороны, дальнейшее моделирование показывает, что при более грубом
округлении критерий Шпигельхальтера становится существенно менее робастным, чем критерии первой группы.

\vspace*{-7pt}

\section{Эмпирическая мощность}

\vspace*{-2pt}


В этом разделе  сравнивается эмпирическая\linebreak мощность критериев в~случае точных данных ($r\hm=0$) 
и~в~случае округленных данных (для опре\-де\-лен\-ности $r\hm=0{,}1$). Показано, что, в~отличие от ве\-ро\-ят\-ности ошибки
первого рода, округление \mbox{практически} не влияет на вероятность ошибки\linebreak второго рода. Мощность исследуется для
четырех альтернативных распределений (Лапласа, Стьюдента, равномерного и~Вейбулла) и~трех различ-\linebreak ных объемов
выборки ($n\hm=50$, $100$ и~$1000$). Альтернативные распределения имеют сле\-ду\-ющие\linebreak па\-ра\-мет\-ры. Распределение Лапласа: нулевое
математическое ожидание, среднеквадратичное отклонение~--- $1/(\sqrt2r)$; распределение Стьюдента: величина $X/(\sqrt2r)$, где
$X$ имеет распределение \mbox{Стьюдента} с~4~степенями свободы; равномерное распределение: на интервале $[-\sqrt3/r,\sqrt3/r]$;
распределение Вейбулла: параметр формы~--- 2, па\-ра\-метр масштаба~--- $1/\sqrt{1-\pi/4}r$. Выбор параметров диктуется степенью
округления~$r$ при шаге дискретизации, равном единице, т.\,е.\ при округлении сформированных данных до ближайшего
целого числа.

Из каждого из четырех приведенных выше распределений генерируются 10\,000~случайных выбо-\linebreak\vspace*{-10pt}

\pagebreak

\end{multicols}

\begin{table*}\small  %tabl8
\begin{center}
\parbox{370pt}{\Caption{Эмпирическая мощность для неокругленных и~округленных данных
для четырех распределений ($n\hm=100$)}
}

\vspace*{2ex}

\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
 & \multicolumn{8}{c|}{Распределение}\\
\cline{2-9}
\multicolumn{1}{|c|}{Критерий}&\multicolumn{2}{c|}{Лапласа}&\multicolumn{2}{c|}{Стьюдента}&\multicolumn{2}{c|}{Равномерное}&\multicolumn{2}{c|}{Вейбулла}\\
\cline{2-9}
&$r=0$&$r=0{,}1$&$r=0$&$r=0{,}1$&$r=0$&$r=0{,}1$&$r=0$&$r=0{,}1$\\
\hline
\hspace*{4mm}P&0,4743&0,5931&0,3052&0,4511&0,4728&0,5147&0,2714&0,3676\\
%\hline
\hspace*{4mm}KS&0,6922&0,8298&0,5117&0,6553&0,5946&0,7382&0,3784&0,5611\\
%\hline
\hspace*{4mm}CvM&0,8152&0,8463&0,6084&0,6757&0,8388&0,8596&0,5017&0,5623\\
%\hline
\hspace*{4mm}AD&0,8136&0,8423&0,6614&0,7231&0,9412&0,9593&0,6081&0,6524\\
%\hline
\hspace*{4mm}SW&0,7790&0,7968&0,7264&0,7586&0,9945&0,9984&0,8026&0,8057\\
%\hline
\hspace*{4mm}SF&0,8254&0,8331&0,7732&0,8133&0,9654&0,9765&0,7145&0,7232\\
%\hline
\hspace*{4mm}JB&0,7823&0,7847&0,7772&0,7906&0,7212&0,7261&0,5483&0,5442\\
%\hline
\hspace*{4mm}AJB&0,7884&0,7973&0,7836&0,7925&0,5487&0,5464&0,5024&0,4771\\
%\hline
\hspace*{4mm}F&0,8072&0,8261&0,6028&0,6572&0,8893&0,9051&0,5285&0,5691\\
%\hline
\hspace*{4mm}G&0&0&0,0007&0,0010&0,9691&0,9739&0,1052&0,1057\\
%\hline
\hspace*{4mm}HG1&0,8322&0,8428&0,7033&0,7387&0,9546&0,9654&0,6521&0,6848\\
%\hline
\hspace*{4mm}HG2&0,8443&0,8532&0,7914&0,8238&0,8485&0,8593&0,6028&0,6356\\
%\hline
\hspace*{4mm}K&0,8071&0,8112&0,7914&0,8325&0,9917&0,9921&0,1781&0,1532\\
%\hline
\hspace*{4mm}S&0,4167&0,4125&0,5312&0,5146&0,0024&0,0019&0,6781&0,6871\\
%\hline
\hspace*{4mm}Sp&0,9360&0,9372&0,8078&0,8161&0,9969&0,9981&0,0452&0,0591\\
%\hline
\hspace*{4mm}WB&0,8217&0,8262&0,7691&0,8033&0,9622&0,9691&0,7084&0,7135\\
\hline
\end{tabular}
\end{center}
\vspace*{-12pt}
\end{table*}




\begin{table*}\small %tabl9
\begin{center}
\parbox{370pt}{\Caption{Эмпирическая мощность для неокругленных и~округленных данных
для четырех распределений ($n\hm=1000$)}
}
\vspace*{2ex}

\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
 & \multicolumn{8}{c|}{Распределение}\\
\cline{2-9}
\multicolumn{1}{|c|}{Критерий}&\multicolumn{2}{c|}{Лапласа}&\multicolumn{2}{c|}{Стьюдента}&\multicolumn{2}{c|}{Равномерное}&\multicolumn{2}{c|}{Вейбулла}\\
\cline{2-9}
&$r=0$&$r=0{,}1$&$r=0$&$r=0{,}1$&$r=0$&$r=0{,}1$&$r=0$&$r=0{,}1$\\
\hline
\hspace*{4mm}P&1&1&0,9901&1&1&1&1&1\\
%\hline
\hspace*{4mm}KS&1&1&1&1&1&1&1&1\\
%\hline
\hspace*{4mm}CvM&1&1&1&1&1&1&1&1\\
%\hline
\hspace*{4mm}AD&1&1&1&1&1&1&1&1\\
%\hline
\hspace*{4mm}SW&1&1&1&1&1&1&1&1\\
%\hline
\hspace*{4mm}SF&1&1&1&1&1&1&1&1\\
%\hline
\hspace*{4mm}JB&1&1&1&1&1&1&1&1\\
%\hline
\hspace*{4mm}AJB&1&1&1&1&1&1&1&1\\
%\hline
\hspace*{4mm}F&1&1&1&1&1&1&1&1\\
%\hline
\hspace*{4mm}G&0&0&0&0&1&1&0,2690&0,2677\\
%\hline
\hspace*{4mm}HG1&1&1&1&1&1&1&1&1\\
%\hline
\hspace*{4mm}HG2&1&1&1&1&1&1&1&1\\
%\hline
\hspace*{4mm}K&1&1&1&1&1&1&0,3812&0,3677\\
%\hline
\hspace*{4mm}S&0,5013&0,5031&0,7644&0,7582&0,0012&0,0008&1&1\\
%\hline
\hspace*{4mm}Sp&1&1&1&1&0&0&0,0212&0,0198\\
%\hline
\hspace*{4mm}WB&1&1&1&1&1&1&1&1\\
\hline
\end{tabular}
\end{center}
\vspace*{-4pt}
\end{table*}

\begin{multicols}{2}


\noindent
рок объема~$n$. Для
каждой выборки и~каждого из~16~критериев гипотеза о~нормальности не отвергается, если полученное P-зна\-че\-ние
больше~0,05, и~вычисляется доля случаев, когда гипотеза отвергается. Другими словами, вычисляется доля случаев,
когда P-зна\-че\-ние меньше~0,05. Это эмпирическая мощ\-ность критерия для данного альтернативного распределения 
и~данного объема выборки. 

Результаты представлены в~табл.~7--9.
Видно, что либо мощ\-ность для округленных данных (практически) такая же, как мощность для точных данных, либо
мощность для округленных данных больше, чем мощность для точных данных (критерии Пирсона и~Кол\-мо\-го\-ро\-ва--Смир\-нова).


\section{Выводы}


\noindent
\begin{enumerate}[1.]
\item  Тесты на нормальность, основанные на моментах выборки, гораздо более устойчивы к~округлению данных, чем
тесты, основанные на порядковой статистике: они существенно \mbox{лучше} контролируют вероятность ошибки первого
\mbox{рода}.

\item Вероятность ошибки второго рода практически не зависит от округления данных для всех критериев нормальности.

\item Если объем выборки большой, то критерии нормальности, основанные на порядковой статистике, не следует
использовать даже при умеренных степенях округления: контроль вероятности ошибки первого рода плохой.
\end{enumerate}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
\bibitem{1-us}
\Au{Farrell P.\,J., Rogers-Stewart~K.}
Comprehensive study of tests for normality and symmetry: Extending the Spiegelhalter test~// 
J.~Stat. Comput. Sim., 2006. Vol.~76. P.~803--816.
\bibitem{2-us}
\Au{Keskin S.}
Comparison of several univariate normality tests regarding Type~I error rate and power of the test in
simulation based on small samples~// J.~Applied Science Research, 2006. Vol.~2. P.~296--300.
\bibitem{3-us}
\Au{Yazici B., Yolacan~S.}
A~comparison of various tests of normality~// J.~Stat. Comput. Sim., 2007. Vol.~7. P.~175--183.
\bibitem{4-us}
\Au{Rom$\tilde{\mbox{a}}$o~X., Delgado~R., Costa~A.}
An empirical power comparison of univariate goodness-of-fit
tests for normality~// J.~Stat. Comput. Sim., 2010. Vol.~80. P.~545--591.
\bibitem{5-us}
\Au{Yap B.\,W., Sim~C.\,H.}
Comparisons of various types of normality tests~// J.~Stat. Comput. Sim., 2011. Vol.~81. P.~2141--2155.
\bibitem{6-us}
\Au{Schneeweiss H., Komlos~J., Ahmad~A.\,S.}
Symmetric and asymmetric rounding: A~review and some new results~// ASTA~--- Adv. Stat. Anal., 2010. Vol.~94. P.~247--271.
\bibitem{7-us}
\Au{Tricker A.\,R.}
The effect of rounding on the significance level of certain normal test statistics~// J.~Appl. Stat., 1990. Vol.~17. P.~31--38.
\bibitem{8-us}
\Au{Tricker A.\,R.}
The effect of rounding on the power level of certain normal test statistics~// J.~Appl. Stat., 1990. Vol.~17. P.~219--228.
\bibitem{9-us}
\Au{Tricker A.\,R.}
The effect of rounding on the significance level and power of certain test statistics for non-normal data~// J.~Appl. Stat., 1990. Vol.~17. P.~329--340.
\bibitem{10-us}
\Au{Tricker A.\,R.}
Effects of rounding on the moments of a~probability distribution~// J.~Roy. Stat. Soc.~D~---
Sta., 1984. Vol.~33. P.~381--390.
\bibitem{11-us}
\Au{Janson S.}
Rounding of continuous random variables and oscillatory asymptotics~// Ann. Probab., 2006. Vol.~34. P.~1807--1826.
\bibitem{12-us}
\Au{Ushakov N.\,G., Ushakov~V.\,G.}
Statistical analysis of rounded data: Measurement errors vs rounding errors~// J.~Math. Sci., 2018. Vol.~234. P.~770--773.
\bibitem{13-us}
\Au{Samsonov S.\,V., Ushakov~N.\,G., Ushakov~V.\,G.}
Estimation of the second moment based on rounded data~// J.~Mathematical Sciences, 2019. Vol.~237. P.~819--825.
\bibitem{14-us}
\Au{Ushakov N.\,G., Ushakov~V.\,G.}
Accuracy of estimating the mean from rounded data~// J.~Mathematical Sciences, 2020. Vol.~246. P.~565--568.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 20.03.22}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{-2pt}

\def\tit{TESTS FOR NORMALITY OF~THE~PROBABILISTIC DISTRIBUTION WHEN~DATA ARE~ROUNDED}


\def\titkol{Tests for normality of~the~probabilistic distribution when~data are rounded}


\def\aut{V.\,G.~Ushakov$^{1,2}$ and~N.\,G.~Ushakov$^{3,4}$}

\def\autkol{V.\,G.~Ushakov and~N.\,G.~Ushakov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-8pt}


\noindent
$^1$Department of Mathematical Statistics, Faculty of Computational Mathematics and Cybernetics, 
M.\,V.~Lomo-\linebreak
$\hphantom{^1}$nosov Moscow State University, 1-52~Leninskie Gory, GSP-1, Moscow 119991, Russian Federation

\noindent
$^2$Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, 44-2~Vavilov\linebreak
$\hphantom{^1}$Str., Moscow 119333, Russian Federation

\noindent
$^3$Institute of Microelectronics Technology and High-Purity Materials of the Russian Academy of Sciences,\linebreak
$\hphantom{^1}$6~Academician Osipyan Str., Chernogolovka, Moscow Region 142432, Russian Federation

\noindent
$^4$Norwegian University of Science and Technology, 15A~S.\,P.~Andersensvei, Trondheim 7491, Norway


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 1}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 1
\hfill \textbf{\thepage}}}

\vspace*{3pt} 



\Abste{Tests for normality are less sensitive to the data rounding than, for example, 
tests for exponentiality but among normality tests, the sensitivity is very different.
 In this paper, the authors find out which tests are more and which ones are less sensitive. 
 The authors show that tests based on sample moments are much more robust with respect to the data 
 rounding than tests based on order statistics (in contrast to the robustness with respect to outliers 
 where order statistics are more robust than sample moments). This, 
however, only applies to the probability of Type~I error. The probability of Type~II error is very 
insensitive to the data rounding for all normality tests.}

\KWE{normal distribution; test for normality; rounded data; significance level; Monte-Carlo simulation}





\DOI{10.14357/19922264230103} 

%\vspace*{-16pt}

\Ack
\noindent
The research was supported by the Ministry of Science and Higher Education of the Russian Federation, project No.\,075-15-2020-799.
  

%\vspace*{4pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
\bibitem{1-us-1}
\Aue{Farrell, P.\,J., and K.~Rogers-Stewart.}
 2006. Comprehensive study of tests for normality and symmetry: Extending the Spiegelhalter test. \textit{J.~Stat. Comput. Sim.} 76:803--816.

\bibitem{2-us-1}
\Aue{Keskin, S.}
 2006. Comparison of several univariate normality tests regarding Type~I error rate and power of the test in simulation based on small samples. 
 \textit{J.~Applied Science Research} 2:296--300.

\bibitem{3-us-1}
\Aue{Yazici, B., and S.~Yolacan.} 2007. A~comparison of various tests of normality. \textit{J.~Stat. Comput. Sim.} 7:175--183.

\bibitem{4-us-1}
\Aue{Rom$\tilde{\mbox{a}}$o X., R.~Delgado, and  A.~Costa.}
 2010. An empirical power comparison of univariate goodness-of-fit tests for normality. \textit{J.~Stat. Comput. Sim.} 80:545--591.

\bibitem{5-us-1}
\Aue{Yap, B.\,W., and C.\,H.~Sim.}
 2011. Comparisons of various types of normality tests. \textit{J.~Stat. Comput. Sim.} 81:2141--2155.

\bibitem{6-us-1}
\Aue{Schneeweiss, H., J.~Komlos, and A.\,S.~Ahmad.}
 2010. Symmetric and asymmetric rounding: A~review and some new results. \textit{ASTA~--- Adv. Stat. Anal.} 94:247--271.

\bibitem{7-us-1}
\Aue{Tricker, A.\,R.} 1990. The effect of rounding on the significance level of certain normal test statistics. \textit{J.~Appl. Stat.} 17:31--38.

\bibitem{8-us-1}
\Aue{Tricker, A.\,R.} 1990. The effect of rounding on the power level of certain normal test statistics. \textit{J.~Appl. Stat.} 17:219--228.

\bibitem{9-us-1}
\Aue{Tricker, A.\,R.} 1990. The effect of rounding on the significance level and power of certain test statistics for non-normal data. 
\textit{J.~Appl. Stat.} 17:329--340.

\bibitem{10-us-1}
\Aue{Tricker, A.\,R.} 1984. Effects of rounding on the moments of a probability distribution.
\textit{J.~Roy. Stat. Soc.~D~--- Sta.} 33:381--390.

\bibitem{11-us-1}
\Aue{Janson, S.} 2006. Rounding of continuous random variables and oscillatory asymptotics. \textit{Ann. Probab.} 34:1807--1826.

\bibitem{12-us-1}
\Aue{Ushakov, N.\,G., and V.\,G.~Ushakov.}
 2018. Statistical analysis of rounded data: Measurement errors vs rounding errors. \textit{J.~Math. Sci.} 234:770--773.

\bibitem{13-us-1}
\Aue{Samsonov, S.\,V., N.\,G.~Ushakov, and V.\,G.~Ushakov.}
 2019. Estimation of the second moment based on rounded data. \textit{J.~Mathematical Sciences} 237:819--825.

\bibitem{14-us-1}
\Aue{Ushakov, N.\,G., and V.\,G.~Ushakov.} 2020. Accuracy of estimating the mean from rounded data. \textit{J.~Mathematical Sciences} 246:565--568.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received March 20, 2022}}




\Contr

\noindent
\textbf{Ushakov Vladimir G.} (b.\ 1952)~--- 
Doctor of Science in physics and mathematics, professor, Department of Mathematical Statistics, Faculty of Computational Mathematics and Cybernetics, 
M.\,V.~Lomonosov Moscow State University, 1-52~Leninskie Gory, GSP-1, Moscow 119991, Russian Federation; 
senior scientist, Institute of Informatics Problems, Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, 
44-2~Vavilov Str., Moscow 119333, Russian Federation; \mbox{vgushakov@mail.ru}

\vspace*{3pt}

\noindent
\textbf{Ushakov Nikolai G.} (b.\ 1952)~--- 
Doctor of Science in physics and mathematics, leading scientist, Institute of Microelectronics Technology 
and High-Purity Materials of the Russian Academy of Sciences, 6~Academician Osipyan Str., Chernogolovka, Moscow Region 142432, 
Russian Federation; professor, Norwegian University of Science and Technology, 15A~S.\,P.~Andersensvei, Trondheim 7491, Norway; 
\mbox{ushakov@math.ntnu.no}

\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература}    