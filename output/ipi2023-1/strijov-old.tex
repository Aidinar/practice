\def\stat{strijov}

\def\tit{ВОССТАНОВЛЕНИЕ МАТРИЦЫ СУПЕРПОЗИЦИИ В~ЗАДАЧЕ~СИМВОЛЬНОЙ РЕГРЕССИИ$^*$}

\def\titkol{Восстановление матрицы суперпозиции в~задаче символьной регрессии}

\def\aut{Р.\,Г.~Нейчев$^1$, И.\,А.~Шибаев$^2$, В.\,В.~Стрижов$^3$}

\def\autkol{Р.\,Г.~Нейчев, И.\,А.~Шибаев, В.\,В.~Стрижов}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Нейчев Р.\,Г.}
\index{Шибаев И.\,А.}
\index{Стрижов В.\,В.}
\index{Neychev R.\,G.}
\index{Shibaev I.\,A.}
\index{Strijov V.\,V.}


{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Работа выполнена при поддержке РФФИ (проекты 20-37-90050 и~20-07-00990).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский физико-технический институт, 
\mbox{neychevr@gmail.com}}
\footnotetext[2]{Московский физико-технический институт, 
\mbox{shibaev.kesha@gmail.com}}
\footnotetext[3]{Федеральный исследовательский центр <<Информатика 
и~управ\-ле\-ние>> Российской академии наук, \mbox{strijov@phystech.edu}}

\vspace*{-10pt}
 



\Abst{Исследуется проблема порождения структуры регрессионной модели. 
Модель представляет собой суперпозицию базовых функций. Структура модели 
описывается взвешенным цвет\-ным графом. Каждая вершина графа соответствует 
некоторой базовой функции. Ребро задает суперпозицию двух функций. Вес ребра 
равен вероятности суперпозиции. Для создания оптимальной модели необходимо 
восстановить ее структуру по матрице смежности графа. Пред\-ла\-га\-емый алгоритм 
восстанавливает минимальное остовное дерево из взвешенного цветного графа. 
Пред\-став\-ле\-но новое решение, основанное на алгоритме дерева Штейнера. 
Алгоритм сравнивается с~альтернативами.}


\KW{символьная регрессия; линейное программирование; 
суперпозиция; минимальное остовное дерево; мат\-ри\-ца смеж\-ности}

\DOI{10.14357/ } 
  
%\vspace*{-4pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}

\section{Введение}

Символьная регрессия~--- это метод по\-стро\-ения нелинейной модели, 
аппроксимирующей выборку. Структура модели определяется суперпозицией базовых 
функций. Набор базовых функций фиксируется для конкретной прикладной задачи. 
Структуры альтернативных моделей генерируются алгоритмом оптимизации для выбора 
оптимальной модели. В данной статье предлагается определять структуру модели 
с~по\-мощью вероятностного графа. Остовное дерево в~графе определяет некоторую 
суперпозицию. Для выбора оптимальной модели необходимо реконструировать 
минимальное остовное дерево по графу.

Методы генетического программирования~\cite{koza1992genetic} находят оптимальное 
подмножество в~наборе суперпозиций базовых функций, но имеют высокую 
вычислительную сложность. В~\cite{searson2010gptips} описаны методы, понижающие 
сложность. Они используют дополнительные ограничения на суперпозиции, например 
используют линейные комбинации базовых функций. Символьная регрессия, 
описанная~в~\cite{stanley2002evolving}, используется для оптимизации структуры 
суперпозиции. Методы решения задачи символьной регрессии основаны на матричном 
представлении структуры модели~\cite{bochkarev2017generation}. Однако эти методы 
не содержат ограничений на чис\-ло аргументов базовых функций и~на структуру 
графа, обеспечивающую допустимую суперпозицию. В~данной работе решается задача 
построения модели с~помощью символьной регрессии.

Требуется восстановить допустимую суперпозицию из предсказанной мат\-ри\-цы 
смежности с~вероятностями ребер. Решается задача вос\-ста\-нов\-ле\-ния~$k$-минимального 
остовного дерева $k$-MST (\textit{англ.}\ Minimum-cost Spanning Tree). Эта задача NP-слож\-ная, 
поэтому применимы только при\-бли\-жен\-ные решения~\cite{ravi1996spanning}. 
Алгоритм~$k$-MST эквивалентен проб\-ле\-ме дерева Штейнера PCST (\textit{англ.}\ 
Prize-Collecting Steiner Tree) из-за его эквивалентности ослабленной формулировке 
постановки задачи линейного программирования~\cite{chudak2004approximate}. 
В~работах~\cite{ravi1996spanning,awerbuch1998new,arora20062+} пред\-став\-ле\-ны 
приближенные решения задачи \mbox{$k$-MST}.



Предлагаемое решение основано на упрощенной версии задачи~$k$-MST, которая 
трансформируется в~задачу PCST с~постоянными призами, одинаковыми для всех 
вершин. Быст\-рый алгоритм PSCT описан в~\cite{hegde2014fast}. Альтернативное 
решение основано на алгоритме~$(2-\varepsilon)$-аппроксимации для задачи PSCT. 
Она сравнивается с~другими алгоритмами, включая алгоритмы обхода дерева в~глубину, обхода дерева в~ширину, алгоритмы Прима.

\begin{table*}[b]\small  %tabl1
\vspace*{-12pt}
\begin{center}
        \parbox{300pt}{\Caption{Вероятности суперпозиций в~матрице смежности порождают 
ориентированный граф}

}
    \label{restored_adjacency_matrix}
\vspace*{2ex}

        \begin{tabular}{|c|c|ccccccc|}
            \hline
            Арность&Функция&$\ast$&$+$&$\ln$&$\sin$&$\times$&$\exp$&$x$\\
            \hline
            $1$&$\ast$ &0,2&{\bf 0,7}&0,5&0,4&0,5&0,3&0,2\\
            $3$&$+$    &0,3&0,2&{\bf 1,0}&{\bf 0,8}&0,6&0,3&{\bf 0,7}\\
            $1$&$\ln$  &0,3&0,2&0,0&0,0&0,1&0,5&{\bf 0,5}\\
            $1$&$\sin$ &0,1&0,4&0,0&0,5&{\bf 0,9}&0,2&0,5\\
            $2$&$\times$&0,3&0,0&0,3&0,5&0,0&{\bf 0,8}&{\bf 0,6}\\
            $1$&$\exp$ &0,3&0,3&0,4&0,1&0,5&0,4&{\bf 0,4}\\
            \hline
        \end{tabular}
\end{center}
\end{table*}

\vspace*{-12pt}


\section{Задача выбора регрессионной модели}

\vspace*{-3pt}

Требуется выбрать регрессионную модель~$\varphi$ из набора альтернативных 
моделей. Модель описывает выборку~$D=\{(x_i,y_i)\}$ и~минимизирует ошибку

\noindent
\begin{equation}
\hat{\varphi}(D)=\mathop{\argmin}\limits_\varphi\sum\limits_{i=1}^m\left(\varphi(x_i)-
y_i\right)^2.
\label{task_1}
\end{equation}
Модель представляет собой суперпозицию базовых функций из некоторого заданного 
набора. На рис.~1 показан ее пример. Структура модели~$\varphi$, 
суперпозиция, соответствует графу~$G=(V,E)$, где базовые функции находятся 
в~вершинах~$V$. {Корневая} вершина обозначается через~$\ast$. Модель:
$$
\varphi(D) =  \ln(x) + x + \sin\left( x\times \exp(x)\right).
$$
 Еe структура в~виде матрицы 
смежности графа пред\-став\-ле\-на~в табл.~\ref{restored_adjacency_matrix}.
Базовые функции перечислены в~первой строке. Элементами матрицы являются 
вероятности ребер~$E$ дерева. Жир\-ным шриф\-том выделены ребра восстановленного 
дерева~$M$, образующие суперпозицию~$\varphi$. Для восстановления структуры 
модели~$\varphi$ как суперпозиции, заданной деревом~$M$, необходимы только 
графовое пред\-став\-ле\-ние~$G$~и~базовые функции.

{ \begin{center}  %fig1
 \vspace*{6pt}
    \mbox{%
\epsfxsize=37.447mm
\epsfbox{str-1.eps}
}

\end{center}



\noindent
{{\figurename~1}\ \ \small{Структура регрессионной модели представляет собой ориентированный 
граф
}}}

%\vspace*{6pt}

\addtocounter{figure}{1}





Поставим задачу восстановления структуры модели. Задано множество 
выборок~$\{D_k\}$. Каждой выборке~$D_k$ соответствует своя модель. Эта модель 
имеет структуру~$M_k$. Таким образом, имеется набор пар $\{(D_k, M_k)\}$, 
выборка и~структура.
Обозначим через~$P$ отображение, которое предсказывает вероятности узлов 
в~графе~$G$ по выборке~$D$. Для выбора модели~$\varphi(D)$ необходимо восстановить 
структуру модели~$M$ по графу~$G$. Обозначим алгоритм восстановления дерева 
через~$R$. Регрессионная модель~$\hat{\varphi}(D)$, которая решает 
задачу~(\ref{task_1}), определяется формулой
$
\hat{M}=R\left(P(D)\right).
$
Поскольку дерево~$M$ играет центральную роль в~этой работе, критерий качества 
алгоритма восстановления дерева имеет вид:


\vspace*{-2pt}

\noindent
$$
\min_{M_k \in G} \fr{1}{K}\sum\limits_{k=1}^K \left[ \hat{M_k} = M_k\right].
$$

\vspace*{-2pt}

\noindent
Восстановленное дерево должно быть эквивалентно заданному дереву, следовательно, 
выбранная модель регрессии при\-бли\-жа\-ет выборку.

\vspace*{-12pt}

\section{Задача восстановления дерева суперпозиции}

\vspace*{-3pt}

Требуется восстановить дерево~$M_k$, задающее  суперпозицию и~решающее 
задачу~(\ref{task_1}). Задан ориентированный взвешенный граф~$G\hm=(V,E)$ 
с~раскрашенными вершинами~$v_i$ и~корневой вершиной~$r$. Каждая вершина~$v_i \hm\in 
V$ имеет свой цвет~$t(v_i)\hm=t_i$. Каждое реб\-ро~$e_i\in E$ имеет свой 
вес~\mbox{$w(e_i)\hm=c_i\hm\in[0,1]$}.

Требуется восстановить ориентированное дерево минимального веса с~корнем~$r$. 
Оно должно покрывать не менее~$k$ вершин в~заданном графе~$G$. Чис\-ло ребер, 
выходящих из вершины~$v_i$ дерева, должно быть меньше или равно~$t_i$. 
Корень~$r$ имеет одно ребро,~$t_r=1$.

Сформулируем это условие в~виде задачи линейного программирования 
с~целочисленными ограничениями:

\vspace*{2pt}

\noindent
\begin{equation}
\left.
\begin{array}{rll}
\underset{\substack{{x_e, z_S} \\ e\in E,\\ S\subseteq V\backslash 
\{r\}}}{\mbox{minimize}} & \displaystyle \sum\limits_{e\in E}c_ex_e &\\[6pt]
\mbox{s.t.}\ & \displaystyle  \sum\limits_{\substack{{e\in\delta(S):}\\ e=(\ast,v_i),\\ v_i\in\delta(S)}} \!\!\!\! x_e + 
\sum\limits_{T:T\supseteq S}  \!\!\!\! z_T\geqslant 1, & S\subseteq 
V\backslash \{r\},\\[6pt]
& \displaystyle \sum\limits_{e\in E:~e=(\ast,v)} \! x_e\leqslant 1, & v\in V,\\[6pt]
& \displaystyle \sum\limits_{e\in E:~e=(v,\ast)}x_e\leqslant t_i, & v\in V,\\[6pt]
& \displaystyle \sum\limits_{S\subseteq V\backslash \{r\}}|S|z_S \leqslant n-k,\\[6pt]
& x_e\in\{0,1\}, & e\in E,\\[6pt]
& z_S\in\{0,1\}, & S\subseteq V\backslash \{r\},
\end{array}\!
\right\}\!
\label{ilp_our}
\end{equation}
где~$x_e = 1$, если ребро~$e$ входит в~финальную суперпозицию, и~$x_e \hm= 0$ 
в~противном случае, $z_S\hm = 1$ для всех вершин, исключенных из финальной 
суперпозиции. Обозначим через~$e\hm=(\ast, v)$ ориентированное ребро с~листом~$v$. 
Обозначим через $e\hm=(v, \ast)$ ориентированное ребро с~вершиной~$v$.

Первое ограничение~(\ref{ilp_our})  определяет структуру графа решения в~виде 
дерева с~корнем~$r$. Второе ограничение определяет ориентацию дерева: каждая 
вершина имеет не более одного входящего ребра. Третье ограничение определяет 
арность используемых базовых функций, поэтому число ребер, имеющих определенную 
вершину в~качестве источника, фиксировано. Четвертое ограничение говорит, что 
итоговое дерево имеет не менее~$k$ вершин. Если все веса неотрицательны, то 
четвертое ограничение на минимальное число вершин принимает более строгий вид: 
число вершин должно быть равно~$k$. Однако более слабое ограничение позволяет 
найти возможные связи с~другими оптимизационными задачами. Ограничения 
в~(\ref{ilp_our}) преследуют ту же цель.

\vspace*{-9pt}

\section{Алгоритмы восстановления дерева $k$-MST и~PCST}

\vspace*{-3pt}

\noindent
\textbf{Определение~1} (\textbf{$k$-минимальное остовное дерево, $k$-MST}).
Задан взвешенный граф~$G\hm=(V,E)$ с~корнем~$r$ и~весами ребер~$w(e_i)\hm=c_i\hm\geqslant 
0$, $e_i\hm\in E$. Требуется построить ориентированное дерево минимального веса 
с~корнем~$r$, покрывающее не менее~$k$ вершин в~$G$.

\smallskip

Если та же задача ставится для ориентированных графов, то конечное дерево 
с~корнем~$r$ должно быть ориентированным. Задача линейного программирования для 
направленного~$k$-MST исключает третье условие в~(\ref{ilp_our}).
В~таком виде задача~$k$-MST отличается от исходной задачи восстановления 
дерева суперпозиций~(\ref{ilp_our}) отсутствием третьего ограничения на арность 
базовых функций. Это эквивалентно ограничению на число ребер, выходящих из 
вершины.

\smallskip

\noindent
\textbf{Определение~2} (\textbf{призовое дерево Штейнера, $\text{PCST}$}).
Задан взвешенный граф $G\hm=(V,E)$ с~корнем~$r$ и~весами ребер~$w(e_i)\hm=c_i\hm\geqslant  0$, $e_i\hm\in E$, где каждой вершине~$v_i \hm\in V$ присвоен 
{приз} $\pi(v_i)\hm=\pi_i\geqslant 0$. Требуется построить дерево~$T$ с~корнем~$r$, 
которое минимизирует функционал
$$
\sum\limits_{e\in E}c_ex_e + \sum\limits_{S\subseteq V\backslash\{r\}} 
\pi(S)z_S,
$$
где~$x_e\in\{0, 1\}$, $x_e\hm=1$, если~$e\hm\in E$ входит в~тройку~$T$, $z_S\hm\in\{0, 1\}$, 
$z_S\hm=1$ для всех вершин, исключенных из дерева~$T$, $S \hm= V\backslash V(T)$ и~$\pi(S)\hm= \sum\nolimits_{v\in S}\pi(v)$.

\smallskip

В случае ориентированных графов эта задача обобщается до~асимметричной задачи 
A-PCST. Задача линейного программирования для~A-PCST принимает вид:
\begin{equation}
\left.
\begin{array}{rll}
\!\!\!\underset{\substack{x_e,z_S \\ e\in E,\\ S\subseteq V\backslash \{r\}}}{\mbox{minimize}} & 
\displaystyle \sum\limits_{e\in E} c_e x_e + \sum\limits_{S\subseteq V\backslash\{r\}}  \!\!\!\!\!\pi(S)z_S &\\[6pt]
\!\!\!\mbox{s.t.} & \displaystyle \sum\limits_{\substack{e\in\delta(S):\\e=(\ast,v_i),\\ v_i\in\delta(S)}} \!\!\!\!\!\! x_e + 
\!\sum\limits_{T:T\supseteq S}  \!\!\! z_T\geqslant 1, & S\subseteq  V\backslash \{r\},\\[6pt]
\!\!\!& \displaystyle \sum\limits_{e\in E:~e=(\ast,v)} \!\!\!\!\!\!\!\! x_e\leqslant 1, & v\in V,\\[6pt]
\!\!\!& x_e\in\{0,1\}, & e\in E,\\[6pt]
\!\!\!& z_S\in\{0,1\}, & S\subseteq V\backslash \{r\}.
\end{array}\!
\right\}\!
\label{ilp_pcst_ord}
\end{equation}
Если последнее ограничение из~(\ref{ilp_our}) входит в~оптимизируемый 
функционал, задачи $k$-MST и~A-PCST имеют эквивалентные 
ограничения и~отличаются только оптимизируемым функционалом. Такое 
преобразование возможно согласно условиям Ка\-ру\-ша--Ку\-на--Так\-ке\-ра~\cite{ras2017approximate}. Если значения призов 
эквивалентны $\pi(v) \hm=  \lambda$, единственное отличие состоит в~постоянном члене~$\lambda(n\hm-k)$. Таким 
образом, задачи оптимизации~$k$-MST и~A-PCST принимают вид:
\begin{align*}
\underset{\substack{x_e,z_S \\ e\in E,\\ S\subseteq V\backslash \{r\}}}{\mbox{minimize}} & 
\sum\limits_{e\in E}c_ex_e + \lambda\left(\sum\limits_{S\subseteq V\backslash \{r\}}|S|z_S - (n-k)\right),\\ 
\underset{\substack{x_e,z_S \\ e\in E,\\ S\subseteq V\backslash \{r\}}}{\mbox{minimize}} & 
\sum\limits_{e\in E}c_ex_e + \lambda\sum\limits_{S\subseteq V\backslash\{r\}}|S|z_S\,. 
\end{align*}

Константа~$\lambda$ обозначает неотрицательный множитель Лагранжа в~задаче~$k$-MST и~приз за вершину 
в~задаче~A-PCST. 
Существует несколько алгоритмов для решения проблемы~PCST, но не для 
решения проб\-ле\-мы A-PCST. Возможное решение~--- снять 
ограничения на ориентацию графа, чтобы алгоритм~PCST мог позже 
восстановить ориентацию дерева.

\vspace*{-9pt}

\section{Решение задачи восстановления ограниченного леса с~помощью алгоритма 
$(2-\varepsilon)$-приближения}

\vspace*{-3pt}

Обзор методов решения задачи восстановления ограниченного леса представлен 
в~\cite{goemans1995general}. Задан взвешенный неориентированный граф~$G\hm=(V,E)$. 
Все его веса~$w(e_i)\hm=c_i\geqslant 0$, $e_i\hm\in E$. Задана некоторая 
функция~$f:2^{V}\to \{0, 1\}$. Требуется решить задачу линейного 
программирования с~целочисленными ограничениями:
\begin{equation}
\left.
\begin{array}{rll}
\underset{x_e:~e\in E}{\mbox{minimize}} & \displaystyle \sum\limits_{e\in E}c_ex_e &\\[6pt]
\mbox{s.t.} & x\left(\delta(S)\right)\geqslant f(S), & S \subset V, \; S \not= \emptyset,\\[6pt]
& x_e\in\{0,1\}, & e\in E,
\end{array}
\right\}
\label{ilp_cfp}
\end{equation}
где~$x(\delta(S))\hm=\sum\nolimits_{e\in \delta(S)}x_e$; $x_e\hm=1$, если 
ребро~$e$ входит в~финальное решение. Функция~$\delta(S)$ обозначает все ребра 
из~$E$ такие, что только одна из смежных вершин входит в~$S$.

Предположим, что отображение~$f$ удовлетворяет условиям
\begin{gather*}
f(V) = 0,\\
 \underbrace{f(S)=f(V\backslash S)}_{\mathrm{симметричность}},\\
\underbrace{A,B\!\subset\! V\!: A\!\cap\! B\! =\! \emptyset, f(A)\!=\!f(B)\!=\!0\!\to\! f(A\!\cup\! B)\! =\! 0}_{\mathrm{дизъюнктивность}}.
\end{gather*}
При выполнении этих условий~$f$ задает число ребер, начинающихся в~множестве 
вершин~$S$.

\smallskip

\noindent
\textbf{Лемма 1.}
\textit{Пусть $B\subseteq S\subset V$. Тогда $f(S) \hm= 0$ и~$f(B) \hm= 0$ приводит к}~$f(S\backslash B) \hm= 0$.

\smallskip

Задача с~таким описанием относится к~\textit{задачам поиска оптимального леса с~ограничениями}. 
Такая постановка задачи~(\ref{ilp_cfp}) с~соответствующим 
отображением~$f$ подходит для многих известных задач взвешенных графов, 
например: минимальный магистральный поиск, $st$-путь, задача Штейнера на 
минимальном дереве. Последняя задача является NP-полной, поэтому применим 
приближенный алгоритм.

\smallskip

\noindent
\textbf{Определение 3} (\textbf{алгоритм $\alpha$-аппроксимации}).
Эвристический полиномиальный алгоритм, дающий решение некоторой задачи 
оптимизации, называется $\alpha$-ап\-прок\-си\-ма\-ци\-ей, если он гарантирует 
удовлетворяющее ограничениям решение этой задачи оптимизации с~коэффициентом, 
меньшим или равным~$\alpha$, так что решение отличается от оптимального не более 
чем в~$\alpha$ раз по оптимизируемому функционалу.


\smallskip

Чтобы предложить приближенный алгоритм, целочисленные ограничения 
в~(\ref{ilp_cfp}) должны быть ослаблены:
\begin{equation}
\left.
\begin{array}{rll}
\underset{x_e:~e\in E}{\mbox{minimize}} & \displaystyle \sum\limits_{e\in E}c_ex_e \\[6pt]
\mbox{s.t.} & \displaystyle \sum\limits_{e\in \delta(S)}x_e\geqslant f(S), & S \subset V\,, \ S \not= \emptyset\,,\\[6pt]
& x_e>0, & e\in E,
\end{array}
\right\}
\label{rlp_cfp}
\end{equation}
Двойственная задача принимает вид:
\begin{equation}
\left.
\begin{array}{rll}
\underset{y_S:~S \subset V, \; S \not= \emptyset}{\mbox{maximize}} & 
\displaystyle \sum\limits_{S\subset V}f(S)y_S \\[6pt]
\mbox{s.t.} & \displaystyle \sum\limits_{S:~e\in \delta(S)}y_S\leqslant c_e, & e\in E\,,\\[6pt]
& y_S>0, &S \subset V, \; S \not= \emptyset\,,
\end{array}
\right\}
\label{rd_cfp}
\end{equation}
относительно дополнительного условия
$$
y_S\cdot \left(\sum\limits_{e\in \delta(S)}x_e - f(S)\right) = 0\,,\enskip S\subset  V\,.
$$

Обозначим множество вершин $A=\{v\hm\in V: f(\{v\})\hm=1\}$. Предлагается адаптивный 
жадный алгоритм $\left(2-{2}/{\vert A\vert }\right)$-ап\-прок\-си\-ма\-ции для задач 
вида~(\ref{ilp_cfp}). Алгоритм состоит из двух этапов. На первом этапе он жадно 
объединяет кластеры вершин, увеличивая двойственные переменные~$y_S$. Изначально 
каждая вершина принадлежит своему кластеру. Если следующее ребро~$e$ достигает 
равенства в~ограничениях в~(\ref{rd_cfp}), это ребро добавляется к~множеству~$S$ и~связанные кластеры объединяются. Этот этап аналогичен алгоритму минимального 
остовного дерева Крускала. На втором этапе из конечного множества~$S$ удаляются 
некоторые ребра. Если обрезка ребра не нарушает ограничений, то это реб\-ро должно 
быть удалено.


Индекс $Z_{\mathrm{DRLP}}$ в~алгоритме~1 обозначает линейное 
программирование с~двойной релаксацией. Начальное значение $F:=\emptyset$ 
в~алгоритме~1 эквивалентно предположению $x_e \hm= 0$, $ e \hm\in E$. 
По условиям нежесткости $y_S \hm= 0$, $S \hm\subset V$,  $S \hm\not= \emptyset$.

На каждом шаге алгоритма кластер $\mathcal{C}$ содержит две компоненты 
$\mathcal{C} \hm= \mathcal{C}_i \hm\cup \mathcal{C}_a$, где $C\hm\in\mathcal{C }_a$, если 
$f(C) \hm= 1$, и~$C\hm\in\mathcal{C}_i$ в~противном случае. Назовем~$\mathcal{C}_a$ 
активным компонентом.
Переменные~$d(v)$ в~этом алгоритме связаны с~переменными~$y_S$ из~(\ref{rd_cfp}) 
соотношением~$d(i) \hm= \sum\nolimits_{S:i\in S}y_S.$ 

Рассмотрим две различные компоненты $C_q$,$C_p$, $C_q\cap C_p\hm=\emptyset$, на 
некоторой итерации первого этапа алгоритма. Все~$y_S$ должны быть равномерно 
распределены по некоторому~$\varepsilon$ без нарушения ограничений
$$
\sum\limits_ {S:~e\in \delta(S)}y_S\leqslant c_e. 
$$
В терминах $d(v)$ это условие принимает вид $\sum\limits_{S:~e\in \delta(S)}y_S 
\hm= d(v_1)\hm+d(v_2)$, $e\hm=( v_1,v_2),$
поэтому $y_S\hm=0$ для любого~$S$, такого что $v_1, v_2\hm\in S$, потому что 
компоненты растут только на первом этапе. Увеличение некоторых компонент на~$\varepsilon$ приводит к~уравнению
$$
d(v_1)+d(v_2)+\varepsilon\cdot \left(f(C_q)+f(C_p)\right)\leqslant 
c_e,\ e=\left(v_1,v_2\right), 
$$
что приводит к~формуле, используемой в~строке~$10$ алгоритма~1. 
В~случае, когда в~состав входит следующее ребро, сумма $\sum\nolimits_{S:~e\in 
\delta (S)}y_S$ не будет увеличиваться, поэтому ограничения выполняются.

Ребра, которые можно удалить из~$F$ без добавления новых активных компонентов, 
удаляются на втором этапе алгоритма. Следующая лемма определяет свойства 
компонент связ\-ности в~$F'$.


\smallskip

\noindent
\textbf{Лемма~2.}\
\textit{Для каждой компоненты связ\-ности~$N$ из~$F'$ выполняется равенство}: $f(N)\hm=0$.

\smallskip

Следующая теорема утверждает, что решение, полученное с~помощью описанного 
алгоритма, удовлетворяет ограничениям исходной задачи линейного 
программирования.

\smallskip

\noindent
\textbf{Теорема~1.}
\textit{Набор ребер $F'$, полученный алгоритмом~$1$, удовлетворяет всем 
ограничениям исходной задачи}~(\ref{ilp_cfp}).


\smallskip

\noindent
\textbf{Лемма~3.}\
\textit{Обозначим граф $H$, каждая вершина которого соответствует одной из компонент 
связ\-ности $C\in\mathcal{C}$ на фиксированном шаге алгоритма. Ребро $(v_1,v_2)$ 
присутствует, если существует ребро $\hat{e}$ исходного графа, входящее в~$F'$: 
$\hat{e} \in F'$, поэтому граф $H$~--- это лес. Внут\-ри $H$ нет листовых вершин, 
со\-от\-вет\-ст\-ву\-ющих неактивным вершинам исходного графа}.

\smallskip

\noindent
\textbf{Теорема 2.}
\textit{Алгоритм~$1$ представляет собой $\alpha$-при\-бли\-жен\-ный алгоритм для 
задачи}~(\ref{ilp_cfp}) \textit{с}~$\alpha \hm= 2 - {2}/{|A|}$, \textit{где} $A\hm=\{v\  V: 
f(\{v\})=1\}$.

\smallskip

Несмотря на эту теоретическую основу, не существует подходящей функции $f$ для 
постановки задачи PCST, указанной в~(\ref{ilp_cfp}). Чтобы быть 
применимым в~этих условиях, алгоритм~1 нуждается в~нескольких 
модификациях.

\vspace*{-9pt}

\section{Модифицированная постановка задачи для~PCST}

\vspace*{-3pt}

Как и~в случае A-PCST, упрощенный вид задачи линейного 
программирования PCST принимает вид:
\begin{equation}
\left.
\begin{array}{rll}
\!\!\!\underset{\substack{x_e,s_v \\ e\in E, v\in V\backslash \{r\}}}{\mbox{minimize}} & 
\displaystyle \sum\limits_{e\in E}c_ex_e + \sum\limits_{v\in V\backslash\{r\}}\!\! \left(1-s_v\right)\pi_v &\\[6pt]
\!\!\!\mbox{s.t.} & \displaystyle \sum\limits_{e\in\delta(S)} \!\! x_e\geqslant s_v, & \hspace*{-22mm}S\subseteq V\backslash \{r\},~v\in S,\\[6pt]
\!\!\!& x_e\geqslant 0, & \hspace*{-22mm}e\in E,\\[6pt]
\!\!\!& s_v\geqslant 0, & \hspace*{-22mm}v\in V\backslash \{r\}.
\end{array}
\right\}
\label{rlp_pcst_inord}
\end{equation}
Эта постановка задачи отличается от исходной~(\ref{ilp_pcst_ord}) тем, что с~ней 
возможно согласовать задачу $k$-MST. Индикаторы~$s_v$ показывают, что 
вершина~$v$ включена в~дерево.

Двойственная задача принимает вид:
\begin{equation}
\left.
\begin{array}{rll}
\underset{\substack{y_S:~S\subset V\backslash\{r\}}}{\mbox{maximize}} & 
\displaystyle \sum\limits_{S\in V\backslash\{r\}}y_S &\\[6pt]
\mbox{s.t.} & \displaystyle \sum\limits_{S:e\in\delta(S)}y_S\leqslant c_e , & e\in 
E,\\[6pt]
& \displaystyle \sum\limits_{S\subseteq T}y_S\leqslant \sum\limits_{v\in T}\pi_v, & T\subset 
V\backslash\{r\},\\[6pt]
& y_S\geqslant 0, & S\subset V\backslash\{r\}.
\end{array}
\right\}
\label{rd_pcst_inord}
\end{equation}

Алгоритм~2 решает эту задачу. Он похож на 
алгоритм~1. Двойные переменные должны обновляться равномерно 
с~дополнительными ограничениями. Тогда~$\varepsilon$ примет минимальное из двух 
значений в~соответствии с~обеими группами ограничений.
Более широкий анализ аппроксимационных свойств обновленного алгоритма 
представлен в~\cite{goemans1995general}. Алгоритм~2 представляет 
собой $\alpha$-приближенный алгоритм для задачи PCST с~$\alpha \hm= 2 \hm- 
{2}/({n-1})$, где $n$~--- число вершин в~графе~$G$.

\vspace*{-9pt}

\section{Вычислительный эксперимент}

\vspace*{-3pt}

Основная цель эксперимента~--- восстановить дерево суперпозиции. Алгоритмы, 
используемые для восстановления, перечислены ниже.

\vspace*{-12pt}

\paragraph*{DFS, BFS.}
Алгоритмы жадного дерева обхода в~глубину и~жадного дерева обхода в~ширину. 
Обход ребер с~наибольшим весом эквивалентен выбору наиболее вероятного пути. 
Алгоритм обхода останавливается, когда число ребер, исходящих из некоторой 
вершины, становится равным арности соответствующей функции.

\vspace*{-12pt}

\paragraph*{Алгоритм Прима.}
Алгоритм восстанавливает минимальное остовное дерево для графа с~дополнительными 
ограничениями на арность базовых функций. Эти ограничения задают минимальный вес 
ребра. После добавления вершины все листовые ребра этой вершины исключаются, 
чтобы сохранить направление дерева. Если число ребер, начинающихся в~какой-либо 
вершине, превышает соответствующую арность, то остальные ребра исключаются из 
множества возможных ребер в~этой вершине. Алгоритм не зависит от процедуры 
обхода. В случае небольшого шума в~матрице смежности этот алгоритм способен 
восстановить дерево суперпозиции без ошибок. 


\vspace*{-12pt}

\paragraph*{Алгоритмы на основе PCST.}
Матрица смежности~$M$ должна быть приведена к~неориентированному виду. 
Использована квадратная матрица~$M'$ без последнего столбца. PCST 
принимает мат\-ри\-цу смеж\-ности $1 \hm- ({1}/{2})(M' \hm+ M'^{\mathsf{T}})$ с~призовым 
значением~0,5 для каждой вершины.
Призовое значение равно~0,5, поскольку при меньших значениях дерево будет 
обрезано: если шум равен~0,5, некоторые вершины могут быть обрезаны по ошибке. 
В~случае больших призовых значений дерево PCST может содержать ненужные 
вершины. Дерево восстанавливается по одному из описанных алгоритмов. Результаты 
$\text{PCST}$ можно использовать в~качестве априорных для других подходов, $M':=({1}/{2})(M_{\mathrm{PCST}}' + M')$,
поэтому результаты PCST обновляются~$M'$.

{ \begin{center}  %fig2
 \vspace*{6pt}
    \mbox{%
\epsfxsize=79mm
\epsfbox{str-2.eps}
}
\end{center}



\noindent
{{\figurename~2}\ \ \small{Качество алгоритмов восстановления с~базовыми функциями небольших 
арностей
}}}

%\vspace*{6pt}

\addtocounter{figure}{1}

Процедура генерации данных имеет следующие допущения: арности функций 
генерируются биномиальным распределением, поэтому существует много функций 
с~малой арностью, все базовые функции имеют только один вход. Любой случай 
с~частичной реконструкцией считается ошибкой. Качество алгоритмов реконструкции
$$
\fr{1}{K}\sum\limits_{k=1}^K \left[ R\left( \bar{N}(M_k)\right)=M_k\right],
$$
где~$R$ ~--- алгоритм реконструкции, а~$\bar{N}=\left(N \hm-
\min(N)\right)/\left(\max(N)\hm-\min(N)\right)$~--- нормированная мат\-ри\-ца шума. 
Мат\-ри\-ца~$N$ генерируется как~$N(M)\hm=M\hm+U(-\alpha,\alpha)$.
Генератор случайных чисел возвращает матрицу того же вида, что и~$M$, где каждый 
элемент является независимой переменной из равномерного распределения 
в~сегменте~$[-\alpha,\alpha]$.

Вот список из семи сравниваемых алгоритмов:
DFS,
BFS,
алгоритм Прима,
$k$-MST через PCST,
$k$-MST\;+\;DFS,
$k$-MST\;+\;BFS,
$k$-MST\;+\;ал\-го\-ритм Прима.
На рис.~2 показана ошибка алгоритмов реконструкции 
с~шумом, близ\-ким к~порогу~0,5. Наилучшие результаты дает алгоритм Прима. Второе по 
точности решение основано на~$\text{BFS}$. Таб\-ли\-ца~2 
соответствует~рис.~2 и~показывает качество реконструкции 
семи алгоритмов для значений граничного шума~0,50--0,58.





%\begin{table*}\small  %tabl2
\begin{center}
\parbox{75mm}{{{\tablename~2}\ \ \small{Качество алгоритмов реконструкции с~равномерным шумом, близким 
к~0,5
}}
}
    
    
\vspace*{6pt}

  {\small  \begin{tabular}{|l|ccccc|}
      \hline
                  & \multicolumn{5}{c|}{Шум}\\%& & Шум & & \\
       \cline{2-6}
        \multicolumn{1}{|c|}{\raisebox{6pt}[0pt][0pt]{Алгоритм}}                          
&0,50&0,52&0,54&0,56&0,58\\
                    \hline
      DFS        &0,20 &0,20 &0,19 &0,18 &0,16\\
      BFS        &0,60 &0,58 &0,51 &0,46 &0,40\\
      Прима    &1,00 &0,94&0,81&0,69&0,57\\
      $k$-MST     &0,17 &0,16 &0,14 &0,12 &0,10\\
      $k$-MST-DFS   &0,17 &0,16 &0,16 &0,14 &0,14 \\
      $k$-MST-BFS   &0,43 &0,40 &0,36 &0,33 &0,29 \\
      $k$-MST-Прима  &0,44 &0,39 &0,34 &0,33 &0,27 \\
      \hline
    \end{tabular}
    }
\end{center}
%\end{table*}

\vspace*{-9pt}

\section{Заключение}

\vspace*{-3pt}

Предлагаются и~сравниваются  алгоритмы вос\-ста\-нов\-ле\-ния суперпозиции для задачи 
символьной регрессии. Алгоритм Прима дает наиболее точ\-ные результаты и~устойчив 
к~небольшому шуму в~данных. Пред\-ла\-га\-емый алгоритм дает точные результаты, но он 
более подвержен шуму в~мат\-ри\-це суперпозиции. Алгоритмы, основанные на BFS и~DFS, 
не могут вос\-ста\-но\-вить исходную суперпозицию с~зашумленными мат\-ри\-ца\-ми 
суперпозиции. Алгоритм PCST с~BFS, используемый для реконструкции мат\-ри\-цы 
суперпозиции, показывает приемлемые для практического использования результаты.

{\small\frenchspacing
 {%\baselineskip=10.8pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
\bibitem{koza1992genetic} 
\Au{Koza J.\,R.} Genetic programming as a means for programming computers by 
natural selection~// Statistics Computing, 1994. Vol.~4. P.~87--112.

\bibitem{searson2010gptips}
\Au{Searson~D.\,P., Leahy~D.\,E., Willis~M.\,J.} GPTIPS: An open source 
genetic programming toolbox for multigene  symbolic regression~// 
Multiconference (International) of Engineers and Computer Scientists Proceedings, 
2010. Vol.~1. P.~77--80.

\bibitem{stanley2002evolving}
\Au{Stanley~K.\,O., Miikkulainen~R.} Evolving neural networks through 
augmenting topologies~// Evolutionary Computation, 2002. Vol.~10. 
Iss.~2. P.~99--127.

\bibitem{bochkarev2017generation}
\Au{Бочкарев~А.\,М., Софронов~И.\,Л., Стрижов~В.\,В.} Порождение экс\-перт\-но-ин\-тер\-пре\-ти\-ру\-емых 
моделей для прогноза проницаемости горной породы~// Системы и~средства информатики, 2017. Т.~27. №\,3. С.~74--87.
%

\bibitem{ravi1996spanning}
\Au{Ravi~R., Sundaram~R., Marathe~M.\,V., Rosenkrantz~D.\,J., Ravi~S.\,S.} 
Spanning trees~--- short or small~// SIAM J.~Discrete Mathematics, 
1996. Vol.~9. Iss.~2. P.~178--200.

\bibitem{chudak2004approximate}
\Au{Chudak~F.\,A.,  Roughgarden~T., Williamson~D.\,P.} Approximate $k$-MSTS 
and $k$-Steiner trees via the primal-dual method and Lagrangean 
relaxation~// Mathematical Programming, 2004. Vol.~100. Iss.~2. P.~411--421.

\bibitem{awerbuch1998new}
\Au{Awerbuch~B., Azar~Y., Blum~A., Vempala~S.} New approximation guarantees 
for minimum-weight $k$-trees and prize-collecting salesmen~// SIAM J. 
Computing, 1998. Vol.~28. Iss.~1. P.~254--262.

\bibitem{arora20062+}
\Au{Aror~S., Karakostas~G.} A~$2+\varepsilon$ approximation algorithm for the 
$k$-MST problem~// Mathematical Programming, 2006. Vol.~107. 
Iss.~3. P.~491--504.

\bibitem{hegde2014fast}
\Au{Hegde~C., Indyk~P., Schmidt~L.} A~fast, adaptive variant of the 
Goemans--Williamson scheme for the prize-collecting steiner tree problem~// Workshop of 
the 11th DIMACS Implementation Challenge, 2014. P.~1--32.
{\sf http://people. csail.mit.edu/ludwigs/papers/dimacs14\_fastpcst.pdf}.

\bibitem{ras2017approximate}
\Au{Ras~C., Swanepoel~K., Thomas~D.\,A.} Approximate Euclidean Steiner 
trees~// J.~Optimiz. Theory Appl., 2017. Vol.~172. 
Iss.~3. P.~845--873.

\bibitem{goemans1995general}
\Au{Goemans~M.\,X., Williamson~D.\,P.} A~general approximation technique for 
constrained forest problems~// SIAM J. Computing, 1995. Vol.~24. 
Iss.~2. P.~296--317.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 23.01.22}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{-2pt}

\def\tit{OPTIMAL SPANNING TREE RECONSTRUCTION IN~SYMBOLIC REGRESSION}


\def\titkol{Optimal spanning tree reconstruction in~symbolic regression}


\def\aut{R.\,G.~Neychev$^1$, I.\,A.~Shibaev$^1$, and~V.\,V.~Strijov$^2$}

\def\autkol{R.\,G.~Neychev, I.\,A.~Shibaev, and~V.\,V.~Strijov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-8pt}


\noindent
$^1$Moscow Institute of Physics and Technology, 9~Institutskiy Per., Dolgoprudny, Moscow Region 141700, Russian\linebreak
$\hphantom{^1}$Federation

\noindent
$^2$Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, 40~Vavilov Str.,\linebreak
$\hphantom{^1}$Moscow 119333, Russian Federation

\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 1}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 1
\hfill \textbf{\thepage}}}

\vspace*{3pt} 



\Abste{This paper investigates the problem of regression model generation. A~model is a~superposition of primitive functions. 
The model structure is described by a~weighted colored graph. Each graph vertex corresponds to a~primitive function. 
An edge assigns a~superposition of two functions. The weight of an edge equals the probability of superposition. 
To generate an optimal model, one has to reconstruct its structure from its graph adjacency matrix. 
The proposed algorithm reconstructs the minimum spanning tree from the weighted colored graph. 
This paper presents a~novel solution based on the prize-collecting Steiner tree algorithm. This algorithm is compared with its alternatives.}


\KWE{symbolic regression; linear programming; superposition; minimum spanning tree; adjacency matrix}



 \DOI{10.14357/ } 

\vspace*{-16pt}

\Ack

\vspace*{-3pt}


\noindent
This work was supported by Russian Foundation for Basic Research, projects 20-37-90050 and 20-07-00990.
  

\vspace*{6pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99} 

\bibitem{1-str}
\Aue{Koza, J.\,R.}
 1994. Genetic programming as a means for programming computers by natural selection. \textit{Statistics Computing} 4:87--112.

\bibitem{2-str}
\Aue{Searson, D.\,P., D.\,E.~Leahy, and M.\,J.~Willis.}
 2010. GPTIPS: An open source genetic programming toolbox for multigene symbolic regression. 
 \textit{Multiconference (International) of Engineers and Computer Scientists Proceedings}. 1:77--80. 

\bibitem{3-str}
\Aue{Stanley, K.\,O., and R.~Miikkulainen.} 2002. Evolving neural networks through augmenting topologies. 
\textit{Evolutionary Computation} 10(2):99--127.

\bibitem{4-str}
\Aue{Bochkarev, A.\,M., I.\,L.~Sofronov, and V.\,V.~Strijov.}
 2017. Po\-rozh\-de\-niye eks\-pert\-no-inter\-pre\-ti\-ru\-emykh mo\-de\-ley dlya prog\-no\-za pro\-ni\-tsa\-emosti gor\-noy po\-ro\-dy 
 [Generation of expertly-interpreted models for prediction of core permeability]. \textit{Sistemy i~Sredstva Informatiki~--- Systems and Means of Informatics}
  27(3):74--87.

\bibitem{5-str}
\Aue{Ravi, R., R.~Sundaram, M.\,V.~Marathe, D.\,J.~Rosenkrantz, and S.\,S.~Ravi.}
 1996. Spanning trees~--- short or small. \textit{SIAM J. Discrete Mathematics} 9(2):178--200.

\bibitem{6-str}
\Aue{Chudak, F.\,A., T.~Roughgarden, and D.\,P.~Williamson.}
 2004. Approximate k-MSTS and k-Steiner trees via the primal-dual method and Lagrangean relaxation. 
 \textit{Mathematical Programming} 100(2):411--421.

\bibitem{7-str}
\Aue{Awerbuch, B., Y.~Azar, A.~Blum, and S.~Vempala.}
 1998. New approximation guarantees for minimum-weight k-trees and prize-collecting salesmen.
 \textit{SIAM J. Computing} 28(1):254--262.

\bibitem{8-str}
\Aue{Arora, S., and G.~Karakostas.} 2006. A~$2+\varepsilon$ approximation algorithm for the $k$-MST problem. 
\textit{Mathematical Programming} 107(3):491--504.

\bibitem{9-str}
\Aue{Hegde, C., P.~Indyk, and L.~Schmidt.} 2014. 
A~fast, adaptive variant of the Goemans--Williamson scheme for the prize-collecting Steiner tree problem. 
\textit{Workshop of the 11th DIMACS Implementation Challenge}. 1--32.
Available at: 
{\sf http://people.csail.mit.edu/ludwigs/papers/\linebreak dimacs14\_fastpcst.pdf} (accessed January~10, 2023).

\bibitem{10-str}
\Aue{Ras, C., K.~Swanepoel, and D.\,A.~Thomas.} 
2017. Approximate euclidean Steiner trees. \textit{J.~Optimiz. Theory  App.} 172(3):845--873.

\bibitem{11-str}
\Aue{Goemans, M.\,X., and D.\,P.~Williamson.} 1995. 
A~general approximation technique for constrained forest problems. \textit{SIAM J. Computing} 24(2):296--317.
 \end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received January 23, 2022}}

\Contr

\noindent
\textbf{Neychev Radoslav G.} (b.\ 1994)~--- 
PhD student, Moscow Institute of Physics and Technology, 9~Institutskiy Per., Dolgoprudny, Moscow Region 141701, Russian Federation;
\mbox{neychev@phystech.edu}

\vspace*{3pt}

\noindent
\textbf{Shibaev Innokentii A.} (b.\ 1997)~--- 
PhD student, Moscow Institute of Physics and Technology, 9~Institutskiy Per., Dolgoprudny, Moscow Region 141701, Russian Federation; 
\mbox{shibaev.kesha@gmail.com}

\vspace*{3pt}

\noindent
\textbf{Strijov Vadim V.} (b.\ 1967)~--- 
Doctor of Science in physics and mathematics, leading scientist, A.\,A.~Dorodnicyn Computing Centre, 
Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, 40~Vavilov Str., Moscow 119333, Russian Federation;
\mbox{strijov@phystech.edu}


\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 