\newcommand{\KL}{\mathrm{KL}}



\def\stat{motrenko}

\def\tit{ПОСТРОЕНИЕ АГРЕГИРОВАННЫХ ПРОГНОЗОВ ОБЪЕМОВ ЖЕЛЕЗНОДОРОЖНЫХ ГРУЗОПЕРЕВОЗОК
C~ИСПОЛЬЗОВАНИЕМ РАССТОЯНИЯ КУЛЬБАКА--ЛЕЙБЛЕРА$^*$}

\def\titkol{Построение агрегированных прогнозов объемов железнодорожных
грузоперевозок} % c использованием расстояния Кульбака--Лейблера$^*$}

\def\autkol{А.\,П.~Мотренко, В.\,В.~Стрижов}

\def\aut{А.\,П.~Мотренко$^1$, В.\,В.~Стрижов$^2$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{Работа выполнена при поддержке РФФИ
(грант 13-07-13139).}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский физико-технический институт, anastasia.motrenko@gmail.com}
\footnotetext[2]{Вычислительный центр Российской академии наук им.\ А.\,А.~Дородницына, strijov@ccas.com}

\vspace*{-6pt}

\Abst{Данное исследование посвящено проблеме построения агрегированных прогнозов
объемов железнодорожных грузоперевозок. Для получения агрегированных прогнозов
требуется кластеризовать временн$\acute{\mbox{ы}}$е ряды таким образом, чтобы распределения
временн$\acute{\mbox{ы}}$х рядов внутри кластера совпадали. При решении задачи кластеризации
требуется оценить близость между временн$\acute{\mbox{ы}}$ми рядами, исходя из их эмпирических
распределений. Вводится критерий принадлежности временн$\acute{\mbox{ы}}$х рядов одному
распределению, основанный на расстоянии Кульбака--Лейблера между гистограммами
временн$\acute{\mbox{ы}}$х рядов. Приводится теоретическое и практическое исследование предложенного
критерия. Решается задача кластеризации временн$\acute{\mbox{ы}}$х рядов на основе матрицы парных
расстояний между ними.}

\KW{эмпирическая функция распределения; расстояние между гистограммами;
расстояние Кульбака--Лейблера; задача двух выборок}

\DOI{10.14357/19922264140209}

\vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}


\section{Введение}
Особенностью задачи прогнозирования объема погрузок по историческим данным о
загружен\-ности железнодорожной сети различными группами грузов является
необходимость определить оптимальный уровень
детализации~\cite{Medvednikova2012, Motrenko2013}: по видам перевозимых грузов,
по наборам станций, по кодам вагонов. Требуется получить прогноз как для объема
погрузок в целом, так и для отдельных групп грузов. При этом спрогнозированный
объем погрузок в целом может не совпадать с суммой прогнозов по отдельным группам.
Для повышения согласованности полученных прогнозов
предлагается~\cite{Medvdnikova2014} вместо прогноза <<в целом>> объединять ряды
только в том случае, если их распределения совпадают, чтобы агрегированные данные
имели тот же статистический смысл, что и исходные ряды. Для решения задачи
агрегации временн$\acute{\mbox{ы}}$х рядов необходимо определить расстояние между
временн$\acute{\mbox{ы}}$ми рядами
таким образом, чтобы оно отражало близость эмпирических распределений между рядами.

В литературе по математической статистике вводится множество коэффициентов,
показывающих, что некоторые два распределения $P$ и~$Q$ близки друг к другу.
Такие коэффициенты в различных источниках называются расстоянием между
распределениями~\cite{Kullback1959}, мерами разделяющей
информации~\cite{Chernoff1952}, мерами статистического
расстояния~\cite{Kolmogorov1965}. В~работе~\cite{AliSilvey1966} описан метод
порождения коэффициентов $d(P, Q)$ <<непохожести>> двух распределений, обладающих
некоторыми стандартными свойствами, например:
\begin{itemize}
\item коэффициент $d(P, Q)$ должен быть определен на всех парах распределений
с одним носителем;
\item значение $d(P, Q)$ должно быть минимально при $P \hm= Q$;
\item при любом измеримом преобразовании носителя распределений~$P$ и~$Q$
расстояние между ними не увеличивается.
\end{itemize}
Идея метода~\cite{AliSilvey1966} заключается в том, чтобы рас\-смот\-реть
различные выпуклые функции случайной величины $Q/P$.
С~точки зрения распределения~$P$ математическое ожидание $Q/P$ независимо от~$Q$, а
дисперсия стремится к нулю при $Q \hm\to P$. Также в~\cite{AliSilvey1966}
показано, что многие известные функции расстояния могут быть получены этим методом.
В~частности, им могут быть порождены все $f$-ди\-вер\-ген\-ции~\cite{scizar2004} и
в том числе расстояние Куль\-ба\-ка--Лейб\-ле\-ра~\cite{Kullback1959}.
В~работе~\cite{Gibs} приведено сравнение многих известных расстояний с
точки зрения скорости схо\-ди\-мости эмпирического распределения к истинному,
а также качественного поведения функции рас\-сто\-яния при сходимости. При решении
задачи кластеризации в обработке изображений были введены меры~\cite{Mallows1972, Irpino}, основанные
на метрике Вассерштейна.

В работе~\cite{Medvednikova2012} для оценки близости распределений используется
расстояние Кульбака--Лейблера между гистограммами, построенными по временн$\acute{\mbox{ы}}$м рядам.
В~данной работе показано, что распределение расстояние Куль\-ба\-ка--Лейб\-ле\-ра между
гис\-то\-грам\-ма\-ми из одного распределения в пределе ограничено сверху распределением~$\chi^2$.

Предложен критерий для решения задачи двух выборок, основанный на расстоянии
Куль\-ба\-ка--Лейб\-ле\-ра между гистограммами временн$\acute{\mbox{ы}}$х рядов. Продемонстрировано
применение критерия к решению задачи двух выборок для различных пар распределений
и показана его состоятельность.\linebreak Для набора временн$\acute{\mbox{ы}}$х рядов о железнодорожных
грузоперевозках решается задача кластеризации с помощью алгоритма кратчайшего
незамкнутого пути~\cite{Dvoenko1999} на основе матрицы парных\linebreak
расстояний~\cite{StrijovRudakov, Dvoenko2013} между рядами. При решении задачи
кластеризации ряды группируются по типу груза.

\section{Постановка задачи}

Задан набор временн$\acute{\mbox{ы}}$х рядов
$\mathbf{X}\hm = \{\mathbf{x}_1, \dots, \mathbf{x}_S\}$, где каждый ряд
$\mathbf{x}_j \hm= \{x_j(i)\in\mathbb{R}\}_{i = 1}^{m_j}$~--- это
последовательность реализаций некоторого стационарного случайного процесса.
Требуется кластеризовать набор
\begin{multline}
\label{eq:clastering}
\mathbf{X} = \bigsqcup\limits_{k = 1}^{K} \mathbf{X}_k\,,\quad
\mathbf{X}_k = \{\mathbf{x}_j,\,j\in \mathcal{A}_k\}\,,\\
\{1,\dots , S\} =
= \bigsqcup\limits_{k=1}^{K} \mathcal{A}_k\,,
\end{multline}
разбив набор $\mathbf{X}$ на $K$ наборов $\mathbf{X}_k$ временн$\acute{\mbox{ы}}$х
рядов таких, что все ряды в $\mathbf{X}_k$ принадлежат одному и тому же
распределению. Здесь $\mathcal{A}_k$~--- множество индексов временн$\acute{\mbox{ы}}$х рядов
$k$-го кластера.

В силу стационарности случайного процесса~$\mathbf{x}$
пренебрежем последовательностью значений ряда~$\mathbf{x}$. Представим временной
ряд~$\mathbf{x}$ как выборку~$X$ реализаций некоторой случайной величины с
распределением~$P$:
\begin{multline}
\label{eq:TS2sample}
X = \{x\in\mathbb{R} | \mbox{~для некоторого\ } i\in\{1, \dots, m\}:\\
 x(i) = x\}\,.
\end{multline}
 Для решения задачи об агрегировании временн$\acute{\mbox{ы}}$х рядов~$\mathbf{x}$ и~$\mathbf{x}'$
 будем сравнивать гистограммы, построенные по выборкам~$X$ и~$X'$,
 сопоставленным каждому из рядов в соответствии с~\eqref{eq:TS2sample}.
 Опишем подробнее процедуру построения гистограммы.

 Пусть объемы выборок~$X$ и~$X'$ равны~$m$ и~$m'$ соответственно.
 Разобьем область значений случайной величины из~$P$ на $N$ промежутков
 $[a_{i}, a_{i+1}]$  и обозначим $p_i \hm= P(a_{i} \hm< x \hm\leq a_{i+1})$
 вероятность случайной величине с распределением~$P$ принять значение из $i$-го
 промежутка; $n_i$ и~$n'_i$~--- количество объектов выборок~$X$ и~$X'$, попавших
 в $i$-й промежуток. Обозначим $\hat{P}_{m}$ гистограмму, построенную по выборке~$X$
 объема~$m$ из распределения~$P$. Гистограмма~$\hat{P}_{m}$ задается
 набором оценок

 \noindent
\begin{multline}
\hat{P}_m(a_{i} < x \leq a_{i+1}) = \fr{n_{i}}{m} = \hat{p}_i\,,\\
i = 1,\dots,N-1\,,
\label{eq:hist}
\end{multline}
 вероятности~$p_i$.

 Для решения задачи кластеризации~\eqref{eq:clastering} вос\-пользуемся
 алгоритмом нахождения кратчайшего незамкнутого пути между временными
 рядами. Результатом применения алгоритма является минимальное остовное дерево:
 граф  с $n-1$ ребрами, покрывающий все $n$ вершин, ребра которого обладают
 минимальной суммарной длиной. Удалив из минимального остовного дерева $K-1$
 самых длинных ребер, получим кластеризацию вершин графа на $K$ кластеров~$\mathbf{X}_k$.
 Вершинами графа являются исследуемые временн$\acute{\mbox{ы}}$е ряды~$\mathbf{x}_j$;
 длина ребра, соединяющего две вершины, равна расстоянию между соответствующими
 временн$\acute{\mbox{ы}}$ми рядами. Найдя расстояние между всеми парами рядов,
 получим матрицу парных расстояний~$D$. В~качестве расстояний между
 рядами~$\mathbf{x}_r$ и~$\mathbf{x}_s$ будем использовать симметризованное
 расстояние Куль\-ба\-ка--Лейб\-ле\-ра между
 гистограммами $\hat{P}_{m_r}$ и $\hat{P}_{m_s}$, построенными по
 временн$\acute{\mbox{ы}}$м рядам:
   \begin{multline}
   \label{eq:matKLdist}
   D(r, s) = {}\\
\hspace*{-1.5mm}{}=\fr{2m_rm_s}{m_r + m_s}\!\left(\!D_{\KL}(\hat{P}_{m_r}||\hat{P}_{m_s}) +
   D_{\KL}(\hat{P}_{m_s}||\hat{P}_{m_r})\!\right)\!.\!\!\!\!
   \end{multline}
  Первый сомножитель в правой части снимает зависимость от объема выборки.
  Необходимость его введения будет объяснена  в следующем разделе.

Конечной целью кластеризации временн$\acute{\mbox{ы}}$х рядов с учетом расстояний между
ними является повыше\-ние согласованности агрегированных прогнозов.
Для оценки качества кластеризации будем рассматривать несогласованность
\begin{equation}
\label{eq:inconsistency}
\delta(i) = \left|\sum\limits_k^{K} \mathbf{\hat{X}}_k(i) -
\sum\limits_j^{n} \mathbf{\hat{x}}_j(i) \right|
\end{equation}
 при прогнозировании  по наборам~$\mathbf{X}_k$ временн$\acute{\mbox{ы}}$х
 рядов и отдельным временн$\acute{\mbox{ы}}$м рядам~$\mathbf{x}_j$. Здесь
 $\hat{\mathbf{X}}_k(i)$~--- прогноз агрегированного ряда в момент~$i$;
 $\hat{x}_j(i)$~--- прогноз $j$-го ряда в момент времени~$i$.
 Чем меньше несогласованность, тем качественнее выполнена кластеризация.
 Очевидно, что наименьшее значение $\delta_{\min} \hm= 0$
 выражения~\eqref{eq:inconsistency} достигается при $K\hm = S$, поэтому
 предлагается ограничить чис\-ло~$K$ или ввести в~\eqref{eq:inconsistency}
 штраф $h(K)$ за его повышение:
  $$
  K = \argmin\limits_{K} \left(\sum\limits_{i = 1}^{m} \delta(i) + h(K)\right).
  $$
  В данной работе ограничимся рассмотрением предложенного критерия принадлежности
  временн$\acute{\mbox{ы}}$х рядов к одному распределению и кластеризации
  временн$\acute{\mbox{ы}}$х рядов на основе расстояния между \mbox{ними}.

\section{Статистическая значимость расстояния Кульбака--Лейблера}
\label{Sec:KLsignificance}

Чтобы показать, что результаты кластеризации временн$\acute{\mbox{ы}}$х
рядов на основе расстояния Кульбака--Лейб\-ле\-ра между ними статистически значимы,
необходимо исследовать распределение рас\-сто\-яния Куль\-ба\-ка--Лейб\-ле\-ра между
гистограммами, построенными по выборкам~$X$ и~$X'$ из одного распределения~$P$.
В~данном разделе будет показано, что, хотя расстояние Кульбака--Лейблера не имеет
предельного распределения, для него можно получить предельные оценки сверху.

Пусть пока выборки $X$ и $X'$ имеют одинаковый объем~$m$. Рассмотрим расстояние
$D_{\KL}(\hat{P}_m||\hat{P}'_{m})$ между гистограммами~$\hat{P}_m$ и~$\hat{P}'_m$.
По определению расстояние Кульбака--Лейблера $D_{\KL}(Q||P)$
между распределениями~$Q$ и~$P$ равно
\begin{equation}
\label{eq:dKL}
D_{\KL}(Q||P) = \int P{f}\left(\fr{Q}{P}\right),
\end{equation}
где $f(t) \hm= t\ln{t}$. Функция~$f$ строго выпукла и дваж\-ды дифференцируема в
единице, и, повторяя рассуждения из~\cite{scizar2004}, разложим подынтегральное
выражение из правой части~\eqref{eq:dKL} по~$f$ в окрестности единицы:
\begin{multline*}
P(x)f\left(\fr{Q(x)}{P(x)}\right) = f(1) + f'(1)(Q(x) - P(x)) + {}\\
{}+
\fr{f''(1)}{2}\,\fr{(Q(x)-P(x))^2}{P(x)} + P(x)o\left(\!\left(\fr{Q(x)}{P(x)} -
1\right)^3\!\right),
\end{multline*}
где $f(1) = 0$;  $f''(1) \hm= 1$.
Подставив вместо~$Q$ распределение $\hat{P}_m$, определяемое~\eqref{eq:hist},
и просуммировав по~$i$, получим соотношение:

\noindent
\begin{multline*}
D_{\KL}(\hat{P}_m||P)  = \sum\limits_{i = 1}^{N}p_i{f}\left(
\fr{\hat{p}_i}{p_i}\right) ={}\\
{} = \fr{1}{2}\sum\limits_i^{N}\fr{(\hat{p}_i - p_i)^2}{p_i} +
\sum\limits_{i = 1}^{N}p_i\cdot
\varepsilon\left(\left(\fr{\hat{p}_i}{p_i} - 1\right)^3\right)\sim{}\\
{}\sim
\fr{1}{2m}\sum\limits_i^{N}\fr{(n_i - mp_i)^2}{mp_i}
\end{multline*}
 и следующий предельный переход:
 \begin{multline}
 \label{eq:step1}
 2m {D}_{\KL}(\hat{P}_m||Q) \sim m\sum\limits_{i=1}^{N}
 \fr{(\hat{p}_i - p_i)^2}{p_i} ={}\\
 {}=  \sum\limits_{i=1}^{N}\fr{(n_i - mp_i)^2}{mp_i}
 \rightarrow  \chi_{\mathcal{N}}^2\mbox{~~при~}m\rightarrow\infty\,.
 \end{multline}
Докажем следующую теорему:

\smallskip

\noindent
\textbf{Теорема~1.}\
\textit{Случайная величина
$2m {D}_{\KL}(Q||\hat{P}_m) \hm\rightarrow \chi_{\mathcal{N}}^2$
по распределению при $m\hm\rightarrow\infty$}.


\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \
Аналогично доказательству предельного перехода~\eqref{eq:step1}
разложим $D_{\KL}(Q||\hat{P}_m)$ по степеням $f(t)$ вблизи единицы и получим:
\begin{multline*}
D_{\KL}(Q||\hat{P}_m) \sim \fr{1}{2} \sum\limits_{i=1}^{N}
\fr{(\hat{P}_m(\xi_i) - Q(\xi_i))^2}{\hat{P}_m(\xi)} = {}\\
{}=\fr{1}{2m}
\sum\limits_{i=1}^{N}\fr{(n_i - mp_i)^2}{n_i}.
\end{multline*}
Пусть $G_m(x)$~--- функция распределения случайной величины
$\sum\limits_{i=1}^{N} {(n_i - mp_i)^2}/(mp_i)$; $F_m(x)$~---
случайной величины $\sum\limits_{i=1}^{N}{(n_i - mp_i)^2}/{n_i}$. Так как
$G_m(x)$ сходится поточечно к $F_{\chi^2_{N-1}}$ при $m\hm\rightarrow\infty$, имеем:
$$
\left\vert G_m(x) - F_{\chi_{N-1}^2}\right\vert <
\fr{\epsilon}{2} \quad \forall m > m'.
$$

Докажем, что $|G_m(x) - F_m(x)|\hm\rightarrow0$ при $m\hm\rightarrow\infty$.
Для этого покажем, что $\forall \varepsilon\hm > 0$ найдется объем выборки~$m_0$
такой, что для всех $m \hm> m_0$ выполняется
\begin{equation}
\mathrm{P}\left(\left|\fr{(n_i - mp_i)^2}{n_i} - \fr{(n_i - mp_i)^2}{mp_i}\right| \leq \frac{\varepsilon}{N}\right) > 1 - \varepsilon.
\!\!
\label{eq:statement}
\end{equation}
Согласно центральной предельной теореме,
$$
\fr{n_i - mp_i}{p_i(1-p_i)\sqrt{m}} \rightarrow \mathcal{N}(0,1)
$$
по распределению при $m\rightarrow \infty$,
причем для скорости сходимости имеет место неравенство Берри--Эссеена:
$$
\left\vert Q_m(x) - \Phi(x)\right\vert \leq \fr{A}{\sqrt{m}}\,,
$$
где $Q_m(x)$~--- функция распределения величины
$(n_i - mp_i)/(p_i(1-p_i)\sqrt{m})$;
$\Phi(x)$~--- функция стандартного нормального распределения;
$A$~--- некоторая константа. Тогда вероятность
\begin{multline}
\label{eq:CLT}
\mathrm{P}\left(\left|\fr{n_i - mp_i}{p_i(1-p_i)\sqrt{m}}\right| <
C\right) = Q_m(C) - Q_m(-C) \geq {}\\
{}\geq 2\Phi(C) - 1 - \fr{2A}{\sqrt{m}}\,.
\end{multline}
Пусть, кроме того, выполняется $0 \hm< 1 \hm- p \hm\leq p_i \hm\leq p \hm< 1$.
Тогда с вероятностью $\mathrm{P}_{C} \hm\geq 2\Phi(C)\hm - 1$ выполняется
\begin{multline*}
\left|\fr{(n_i - mp_i)^2}{n_i} - \fr{(n_i - mp_i)^2}{mp_i}\right| =
\fr{|n_i - mp_i|^3}{mn_ip_i} \leq{}\\
{}\leq \fr{C^3(1-p_i)^3p_i^2}{n_i}\sqrt{m} \leq
 \fr{C^3(1-p)^3p}{\sqrt{m} - C(1-p)}\,.
 \end{multline*}
Обозначим $m_1 = [4C^2(1\hm-p)^2]$, тогда при $m\hm > m_1$ имеет место
$\sqrt{m} \hm- C(1-p_i)> (1/2)\sqrt{m}$ и
$$
\left|\fr{(n_i - mp_i)^2}{n_i} - \fr{(n_i - mp_i)^2}{mp_i}\right| \leq
\fr{2C^3(1-p_i)^3p_i}{\sqrt{m}}\,.
$$
Тогда для фиксированного~$\varepsilon$ определим
\begin{gather*}
C_{\varepsilon} = \fr{\epsilon^{1/3}m^{1/6}}{(1-p_i)(2p_iN)^{1/3}}\,;\\
\mathrm{P}_m(\varepsilon) = 2\Phi(C_{\varepsilon}) - 1 - \fr{2A}{\sqrt{m}}\,.
\end{gather*}
При заданном $\varepsilon$ вероятность $\mathrm{P}_m(\varepsilon) \hm\rightarrow 1$
при $m\hm\rightarrow\infty$, поэтому найдется~$m_2$ такое, что
для любого $m \hm> m_2$ выполнено $\mathrm{P}_m(\varepsilon) \hm> 1 \hm- \varepsilon$.
Выбрав $m_0 \hm= \max(m_1, m_2)$, получим утверждение~\eqref{eq:statement}.
Тогда
\begin{multline*}
\left|\sum\limits_{i = 1}^{N}\fr{(n_i - mp)^2}{n_i} -
\fr{(n_i - mp)^2}{mp} \right| \leq {}\\
{}\leq
\sum\limits_{i = 1}^{N}\left|\fr{(n_i - mp)^2}{n_i} - \fr{(n_i - mp)^2}{mp} \right|
< \varepsilon \mbox{ при~}m > m_0.\hspace*{-5.0964pt}
\end{multline*}

Из только что доказанного следует, что $|F_m(x) \hm- G_m(x)| \hm\rightarrow 0 $
при $m\hm\rightarrow 0$. Тогда $\forall \epsilon \hm> 0 \;\exists m'':$
при $m \hm> m''$ выполняется
\begin{multline*}
\left\vert F_m(x) - F_{\chi^2_{N-1}}\right\vert
< \left\vert F_m(x) - G_m(x)\right\vert + {}\\
{}+\left\vert G_m(x) - F_{\chi^2_{N-1}}\right\vert
< \fr{\epsilon}{2} + \fr{\epsilon}{2}\,.
\end{multline*}


\smallskip

Доказанная теорема и утверждение~\eqref{eq:step1} позволяют получить
оценки распределения случайных величин $2m{D}_{\KL}(\hat{P}_m||Q)$ и
$2m{D}_{\KL}(Q||\hat{P}_m)$ при больших~$m$. Для решения задачи
кластеризации~\eqref{eq:clastering} потребуется также исследовать
поведение расстояния Куль\-ба\-ка--Лейблера
${D}_{\KL}(\hat{P}_m||\hat{P}_l)$ между гистограммами, построенными по выборкам~$X$
и~$X'$ различных длин~$m$ и~$l$. Воспользовавшись неравенством треугольника
$$
D_{\KL}(\hat{P}_m||\hat{P}_l)  \leq D_{\KL}(\hat{P}_m||Q)
+ D_{\KL}(Q||\hat{P}_l)\,,
$$
получим следствия из теоремы~1.

\smallskip

\noindent
\textbf{Следствие~1.}
$ 2m{D}_{\KL}(\hat{P}_m||\hat{P}'_m)  \leq \chi^2_{2\mathcal{N}}$ в
пределе при $m\hm\rightarrow\infty$. \\

\smallskip

\noindent
\textbf{Следствие 2.} Пусть выборки $X$, $X'$ растут таким образом, что
$ {m}/{l} \hm\rightarrow \rho$,  $0 \hm< \rho \hm< \infty.$
Тогда
$$
2\fr{ml}{m+l}{D}_{\KL}(\hat{P}_m||\hat{P}_l)  \leq \chi^2_{2\mathcal{N}}
$$ в пределе при $m, l\hm\rightarrow\infty$.

\smallskip

\noindent
Д\,\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \
Действительно, при выполнении условия  $ {m}/{l} \hm\rightarrow \rho$,
$0 \hm< \rho \hm< \infty,$ имеем
 $$
 \fr{l}{m+l} \rightarrow \fr{1}{1 + \rho}\,;\enskip
 \fr{m}{m+l} \rightarrow \fr{\rho}{1 + \rho}\,;
 $$
\begin{multline*}
2\fr{ml}{m+l}D_{\KL}(\hat{P}_m||\hat{P}_l)  \leq \fr{l}{m+l}\,2mD_{\KL}(\hat{P}_m||Q)  + {}\\
{}+
\fr{m}{m+l}2lD_{\KL}(Q||\hat{P}_l) \rightarrow \chi^2_{2\mathcal{N}}\,.
\end{multline*}


\smallskip

Обозначим величину $(2ml/(m+l))D_{\KL}(\hat{P}_m||\hat{P}'_m)$ через~$\xi_{m,l}$.
Следствие~2 дает верхнюю оценку поведения случайной величины $\xi_{m,l}$ при
больших~$m$ и~$l$, а именно: пусть $\eta\hm\sim \chi_{2\mathcal{N}}^2$, тогда при
достаточно больших~$m$ и~$l$ для любого элементарного исхода~$w$
из вероятностного пространства~$\Omega$ выполнено  $\xi_{m,l}(w) \hm< \eta(w)$.
Следовательно, для любого $x\hm\in\mathbb{R}$ верно
\begin{equation}
\label{eq:KLchi}
\mathrm{P}(\xi_{m,l} < x) \geq \mathrm{P}(\eta < x)\,.
\end{equation}
В следующем разделе покажем, как этот факт будет использоваться для
проверки принадлежности временн$\acute{\mbox{ы}}$х рядов к одному распределению.




\section{Проверка принадлежности временн$\acute{\mbox{ы}}$х рядов к~одному распределению}

Для решения задачи агрегирования временн$\acute{\mbox{ы}}$х рядов~$\mathbf{x}$ и~$\mathbf{x}'$
необходимо уметь принимать решение о принадлежности временн$\acute{\mbox{ы}}$х
рядов к одному распределению. Опишем процедуру проверки гипотезы о принадлежности
выборок~$X$ и~$X'$, составленных~\eqref{eq:TS2sample} из временн$\acute{\mbox{ы}}$х
рядов~$\mathbf{x}$ и~$\mathbf{x}'$.
Пусть нулевая гипотеза~$H_0$ состоит в принадлежности выборок~$X$ и~$X'$ к одному
распределению:
$$
H_0: P(x) = P'(x)\,.
$$
Сформулируем критерий проверки гипотезы~$H_0$ при альтернативе
$H_1:\,P(x) \hm\neq P'(x)$. Для этого определим критическую область $U(\alpha)$
для статистики $t_{m,l}$ с уровнем значимости~$\alpha$:
 $$
 U(\alpha) = \left\{t: \bar{t}_{1 -\alpha} > t \mbox{~или~} t > \bar{t}_{\alpha}\right\}\,,
 $$
 где критическое значение $\bar{t}_{\alpha}$ определяется соотношением
 \begin{equation}
 \label{eq:talpha}
 \mathrm{P}(t > \bar{t}_{\alpha}| H_0) = \alpha\,.
 \end{equation}
 Так как предельное распределение величины~$\xi_{m,l}$ неизвестно,
 будем использовать критическую область, задаваемую распределением~$\chi_{2\mathcal{N}}^2$.
 Будем говорить, что данные отвергают гипотезу~$H_0$ в случае, если
 статистика~$t_{m,l}$ принадлежит критической области
 \begin{equation}
 \label{eq:Uchi2}
U^{\chi^2}(\alpha) = \left\{
t: \bar{t}^{\chi^2}_{1 -\alpha} > t \mbox{~или~} t > \bar{t}^{\chi^2}_{\alpha}\right\},
\end{equation}
где $\bar{t}^{\chi^2}$~---  критическое значение величины~$\chi_{2\mathcal{N}}^2$:
 $$
 \mathrm{P}(t > \bar{t}^{\chi^2}_{\alpha}| t\sim\chi^2_{2\mathcal{N}}) = \alpha\,.
 $$
  Из неравенства~\eqref{eq:KLchi} и определения~\eqref{eq:talpha}
  критических значений следует, что критические области~$U$ и~$U^{\chi^2}$
  не сравнимы, т.\,е.\
 $$
 \bar{t}_{1-\alpha} < \bar{t}_{1-\alpha}^{\chi^2}\,; \quad
 \bar{t}_{\alpha} < \bar{t}_{\alpha}^{\chi^2}\,.$$
 Это означает, что возможны следующие ситуации.
 \begin{enumerate}
 \item Случай $\bar{t}_{1-\alpha}^{\chi^2} \hm< t_{m,l} \hm< \bar{t}_{\alpha}$,
 когда статистика~$t_{m,l}$ одновременно принадлежит истинной, но неизвестной
 критической области~$U$ и вычислимой критической области~$U^{\chi^2}$.
 \item Случай $\bar{t}_{1-\alpha} \hm< t_{m,l}\hm < \bar{t}_{1-\alpha}^{\chi^2}$,
 когда статистика~$t_{m,l}$ принадлежит истинной, но неизвестной критической
 области~$U$ и не принадлежит~$U^{\chi^2}$. Так как $t_{m,l}\hm\in\,U$,
 то с высокой вероятностью гипотеза~$H_0$ неверна и есть риск принять
 неверное решение об истинности гипотезы~$H_0$. Таким образом, зазор
 между $\bar{t}_{1-\alpha}$ и $\bar{t}_{1-\alpha}^{\chi^2}$ повышает вероятность
 ошибки второго рода.
  \item Случай $\bar{t}_{\alpha} \hm< t_{m,l} \hm< \bar{t}_{\alpha}^{\chi^2}$,
  когда статистика~$t_{m,l}$ попадает в~$U^{\chi^2}$, хотя на самом деле~$t_{m,l}$~не
  принадлежит~$U$. В~этом случае велика вероятность, что $H_0$ верна, но
  решение будет принято в пользу~$H_1$. Таким образом, зазор между
  $\bar{t}_{\alpha}$ и $\bar{t}_{\alpha}^{\chi^2}$ повышает вероятность
  ошибки первого рода.
 \end{enumerate}

 Второй случай разрешается следующим образом: использование симметризованного
 рас\-сто\-яния позволяет перейти от двусторонних критериев~$U$ и~$U^{\chi^2}$
 вида~\eqref{eq:Uchi2} к односторонним критериям:
  $$
  U_1(\alpha) = \left\{t: t > \bar{t}_{\alpha}\right\}\,;\quad
  U_1^{\chi^2}(\alpha) = \left\{t: t > \bar{t}^{\chi^2}_{\alpha}\right\}.
  $$
  В этом случае $U_1^{\chi^2}\subseteq U_1$ и справедливо следствие:
$$
t_{m,l}\hm\in\,U_1^{\chi^2}\hm\Rightarrow t_{m,l}\hm \in U_1\,.
$$

  Кроме того, далее будет показано (теорема~2), что при увеличении объема
  выборки~$m$ вероятность отклонить гипотезу~$H_0$ с помощью
  критерия~\eqref{eq:Uchi2} в случае, если гипотеза~$H_0$ неверна, стремится
  к единице.
  Влияние третьего случая на возможность применения критерия~\eqref{eq:Uchi2}
  для принятия нулевой гипотезы исследуется экспериментально. Эксперименты,
  приведенные ниже и в разд.~5, показывают, что при истинности нулевой гипотезы области $U$ и $U^{\chi^2}$ достаточно близки для принятия верного решения.

  \begin{figure*} %fig1
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=164.559mm
\epsfbox{str-1.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Гистограммы, построенные по двум выборкам из нормального
распределения~(\textit{а}, \textit{б}) и зашумленного~(\textit{в}, \textit{г})
и зависимость статистики~$t_m$
от объема выборки~(\textit{д}, \textit{е})
(cплошными кривыми отмечены границы доверительного интервала для~$t_m$ при
$\alpha \hm= 0{,}1$):
\textit{1}~--- $\overline{t}_{1-\alpha}^{\chi^2}/(2m)$;
\textit{2}~--- $\overline{t}_\alpha^{\chi^2}/(2m)$;
\textit{3}~--- $t_m/(2m)$}\label{fg:norm}
\end{figure*}

\paragraph*{Пример применения критерия~(12) при истин\-ности~{\boldmath{$H_0$}}.}
На рис.~\ref{fg:norm} изображены гистограммы для двух выборок из стандартного нормального распределения
(рис.~\ref{fg:norm},\,\textit{а} и~1,\,\textit{б})
и стандартного нормального распределения с шумом
$\varepsilon\hm\sim 0{,}1{R}[0,1]$ (рис.~\ref{fg:norm},\,\textit{в} и~1,\,\textit{г}),
а также зависимость расстояния Кульбака--Лейблера
$D_{\KL}(\hat{P}_{m}||\hat{P}'_{m})$ между дискретными распределениями,
задаваемыми гистограммами~$\hat{P}_{m}$ и~$\hat{P}'_{m}$, между выборками
одинакового объема~$m$  от объема выборки~$m$ и область допустимых значений
с точки зрения критерия~\eqref{eq:Uchi2}
(рис.~\ref{fg:norm},\,\textit{д} и 1,\,\textit{е}).
Здесь вместо критических значений $\bar{t}^{\chi^2}_{1-\alpha}$,
$\bar{t}^{\chi^2}_{\alpha}$ и $t_m \hm= 2m{D}_{\KL}$ отложены величины
$\bar{t}^{\chi^2}_{1-\alpha}/(2m)$,  $\bar{t}^{\chi^2}_{\alpha}/(2m)$ и $t_m/(2m)$,
чтобы продемонстрировать масштаб расстояния Кульбака--Лейблера и наличие
сходимости. Рисунки показывают, что в данном случае использование
распределения~$\chi_{2\mathcal{N}}^2$ в качестве оценки предельного распределения статистики~$t_m$
позволяет принять верное решение о принадлежности рядов к одному  распределению.
Кривые~\textit{1} и~\textit{3} показывают границу области, в которую вошло $1\hm- \alpha \hm= 90\%$
выборки, и задают оценку критической области для
$D_{\KL}(\hat{P}_m||\hat{P}'_m)$. Более подробно результаты описаны в разд.~5.



Покажем теперь, что критерий~\eqref{eq:Uchi2} также можно использовать
для отвержения гипотезы~$H_0$.

\smallskip

\noindent
\textbf{Теорема~2.}
\textit{Критерий~\eqref{eq:Uchi2} состоятелен:
$$
\lim\limits_{m\rightarrow\infty} \mathrm{P}(t_m \in U | H_1) = 1\,,
$$
т.\,е.\ вероятность отвергнуть гипотезу~$H_0$, если распределения
временн$\acute{\mbox{ы}}$х рядов~$X$ и~$X'$ не совпадают, с увеличением выборки стремится к единице.}

\begin{figure*}[b] %fig2
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=164.105mm
\epsfbox{str-2.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Зависимость статистики~$t_m$ от объема выборки для различных пар
распределений; сплошными кривыми отмечены границы доверительного интервала
для~$t_m$ при $\alpha\hm = 0{,}1$:
(\textit{а})~$\mathrm{Exp}\,(1)||\mathrm{Exp}\,(1)$;
(\textit{б})~$\mathrm{Exp}\,(1)||\mathcal{N}(0,1)$;
(\textit{в})~$\mathrm{Exp}\,(1)||R(0,1)$;
(\textit{г})~$\mathcal{N}(0,1)||\mathrm{Exp}\,(1)$;
(\textit{д})~$\mathcal{N}(0,1)||\mathcal{N}(0,1)$;
(\textit{е})~$\mathcal{N}(0,1)||R(0,1)$;
(\textit{ж})~$R(0,1)||\mathrm{Exp}\,(1)$;
(\textit{з})~$R(0,1)||\mathcal{N}(0,1)$;
(\textit{и})~$R(0,1)||R(0,1)$
\label{fg:others}}
\end{figure*}


\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \
Пусть функции распределения~$P$ и~$P'$ временн$\acute{\mbox{ы}}$х
рядов не совпадают. Тогда найдется $x^{*}\hm\in\mathbb{R}$, при котором
значения этих функций различны: $P(x^{*})\hm\neq P'(x^{*})$.
Следовательно, найдется такой способ разбиения пространства~$\mathbb{R}$,
что для некоторого~$i$ вероятность попадания в \mbox{$i$-й} промежуток не одинакова
для рассматрива\-емых случайных величин:
$$
P(a_i < x \leq a_{i+1}) = p_i \neq p'_i = P'(a_i < x \leq a_{i+1})\,.
$$
Пусть $p_i > p'_i$. Согласно~\eqref{eq:CLT} при больших~$m$ с
вероятностью~$\mathrm{P} \hm> (2\Phi(C_1)\hm - 1)(2\Phi(C_2) \hm- 1)$ выполнено
$$
\left\vert n_i - mp_i\right\vert < C_1\sqrt{m}\,; \quad
\left\vert n'_i - mp'_i\right\vert < C_2\sqrt{m}\,.
$$
Для любого $\varepsilon > 0$ найдется константа
$C_{\varepsilon}: \mathrm{P} \hm> (2\Phi(C_{\varepsilon}) \hm- 1)^2 \hm> 1 \hm- \varepsilon$.
Выберем $C_1 \hm= C_2 \hm= C_{\varepsilon}$.
Тогда $(n_i - n'_i) \hm> m(p_i \hm- p'_i) \hm+ O(\sqrt{m})$ и
\begin{equation}
\label{eq:O(m)}
\fr{(n_i - n'_i)^2}{n_i} > m\fr{(p_i - p'_i)^2}{p_i} + O(\sqrt{m}) > Cm\,.
\end{equation}
Следовательно,  для любого $\alpha \hm\in (0,1)$ при достаточно больших~$m$
$$
t_m = 2mD_{\KL}(\hat{P_m^1}||\hat{P_m^2}) \sim
\sum\limits_{i=1}\fr{(n_i - n'_i)^2}{n_i} > Cm > \bar{t}_{\alpha}
$$
с вероятностью $\mathrm{P} > 1 \hm- \epsilon$, т.\,е.\
вероятность $\mathrm{P}(t_m \hm> \bar{t}_{\alpha}) \hm\rightarrow 1$ при
$m \hm\rightarrow \infty$.


\smallskip

     \begin{figure*}[b] %fig3
     \vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=163.363mm
\epsfbox{str-3.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Зависимость фактического уровня значимости от объема выборки при различных уровнях
значимости критерия~$\chi_{2\mathcal{N}}^2$ (\textit{1}~--- $\alpha\hm= 10^{-1}$;
\textit{2}~--- 10$^{-2}$; \textit{3}~--- $\alpha\hm= 10^{-3}$):
(\textit{a})~$\mathrm{Exp}\,(1)||\mathrm{Exp}\,(1)$;
(\textit{б})~$\mathcal{N}(0,1)||\mathcal{N}(0,1)$;
(\textit{в})~$R(0,1)||R(0,1)$\label{fg:alpha}}
\end{figure*}


\section{Вычислительный эксперимент}\label{sec:CompExp}

Работа критерия была рассмотрена на различных парах распределений.
Для выбранной пары распределений повторялась следующая процедура:
 \begin{enumerate}[(1)]
 \item генерировались выборки~$X$ и~${X'}$ одинакового объема~$m$;
 \item по выборкам строились гистограммы~$\hat{P}_m$ и~$\hat{P}^\prime_m$
 с фиксированным числом разбиений $N \hm= 20$ и вычислялись расстояния
 Кульбака--Лейблера $D_{\KL}(\hat{P}_m || \hat{P}^\prime_m)$;
     \item расстояния усреднялись по 1000~генерациям выборок;
     \item объем $m$ выборки увеличивался.
     \end{enumerate}
     На каждом из графиков на рис.~\ref{fg:others} отложены рас\-сто\-яния
     $D_{\KL}(\hat{P}_m | \hat{P}^\prime_m)$ в зависимости от объема выборки и
     критические значения~$\bar{t}^{\chi^2}/(2m)$ при заданном уровне
     значимости~$\alpha$. Заметим, что в случае различных распределений
     расстояние $D_{\KL}(\hat{P}_m | \hat{P}^\prime_m)$ быстро попадает в критическую
     область и характер его зависимости от~$m$ согласуется с
     оценкой~\eqref{eq:O(m)}. Отрицательные значения, не характерные для
     расстояния Куль\-ба\-ка--Лейб\-ле\-ра, возникают при чис\-лен\-ном приближении
     интеграла~\eqref{eq:dKL}, когда распределение в знаменателе под знаком
     логарифма\linebreak имеет большую область определения. Именно из-за отрицательных
     значений был использован двусторонний критерий. В дальнейших экспериментах
     было использовано симметризованное расстояние
     Куль\-ба\-ка--Лейб\-ле\-ра~\eqref{eq:matKLdist}, что позволило использовать
     односторонний критерий. На графиках, иллюстрирующих применение критерия
     к выборкам из одного распределения (рис.~\ref{fg:others},\,\textit{а}, \textit{д}, \textit{и}),
     также показаны штриховыми кривыми~\textit{1} и~\textit{2}
     значения $\bar{t}/(2m)$, где $\bar{t}$~---
     оценки критических значений, полученные экспериментально:
     $$
     \bar{t}_{\alpha} = \min\left\{\bar{t} : \fr{1}{M}\sum\limits_{t\in{T}} [t > \bar{t}]
     < \alpha\right\}.
     $$
      Здесь суммирование индикаторной функции $[t \hm> \bar{t}]$ ведется по
      всей выборке~$T$ статистик~$t$, полученных по~$M$ генерациям пар выборок~$X$
      и~$X'$ (в данном эксперименте $M\hm = 1000$). Видно, что, хотя критические
      области~$U^{\chi^2}$ и~$U$ не совпадают, при истинности гипотезы~$H_0$
      статистика~$t_m$ не попадает ни в~$U^{\chi^2}$, ни в~$U$.


\paragraph*{Оценка фактического значения~{\boldmath{$\alpha$}}.}
Так как распределение статистики~$t_m$ не совпадает с распределением~${\chi^2}$,
уровень значимости~$\alpha$, при котором определяется критическая
область~$U^{\chi^2}$, не соответствует реальному уровню значимости критерия.
Чтобы оценить реальный уровень значимости решения о принятии или отвержении
гипотезы~$H_0$, необходимо подсчитать долю объектов выборки~$T$,
попавших в~$U^{\chi^2}$ при заданном~$\alpha$:
$$
\hat{\alpha} = \fr{1}{M}\sum\limits_{t\in{T}} \left[t > \bar{t}^{\chi^2}_{\alpha}\right]\,.
$$
 Результаты отражены на рис.~\ref{fg:alpha}. Из рисунков следует, что для
 достижения уровня значимости $\alpha \hm= 0{,}1$ нужно использовать в качестве
 оценки~$U$ критическую область~$U^{\chi^2}$ c уровнем значимости $\alpha\hm = 0{,}001$.



\paragraph*{Кластеризация временн$\acute{\mbox{\textbf{ы}}}$х рядов, отражающих железнодорожные
грузоперевозки.}
Продемонстрировав таким образом статистическую значимость рассто\-яния
Куль\-ба\-ка--Лейб\-ле\-ра, построим кластеризацию набора временн$\acute{\mbox{ы}}$х рядов
Российских железных дорог.
Данные о перевозках включают даты отправления и прибытия, станции внутри
железнодорожной ветки и группы грузов. Для исследования были выбраны временн$\acute{\mbox{ы}}$е
ряды с весами вагонов, нагруженных различными группами грузов, агрегированные
по станциям. Вначале из рассмотрения были исключены ряды, содержащие менее
50~отсчетов времени.
Матрицы~$D$ симметризованных расстояний Кульбака--Лейблера~\eqref{eq:matKLdist}
для набора исследуемых временн$\acute{\mbox{ы}}$х рядов изображены на рис.~\ref{fg:matKLdist}.
Решая задачу кластеризации~\eqref{eq:clastering}, необходимо стремиться при\-вес\-ти
матрицу~$D$ к блочному виду. В~левом столбце таблицы показано, как именно
перевозимые группы грузов были разбиты на кластеры для случая $K \hm= 5$.

\end{multicols}

\begin{figure} %fig4
     \vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=161.515mm
\epsfbox{str-4.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Симметризованные матрицы попарных расстояний Кульбака--Лейблера между
временн$\acute{\mbox{ы}}$ми рядами для различных групп грузов: до кластеризации~(\textit{a})
и после нее для $K \hm= 5$~(\textit{б}) и  10~кластеров~(\textit{в})}
\label{fg:matKLdist}
\end{figure}

\begin{table}\small
\begin{center}
\begin{tabular}{|p{7.8cm}||p{7.8cm}|}
\multicolumn{2}{c}{Группы грузов}\\[6pt]
\hline
 1~--- Каменный уголь; 2~--- Кокс;  3~--- Нефть и нефтепродукты; 7~---
 Руда железная и марганцевая; 8~--- Руда цветная и серное сырье;
 9~--- Черные металлы; 10~--- Метизы и оборудование; 11~---
 Металлические конструкции;  14~--- Сельскохозяйственные машины;
 15~--- Автомобили; 16~--- Цветные металлы; изделия из них и лом цветных металлов;
 17~--- Химические и минеральные удобрения; 18~--- Химикаты и сода;
 20~--- Промышленное сырье и формовочные материалы; 22~--- Огнеупоры;
 23~--- Цемент; 25~--- Сахар; 26~--- Мясо и масло животное; 27~--- Рыба;
 28~--- Картофель, овощи и фрукты; 36~--- Комбикорма;  38~--- Жмыхи;
 39~--- Бумага; 42~--- Грузы в контейнерах
 &
 1~--- Каменный уголь; 2~--- Кокс;  3~--- Нефть и нефтепродукты;
 \textbf{6~--- Флюсы}; \textbf{21~--- Шлаки гранулированные}; 7~---
 Руда железная и марганцевая; 8~--- Руда цветная и серное сырье;
 10~--- Метизы и оборудование; 11~--- Металлические конструкции;
 12~--- Метизы; 14~--- Сельскохозяйственные машины; 15~--- Автомобили;
 16~--- Цветные металлы, изделия из них и лом цветных металлов; 17~---
 Химические и минеральные удобрения; 18~--- Химикаты и сода;  20~---
 Промышленное сырье и формовочные материалы; 22~--- Огнеупоры; 23~---
 Цемент; 25~--- Сахар; 26~--- Мясо и масло животное; 27~--- Рыба; 28~---
 Картофель, овощи и фрукты; 36~--- Комбикорма;  38~--- Жмыхи;   39~---
 Бумага; 42~--- Грузы в контейнерах\\
\hline
43~--- Остальные и сборные грузы; 19~--- Строительные грузы
&
9~--- Черные металлы; 12~--- Метизы\\
\hline
31~--- Промышленные товары народного потребления; 34~--- Зерно
&43~--- Остальные и сборные грузы; 19~--- Строительные грузы;
35~--- Продукты перемола \\
\hline
13~--- Лом черных металлов
&
31~--- Промышленные товары народного потребления;
\textbf{29~--- Поваренная соль}; 34~--- Зерно\\
\hline
35~--- Продукты перемола
& 13~--- Лом черных металлов\\
\hline
\end{tabular}
\end{center}
\end{table}

\begin{multicols}{2}

Ряды, содержащие менее 50~отсчетов, последовательно присоединялись к
каждому из рядов, содержавших более 50~отсчетов. Затем для объединенного
ряда и исходного ряда длиной более 50~отсчетов проверялась гипотеза о
при\-над\-леж\-ности  рядов к одному распределению. Результаты проверки гипотезы
и значения статистики~$t_{m,l}$ изоб\-ра\-же\-ны на рис.~\ref{fg:KLtest},\,\textit{а},~\textit{б}.
Строки соответствуют временн$\acute{\mbox{ы}}$м рядам длиной менее 50~отсчетов,
столбцы~--- длиной более 50~отсчетов. Результат проверки гипотезы~$H_0$
отмечен синим цветом, если гипотеза отвергается, красным~--- если гипотеза
принимается. Было выполнено слияние рядов <<Поваренная соль>> и
<<Продукты промышленного потребления>>, а также <<Флюсы>> и
<<Шлаки гранулированные>> с временн$\acute{\mbox{ы}}$м рядом <<Нефть и нефтепродукты>>.
Затем снова была выполнена кластеризация, результаты которой занесены в
правый столбец таблицы. Вид матрицы парных расстояний после слияния
временн$\acute{\mbox{ы}}$х рядов и их кластеризации представлен на
рис.~\ref{fg:KLtest},\,\textit{в}.

\begin{figure*} %fig5
\vspace*{1pt}
\begin{center}
\mbox{%
\epsfxsize=161.515mm
\epsfbox{str-5.eps}
}
\end{center}
\vspace*{-9pt}
\Caption{Результат проверки гипотезы о принадлежности исходного временн$\acute{\mbox{о}}$го
ряда и временн$\acute{\mbox{о}}$го ряда, получаемого присоединением к нему
некоторого более короткого ряда, к одному распределению~(\textit{а});
значения статистики~$t_{m,l}$ при проверке гипотезы~$H_0$~(\textit{б});
матрица парных расстояний после объединения временн$\acute{\mbox{ы}}$х рядов и их
кластеризации~(\textit{в})}
\label{fg:KLtest}
\end{figure*}






\section{Заключение}

Расстояние Кульбака--Лейблера широко применяется для сравнения
распределений, однако считается непригодным для использования в статистических
целях из-за того, что не имеет предельного распределения.
В~данной работе показано, что распределение расстояния Кульбака--Лейблера
в пределе ограничено сверху хи-квад\-ра\-том. Это дает, пусть и ограниченную,
возможность использования расстояния Куль\-ба\-ка--Лейб\-ле\-ра между распределениями
в качестве статистики для проверки гипотезы о принадлежности двух выборок
одному распределению и позволяет говорить о статистической значимости
расстояния Куль\-ба\-ка--Лейб\-ле\-ра. Код, позволяющий выполнить процедуру проверки
нулевой гипотезы о принадлежности выборок к одному распределению на основе
расстояния Кульбака--Лейблера между их гистограммами, находится в свободном
доступе~\cite{KLtestCode}. В~работе продемонстрировано использование
предлагаемого критерия, а также приведен пример кластеризации временн$\acute{\mbox{ы}}$х
рядов на основе расстояния Кульбака--Лейблера.

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{99}
\bibitem{Medvednikova2012}
\Au{Вальков~А.\,С., Кожанов~Е.\,М., Медведникова~М.\,М., Хусаинов~Ф.\,И.}
Непараметрическое прогнозирование загруженности системы железнодорожных
узлов по историческим данным~// Машинное обучение и анализ данных,  2012.
T.~1. №\,4. C.~448--465.
    \bibitem{Motrenko2013}
    \Au{Вальков~А.\,С., Кожанов~Е.\,М., Мотренко~А.\,П., Хусаинов~Ф.\,И.}
    Построение кросс-корреляционных зависимостей при прогнозе загруженности
    железнодорожного узла~// Машинное обучение и анализ данных,  2013.
    T.~1. №\,5.  C.~505--518.
    \bibitem{Medvdnikova2014}
    \Au{Медведникова~М.\,М.}  Согласование агрегированных
    непараметрических прогнозов временн$\acute{\mbox{ы}}$х рядов~// Машинное обучение и анализ
    данных, 2014  (в печати). T.~1. №\,8.
\bibitem{Kullback1959}
\Au{Kullback S.} Information theory and statistics. --- New York: Wiley, 1959. 395~p.
\bibitem{Chernoff1952}
\Au{Chernoff H.}   A~measure of asymptotic efficiency for tests of a hypothesis
based on the sum of observations~// Ann.  Math. Stat., 1952.
Vol.~4. No.\,23. P.~493--655.
\bibitem{Kolmogorov1965}
\Au{Kolmogorov~A.\,N.} On the approximation of distributions of sums of
independent summands by infinitely divisible distributions~//
{Contributions to statistics}.~--- Oxford: Pergamon Press, 1965. P.~158--174.
    \bibitem{AliSilvey1966}
    \Au{Ali~S.\,M., Silvey~S.\,D.} A~general class of coefficients of
    divergence of a distribution from another~// J.~R. Stat. Soc.
    Ser.~B (Methodoligical),  1966. Vol.~1. No.\,28. P.~131--142.
\bibitem{scizar2004}
\Au{Csiszar I., Shields P.} Information theory and statistics: A~tutorial~//
Foundations Trend Comm. Inform. Theory, 2004. No.\,4. P.~417--528.
\bibitem{Gibs}
\Au{Gibbs A.\,L., Su F.\,E.} On choosing and bounding probability
metrics~// Intern. Stat. Rev., 2002. Vol.~3. No.\,70. P.~419--435.
\bibitem{Mallows1972}
\Au{Mallows C.}  A~note on asymptotic joint normality~//
Ann. Math. Stat., 1972. Vol.~42. No.\,2. P.~508--515.
    \bibitem{Irpino}
    \Au{Irpino A., Verde R., Lechevallier~Y.}
    Dynamic clustering of histograms using Wasserstein metric~//
    Advances in computational statistics.~--- Heidelberg: Physica-Verlag, 2006. P.~869--876.
\bibitem{Dvoenko1999}
\Au{Двоенко~С.\,Д.} Неиерархический дивизимный алгоритм кластеризации~//
Автоматика и телемеханика, 1999. №\,4. С.~117--123.

\bibitem{StrijovRudakov}
\Au{Стрижов~В.\,В., Кузнецов~М.\,П., Рудаков~К.\,В.} Метрическая
кластеризация последовательностей аминокислотных остатков в ранговых шкалах~//
Математическая биология и биоинформатика, 2012. Т.~7. №\,1. С.~345--359.
\bibitem{Dvoenko2013}
\Au{Двоенко~С.\,Д., Пшеничный~Д.\,О.} О~метрической коррекции мат\-риц
парных сравнений~// Машинное\linebreak обучение и анализ данных, 2013.  T.~1. №\,5.  C.~606--620.

\bibitem{KLtestCode}
\Au{Мотренко~А.\,П.} Статистический тест для проверки гипотезы о
принадлежности двух выборок одному распределению на основе расстония
Кульбака--Лейблера~// Algorithms of machine learning.~---
Sourceforge, 2014.
{\sf
http://sourceforge.net/p/mlalgorithms/ code/HEAD/tree/Group874/Motrenko2014KL/code/ KLtest.m}.


\end{thebibliography}
} }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в редакцию 12.13.14}}

%\newpage


\vspace*{12pt}

\hrule

\vspace*{2pt}

\hrule


\def\tit{OBTAINING AN AGGREGATED FORECAST OF RAILWAY FREIGHT TRANSPORTATION USING KULLBACK--LEIBLER DISTANCE}

\def\titkol{Obtaining an aggregated forecast of railway freight transportation using Kullback--Leibler distance}

\def\aut{A.\,P.~Motrenko$^1$ and~V.\,V.~Strijov$^2$}
\def\autkol{A.\,P.~Motrenko and~V.\,V.~Strijov}


\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-9pt}

\noindent
$^1$Moscow Institute of Physics and Technology, 9 Institutskiy per., Dolgoprudny, Moscow Region 141700,
Russian\\
$\hphantom{^1}$Federation\\
$^2$Dorodnicyn Computing Centre, Russian Academy of Sciences,
40 Vavilov Str., Moscow 119333, Russian\\
$\hphantom{^1}$Federation



\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND APPLICATIONS\ \ \ 2014\ \ \ volume~8\ \ \ issue\ 2}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND APPLICATIONS\ \ \ 2014\ \ \ volume~8\ \ \ issue\ 2
\hfill \textbf{\thepage}}}

\vspace*{6pt}

\Abste{This study addresses the problem of obtaining an aggregated forecast
of railway freight transportation. To improve the quality of aggregated
forecast,  the time series clusterization problem is solved in such a way that the
time series in each cluster belong to the same distribution. To solve the
clusterization problem, it is necessary to estimate the distance between empirical
distributions of the time series. A~two-sample test  based on
the Kullback--Leibler distance between histograms of the time series is introduced.
Theoretical and experimental research of the suggested test is provided. Also,
as a demonstration, the clusterization of a set of railway time series based
on the Kullback--Leibler distance between time series is obtained.}

\KWE{empirical distribution function; distance between histograms;
Kullback--Leibler distance; two-sample problem}

\DOI{10.14357/19922264140209}

\vspace*{-12pt}

\Ack
\noindent
The work was supported by the Russian Foundation for Basic
Research (grant No.\,13-07-13139).


  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{99}

\bibitem{Medvednikova2012-1}
\Aue{Val'kov, A.\,S., E.\,M.~Kozhanov, M.\,M.~Medvednikova, and F.\,I.~Khusainov}.
2012. Neparametricheskoe prognozirovanie zagruzhennosti sistemy zheleznodorozhnykh uzlov
po istoricheskim dannym [Nonparametric forecasting of railroad stations
occupancy according to historical data].
\textit{Mashinnoe Obuchenie i Analiz Dannykh}
[J.~Machine Learning and Data Analysis] 4(1):448--465.

\bibitem{Motrenko2013-1}
\Aue{Val'kov, A.\,S., E.\,M.~Kozhanov, A.\,P.~Motrenko, and F.\,I.~Khusainov}.
2013. Postroenie kross-korrelyatsionnykh zavisimostey pri prognoze zagruzhennosti
zheleznodorozhnogo uzla [Constructing a cross-correlation model to forecast the
utilization of a railway junction station].
\textit{Mashinnoe Obuchenie i Analiz Dannykh}
[J.~Machine Learning and Data Analysis]. 5(1):505--518.

\bibitem{Medvdnikova2014-1}
\Aue{Medvednikova, M.\,M.}  2014 (in press). Soglasovanie agregirovannykh
neparametricheskikh prognozov vremennykh ryadov
[Matching of aggeragared nonparametric forecasts of time series].
\textit{Mashinnoe Obuchenie i Analiz Dannykh}
[J.~Machine Learning and Data Analysis] 8(1). [In Russian.]

\columnbreak

\bibitem{Kullback1959-1}
\Aue{Kullback,~S.}  1959. \textit{Information theory and statistics}.
New York: Wiley. 395~p.
\bibitem{Chernoff1952-1}
\Aue{Chernoff,~H.} 1952. A~measure of asymptotic efficiency for tests of a
hypothesis based on the sum of observations. \textit{Ann. Math. Stat.} 4(23):493--655
\bibitem{Kolmogorov1965-1}
\Aue{Kolmogorov, A.\,N.} 1965. On the approximation of
distributions of sums of independent summands by infinitely divisible
distributions.
\textit{Contributions to statistics}. Oxford: Pergamon Press. P.~158--174.
\bibitem{AliSilvey1966-1}
\Aue{Ali, S.\,M., and S.\,D.~Silvey}. 1966.
A~general class of coefficients of divergence of a distribution from another.
\textit{J.~R. Stat. Soc. Series B (Methodoligical)} 1(28):131--142.
\bibitem{scizar2004-1}
\Aue{Csiszar,~I., and P.~Shields}. 2004. Information theory and statistics:
A~tutorial. \textit{Foundations Trend Comm. Inform. Theory}
4:417--528.
\bibitem{Gibs-1}
\Aue{Gibbs, A.\,L., and F.\,E.~Su}.  2002. On choosing and bounding probability
metrics. \textit{Intern. Stat. Rev.} 3(70):419--435.
\bibitem{Mallows1972-1}
\Aue{Mallows,~C.} 1972. A~note on asymptotic joint normality.
\textit{Ann. Math. Stat.} 42(2):508--515.

\pagebreak

\bibitem{Irpino-1}
\Aue{Irpino,~A., R.~Verde, and Y.~Lechevallier}.  2006.
Dynamic clustering of histograms using Wasserstein metric.
\mbox{\textit{COMPSTAT}}. 869--876.
\bibitem{Dvoenko1999-1}
\Aue{Dvoenko, S.\,D.}
1999. Neierarkhicheskiy divizimnyy algoritm klasterizatsii
[Nonhierarchical divisible clasterization algorithm].
\textit{Avtomatika i Telemekhanika} [Automation and Remote Control] 4:117--123.

\bibitem{StrijovRudakov-1}
\Aue{Strizhov, V.\,V., M.\,P.~Kuznetsov, and K.\,V.~Rudakov}.
2012. Metricheskaya klasterizatsiya posledovatel'nostey aminokislotnykh
ostatkov v rangovykh shkalakh [Metric clustering of sequences of amino acid
residues in rank scales].
\textit{Matematicheskaya Biologiya i Bioinformatika}\linebreak\vspace*{-12pt}

\columnbreak

\noindent
[Mathematical Biology and Bioinformatics] 7(1):345--359.
\bibitem{Dvoenko2013-1}
\Aue{Dvoenko, S.\,D., and D.\,O~Pshenichnyy}.  2013.
O~metricheskoy korrektsii matrits parnykh sravneniy
[On metric correction of matrices of pairwise comparisons].
\textit{Mashinnoe Obuchenie i Analiz Dannykh}
[J.~Machine Learning and Data Analysis]  5(1):606--620.

\bibitem{KLtestCode-1}
\Aue{Motrenko, A.\,P.}  2014.
Statisticheskiy test dlya proverki gipotezy o prinadlezhnosti dvukh vyborok
odnomu raspredeleniyu na osnove rasstoniya Kul'baka--Leyblera
[A~statistical test for the two-sampe problem based on the Kullback--Leibler
distance]. {\sf http://sourceforge.net/ p/mlalgorithms/code/HEAD/tree/Group874/ Motrenko2014KL/code/KLtest.m}.

\end{thebibliography}
} }


\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received March 12, 2014}}

\vspace*{-18pt}




\Contr

\noindent
\textbf{Motrenko Anastasia P.} (b.\ 1992)~---
student, Moscow Institute of Physics and Technology, 9 Institutskiy per., Dolgoprudny, Moscow Region 141700,
Russian Federation;   anastasia.motrenko@gmail.com

\vspace*{3pt}

\noindent
\textbf{Strijov Vadim V.} (b.\ 1967)~---
Candidate of science (PhD) in physics and mathematics, associate professor,
scientist, Dorodnicyn Computing Center, Russian Academy of Sciences,
40 Vavilov Str., Moscow 119333, Russian Federation;   strijov@ccas.com

 \label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература}