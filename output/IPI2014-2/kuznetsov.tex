\def\stat{kuznetsov}

\def\tit{УНИВЕРСАЛЬНАЯ ТЕХНОЛОГИЯ ОЦЕНКИ БЛИЗОСТИ ИНФОРМАЦИОННЫХ
ОБЪЕКТОВ}

\def\titkol{Универсальная технология оценки близости информационных
объектов}

\def\autkol{Л.\,А.~Кузнецов}

\def\aut{Л.\,А.~Кузнецов$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

%{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]{Работа
%выполнена при финансовой поддержке РФФИ (проект 11-01-00515а).}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Российская академия народного хозяйства и государственной службы при Президенте Российской Федерации
(Липецкий филиал), Kuznetsov.Leonid48@gmail.com}

  \Abst{Изложена технология определения степени подобия информационных объектов,
которые представлены текстами или графическими изображениями. Объекты
формализуются вероятностными моделями. Структура модели задается алгеброй на
минимальном наборе изобразительных компонентов объекта. Количественными
характеристиками структуры объектов являются распределения вероятностей на заданной
алгебре. Количество информации в объектах оценивается энтропией. На энтропиях задается
мера информационного подобия сопоставляемых объектов. Показана методика
формирования оценки для текстовых и графических объектов. Приведены примеры
реализации алгоритмов оценки и показана более высокая эффективность разработанных
методов по сравнению с методами, описанными в литературе. Технология формирования
образов информационных объектов и сравнения их семантического содержания является
универсальной. Показаны возможности адаптации разработанной технологии к
содержательным характеристикам исследуемых объектов.}

  \KW{информационный объект; текст; изображение; вероятностная модель; семантическое
подобие; энтропия; мера подобия}

\DOI{10.14357/19922264140213}

\vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}


\section{Введение}

  Оценка близости информационных объектов является наиболее
распространенным компонентом информационных технологий. На компоненте
оценки информационного подобия объектов базируются технологии поиска
информации, сравне\-ния проектов, оценки оригинальности научных результа\-тов
и~т.\,п. На этом компоненте в дальнейшем будут разработаны автоматические
про\-цедуры дифференцированной оценки знаний, вклю\-ча\-ющие оценку уровня
близости текстов на естественных и формальных языках, структури\-рованных и
неструктурированных графических объектов, т.\,е.\ всех компонентов
представления знаний, к определению уровня усвоения которых сводится
проверка качества обучения. Совокупность процедур оценки близости
информационных объектов, представленных на разных <<языках>>, позволит
создавать автоматизированные системы проверки качества на всех уровнях
обучения. Такие системы позволят исключить тестовый самообман, обеспечить
объективность полноценной оценки качества подготовки, устранить
возможность коррупции и разнообразных подтасовок в сфере образования.

  Ниже излагается универсальная технология формальной оценки уровня
подобия информационных объектов, имеющих однотипное представление на
естественном языке (тексты), на формальном языке (формулы математические,
химические и~др.), графическое представление (схемы, чертежи, картины).

  Информационные объекты обычно представляют собой композицию
количественных данных и неформализованных сведений, которые могут быть\linebreak
представлены текстовой и графической информацией. В~зависимости от
содержания и предназначения объекта доля текстовой и графической
информа\-ционных составляющих может иметь определяющее значение.
Поэтому разработка моделей формального описания и оценки подобия
объектов, представленных текстовой и графической информацией, является
важной задачей, решению которой посвящена работа.

  В информационно-поисковых системах при классификации текстов, при
проверке текстов на плагиат~[1] применяются статистические подходы на
основе век\-тор\-но-про\-стран\-ст\-вен\-ной модели текста, предложенный
Солтоном с соавторами в 1975~г.~[2]. В~ней текст представляется вектором частот
входящих в него слов, а оценка близости текстов равна косинусу угла между
векторами текстов.

  Более эффективные инструменты оценки близости информационных
объектов могут быть синтезированы на основе их представления в виде
однотипных вероятностных моделей, допускающих структуризацию и
количественное сопоставление содержащейся в них информации. Исследования
показали, что вероятностная модель позволяет формально и с произвольной
глубиной детализации описывать объекты, представленные текстами на
естественных и формальных языках~[3] или структурированными~[4] и
неструктурированными графическими изображениями~[5]. Вероятностная
модель позволяет формализовать объекты в виде системы классов различной
информационной значимости. Система классов может адаптироваться к
содержательной специфике сопоставляемых объектов и алфавитам их
представления. Оценка уровня близости объектов производится на системе
классов с учетом их ин\-фор\-ма\-ци\-он\-но-се\-ман\-ти\-че\-ской значимости.
Процедуры формирования системы классов на заданном алфавите и уровня их
значимости могут быть реализованы в виде самонастраивающихся по принципу
обратной связи систем.

\section{Вероятностная модель}

  Сопоставляемые информационные объекты формализуются в виде
вероятностных моделей. Абстрактная вероятностная модель эксперимента с
конечным числом исходов, или просто вероятностная модель, вводится в
теории вероятностей для формального представления результатов
произвольного эксперимента. Модель представляет собой совокупность
трех составляющих~[6]:
  \begin{equation}
  M=\{ \Omega, \aleph, P(A_i)\}\,,
  \label{e1-kuz}
  \end{equation}
  где $\Omega = \{\omega_1, \omega_2, \ldots , \omega_n\}$~--- множество
элементарных событий (исходов или реализаций исследу\-емой случайной
величины);
  $\aleph\hm= \{A_1, A_2, \ldots , A_m\}$~--- множество (система) случайных
событий (алгебра);
  $P(A_i)$, $i \hm= 1, 2, \ldots , m$,~--- вероятности случайных событий.

  В контексте оценки близости информационных объектов под случайными
величинами могут пониматься величины или элементы, совокупностью
которых представляется объект. Случайной величиной или элементом
информационного объекта, представленного текстом на естественном языке,\linebreak
является слово. Для структурированного графи\-ческого объекта,
представленного, например, электри\-ческой схемой, случайной величиной
является стандартизованное обозначение элементов электрических схем. Для
неструктурированного графического объекта, представленного, например,
картиной, случайными величинами являются цвет и координаты пикселов,
отражающих ее на мони\-торе.

  В соответствии с содержанием информационных объектов случайные
величины, используемые для их представления, принимают свои значения~---
элементарные события~--- из конечных множеств, соответствующих
содержанию. Под элементарными событиями понимаются неделимые при
сравнении элементы~$\omega$, из которых формируются объекты. Случайная
величина <<слово>> (для русского текста) может принимать значения всех
слов, имеющихся в словарях русского языка. Случайная величина <<элемент
электрических схем>> может принимать значения элементов из
соответствующего ГОСТа~\cite{7-kuz}. Случайная величина <<пиксел>>
принимает значения из палитры цветов, представимых на мониторе, и
возможных координат его положения.

  Любые объекты представляют собой множества реализаций, или, по
терминологии теории вероятностей, элементарных исходов соответствующих
случайных величин. Текст представляется множеством различных слов,
которые являются реализациями случайной величины <<слово>>,
электрическая схема представляется набором значений величины <<элемент
электрических схем>>, картина~--- множеством реализаций величины
<<пиксел>>. Современные возможности информационных технологий
позволяют достаточно просто проверить полную идентичность
информационных объектов, представленных в электронном виде. Но в
большинстве задач обработки информации требуется не установка
идентичности, а оценка степени бли\-зости информационных объектов,
отраженная некоторой количественной мерой.

  Такая задача может быть решена с использова\-нием вероятностной модели
информационных\linebreak объектов, позволяющей структурировать множество
реализаций случайной величины $\Omega\hm= \{\omega_1,\omega_2, \ldots
,\omega_n\}$ введением системы классов $\aleph\hm=\{A_1, A_2, \ldots , A_m\}$.
Классы~$A_j$, $j\hm=1, 2, \ldots , m$,\linebreak позволяют отразить разнообразные
содержательные особенности и информационную значимость отдельных
совокупностей реализаций случайной величины. Классами может быть
формально пред\-став\-ле\-на семантика информационных объектов, являющаяся
определяющей при оценке их подобия.

  Случайные события $A_i$ конструируются на множестве реализаций
случайной величины $\Omega\hm= \{\omega_1,\omega_2, \ldots ,\omega_n\}$ с
помощью операций $\cup$~--- сложения случайных событий (объединения
множеств),\linebreak $\cap$~--- произведения случайных событий (пересечения
множеств), $\overline{\ \  \vphantom{A} }$~--- отрицания событий (дополнения множеств).
Случайные события~$A_i$ представляют подмножества множества~$\Omega$.
Случайные\linebreak события, получаемые из~$A_i$ с помощью перечисленных
операций, также принадлежат алгебре~$\aleph$. В~ал\-геб\-ру~$\aleph$ входят
невозможное событие (пустое множество~$\emptyset$) и достоверное событие
(множество~$\Omega$).

  Целью практического применения вероятностной модели~(1) является
структуризация информации, содержащейся в множестве~$\Omega$, и
выявление некоторых неслучайных ее характеристик, скрытых во множестве
случайных реализаций $\{\omega_1,\omega_2, \ldots ,\omega_n\}$. Именно эти
содержательные характеристики исследуемой случайной величины и
отражаются в модели~(1) случайными событиями~$A_i$, составляющими
алгебру~$\aleph$.

  Введение алгебры случайных событий $\aleph\hm= \{A_1, A_2, \ldots , A_m\}$
задает систему содержательных (качественных) характеристик, позволяющих
разделить множество элементарных событий $\Omega\hm=
\{\omega_1,\omega_2, \ldots ,\omega_n\}$ на классы~$A_1, A_2, \ldots , A_m$.
Принципиальным в данном контексте свойством ал\-геб\-ры является возможность
конструирования новых случайных событий из множества уже имеющихся,
потому что новые случайные события, полученные объединением,
пересечением и отрицанием принадлежащих алгебре событий, также
принадлежат алгебре, или точнее:

\vspace*{-2pt}

\noindent
  \begin{multline}
\mbox{из}\  A_i,\ A_j \in\aleph\  \mbox{ следует }\ A_i \cap A_j\in \aleph,\\
 A_i\cup a_j \in \aleph\
\mbox{ и }\ \overline{A}_i \in \aleph,\ \  i, j\in [1, m]\,.
\label{e2-kuz}
\end{multline}

  На основании~(2) алгебра на каждом новом этапе формирования (эволюции)
модели~(1) может неограниченно расширяться и изменяться применением
операций сложения, перемножения и отрицания к системе случайных событий
предшест\-ву\-юще\-го этапа.

  Количественной мерой, определяющей соотношение случайных событий,
образующих алгебру, является третий элемент модели~(1)~--- вероятности
случайных событий $P(A_i)$, которые находятся по вероятностям
элементарных событий:

\vspace*{2pt}

\noindent
  \begin{equation}
  P(A_i)= \sum\limits_{\omega_j\in A_i} p(\omega_j)\,,
  \label{e3-kuz}
  \end{equation}
где $p(\omega_j)$~--- вероятность элементарного события~$\omega_j$.

  Можно видеть, что вероятностная модель~(1) позволяет отразить всю
возможную информацию о случайной величине, которая может быть
формально извлечена из множества ее реализаций~$\Omega$. Система
случайных событий~$\aleph$ обеспечивает возможность выявления
неоднородности элементов множества~$\Omega$, а вероятности случайных
событий $A_i\hm\in \aleph$, $i\hm =1, 2, \ldots , m$, позволяют количественно
оценить степень неоднородности. Возможность модификации алгебры~(2)
позволяет осуществлять адаптацию структуры вероятностной модели~(1),
направление и результаты которой могут определяться некоторыми
функционалами, заданными на распределении вероятностей~(3).

\section{Вероятностная модель текстовых информационных
объектов}

  Оценка близости информационных объектов может осуществляться
сопоставлением их вероятностных моделей. Современные информационные
технологии позволяют представить в электронном виде информацию,
полностью характеризующую объекты самого разного содержания. При этом
информация на электронных носителях обычно представляет собой
комбинацию текстов на естественном языке и графических изображений.
Поэтому для формального представления содержательных информационных
объектов в виде вероятностных моделей~(1)--(3) необходимы инструменты
трансформации текстов и графических изображений в такие абстрактные
модели.

  Пусть информационный объект представлен текстом на естественном языке.
Будем иметь в виду структурированные языки, наделенные морфологией и
синтаксисом. Рассмотрим погружение информационного объекта в
вероятностную модель~(1), или, что одно и то же, формирование по тексту,
представленному на естественном языке, вероятностной модели~(1).
Вероятностная модель позволяет осуществить на необходимом уровне
детализации разложение моделируемых текстов на морфологические и
синтаксические компоненты, которые в обобщенном виде отражают
однотипные семантические представления.

  Уровень детализации структуры текстов определяется из условия конечного
предназначения вероят\-ностной модели~--- оценки степени семантического
подобия объектов (текстов). При разработке технологии можно исходить из
общепринятой практики неавтоматизированной экспертной оценки
семантической близости информационных объектов, представленных текстами
на естественном языке. Эксперт в содержании текстов выделяет и сопоставляет
определяющие семантические аспекты: (1)~объекты, т.\,е.\ о чем или о ком
сообщается в текстах; (2)~действия объекта или с объектом; (3)~образ и условия
действия (как, при каких условиях, где, когда действует объект или
осуществляются действия с ним); (4)~результат действий и~т.\,п.

  Отражению всех содержательных аспектов в структурированных языках
соответствуют определенные синтаксические конструкции, опирающиеся на
морфологию. В~результате разложения сопоставляемых текстов по алгебрам
единой структуры тексты трансформируются в обобщенные предложения, в
которых роль отдельных членов играют введенные компоненты алгебры~---
случайные события~$A_i$, $i\hm=1, 2, \ldots , m$, представляющие обобщенные
подлежащие, сказуемые, дополнения, обстоятельства и~т.\,п. Оценка близости
текстов на множестве компонентов алгебры, с учетом семантической ценности
слов и конструкций, позволяет принципиально изменить качество оценки
подобия текстов по сравнению с отмеченным методом простого подсчета
одинаковых слов в текстах (пересечения списков слов).

  Для иллюстрации формирования вероятностной модели текста~[8] ниже
используется простой объект, представленный на естественном языке
нижеследующим абзацем текста статьи, выделенным курсивом.

  \textit{Адаптация абстрактной модели~$(1)$ к описанию информационных
объектов, представленных текстовой и графической информацией,
достигается конкретизацией случайных величин и алгебры к содержательной
специфике объекта.}

  Содержание этого предложения может быть выражено бесконечным
множеством семантически равноценных фраз, в которых могут использоваться
наборы других слов. Из этого следует, что с
  ин\-фор\-ма\-ци\-он\-но-се\-ман\-ти\-че\-ских позиций слово может
трактоваться случайной величиной, а конкретные слова, использованные в этом
(и любом другом) предложении~--- реализациями, элементарными исходами
случайной величины <<слово>>. Поэтому выделенное предложение может
трактоваться как результат эксперимента, в котором случайная величина
<<слово>> получила следующие элементарные исходы (множество
реализаций):

\vspace*{-2pt}

\noindent
  \begin{multline}
  \Omega_1 =\{\omega_1 = \mbox{адаптация},\ \omega_2 = \mbox{абстрактной},\\
\omega_3 = \mbox{модели},\
  \omega_4 = 1,\ \omega_5 = \mbox{к},\  \omega_6 = \mbox{описанию},\\
  \omega_7 =
\mbox{информационных},\ \omega_8 = \mbox{объектов},\\
\omega_9 = \mbox{представленных},\
  \omega_{10} = \mbox{текстовой},\\
  \omega_{11} = \mbox{и},\ \omega_{12} =
\mbox{графической},\ \omega_{13} = \mbox{информацией},\\
  \omega_{14} = \mbox{достигается},\ \omega_{15}= \mbox{конкретизацией},\\
  \omega_{16} = \mbox{случайных},\ \omega_{17} = \mbox{величин},\ \omega_{18} =
\mbox{и},\\
\omega_{19} = \mbox{алгебры},\ \omega_{20} = \mbox{к},\
  \omega_{21} = \mbox{содержательной},\\
  \omega_{22}= \mbox{специфике},\ \omega_{23} = \mbox{объекта}\}\,.
  \label{e4-kuz}
  \end{multline}

  \vspace*{-2pt}

  Называя элементарные исходы, как оговорено выше, просто элементами,
можно сказать, что исследуемый текст состоит из элементов~(4). Различ\-ные
слова, образующие~$\Omega_1$, несут существенно отличающуюся
семантическую нагрузку, которая\linebreak связа\-на с их морфологической и
синтаксической принадлежностью. Поэтому дифференциация слов~---
элементарных исходов~$\Omega_1$ с учетом их семантической значимости
позволяет значительно повысить уровень адекватности формальной моде-\linebreak\vspace*{-12pt}
\columnbreak

\noindent
ли,
отражающей информационные объекты. При дифференциации слов
целесообразно использовать естественную структуру языка, регламентируемую
морфологией и синтаксисом.

  В структурированных языках морфология определяет принадлежность слов к
частям речи, их грамматические категории и формы. Семантический вес слов
определяется их принадлежностью к определенным частям речи. Синтаксис
регламентирует строй языка, место и роль в предложении отдельных слов,
которые отражают их семантическую значимость. Роль и место слов в
предложении, регули\-ру\-емые синтаксисом, тесно связаны с их морфологией,
определяющей принадлежность слов к\linebreak частям речи и форму представления.
Морфология и синтаксис дополняют друг друга и позволяют синтезировать
алгебру, достаточно полно отражающую семантическую нагрузку слов в тексте.

  Алгебра может синтезироваться на морфологической основе. При этом
система случайных \mbox{событий}, по которым распределяются слова, синтезируется
на частях речи. Для большинства структурированных языков это
существительные, прилагательные, числительные, местоимения и глаголы.

  Синтаксис также может быть принят за основу системы случайных событий,
по которым распределяются слова, составляющие текст. В~этом случае система
событий будет представлена наборами подлежащих, сказуемых, определений,
дополнений и других членов предложения. Система случайных событий, по
которым раскладываются тексты, может конструироваться на комплексной
основе морфологии и синтаксиса.

  Используя для иллюстрации простейшую морфологическую алгебру,
отражающую знаменательные части речи: существительные, прилагательные,
числительные, местоимения, наречия и глаголы (предлоги и союзы
игнорируются), получаем следующую систему случайных событий:

\vspace*{-2pt}

\noindent
  \begin{multline}
\aleph_1 = \{A_1~\mbox{--- существительное},\\
A_2~\mbox{--- прилагательное},\ A_3~\mbox{---
числительное},\\
A_4~\mbox{--- глагол}\}\,,
\label{e5-kuz}
\end{multline}
где

\vspace*{-2pt}

\noindent
\begin{multline*}
A_1=\{\omega_1 = \mbox{адаптация},\ \omega_3= \mbox{модели},\\
\omega_6=
\mbox{описанию},\ \omega_8= \mbox{объектов},\\
\omega_{13}= \mbox{информацией},\ \omega_{15}\ = \mbox{конкретизацией},\\
\omega_{17} = \mbox{величин},\ \omega_{19} = \mbox{алгебры},\\
\omega_{22} =
\mbox{специфике},\ \omega_{23} = \mbox{объекта}\}\,;
\end{multline*}

\vspace*{-12pt}

\noindent
\begin{multline*}
    A_2 = \{\omega_2 = \mbox{абстрактной},\\
     \omega_7= \mbox{информационных},\\
          \omega_9 = \mbox{представленных},\ \omega_{10} =
\mbox{текстовой},
     \end{multline*}

     \noindent
     \begin{multline*}
\omega_{12} = \mbox{графической},\ \omega_{16} = \mbox{случайных},\\
\omega_{21} = \mbox{содержательной}\}\,;
    \end{multline*}

    \noindent
    $$
    A_3=\{\omega_4= 1\}\,;
    $$
    $$
    A_4 =\{\omega_{14}= \mbox{достигается}\}\,.
    $$

  Четыре слова (к, и, и, к), содержащиеся в~$\Omega_1$~(4), исключены из
дальнейшего рассмотрения, так что общее число сохраненных элементарных
событий~--- количество исходов~--- 19. Вероятность каж\-до\-го из них
$p(\omega_j) \hm= 1/19$. Вероятности случайных событий будут равны:
  \begin{gather*}
  P(A_1) = \fr{10}{19}\,;\enskip  P(A_2) = \fr{7}{19}\,;\\
  P(A_3) = \fr{1}{19}\,;\enskip  P(A_4) = \fr{1}{19}\,.
%  \label{e6-kuz}
  \end{gather*}
  При этом выполняется условие нормированности вероятности:
$$
P(A_1) + P(A_2) + P(A_3) + P(A_4) = 1\,.
$$

  Формальное представление выделенного текста в виде вероятностной
модели~(1) имеет вид:
  \begin{equation}
  M_1 =\{ \Omega_1, \aleph_1, P(A_i)\}\,,
  \label{e7-kuz}
  \end{equation}
где $\Omega_1$~--- множество~(\ref{e4-kuz}) элементарных исходов~--- слов,
принадлежащих знаменательным частям речи;
  $\aleph_1$~--- система случайных событий~(\ref{e5-kuz}), ассоциируемая (в
примере) со знаменательными частями речи;
  $P(A_i)$, $i \hm= 1, 2, 3, 4$,~--- вероятности случайных событий.

  Индекс~1 в модели~(\ref{e7-kuz}) подчеркивает, что это модель конкретного
информационного объекта, определенного множеством элементарных
исходов~$\Omega_1$. При сопоставлении информационных объектов,
представленных текстами, они формализуются моделями~$M_1$ и~$M_2$
вида~(\ref{e7-kuz}), которые отражают их вероятностную структуру на
введенной алгебре. Уровень подобия объектов оценивается по близости
распределений вероятностей по единой для обоих объектов алгебре.
Количественной мерой подобия является взаимная информация в объектах,
определение которой рассматривается ниже.

\section{Вероятностная модель графических информационных
объектов}

  Графические информационные объекты, оценку содержательной близости
которых требуется производить при решении различных практических задач,
формализуются в виде вероятностной модели~(1). Построение формального
образа~(1) графического объекта зависит от наличия или отсутствия некоторого
конечного <<алфавита>> в его исходном представлении. Под <<алфавитом>> в
данном случае понимается конечный набор определенных графических
структур~--- элементов, из которых компонуются сопоставляемые в процессе
оценки близости графические информационные объекты.

  Наличие <<алфавитов>> характерно для изображений большинства
искусственно создаваемых объектов: сооружений и схем различного
содержания и предназначения. Такие объекты можно назвать
структурированными. Отличными от них являются неструктурированные
изображения, например объекты искусства или визуальные изображения
некоторых фаз, картин протекания технологических процессов и состояний в
них некоторого континуума.

  Построение формального образа~(1) структурированного объекта может
осуществляться по изложенной в предыдущем пункте методике. Наличие
конечного алфавита или конечного набора элементов позволяет все элементы
моделируемого объекта однозначно связать с конечным множеством $\aleph$
классов~$A_j$ элементов. Классы~$A_j$ могут конструироваться из
элементов~$\omega_i$, $i\hm= 1, 2, \ldots , n$, в соответствии с~(2) и отражать
любые сложные\linebreak
композиции из элементов и классов, соответствующие
содержательным представлениям в предметной области. По близости
однотипных классов оценивает\-ся степень отличия или подобия сопоставляемых
объектов. Эти классы, подобно частям речи в предыдущем примере,
объявляются случайными событиями~$A_k$, $k\hm=1, 2, \ldots , K$, множество
которых образует алгебру~$\aleph$. В~результате сопоставляемые графические
объекты, отражающие проекты здания или электрические схемы,
формализуются в виде вероятностных моделей~(1), структура которых
детализируется по существенным для оценки степени их подобия компонентам.
Количественная мера близости объектов определяется по распределению
вероятностей на единой для них алгебре~$\aleph$.

  Неструктурированные графические объекты представляют собой некоторые
непрерывные изоб\-ра\-же\-ния, степень близости которых требуется оценить.
Близкая задача решается в биометрических системах, обеспечивающих оценку
сходства контролируемого изображения с заданным его эталоном на
определенном уровне доверительной вероятности~\cite{9-kuz}. При этом
системы настраиваются на определенный класс объектов (эталонов).
В~рассматриваемом подходе предполагается, что объекты могут иметь
произвольную палитру и очертания. В~этом случае для представления объектов
в виде вероятностных моделей~(1) их необходимо структурировать.

  Любое изображение в электронном виде представляется множеством
  точек~--- пик\-се\-лов. Каждый пиксел содержит в себе закодированную
информацию о цвете, формат представления которой зависит от используемой
цветовой модели. Цветовая модель с помощью современных графических
редакторов может быть трансформирована в любую другую цветовую модель,
которая по тем или иным причинам более удобна для исследователя.

  Наиболее распространенной в современных графических форматах является
цветовая модель $RGB$ (см., например,~\cite{11-kuz, 10-kuz}). Модель $RGB$
является аддитивной, в ней новые цвета образуются путем добавления
основных цветов к базовому черному цвету. Как следует из названия самой
модели, основными цветами являются красный, зеленый и синий. Каждая точка
несет в себе информацию об интенсивностях этих трех основных цветов, из
которых образуется все множество видимых человеком цветовых оттенков. На
представление интенсивности каждого цвета отводится 8~бит (или один октет),
так что цвет может иметь 256~уровней интенсивности (от~0 до~255).
Сочетание цветовых интенсивностей $(0, 0, 0)$ соответствует черному цвету,
$(255, 255, 255)$~--- белому цвету. Суммарное количество цветов, которое
можно представить данной моделью, равно $256\times256\times256 \hm=
16\,777\,216$. Цветовое пространство $RGB$ можно представить в виде
трехмерного куба с осями~$R$, $G$ и~$B$. Сторона куба имеет длину
256~единиц с координатами начала отрезка~0 и конца отрезка~255.

  При переходе к вероятностной модели~(1) случайными величинами
считаются интенсивности цветов в точке. В~существующих алгоритмах
сравнения изображений (например, в методе цветовых
  гистограмм~\cite{11-kuz, 10-kuz}) $RGB$-про\-стран\-ст\-во делится на
несколько непересекающихся подпространств, или областей. При обработке
изображений подсчитывается количество пикселов, попадающих в каж\-дую из
выделенных областей пространства $RGB$. В~результате получается
гистограмма распределения час\-тот по подпространствам. Сравнением
гистограммы исследуемого объекта с гистограммой эталона оценивается
степень их близости. При этом вследствие предопределенности эталона
исключается необходимость отражения геометрии объекта.

  Оценка близости произвольных графических объектов требует
сопоставления не только цветовой палитры, но и привязки геометрии объектов
к сис\-те\-ме координат для сопоставления конфигурации. Разработана
модификация метода цветовых гистограмм, позволяющая отразить
конфигурацию сопоставляемых объектов~\cite{12-kuz}. Модификация состоит
в добавлении к традиционному $RGB$-про\-стран\-ст\-ву координатных
осей~$X$ и~$Y$. Комбинированное с координатными осями
  $RGBXY$-про\-стран\-ст\-во позволяет хранить информацию о цветовой
интенсивности и пространственном расположении точек изображения.

  Пятимерное $RGBXY$-пространство может быть разбито на систему
непересекающихся подпространств, которые позволяют определить сис\-те\-му
случайных событий~$A_i$, $i\hm=1, 2, \ldots , m$, образующих
алгебру~$\aleph$. Сетка разбиения необязательно равномерная, что позволяет
детализировать образы изображений. Распределение точек изображения по
подпространствам формирует распределение вероятностей для образов
сопоставляемых объектов. В~результате не структурированные исходно
графические объекты формализуются в виде вероятностных моделей~(1).

\section{Технология оценки близости объектов}

  Технология оценки степени близости со\-по\-став\-ляемых объектов,
представленных их образами в виде вероятностных моделей~(1), может
базироваться на представлениях теории ин\-формации. В~тео\-рии информации
вводится мера количества информации, содержащегося в случайной величине,\linebreak
которая позволяет определить количественные меры соотношения информации
в случайных объектах, характеризующие уровень близости объектов.

  Информационные объекты исходно пред\-став\-ле\-ны различными наборами
элементарных событий $\Omega_1\hm= (\omega^1_1, \omega^1_2,
\ldots , \omega^1_{N_1})$,  $\Omega_2\hm= (\omega_1^2,
\omega_2^2, \ldots$\linebreak $\ldots , \omega^2_{N_2})$~--- реализаций случайных
величин.\linebreak В~данном контексте под случайными величинами понимаются
минимальные неделимые (атомарные) элементы, наборами которых
пред\-став\-ля\-ют\-ся информационные объекты: слова, элементы изображения
формул, схем, пикселы и~т.\,п. Элементарными событиями~--- значениями
случайных величин (реализациями) будут конкретные слова исследуемого
текста, элементы изображения конкретных формул, схем,
  $RGBXY$-зна\-че\-ния пикселов и~т.\,п.

  Для представления объектов в виде вероятностных моделей (образов)
вводится единая алгебра\linebreak $\aleph\hm= \{A_1, A_2, \ldots , A_m\}$, структура
которой должна максимально полно отражать принципиальные\linebreak компоненты
информационной сущности со\-по\-став\-ля\-емых объектов. Содержание
информационных объектов $\Omega_1\hm= (\omega_1^1, \omega_2^1,
\ldots , \omega^1_{N_1})$, $\Omega_2\hm= (\omega_1^2,
\omega_2^2,  \ldots$\linebreak $\ldots , \omega^2_{N_2}\}$ раскладывается по системе
событий $\aleph \hm= \{ A_1, A_2, \ldots , A_m\}$. В~результате информационные
объекты представляются в виде систем случайных событий:
  \begin{equation}
  \label{e8-kuz}
\left.
\begin{array}{rl}
\hspace*{-10mm}\Omega_1&= (\omega_1^1, \omega_2^1,\ldots , \omega^1_{N_1})
\Rightarrow{}\\
&\hspace*{15mm}{}\Rightarrow \aleph = \{ A_1^1, A_2^1, \ldots , A_m^1\}\,; %\label{e8a-kuz}
\\[9pt]
  \hspace*{-10mm}\Omega_2&= (\omega_1^2, \omega_2^2,\ldots , \omega^2_{N_2})
\Rightarrow {}\\
&\hspace*{15mm}{}\Rightarrow\aleph = \{ A_1^2, A_2^2, \ldots , A_m^2\}\,. %\label{e8b-kuz}
\end{array}
\right\}
\end{equation}

  На основании свойства~(2) из случайных событий с помощью операций над
множествами могут быть синтезированы новые случайные события,
принадлежащие алгебре $\aleph \hm= \{A_1, A_2, \ldots$\linebreak $\ldots , A_m\}$.  Количественной
характеристикой распределения реализаций $\Omega_1\hm= (\omega_1^1,
\omega_2^1, \ldots  , \omega^1_{N_1})$, $\Omega_2\hm=
(\omega_1^2, \omega_2^2, \ldots , \omega^2_{N_2})$, составляющих
объекты, по системе случайных событий $\aleph\hm=\{A_1, A_2, \ldots , A_m\}$
служат, в соответствии с~(\ref{e3-kuz}), эмпирические вероятности
  \begin{equation}
  P(A_j^1) =\sum\limits_{w_i^1\in A_j^1} p(\omega_i^1)\,;\enskip  P(A_j^2)
=\sum\limits_{\omega^2_i\in A_j^2} p(\omega_i^2)\,.
  \label{e9-kuz}
  \end{equation}

  В результате информационные объекты $M_1$ и~$M_2$, заданные
множествами реализаций $\Omega_1\hm= (\omega_1^1, \omega_2^1,
 \ldots , \omega^1_{N_1})$, $\Omega_2\hm= (\omega_1^2,
\omega_2^2, \ldots , \omega^2_{N_2})$, представляются в виде
вероятностных моделей
  \begin{equation}
  \label{e10-kuz}
  \left.
  \begin{array}{rl}
  M_1 &=\{ \Omega_1,\aleph, P(A_j^1)\}\,; %\label{e10a-kuz}
  \\[9pt]
  M_2 &= \{\Omega_2, \aleph, P(A_j^2)\}\,. %\label{e10b-kuz}
  \end{array}
  \right\}
\end{equation}

  Назовем формализованное представление информационных
объектов~(\ref{e10-kuz}) в виде вероятностных моделей~(1) образами объектов. Задача состоит
в оценке подобия объектов, имеющих образы~(\ref{e10-kuz}).

  Формальная оценка степени подобия объектов может базироваться на
количественных характеристиках их образов. Адекватной основой для синтеза
таких характеристик представляется теория информации, основоположником
которой является К.~Шеннон~\cite{13-kuz}. В~теории информации количество
информации, содержащееся в случайной величине, может оцениваться энтропией,
которая определяется по распределению вероятностей случайной величины.
Энтропия вероятностной модели, отражающая количество информации в ней,
может определяться в виде
  \begin{equation}
  H=-\sum\limits_{A_j\in \aleph} P(A_j) \ln P(A_j)\,,
  \label{e11-kuz}
  \end{equation}
где $P(A_j)$~--- вероятности случайных событий~(\ref{e9-kuz}).

  На основании энтропии могут быть синтезированы различные меры близости
информационных объектов. Учитывая аналогию терминов и пред\-став\-ле\-ний
теории вероятностей и теории множеств, воспользуемся графической
иллюстрацией,\linebreak\vspace*{-12pt}


\noindent
\begin{center}  %fig1
 \mbox{%
 \epsfxsize=76.556mm
 \epsfbox{kuz-1.eps}
 }
  \end{center}
%  \vspace*{6pt}
{{\figurename~1}\ \ \small{Геометрическая интерпретация  операций с количествами информации,
содержащимися в одноименных случайных событиях системы~$\aleph$ двух объектов}}

\vspace*{12pt}

\addtocounter{figure}{1}


\noindent
 представленной на рис.~1, для пояснения существа
предлагаемых мер близости информационных объектов.


  Площадь эллипсов $A_j^1$ и~$A_j^2$ на рис.~1 условно отображает
вероятности случайных событий $A_j^1$ и~$A_j^2$ (множества
реализаций~$\omega$, принадлежащих этим событиям). Для отдельных
реализаций и сформированных из них случайных событий вероятности могут
быть определены по~(\ref{e9-kuz}). Но для оценки близости объектов
необходимо рассматривать объект, представляющий собой объединение
исходных. Множество его реализаций получается объединением
множеств~(\ref{e8-kuz}) $\Omega\hm=
(\Omega_1\hm+\Omega_2)$, и количество элементов в объединенном объекте
равно сумме $N\hm = N_1 \hm+ N_2$. Поэтому вероятности комбинированных
случайных событий, показанных на рис.~1, определяются следующим образом:
  \begin{align*}
  p_i(\omega_i^l)& =\fr{n(\omega_i^l)}{N_1+N_2}\,;\\
  P_j^l(A_j^l) &=\sum\limits_{\omega_i^l\in A_j^l} p_i(\omega_i^l)\,;\enskip l=1,2\,,
%  \label{e12-kuz}
\end{align*}
где $n(\omega_i^l)$~--- количество реализаций~$\omega_i^l$ в множестве
реализаций~$\Omega^l$.

  Для оценки близости могут быть использованы комбинированные случайные
события, определенные для объединенного объекта $\Omega\hm=
(\Omega_1+\Omega_2)$. Они получаются (см.\ рис.~1) композицией случайных
событий первого~$A_j^1$, $j\hm=1, 2, \ldots , m$, и второго~$A_j^2$, $j\hm=1,
2, \ldots , m$, объектов с помощью отмеченных выше операций для всех
компонентов системы~$\aleph$. Это следующие комбинированные случайные
события:
  \begin{enumerate}[(1)]
\item сумма (объединение) случайных событий $A_j^1$ и $A_j^2$, которая на
рис.~1 представляется пло\-щадью обоих эллипсов и определя\-ет\-ся в виде
\renewcommand{\theequation}{\arabic{equation}a}
\begin{equation}
\hspace*{-3mm}A_j^{1+2} =A_j^1+A_j^2 =\{\omega\in \Omega \vert \omega\in [A_j^1+A_j^2]\}\,;
\label{e13a-kuz}
\end{equation}
\item произведение (пересечение) случайных событий~$A_j^1$ и~$A_j^2$,
включающее реализации, принадлежащие одновременно $A_j^1$
и~$A_j^2$, и опреде\-ля\-емое в виде
\setcounter{equation}{10}
\renewcommand{\theequation}{\arabic{equation}{б}}
\begin{equation}
\hspace*{-8mm}A_j^{1\&2} =A_j^1\&A_j^2 =\{ \omega\in\Omega \vert\omega \in A_j^1\ \&\
\omega \in A_j^2\}\,,
\label{e13b-kuz}
\end{equation}
на рис.~1 ему соответствует площадь с вертикальной штриховкой;
\item разность случайных событий $A_j^1$ и~$A_j^2$ (событие, включающее
элементы $\omega\hm\in \Omega$, принадлежащие $A_j^1$ и не
принадлежащие~$A_j^2$), которая определяется в виде
\setcounter{equation}{10}
\renewcommand{\theequation}{\arabic{equation}в}
\begin{equation}
\hspace*{-8mm}A_j^{1-2} =A_j^1-A_j^2 =\{ \omega\in \Omega \vert \omega \in
A_j^1\ \&\ \omega\not\in A_j^2\}\,,
\label{e13c-kuz}
\end{equation}
на рис.~1 ей соответствует площадь с горизонтальной штриховкой;
\item разность случайных событий~$A_j^2$ и~$A_j^1$, отражаемая на
рис.~1 областью без штриховки и определяемая в виде
\setcounter{equation}{10}
\renewcommand{\theequation}{\arabic{equation}г}
\begin{equation}
\hspace*{-8mm}A_j^{2-1} =A_j^2 -A_j^1 = \{ \omega \in \Omega \vert \omega\in A_j^2\ \&\
\omega\not\in A_j^1\}\,.
\label{e13d-kuz}
\end{equation}
  \end{enumerate}

  \setcounter{equation}{11}

  События~(11) позволяют отразить уровень совпадения или различия
множеств реализаций, входящих в однотипные случайные события системы
$\aleph\hm=\{A_1, A_2, \ldots , A_m\}$, по которой раскладываются образы
сопоставляемых объектов. В~зависимости от сущности объекта его реализации
представляют собой слова естественного или искусственного (формального)
языка, компоненты структурированных или неструктурированных графических
объектов.

  Нетрудно видеть, что пересечение~(\ref{e13b-kuz}) отражает множество
общих для обоих объектов реализаций $j$-го типа, которое и определяет
степень близости объектов: чем больше значение~(\ref{e13b-kuz}), тем больше
степень их подобия. Наоборот, разности~(\ref{e13c-kuz}), (\ref{e13d-kuz}),
независимо от знака, отражают отличие объектов, которое возрастает с
увеличением разности.

  Сумма (\ref{e13a-kuz}) представляет объединение реализаций (элементарных
событий) обоих объектов. Сопоставляемые объекты известны в виде
множеств~$\Omega_1$ и~$\Omega_2$ элементарных событий, так что их
объединение представляет общее множество элементарных событий
  \begin{multline}
  \Omega = (\Omega_1+\Omega_2) ={}\\
  {}=(\omega_1^1, \omega_2^1, \ldots
, \omega^1_{N_1}, \omega_1^2, \omega_2^2,\ldots ,
\omega^2_{N_2})\,.
  \label{e14-kuz}
  \end{multline}

  На множестве~$\Omega$ могут быть определены вероятности всех типов
комбинированных случайных событий~(11) на всех компонентах алгебры
$\aleph \hm=\{A_1, A_2, \ldots , A_m\}$ в виде суммы вероятностей $p(\omega_i)$
реализаций~$\omega_i^1$ и~$\omega_i^2$:
  \begin{multline*}
  P(A_j^V) =\sum\limits_{\omega_i\in A_j^V} p(\omega_i)
=\sum\limits_{\omega_i\in A_j^V}\fr{ n(\omega_i)}{N_1+N_2}\,,\\ j=1,2,\ldots ,
m\,,
%  \label{e15-kuz}
  \end{multline*}
где $n(\omega_i)$~--- количество исходов $\omega_i$ в множестве~$\Omega$,
соответствующих указанной верхним индексом~$V$ операции из набора~(11).

  Количество информации в случайных событиях определяется
энтропией~(\ref{e11-kuz}), которая может быть вычислена по распределению
вероятностей событий любого типа из~(11) по системе~$\aleph$. Собственно
энтропия является абстрактной величиной и не может характеризовать степень
близости объектов. Но если использовать отношение энтропий,
характеризующих количество информации в комбинированных случайных
событиях, определенных на множестве~(\ref{e14-kuz}), то можно получить
меры бли\-зости, достаточно адекватные задаче оценки подобия объектов.

  Например, система случайных событий~(\ref{e13b-kuz}) отражает объем
общей для сопоставляемых объектов информации, который количественно
может оцениваться энтропией, вычисляемой по вероятностям
системы~(\ref{e13b-kuz}):

\noindent
  \begin{equation}
  H(1\&2) =-\sum\limits_{j=1}^m P(A_j^{1\&2}) \ln P(A_j^{1\&2})\,.
  \label{e16-kuz}
  \end{equation}

  Информация, отличающая объекты~1 и~2, отражается случайными
событиями~(\ref{e13c-kuz}). Количественно объем этой информации
определяется энтропией, вычисляемой по вероятностям
  событий~(\ref{e13c-kuz}):

  \noindent
  \begin{equation}
  H(1-2) =-\sum\limits_{j=1}^m P(A_j^{1-2}) \ln P(A_j^{1-2})\,.
  \label{e17-kuz}
  \end{equation}

  Меры степени отличия объектов могут содержательно соответствовать
интуитивным представлениям о близости как о расстоянии между объектами.
Отношение количества различающей объекты информации~(\ref{e17-kuz}) к
количеству информации, общей для обоих объектов~(\ref{e16-kuz}),
представляет одну из таких безразмерных величин

\noindent
  \begin{equation}
  \rho1 =\fr{ H(1-2) }{H(1\&2)}\,.
  \label{e18-kuz}
  \end{equation}

  Для оценки диапазона изменения величины~(\ref{e18-kuz}) можно
рассмотреть два предельных варианта: (1)~объекты идентичны и (2)~объекты не
имеют общих элементов. Значение~(\ref{e18-kuz}) в первом варианте
получается из условий идентичности множеств элементарных событий,
образующих объекты: $\Omega_1\hm= \Omega_2\hm\to N_2\hm=N_1$ и
$(\omega_1, \omega_2, \ldots , \omega_{N_1})\hm=(\omega_1, \omega_2, \ldots ,
\omega_{N_2})$. Отсюда следует совпадение определенных на~$\Omega_1$
и~$\Omega_2$ случайных событий~$A_j^1$, $A_j^2$, $j\hm=1, 2, \ldots , m$, и
равенство распределений ве-\linebreak\vspace*{-12pt}

\pagebreak

\noindent
роятностей $P_1(A_j^1)\hm= P_2(A_j^2)$. Поэтому
разность вероятностей равна нулю: $P(A_j^{1-2})\hm= P(A_j^1\hm-
A_j^2)\hm=P(0)$, $j \hm= 1,2, \ldots , m$. В~теории информации принято
соглашение $P(0) \ln P(0) \hm= 0$; следовательно, $H(1\mbox{--}2)\hm=0$.

  Сопоставляемые объекты предполагаются независимыми. Пересечение
множеств $A_j^1\hm= A_j^2$ равно $A_j^{1\&2} \hm= A_j^1\&A_j^2\hm=
2A_j^1\hm= 2A_j^2$ и $P(A_j^{1\&2})\hm= P(A_j^1)\times P(A_j^2)$, $j\hm=1,
2, \ldots , m$; следовательно, $H(1\&2)_j \hm= H(A_j^1)\hm+ H(A_j^2)$ и общая
энтропия~(\ref{e16-kuz}) будет отражать количество информации в обоих
объектах $H(1\&2)$, отличное от нуля. Поэтому в первом варианте
идентичности объектов значение~(\ref{e18-kuz}) $\rho1\hm= 0 / H(1\&2) \hm=
0$.

  Второй вариант, когда объекты не имеют общих элементов, дает разность,
равную содержанию уменьшаемого, а пересечение~--- равное нулю. Поэтому
получается $\rho1\hm=\infty$. Так что мера~(\ref{e18-kuz}) изменяется от нуля
для совпадающих объектов до бес\-ко\-неч\-ности для объектов, не имеющих общих
элементов, что соответствует представлениям о расстоянии, как мере близости.

  Могут быть использованы и другие, близкие по смыслу~$\rho1$, меры.
Например, в числителе~(\ref{e18-kuz}) энтропию, отражающую вероятности
событий~(\ref{e13c-kuz}), можно заменить энтропией, отражающей общее
количество информации в объектах, вычисляемой по вероятностям
событий~(\ref{e13a-kuz}). В~этом случае мера получается в виде
  \begin{equation}
  \rho2 =\fr{H(1+2)}{H(1\&2)}\,,
  \label{e19-kuz}
  \end{equation}
где $H(1+2)$ вычисляется по~(\ref{e17-kuz}) заменой событий~(\ref{e13c-kuz})
событиями~(\ref{e13a-kuz}).

  Мера~(\ref{e19-kuz}) также может интерпретироваться расстоянием между
объектами, которое для идентичных объектов будет равно единице, а для
абсолютно разных~--- бесконечности. Для придания содержательного
соответствия технологии оценки близости объектов существу объектов и
решаемым задачам меры подобия типа~(\ref{e18-kuz}) или~(\ref{e19-kuz}) могут
градуироваться в соответствующих единицах. Разработанная технология
позволяет дифференцировать информационные объекты по системе случайных
событий~--- алгебре~$\aleph$, отражающей их семантическую значимость.

  При разработке своего подхода к оценке бли\-зости информационных
объектов автор сознательно сделал упор на использование табличного их\linebreak
представления по следующей причине. Информационные объекты разного типа
являются композициями некоторых атомарных (неделимых при исследова\-нии)
элементов. На этих атомарных элементах конструируется алгебра~$\aleph$
вероятностной модели~(1). После определения алгебры информационный
объект раскладывается по системе случайных событий и представляется
таблицей, столбцы которой именуются случайными событиями.

  В реляционных базах данных таблица именуется отношением, а столбцы~---
атрибутами. Дело, конечно, не в названиях, а в том, что табличное
представление информационного объекта превращает его в обычное отношение
структуры данных. Для работы с отношением (в данном контексте~--- с
пред\-став\-ле\-ни\-ем вероятностного образа объекта) могут быть использованы
операции реляционной ал\-геб\-ры, которые позволяют из исходных отношений
конструировать и автоматически формировать новые отношения, наращивая
уровень их сложности композицией предшествующих атрибутов. Поэтому
табличное представление образов информационных объектов открывает
возможности использовать реляционную алгебру для автоматизации процедур
их исследования и детализации представления объектов.

  Например, синтаксис определяет построение из слов~--- атомарных
компонентов языка~--- различных конструкций, несущих определенную
семантическую нагрузку. Поэтому, начиная с алгебры, представленной
атомарными компонентами, могут вводиться композиционные конструкции
атомарных компонентов с постепенным наращиванием сложности из
компонентов предшествующих уровней. Выполняться все эти операции могут
стандартными средствами реляционных баз данных.

  На основе математического аппарата реляционных баз данных может быть
реализована автоматизированная рекурсивная процедура формирования
структуры вероятностных образов (алгебры) сравниваемых объектов.
Начальное приближение $\aleph (0)$ системы случайных
  событий~(\ref{e8-kuz}) задается на уровне атомарных событий, формируются
вероятностные модели $M_1(0)$ и $M_2(0)$~(\ref{e10-kuz}), определяется мера
их близости. Затем на основе~$\aleph (0)$ начального приближения,
свойств~(\ref{e2-kuz}) алгебры, синтезируются новые случайные события и их
атрибуты~--- композиции атрибутов из $\aleph (0)$. В~результате получается
алгебра $\aleph (1)$, по атрибутам которой формируются новые отношения
(таблицы) $M_1(1)$ и $M_2(1)$, определяется мера близости объектов и
сравнивается с полученной на $M_1(0)$ и~$M_2(0)$. На основании сравнения
значений меры выбирается продолжение рекурсии или прекращение процесса
уточнения оценки близости объектов.

  Усиление дифференциации семантической значимости отдельных
компонентов алгебры~$\aleph$ в конкретных задачах достигается введением
весовых коэффици\-ен\-тов. Для настройки технологии на конкретные объекты и
задачи может применяться детализация алгебры, адаптация весов и
градуировки меры подобия объектов на основании эмпирической информации.
Эти возможности позволяют создавать инструменты эффективной оценки
близости содержательной сущности информационных объектов.

\section{Иллюстрация применения технологии }

  Тестирование разработанной технологии оценки близости информационных
объектов было осуществлено на текстовых и графических объектах.\linebreak Результаты
ее применения изложены в ряде работ. В~\cite{8-kuz} приведены результаты
экспериментальной проверки возможности применения раз\-ра\-ботанной
технологии для автоматизированной \mbox{оценки} знаний студентов. В~штатном
режиме контроля знаний группа из 22~студентов написала изложение на
английском языке. Изложения были проверены и оценены по 100-балль\-ной
шкале преподавателем по стандартной методике. Затем тексты работ студентов
и исходный текст, прочитанный преподавателем, были введены в систему, в
которой работы студентов представлялись в виде об\-ра\-зов-ко\-пий $M_1(S)$,
$S\hm=1, 2, \ldots , 22$, а исходный текст принимался за эталон~$M_2$.

     Близость ответов эталону оценивалась по изложенной выше методике.
Для представления объектов в эксперименте использовалась сле\-ду\-ющая
система событий~(\ref{e8-kuz}): $A_1 = \mbox{существительное}$; $A_2 =
\mbox{гла\-гол}$; $A_3 = \mbox{прилагательное}$; $A_4 = \mbox{наречие}$;
$A_5 = \mbox{числительное}$; $A_6 = \mbox{неопределенное слово}$.

     Количество взаимной информации $H^{\mathrm{Э}\&\mathrm{О}}$ было
вычислено по~(\ref{e16-kuz}) для всех ответов. Для придания абстрактной
энтропии содержательного смыс\-ла она с использованием оценок,
выставленных преподавателем, была проградуирована в единицах 100-балль\-ной
системы оценок, принятой в вузе. Параметры модели градуировки
определялись методом наименьших квадратов в двух вариантах: первый в виде
$y\hm=a \hm+ b H^{\mathrm{Э}\&\mathrm{О}}$ и второй в виде $y_1 \hm= a_0 +
\sum\limits_i a_i H_i^{\mathrm{Э}\&\mathrm{О}}$, где $H_i^{\mathrm{Э}\&\mathrm{О}}$~---
энтропии случайных событий~$A_i^{\mathrm{Э}\&\mathrm{О}}$, $i \hm= 1, 2, \ldots ,
6$. Фактически во втором варианте параметры~$a_i$, $i \hm =1, 2, \ldots , 6$,
отражают различный <<вклад>> семантических компонентов в соответствие
между эталоном и ответом и иллюстрируют возможности адаптации
градуировки к содержательным особенностям проверяемых дисциплин, к
методикам оценки и~т.\,п. Более подробно детали структуризации текстов,
определения взаимной информации и методики ее градуировки изложены
в~\cite{8-kuz}.

\noindent
\begin{center}  %fig2
 \mbox{%
 \epsfxsize=80.161mm
 \epsfbox{kuz-2.eps}
 }
  \end{center}
%  \vspace*{6pt}
{{\figurename~2}\ \ \small{Сопоставление оценок преподавателя и оценок системы:
\textit{1}~--- при градуировке без взвешивания частей речи; \textit{2}~--- при взвешивании
частей речи}}

\vspace*{12pt}

\addtocounter{figure}{1}

     На рис.~2 приводится графическая иллюстрация результата
     из~\cite{8-kuz}, отражающая уравнения градуировки и отличие оценки,
определяемой автоматически по близости ответа эталону, от оценки,
выставленной преподавателем.


     Среднеквадратичное отклонение оценок, выставленных преподавателем,
от оценок по количеству информации~$y$ при градуировке по первому варианту
составляет 11,04~балла, коэффициент корреляции равен~0,847, при
градуировке по второму варианту уклонение составило 6,324~балла, а
множественный коэффициент корреляции достиг~0,955.

  При детальном анализе выяснилось, что две оценки, выставленные
преподавателем и существенно выпадавшие из общего ряда, были не в полной
мере адекватны содержанию изложений. Исключение двух этих точек и расчет
по оставшимся 20~точкам принципиально изменяет результат:
среднеквадратичная ошибка оценки~$y$ становится равной 1,593~балла, а
оценки~$y_1$~--- 1,248~балла.

  Регрессия, полученная для этого эмпирического материала, следуя
  век\-тор\-но-про\-стран\-ст\-вен\-ной модели текста, предложенной
Г.~Солтоном~[2], для всех 22~изложений дает среднеквадратичное отклонение
прогноза оценки от оценки преподавателя 13,27~балла. После удаления из
массива двух выпадавших точек ошибка составила 2,155~балла, т.\,е.\ почти в
два раза выше, чем при использовании информационной модели 1, 248~балла.

\begin{table*}\small
\begin{center}
\Caption{Алгебра событий и характеристики сопоставления схем}
\vspace*{2ex}

%\tabcolsep=1pt
\begin{tabular}{|c|c|c|c|}
\hline
\tabcolsep=0pt\begin{tabular}{c}Случайные\\ события\end{tabular} & Перечень& Количество &Вероятность\\
\hline
\multicolumn{1}{|l|}{$A_1$~--- элементы}& R4, L1, \ldots & $n_1$ & $n_1/N$\\
\multicolumn{1}{|l|}{$A_2$~---ветви}& L1C1, L2C2,\ldots & $n_2$ & $n_2/N$\\
\multicolumn{1}{|l|}{$A_3$~--- узлы} & T1BC1R4,\ldots & $N_3$ & $N_3/N$\\
\hline
\end{tabular}
\end{center}
\end{table*}

  Разработанная технология формального сопоставления информационного
содержания текстов и синтеза количественной меры семантической\linebreak
 близости
слов языка позволяет автоматизировать исследования проблем в об\-ласти
языкознания. Например, семантические отношения между словами (синонимы,
антонимы, паронимы, гипонимы и~т.\,п.)\ определяются в настоящее время
субъективно представителями разных школ. Субъективные представления не
формализуются, не могут быть упорядочены или сопоставлены.

  Между тем понятно, что в основе определения семантических отношений
лежат различные композиции множеств оттенков значений со\-по\-став\-ля\-емых
слов~(11), которые представлены в существующих словарях. Изложенный
подход позволяет формализовать и, следовательно, автоматизировать
процедуры количественной оценки меры <<информационного расстояния>>
между словами. На этой основе могут быть введены объективные,
количественные меры синонимичности, антонимичности и~т.\,п. Интересные
результаты в этой области могут быть получены с использованием нечетких
отношений вместо четких, показанных на рис.~1.

  В работе~\cite{14-kuz} изложена технология разработки универсального
метрического тезауруса языка на примере русского языка. Технология
базируется на формировании для каждого слова языка его содержательного
образа в виде вероятностной модели. Существуют специализированные
словари, ориентированные на определенные сферы деятельности и знаний.
Обычно эти словари составляются экспертами в области языкознания на
основании их субъективных представлений о семантике слов.

  Технология представления текстов вероятностными моделями позволяет
автоматизировать со\-здание тезауруса языка в виде обобщенных
со\-держательных образов отдельных слов языка. Обобщен\-ный образ
формируется в виде структурированной на выбранной алгебре~$\aleph$ суммы
отражающих смысл слова словарных статей из всех доступных словарей.
Тезаурус формируется автоматически по введенным электронным версиям
имеющихся словарей и представляет словарь, в котором с каждым словом
связан его максимально полный содержательный образ.

  Разработанный универсальный метрический тезаурус позволяет формально,
опираясь на всю имеющуюся информацию о значении слов, и в этом смысле
объективно, решать проблему синонимов при оценке близости текстов.
Метрическая оценка семантической близости слов производится автоматически
по изложенной технологии со\-по\-став\-ле\-ни\-ем их образов. Мерой близости
является расстояние, определяемое в виде~(\ref{e18-kuz}) или~(\ref{e19-kuz})
по обобщенным образам слов. При появлении новых версий электронных
словарей они могут вводиться в систему и автоматически ассимилироваться ею.
Технология создания тезауруса с использованием образов слов в виде
вероятностных моделей~(1) инвариантна по отношению к структурированным
языкам и может быть использована в любом из них. Универсальный
электронный тезаурус~\cite{14-kuz} является мощным инструментом для
исследований в сфере филологии и языкознания.

  В работе~\cite{4-kuz} показана возможность применения информационной
технологии и вероятностной модели~(1) для оценки близости схем. Схемы
используются в процессе изучения многих дисциплин технического
направления и поэтому широко представлены в обучающих системах. Для
примера использовались электрические схемы, множества элементарных
событий при представлении которых формируются элементами,
регламентированными стандартом~\cite{7-kuz}.

  В табл.~1 показана система случайных событий, составляющих алгебру в
этом случае, и количественные характеристики схем, при этом~$n_i$, $i\hm= 1,
2, 3$,~--- количество компонентов (реализаций) $i$-го типа, $N\hm=n_1 \hm+
n_2\hm + n_3$~--- общее количество компонентов в схеме.



  Проверка осуществлялась на схеме, содержащей компоненты $n_1\hm=41$,
$n_2\hm=34$, $n_3\hm=18$, $N\hm=93$. Ошибки экзаменуемых моделировались
устранением компонентов из схем-от\-ве\-тов. На рис.~3 показаны результаты
увеличения информационного расстояния между эталоном и ответами по мере
нарастания их ошибочности.



  Полученные результаты показали~\cite{4-kuz} возможность синтеза
автоматизированных процедур для оценки уровня соответствия схем их
эталонному образу. Такие процедуры позволяют, в частности, разрабатывать в
обучающих системах модули проверки ответов обучаемых в этой области.

  \begin{table*}[b]\small %tabl2
%  \vspace*{-3pt}
  \begin{center}
  \Caption{Результаты оценки близости объектов разными методами}
  \vspace*{2ex}

\tabcolsep=4pt
  \begin{tabular}{|c|c|p{29mm}|p{29mm}|p{29mm}|l|}
  \hline
&\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Метод}}&\multicolumn{4}{c|}{Характеристики для образов}\\
\cline{3-6}
&&\multicolumn{1}{c|}{Образ 1}&\multicolumn{1}{c|}{Образ 2}&\multicolumn{1}{c|}{Образ 3}&Совместная\\
\cline{2-6}
&&&&&\\[-15pt]
\multicolumn{1}{|c|}{\raisebox{-48pt}[0pt][0pt]{Тип}}&
\multicolumn{1}{|c|}
{\raisebox{-48pt}[0pt][0pt]{\tabcolsep=0pt\begin{tabular}{c}Графическое\\
представление\end{tabular}}}&
\begin{center}
 \mbox{%
 \epsfxsize=28mm
 \epsfbox{kuz-t-1.eps}
 }
 \end{center}&
 \begin{center}
 \mbox{%
 \epsfxsize=28mm
 \epsfbox{kuz-t-2.eps}
 }
 \end{center}&
 \begin{center}
 \mbox{%
 \epsfxsize=28mm
 \epsfbox{kuz-t-3.eps}
 }
 \end{center}&\multicolumn{1}{|c|}{\raisebox{-48pt}[0pt][0pt]{---}}\\
 &&&&&\\[-15pt]
\hline
\multicolumn{1}{|l|}{\raisebox{-12pt}[0pt][0pt]
{\tabcolsep=0pt\begin{tabular}{l}Класси-\\ ческие\end{tabular}}}&
\tabcolsep=0pt\begin{tabular}{c}Разбиение\\ $RGB$-осей\end{tabular}&
\multicolumn{1}{c|}{---}&\multicolumn{1}{c|}{---}&\multicolumn{1}{c|}{---}&
\tabcolsep=0pt\begin{tabular}{c}$R_{12} = 0{,}897$\\
$R_{13} = 0{,}735$\end{tabular}\\
\cline{2-6}
&\tabcolsep=0pt\begin{tabular}{c}Разбиение\\ $RGB$-пространства\end{tabular}&
\multicolumn{1}{c|}{---}&\multicolumn{1}{c|}{---}&\multicolumn{1}{c|}{---}&
\tabcolsep=0pt\begin{tabular}{l}$R_{12} =
0{,}7$\\
$R_{13} = 0{,}746$\end{tabular}\\
\hline
\multicolumn{1}{|l|}{\raisebox{-32pt}[0pt][0pt]
{\tabcolsep=0pt\begin{tabular}{l}Разрабо-\\ танные\end{tabular}}}&\tabcolsep=0pt\begin{tabular}{c}Модифицированный\\ метод\end{tabular}&
\multicolumn{1}{c|}{---}&\multicolumn{1}{c|}{---}&\multicolumn{1}{c|}{---}
&\tabcolsep=0pt\begin{tabular}{l}$R_{12} = 0{,}324$\\
$R_{13} = 0{,}913$\end{tabular}\\
\cline{2-6}
&\tabcolsep=0pt\begin{tabular}{c}Интегральный\\ метод\end{tabular}&
\multicolumn{1}{c|}{$E_1 = 461{,}811$}&\multicolumn{1}{c|}{$E_2 =
463{,}793$}&\multicolumn{1}{c|}{$E_3 = 462{,}152$}&
\tabcolsep=0pt\begin{tabular}{l}$R_{12}= 0{,}055$\\
$R_{13} = 0{,}922$\end{tabular}\\
\cline{2-6}
&\tabcolsep=0pt\begin{tabular}{c}Дифференциальный\\ метод\end{tabular}&\multicolumn{1}{c|}{$E_1 =
1134{,}189$}&\multicolumn{1}{c|}{$E_2 = 1280{,}136$}&\multicolumn{1}{c|}{$E_3 =
1234{,}701$}&\tabcolsep=0pt\begin{tabular}{l}$R_{12} = 0{,}069$\\
$R_{13} = 0{,}938$\end{tabular}\\
\cline{2-6}
&&&&&\\[-9pt]
&\tabcolsep=0pt\begin{tabular}{c}Энтропийное\\ расстояние\end{tabular}&\multicolumn{1}{c|}{\tabcolsep=0pt\begin{tabular}{c}$H_{12}(\cup)
= 971{,}602$\\
$H_{13}(\cup) = 1227{,}317$\end{tabular}}&\multicolumn{1}{c|}{$H_{12}(\cap) =
110{,}171$}&\multicolumn{1}{c|}{$H_{13}(\cap) =
740{,}361$}&\tabcolsep=0pt\begin{tabular}{l}$\rho2^{12}= 4{,}41$\\
$\rho2^{13}= 0{,}829$\end{tabular}\\
\hline
\end{tabular}
\end{center}
\end{table*}

  Применение разработанной технологии для оценки близости
неструктурированных графических объектов~\cite{5-kuz} показало
возможность на ее\linebreak\vspace*{-12pt}

\pagebreak

\noindent
\begin{center}  %fig2
 \mbox{%
 \epsfxsize=76.837mm
 \epsfbox{kuz-3.eps}
 }
  \end{center}
%  \vspace*{6pt}
{{\figurename~3}\ \ \small{График роста информационного расстояния при последовательном увеличении
отклонений схем-от\-ве\-тов от эталона}}

\vspace*{12pt}

\addtocounter{figure}{1}


\noindent
 основе существенного повышения уровня до\-сто\-вер\-ности
оценки. Этот вывод следует непосредственно из данных воспроизводимой
табл.~2 из~\cite{5-kuz}, в которой показаны сопоставляемые объекты и меры их
близости, полученные по разным технологиям. Объекты выбраны так, чтобы их
подобие и отличие были очевидны: уровень подобия объектов~1 и~3 намного
выше, чем объектов~1 и~2, или 2 и~3.

  В работе~\cite{5-kuz} приведены результаты исследования различных мер
для оценки степени близости объектов. Для исследования были реализованы
стандартные, используемые на практике методы и оригинальные, опирающиеся
на сопоставление количеств информации в объектах.




  Для стандартного метода цветовых гистограмм~[9--11], в
основу которого положена $RGB$-мо\-дель, были реализованы алгоритмы,
ис\-поль\-зу\-ющие модификации разбиения $RGB$-про\-стран\-ст\-ва на
подпространства и $RGB$-осей~--- на интервалы. Цветовые модели объектов,
как это принято в биометрических системах, представлялись в виде цветовых
гистограмм. Оценка близости объектов производилась по корреляции их
цветовых гистограмм.

  Затем были разработаны алгоритмы, реализу\-ющие оригинальную
технологию представления объектов в виде вероятностных моделей,
син\-те\-зи\-ру\-емых разбиением пятимерного $RGBXY$-про\-стран\-ст\-ва на
сис\-те\-му непересека\-ющих\-ся подпространств, образующих алгебру
$\aleph\hm=\{A_1, A_2, \ldots , A_m\}$.

  На алгебре $\aleph\hm=\{A_1, A_2, \ldots , A_m\}$ определялись
комбинированные события~(\ref{e13a-kuz}) и~(\ref{e13b-kuz}) и
соответствующие им распределения вероятностей для объектов~1, 2, 3,
показанных в табл.~2. На распределениях вероятностей на системе введенных
классов~$\aleph$ вычислялись соответствующие энтропии.
В~исследовании~\cite{5-kuz} близость объектов в информационном масштабе
оценивалась энтропийным расстоянием между ними, определяемым в
виде~(\ref{e19-kuz}), которое изменяется от~1 для совпадающих объектов
до~$\infty$ для объектов, не имеющих общих элементов.

  Оценка близости графических объектов, показанных в табл.~2, была
произведена по су\-ще\-ст\-ву\-ющим и разработанным технологиям. При
использовании стандартного метода цветовых гистограмм оценка
осуществлялась коэффициентом корреляции цветовых гистограмм объектов,
которые обозначены~$R_{ij}$, где $i, j$~--- номера объектов в первой строке
табл.~2.  %Полученные результаты приведены в табл.~2.

  В алгоритмах биометрической идентификации~\cite{9-kuz} пороговое
значение степени соответствия устанавливается обычно на уровне~0,65. Из
табл.~2 следует, что значения коэффициента подобия, полученные по
классическим алгоритмам разбиения $RGB$-осей на интервалы и
  $RGB$-про\-странств на прямоугольные параллелепипеды, превышают
пороговое значение для пар~1,~2 и~1,~3. Это свидетельствует об идентичности
всех трех объектов. Оценки близости всех трех объектов практически
совпадают, хотя отличие объекта~2 от~1 и~3 очевидно.

  Введение в оценку близости объектов системы координат
(модифицированный метод $RGBXY$) существенно изменяет результат.
Коэффициент подобия образов~1 и~2 при использовании модифицированного
алгоритма принимает значение $R \hm= 0{,}324$, которое более чем в 2~раза
ниже коэффициентов~0,897 и~0,7, полученных с использованием классических
алгоритмов. Одновременно коэффициент подобия объектов~1 и~3 увеличился.
Сопоставление <<модифицированных про\-стран\-ст\-вен\-но-цве\-то\-вых
гистограмм>> показывает, что объекты~1 и~3 примерно в 3~раза <<ближе>>,
чем объекты~1 и~2.

  Информационный метод дает адекватную сопоставляемым изображениям
меру соответствия в виде расстояния между ними. Расстояние $\rho2$
пропорционально различию объектов и тем больше, чем меньше степень их
совпадения. Расстояние $\rho2_{1,2}\hm = 4{,}41$ между объектами~1 и~2 более
чем в пять раз превышает расстояние $\rho2_{1,3}\hm = 0{,}829$ между
объектами~1 и~3. Можно видеть, что реально следующая из рисунков,
включенных в табл.~2, близость объектов~1 и~3 отражается близостью
значения $\rho2_{1,3}\hm = 0{,}829$ к минимально возможному, равному~1, для
совпадающих объектов.

  Градуировка шкалы меры $\rho2$ (и иных, полу\-ча\-емых информационным
методом) может быть осуществлена на основании реального эмпирического
материала. Технология вычисления оценки инвариантна по отношению к
разбиению объектов на подмножества. Разбиение объектов может
производиться с переменным шагом по осям координат, что позволяет
акцентировать внимание на областях с высокой плотностью информации
использованием мелкого шага. Процедура оценки близости объектов может
быть итеративной с использованием на каждом следующем шаге более
детальных образов объектов, получаемых детализацией алгебры~$\aleph$,
использованной на предыдущем этапе оценки. И~сетка разбиения, и веса
областей могут автоматически адаптироваться в процессе функционирования
сис\-темы.

\section{Заключение }

  Формальная оценка семантического подобия информационных объектов
может базироваться\linebreak на количественной мере сопоставления их содержания.
Случайность элементарных компонентов\linebreak описания информационных объектов
и произвольность формы представления объектов в информационных
технологиях выдвигает актуальную задачу разработки формальной технологии
и меры оценки уровня их семантического подобия. Объекты представляются
множествами случайных реализаций набора элементарных изобразительных
компонентов.

  Элементарные компоненты различны для разных форм представления, но
являются общими для сопоставляемых объектов. Единый подход к содержанию
информационных объектов как множеству\linebreak реализаций случайных величин
позволяет разра\-ботать единую технологию оценки их бли\-зости. Различия
представления объектов разного типа сводятся лишь к разным наборам
элементарных изобразительных компонентов.

  Информационные объекты разного типа формализуются вероятностными
моделями, в которых реализации группируются в случайные события в
соответствии с их информационной ценностью. Количественными
характеристиками разложения информационных объектов по системам
случайных событий являются распределения вероятностей. Распределения
вероятностей определяют энтропии объектов. Энтропии отражают количества
информации в сопоставляемых информационных объектах и позволяют
синтезировать количественную меру их близости, подобную метрической.

  Технология позволяет разработать универсальные эффективные процедуры
оценки подобия информа\-ционных объектов, представленных графически и
текстами на естественном или искусственном языке. Процедуры могут
использоваться в сис\-те\-мах поиска информации, оценки близости текстовых и
графических объектов, автоматизированной проверки уровня усвоения знаний.

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{99}
\bibitem{1-kuz}
\Au{Manning Ch.\,D., Raghavan P., Sch$\ddot{\mbox{u}}$tz~H}. An introduction to
information retrieval.~--- Cambridge: University Press, 2009. 569~p.
\bibitem{2-kuz}
\Au{Salton G., Wong A., Yang~C.\,S.} A~vector space model for automatic
indexing~// Comm. ACM, 1975. Vol.~18. No.\,11. P.~613--620.
\bibitem{3-kuz}
\Au{Кузнецов Л.\,А.} Веро\-ят\-ност\-но-ста\-ти\-сти\-че\-ская оценка
адекватности информационных объектов~// Информатика и её применения,
2011. Т.~5. Вып.~4. С.~39--50.
\bibitem{4-kuz}
\Au{Кузнецов Л.\,А., Кузнецова В.\,Ф., Антонов~Д.\,И.} Оценка близости
графических объектов на примере электрических схем с помощью
информационного критерия~// Открытое и дистанционное образование, 2013.
№\,2(50). С.~35--43.
\bibitem{5-kuz}
\Au{Кузнецов Л.\,А., Бугаков Д.\,А.} Разработка меры оценки информационного
расстояния между графическими объектами~//
Ин\-фор\-ма\-ци\-он\-но-управ\-ля\-ющие сис\-те\-мы, 2013. №\,1. С.~74--79.
\bibitem{6-kuz}
\Au{Гнеденко Б.\,В.} Курс теории вероятностей.~--- 9-е изд., испр.~---
М.: ЛКИ, 2007. 448~с.
\bibitem{7-kuz}
ГОСТ 2.743-91 ЕСКД. Обозначения условные графические в схемах. Элементы
цифровой техники.~--- М.: Госстандарт, 1991. 75~с.
\bibitem{8-kuz}
\Au{Кузнецов Л.\,А., Кузнецова В.\,Ф.} Оценка семантической адекватности
текстов информационным методом~// Информатика и её применения, 2013.
Т.~7. Вып.~1. С.~19--29.
\bibitem{9-kuz}
\Au{Гаспарян А.\,В., Киракосян А.\,А.} Система сравнения отпечатков пальцев
по локальным признакам~// Вестник РАУ. Сер.
Фи\-зи\-ко-ма\-те\-ма\-ти\-че\-ские и естественные науки, 2006. №\,2. С.~85--91.

\bibitem{11-kuz}
\Au{Swain M.\,J., Ballard D.\,H.} Color indexing~// Int. J.~Computer Vision, 1991.
Vol.~7. No.\,1. P.~11--32.

\bibitem{10-kuz}
\Au{Sticker M., Orengo M.} Similarity of color images~// SPIE Conference
Proceedings, 1995. Vol.~2420. P.~381--392.

\bibitem{12-kuz}
\Au{Кузнецов Л.\,А., Бугаков Д.\,А.} Развитие метода сравнения и
классификации графических объектов~// Вестник компьютерных и
информационных технологий, 2013. №\,2(104). С.~11--16.
\bibitem{13-kuz}
\Au{Шеннон К.} Работы по теории информации и кибернетике.~--- М.: Изд-во
ИЛ, 1963. 833~с.
\bibitem{14-kuz}
\Au{Кузнецов Л.\,А., Кузнецова В.\,Ф., Капнин~А.\,В.} Универсальный
метрический тезаурус русского языка~// Информатика и её применения,
2013. Т.~7. Вып.~3.\linebreak С.~27--35.

\end{thebibliography}
} }

\end{multicols}

\vspace*{-9pt}

\hfill{\small\textit{Поступила в редакцию 10.12.13}}

%\newpage


\vspace*{10pt}

\hrule

\vspace*{2pt}

\hrule


\def\tit{UNIVERSAL TECHNOLOGY OF INFORMATION OBJECTS PROXIMITY ASSESSMENT}

\def\titkol{Universal technology of information objects proximity assessment}

\def\aut{L.\,A.~Kuznetsov}
\def\autkol{L.\,A.~Kuznetsov}


\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-9pt}

\noindent
Russian Presidential Academy of National Economy and Public Administration
(Lipetsk Branch), 3 Internatsional'naya Str., Lipetskaya oblast, Lipetsk 398050,
Russian Federation



\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND APPLICATIONS\ \ \ 2014\ \ \ volume~8\ \ \ issue\ 2}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND APPLICATIONS\ \ \ 2014\ \ \ volume~8\ \ \ issue\ 2
\hfill \textbf{\thepage}}}

\vspace*{6pt}


\Abste{The paper outlines the technology used to determine the degree of similarity
of information objects, which are represented by text or graphic images. Objects are
formalized by probabilistic models. The structure of the model is set by an algebra on
a minimum set of graphic components of an object. Quantitative characteristics of
the structure of objects are the probability distributions on the algebra. The amount of
information in objects is estimated by entropy. The similarity measure of information
objects is based on entropy. The paper describes the method of estimating the
proximity of text and graphic objects. The paper provides several examples of
estimation algorithms implementation. It is shown that the developed method is more
efficient compared to the methods described in the literature. The technology used to
form images of information objects and to compare their semantic content is universal.
It is possible to adapt the technology to the meaningful characteristics of objects
being analyzed.}

  \KWE{information object; text; image; probabilistic model; semantic similarity;
entropy; measure of similarity}

\DOI{10.14357/19922264140213}

%\Ack
%\noindent


  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{99}


\bibitem{1-kuz-1}
\Aue{Manning, Ch.\,D., P. Raghavan, and H.~Sch$\ddot{\mbox{u}}$tz}.
2009. \textit{An introduction to information retrieval}.
Cambridge: University Press. 569~p.
\bibitem{2-kuz-1}
\Aue{Salton, G., A. Wong, and C.\,S.~Yang}. 1975.
A~vector space model for automatic indexing.
\textit{Comm. ACM}.  11:613--620.
\bibitem{3-kuz-1}
\Aue{Kuznetsov, L.\,A.} 2011. Veroyatnostno-statisticheskaya
otsen\-ka adekvatnosti informatsionnykh ob"ektov
[Probabilistic and statistical evaluation of the adequacy of information objects].
\textit{Informatika i ee Primeneniya}~---
\textit{Inform. Appl.} 5(4):39--50.
\bibitem{4-kuz-1}
\Aue{Kuznetsov, L.\,A., V.\,F.~Kuznetsova, and D.\,I.~Antonov}.
2013. Otsenka blizosti graficheskikh ob"ektov na primere elektricheskikh
skhem s pomoshch'yu informatsionnogo kriteriya
[Estimation of the distance graphical objects on the example of electrical
circuits using information criterion].
\textit{Otkrytoe i Distantsionnoe Obrazovanie} [Open and Distance Education]
2:35--43.
\bibitem{5-kuz-1}
\Aue{Kuznetsov, L.\,A., and D.\,A.~Bugakov}. 2013.
Razrabotka mery otsenki informatsionnogo rasstoyaniya mezhdu graficheskimi
ob"ektami [Development of measures assessing the information distance between
graphic objects].
\textit{Informatsionno-Upravlyayushchie Sistemy}
[Information and Control Systems] 1:74--79.
\bibitem{6-kuz-1}
\Aue{Gnedenko, B.\,V.} 2007. \textit{Kurs teorii veroyatnostey}
[Course of probability theory].  Moscow: LKI Publs. 448~p.
\bibitem{7-kuz-1}
GOST 2.743-91 ESKD. Oboznacheniya uslovnye gra\-fi\-che\-skie v skhemakh.
Elementy tsifrovoy tekhniki [State Standard 2.743-91 ESKD.
Graphic symbols in schemes. Elements of digital technology].
M.: Gosstandart, 1991. 75~p.
\bibitem{8-kuz-1}
\Aue{Kuznetsov, L.\,A., and V.\,F.~Kuznetsova}. 2013. Otsen\-ka semanticheskoy
adekvatnosti tekstov informatsionnym metodom
[Evaluation of the semantic adequacy of texts by information method].
\textit{Informatika i ee Primeneniya}~--- \textit{Inform. Appl.} 7(1):19--29.
\bibitem{9-kuz-1}
\Aue{Gasparyan, A.\,V., and A.\,A.~Kirakosyan}. 2006.
Sistema sravneniya otpechatkov pal'tsev po lokal'nym priznakam
[Fingerprint comparisons on local characteristics].
\textit{Vestnik RAU. Ser. Fiziko-Matematicheskie i Estestvennye Nauki}
[Herald of RAU. Physics, Mathematics, and Natural Sciences ser.] 2:85--91.

\bibitem{11-kuz-1}
\Aue{Swain, M.\,J., and D.\,H.~Ballard}. 1991. Color indexing.
\textit{Int. J.~Computer Vision} 7(1):11--32.

\bibitem{10-kuz-1}
\Aue{Sticker, M., and M.~Orengo}. 1995. Similarity of color images.
\textit{SPIE Conference Proceedings} 2420:381--392.

\bibitem{12-kuz-1}
\Aue{Kuznetsov, L.\,A., and D.\,A.~Bugakov}. 2013. Razvitie metoda sravneniya i
klassifikatsii graficheskikh ob"ektov
[Development of the method of comparison and classification].
\textit{Vestnik Komp'yuternykh i Informatsionnykh Tekhnologiy}
[Computer and Information Bulletin Technology] 2(104):11--16.
\bibitem{13-kuz-1}
\Aue{Shennon, K.} 1948. A~mathematical theory of communication. Pt.~I, II.
\textit{Bell. Syst. Techn. J.} 27(3):379--423; 27(4):623--656.
\bibitem{14-kuz-1}
\Aue{Kuznetsov, L.\,A., V.\,F.~Kuznetsova, and A.\,V.~Kapnin}.
2013. Universal'nyy metricheskiy tezaurus russkogo yazyka
[Universal Russian language thesaurus metric].
\textit{Informatika i ee Primeneniya}~--- \textit{Inform. Appl.} 7(3):27--35.

\end{thebibliography}
} }


\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received December 10, 2013}}

\vspace*{-18pt}



\Contrl

\noindent
\textbf{Kuznetsov Leonid A.} (b.\ 1942)~--- Doctor of Science in technology,
professor, Honored Scientist of Russian Federation,
Head of Department, Russian Presidential Academy of National
Economy and Public Administration (Lipetsk Branch),
3 Internatsional'naya Str., Lipetskaya oblast, Lipetsk 398050,
Russian Federation; Kuznetsov.Leonid48@gmail.com




 \label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература}
