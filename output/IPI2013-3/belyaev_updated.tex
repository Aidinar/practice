 \renewcommand{\figurename}{\protect\bf Figure}
\renewcommand{\tablename}{\protect\bf Table}
\renewcommand{\bibname}{\protect\rmfamily References}

\def\stat{belyev}

\def\tit{APPROXIMATION OF A~MULTIDIMENSIONAL DEPENDENCY BASED ON A LINEAR EXPANSION IN A 
DICTIONARY OF~PARAMETRIC FUNCTIONS$^*$}

\def\titkol{Approximation of a multidimensional dependency based on linear expansion in a 
dictionary of parametric functions}

\def\autkol{M.\,G.~Belyaev and E.\,V.~Burnaev}

\def\aut{M.\,G.~Belyaev$^1$ and E.\,V.~Burnaev$^2$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1] {The authors are partially supported by Laboratory for Structural Methods of 
Data Analysis in Predictive Modeling, MIPT, RF government grant, ag.\ 
11.G34.31.0073; RFBR grant 13-01-00521. Results, described in this work, were 
obtained in the framework of ``COPTI-X: Surrogate Model Construction for 
Structure Approximation and Optimization'' joint project with Airbus Operations 
SAS.}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Institute for Information Transmission Problems RAS, Moscow 
Institute of Physics and Technology, Datadvance LLC, belyaev@iitp.ru}
\footnotetext[2]{Institute for Information Transmission Problems RAS, Moscow 
Institute of Physics and Technology, Datadvance LLC, burnaev@iitp.ru}

\Abste{The problem of a multidimensional function approximation using a finite 
set of pairs ``point''\,--\,``function value at this point'' is considered. As  
a model for the function, an expansion in a dictionary containing nonlinear 
parametric functions has been used. Several subproblems should be solved when 
constructing an approximation based on such model: extraction of a validation 
sample, initialization of parameters of the functions from the dictionary, and 
tuning of these parameters. Efficient methods for solving these subproblems 
have been suggested. Efficiency of the proposed approach is demonstrated on 
some problems of engineering design.}

\KWE{nonlinear approximation; parametric dictionaries}

\vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}

\section{Introduction}

\noindent For engineering design, it is necessary to model complex physical 
phenomena. Typically used models are represented by complex systems of 
differential equations. Such systems do not have analytical solutions; so, 
computationally heavy numerical methods are used. One approach to solving 
problems of engineering design,
   actively developing in recent years, is the surrogate modeling~\cite{surrogateModeling, kuleshov2}.
In this approach, a complex physical phenomenon is described by a simplified 
(surrogate) model constructed using data mining techniques and a set of 
examples,
   representing results of a detailed physical modeling and/or real experiments.
The problem of approximation of a multidimensional function using a finite set 
of pairs ``point''\,--\,``value of the function at this point'' is one of the 
main problems to be solved in the construction of the surrogate model.  
This problem  will be considered in the following formulation:

\medskip

\noindent \textbf{Problem 1.}\ \textit{Let $f\left( {\vec x} \right) \in R^1$ 
be some continuous function on a compact set 
$
\mathrm{D} \subset R^d$ with known 
output values in a finite set of input points. The set 
 \begin{equation*}
 S_{\mathrm{learning}} = \{ {\vec x}_i, y_i \}_{i=1}^{N_{\mathrm{learning}}}\,,\ \ \ 
{\vec x}_i \in \mathrm{D}\,,\enskip 
y_i = f\left( {\vec x}_i\right)\,,
\end{equation*} 
forms the learning sample.
The approximation problem is to construct an approximation      
$\hat f\left( {\vec x} \right)$ (approximator) of the function $f\left( {\vec x} \right)$
    using the given data sample $S_{\mathrm{learning}}$ such that}
    $f\left( {\vec x} \right) \approx \hat f\left( {\vec x} \right)$
for all $\vec x\in\mathrm{D}$.


\medskip

\noindent \textbf{Remark~1.}\ In general case, the values of the function $f\left( 
{\vec x} \right)$ are known only for the finite set of input points; so, the 
proximity $f\left( {\vec x} \right) \approx \hat f\left( {\vec x} \right)$ is 
usually measured be the mean square error
$$
Q\left( S_{\mathrm{test}}, \hat f \right) = \left(\fr{1}{N_{\mathrm{test}}}\right) 
    \sum\limits_{i=1}^{N_{\mathrm{test}}} \left( y_i - \hat f \left( 
    \vec x_i\right) \right)^2
    $$ 
    calculated using an independent test data sample
      $$
      S_{\mathrm{test}} = \{ {\vec x}_i, y_i \}_{i=1}^{N_{\mathrm{test}}}\,,\enskip  
{\vec x}_i \in \mathrm{D}\,,\ 
\ y_i = f\left( {\vec x}_i\right)\,.
$$ 

The criterion $Q\left( S_{\mathrm{test}}, \hat f \right)$ 
of approximation quality makes sense if input vectors from the samples $S_{\mathrm{learning}}$ 
and $S_{\mathrm{test}}$ are generated by the same distribution and cover the design space 
$\mathrm{D}$ sufficiently densely.
The function $Q\left( S, \hat f \right)$ for some set~$S$ 
of pairs ``point''\,--\,``value of the function at this point'' is called an 
error function on the set~$S$.

\medskip

Due to requirements of surrogate modeling problems (in particular, the need to build quickly 
computable global approximation model and to work with large data samples),
   the most common method of solving approximation problems is based on Artificial Neural Networks (ANN)~\cite{elementsOfStatLearning}. 
An approximation based on the ANN model provides high-speed calculations of output predictions. The ANN model can be easily ``extended'' 
by increasing number of layers and/or their sizes as the learning sample size increases while the computational complexity of the 
approximation model construction grows only linearly.

A typical scheme of approximation construction based on the ANN model can be 
divided into two phases:
\begin{enumerate}[(1)]
\item an initialization phase (setting the initial values of the 
model parameters;  and \\[-9pt]
\item extraction of the validation sample) and a training phase (tuning the ANN 
 parameters to fit the data sample).
 \end{enumerate}
  Usually, random methods are used during the 
 initialization phase. Such methods lead to a large scatter of the approximation accuracy.
 Surrogate models are constructed to replace computationally 
 heavy objective functions (and/or constraints) in optimization problems~\cite{copti}. 
 Engineering design based on surrogate models is iterative:
 \begin{enumerate}[(1)]
 \item  find the optimum of the 
 objective function (surrogate model);\\[-9pt]
 \item  generate additional pairs
   ``point''\,--\,``value of the function at the point'' in the neighbourhood of the optimum;\\[-9pt] 
\item reconstruct the surrogate model and optimize it,\linebreak etc.
\end{enumerate}
 Therefore, 
  unpredictable significant changes in the surrogate model structure and significant variations of 
  the approximation accuracy deteriorate surrogate based optimization.

This paper investigates methods for constructing approximations based on the 
linear expansion in nonlinear functions from the parametric dictionary (ANN model 
with one hidden layer).
Here, the methods for initialization and training that reduce the average approximation 
error and its variations are suggested. Let describe the structure of the paper.

The model based on a linear expansion in a dictionary of parametric functions is described in 
subsection~2.1. The main steps of the approximation construction based on
  this model are described in subsection~2.2.
Subsection~2.3 is devoted to various subproblems that arise when 
constructing an approximation using the proposed algorithm.
In section~3, the subproblems of the initialization step
 of the approximation construction algorithm are considered. 
In subsection~3.1, a new algorithm is described for the validation sample 
extraction, such that points from the validation sample are distributed as uniformly
 as possible among the remaining points of the learning sample. 
 A~computationally efficient deterministic algorithm for the validation sample extraction 
 based on the greedy optimization of some uniformity criterion.
In subsection~3.3, a new algorithm is described for the initialization of functions 
from the parametric dictionary. 
In section~4, a new training algorithm is considered. 
In subsection~4.1, a special form of the error function that takes 
into account the structure of the approximation error dependence on different groups 
of parameters and includes adaptive regularization is suggested.
In subsection~4.2, a new method for the regularization 
parameter selection is described.
Both sections~\ref{stage1} and~\ref{stage2} contain results of the computational experiments on artificial functions.
Experimental results for some engineering design problems are described 
in section~\ref{experiments}.
{\looseness=1

}

\section{Algorithm for~Approximation Construction}

\subsection{Model based on a linear expansion in~a~dictionary of~parametric functions}
\label{model}

\noindent
The approximation $\hat f\left( {\vec x} \right)$ is modeled
by the linear expansion in a 
dictionary of parametric functions, i.\,e.,
$$ 
\hat f\left({\vec x}\right) = \sum\limits_{j = 1}^p \alpha_j 
\psi_j\left( {\vec \theta_j},  {\vec x} \right) + \alpha_0\,.
$$
Let rewrite this equality in matrix form
$$
\hat f \left( {\vec x} \right) = {\vec \psi} \left( {\Theta}, {\vec x} \right) {\vec \alpha}
$$ 
where the vectors are denoted by caps with vector signs and matrices are denoted by caps 
$({\vec \alpha} = \{ \alpha_j \}_{j = 0}^p\,,\enskip \Theta$\linebreak $ = \{ \vec \theta_j \}_{j = 1}^p)$.
The row-vector ${\vec \psi} \left( {\Theta}, {\vec x} \right)$ consists of the dictionary functions 
values at the point ${\vec x}$ ($\psi_0 \equiv 1$ corresponds to $\alpha_0$).
Therefore, the approximator $\hat f \left( {\vec x}\right)$ is defined by the 
matrix~$\Theta$ of dictionary functions parameters and by the vector
  ${\vec \alpha}$ of the linear combination coefficients.
In order to form the dictionary, sigmoid functions (sigmoids) are used:
\begin{gather*}
  \psi_j\left( {\vec \theta_j}, {\vec x} \right) =
        \sigma\left({\vec x}^{\mathrm{T}}\theta_j + \theta_j^0\right)\,;\\
        {\vec\theta}_j = (\theta_j,\theta_j^0)\,,\enskip 
        \theta_j \in R^d\,, \enskip 
        \theta_j^0\in R^1\,,
        \end{gather*}
        where
        $$
     \sigma\left(z\right) = \fr{e^z - e^{-z}}{e^z + e^{-z}}\,,\ z\in R^1\,.
$$
The dictionary consisting of such functions can be used for approximation of rather wide class 
of  functions~$f$ (see the results in papers~\cite{petrushev, sigmoidApprox1}).
For example, in \cite{sigmoidApprox1}, it is shown that the approximator
 $\hat f$, composed of $p$ sigmoid functions, allows to get the approximation 
 accuracy of the order $O \left( 1/p^{{1}/{d}}\right)$. 
However, if in the dictionary 
are  not included arbitrary sigmoid functions but  they are selected
depending on the approximated function~$f$ 
  (``tune'' the dictionary functions),
then the approximation accuracy has the order $O\left(1/p\right)$.

\subsection{Structure of the Approximation Algorithm}
\label{approxAlgo}

\noindent
In order to construct the dictionary, it is necessary to select type and  
number of functions in the dictionary and initialize their parameters.
It is impossible to determine the dictionary functions parameters explicitly.
The standard approach approximation construction has been applied that uses partitioning 
of the original sample into two parts $S_{\mathrm{learning}} = 
S_{\mathrm{train}} \cup S_{\mathrm{validation}}$ 
in order to prevent overtraining~\cite{vapnik}.

\bigskip

\noindent
\textbf{Algorithm~1} (main steps of the approximation construction algorithm) % \label{alg:1}
\noindent
\begin{enumerate} 
    \item {Model Selection Step (in the considered case, the model structure 
    is defined by the number $p$ of the dictionary functions)}.\\[-9pt]
    \item Initialization Step:\\[-9pt] 
    \begin{itemize}
    \item[(a)] divide the sample $S_{\mathrm{learning}}$ 
    into subsamples $S_{\mathrm{train}}$ and $S_{\mathrm{validation}}$; and \\[-9pt]
\item[(b)] set the initial values of the dictionary functions parameters~$\Theta$ 
and expansion coefficients~$\vec \alpha$.\\[-9pt]
\end{itemize}
    \item \label{train} Training Step:\\[-9pt] 
    \begin{itemize}
\item[(a)] iteratively minimize $Q\left(S_{\mathrm{train}}, \hat f \right)$ with 
    respect to the parameters $\Theta$ and $\vec \alpha$; and\\[-9pt] 
\item[(b)] stop minimization if the error $Q\left( S_{\mathrm{validation}}, \hat f \right)$ 
    begin to increase.
    \end{itemize}
  \end{enumerate}

\medskip

Each of the steps of Algorithm~1 is a separate subproblem. 
There exists a lot of methods for solution of these subproblems. 
In this paper, more efficient methods are proposed
(except solution for the subproblem of the dictionary size~$p$ selection).
As for the choice of the dictionary size~$p$, usually, 
some upper bound on its value is defined depending on the 
learning sample size and the exact value of~$p$ is selected using cross-validation.

\subsection{Optimization Algorithm}

\noindent
Usually, in order to optimize the error function (see step~3 of Algorithm~1) 
with respect to parameters of complex regression models (for example, multilayer 
neural networks),
gradient methods are used due to very high dimensionality of the parametric space.
Since in the considered case the number of parameters is relatively small,  
second-order optimization methods can be used.
The Gauss--Newton method~\cite{Nocedal} is the most common method for minimizing 
functions of the form
$$
Q\left({S_{\mathrm{train}}}, \hat f\right) = \left( \vec y - \hat f({X}) \right)^{\mathrm{T}} 
 \left( \vec y - \hat f({ X}) \right)
 $$
 

 
 \noindent
 where $X$ is a matrix of all points from 
 $S_{\mathrm{train}}$ and $\vec y = f(X)$ is a vector of the function $f$ values at 
 these points.  
In fact, the main difference between this method and the Newton method consists in
how the matrix of second-order derivatives of the error function is calculated.
Let denote by $\Omega = \{\Theta,\vec \alpha\}$ the set of all parameters of the model
 (parameters of the dictionary functions and the corresponding expansion coefficients); 
 then, assuming that a residual vector components $\vec e = \hat f({ X}) - \vec y$ are 
 small, one gets
\begin{equation}
  \label{nls}
  Q_{\Omega \Omega} = \hat f_{\Omega}^{\mathrm{T}} \hat f_{\Omega} + 
  \sum\limits_{i=1}^{N_{\mathrm{train}}} e_i \hat f_{\Omega \Omega} 
  \left(\vec x_i\right) \approx \hat f_{\Omega}^{\mathrm{T}} 
  \hat f_{\Omega} = {J}^{\mathrm{T}} { J}
\end{equation}
where ${J} = \hat f_{\Omega}$ is the matrix of the model~$\hat f$ derivatives with respect 
to $\Omega$ at the points $S_{\mathrm{train}}$.
Since $Q_{\Omega \Omega} \approx { J}^{\mathrm{T}} { J} \succeq 0$, then the 
approximate matrix of the second derivatives, calculated according to formula~(\ref{nls}), 
is always nonnegative definite. This partially solves degeneracy problem of the Newton method being applied to 
nonconvex functions.

Nevertheless, let note that during the minimization of the error function approximation of 
the Hessian,
 $Q_{\Omega \Omega} \approx { J}^{\mathrm{T}} { J}$ can become degenerate and noninvertible.
 {\looseness=1
 
 }
 
The Levenberg--Marquardt algorithm \cite{LM} was developed to solve this degeneracy problem. 
The main idea is to add identity matrix with regularization multiplier to the approximate 
Hessian matrix when searching the step size according to the Gauss--Newton method, i.\,e.,
{\looseness=1

}
\begin{equation}
  \label{lm}
  \Omega^k = \Omega^{k-1} - \left( { J}^{\mathrm{T}} { J} + \mu \mathrm{I} \right)^{-1} Q_\Omega\,.
\end{equation}
The parameter $\mu$ defines behavior of the algorithm:
for small~$\mu$, the step size is close to the step size of the Gauss--Newton 
method; for big~$\mu$, the step is done along the antigradient with the size 
approximately equal to ${1}/{\mu}$.
Therefore, one can always find such value of the parameter~$\mu$ which provides decrease of the error function. 
When training the model, the Levenberg--Marquardt algorithm will be used (this method is 
also realized in MatLab for ANN training).

\section{Initialization Step}
\label{stage1}

\noindent
In this section, the algorithms for solving two subproblems of the initialization step
are proposed:
extraction of the validation sample and initialization of the model parameters.
Also, in subsection~3.3,  a methodology for an experimental comparison 
of approximation algorithms is described and the results of this comparison
are provided.

\subsection{Extraction of the Validation Sample}
\label{divideSample}

\noindent
Let consider the first subproblem of the initialization step, i.\,e., 
decomposition of the initial sample 
$S_{\mathrm{learning}}$ into two parts $S_{\mathrm{train}}$ and $S_{\mathrm{validation}}$ where
$S_{\mathrm{train}}$ is used for an iterative tuning of the model parameters and $S_{\mathrm{validation}}$ is used 
to estimate a generalization ability (an estimate of the proximity between the original function 
and its approximation) and to stop the iterative tuning process when the overtraining 
appears.

In order to estimate the generalization, the set of points
$X_{\mathrm{validation}} = \{\vec x \in S_{\mathrm{validation}}\}$ should be ``uniformly'' 
distributed among other points of the learning sample 
$X_{\mathrm{learning}} = \{\vec x \in S_{\mathrm{learning}}\}$.
Standard algorithms for approximation construction perform decomposition into the validation
 $S_{\mathrm{validation}}$ and the training $S_{\mathrm{train}}$ samples randomly, which often results in 
 inconsistent decomposition.

Let estimate the uniformity of $X_{\mathrm{learning}}$ decomposition into the 
sets $X_{\mathrm{train}}$ and $X_{\mathrm{validation}}$ using the following criterion:
\begin{multline}
  \label{GurMorMit}
   U(X_{\mathrm{train}}, X_{\mathrm{validation}}) = 
   \fr{1}{\# r^{1}}\sum\limits_{ \{\vec x_i, \vec x_j\} \in r^{1}} 
   \fr{1}{\| \vec x_i - \vec x_j\|}\\
   {} - \fr{1}{\# r^{2}}
   \sum\limits_{ \{\vec x_i, \vec x_j\} \in r^{2}} \fr{1}{\|\vec x_i - \vec x_j\|}
\end{multline}
where $r^{1}$ is the set of pairs of points such that each of points belongs either to
 $X_{\mathrm{train}}$ or to $X_{\mathrm{validation}}$;
  $r^{2}$ is the set of pairs of points such that one of them belongs to
 $X_{\mathrm{train}}$ and another belongs to $X_{\mathrm{validation}}$; and
  $\# r^{i}$ is the cardinality of $r^{i}$, $i = 1, 2$.
  When minimizing  $U(X_{\mathrm{train}}, X_{\mathrm{validation}})$ 
  (with respect to different decompositions of $X_{\mathrm{learning}}$), 
  the distance between points from one class is maximized and the distance 
  between points from different classes is minimized that fully meets all objectives.

Optimization of the criterion~\eqref{GurMorMit} is an $NP$-hard combinatorial problem
that cannot be solved for reasonable time when the sample size $N_{\mathrm{learning}} \gg 1$. 
On the other hand, for the case $N_{\mathrm{learning}} \sim 10$, the optimization 
can be performed by 
the full search. Therefore, let consider the simplification of this optimization problem:
divide all the design domain into rather small hypercubes and optimize the criterion locally by relocating points from one class
 ($S_{\mathrm{train}}$) to another  ($S_{\mathrm{validation}}$) only within each of the hypercubes.
 
In order to divide the design domain, Classification and Regression Trees~\cite{CART} have been used. 
This method is based on the sequence of simple cuts of the design domain with respect to 
the input vector components. In each of the hypercubes, obtained during the previous iteration, 
a constant approximation was constructed by averaging the output values of the points belonging to this 
hypercube.
The input component and the location of the next cut are selected optimally in the 
sense of the mean square error of the corresponding piecewise constant approximation.
There are a lot of criteria for stopping the tree construction process. These criteria are 
based on the generalization ability estimation of the tree~\cite{elementsOfStatLearning}. 
Here, as a stopping criterion, an upper bound on the number of points belonging 
to each leaf of the tree is used since the optimization complexity of the criterion~\eqref{GurMorMit} 
depends on this upper bound.

\medskip

\noindent
\textbf{Algorithm~2} (sample $S_{\mathrm{learning}}$ decomposition) %\label{alg:2}
\ 
\noindent
  \begin{enumerate}
    \item {Construct a regression tree~\cite{CART} with an upper 
    bound on the number of points belonging to the tree leaves (the 
    number of points should be bigger than $\mathrm{leaf}_{\min} = 8$ and smaller than 
    $\mathrm{leaf}_{\max}=16$) approximating the function $f$ with piecewise constant approximation}. 
{Let the number of leaves of the constructed tree be equal to some $K$}. 
    \item {Let $s_k$ be the set of points 
    $\vec x \in X_{\mathrm{learning}}$ belonging to the leaf with the number~$k$}.
    \item {For all $k = 1, \dots, K$ using greedy algorithm (local optimization 
    in each separate hypercube),  decompose the set $s_k$ into subsets $s_k^{\mathrm{val}}$ and 
    $s_k^{\mathrm{tr}}$ such that the criterion  $U(s_k^{\mathrm{val}}, s_k^{\mathrm{tr}})$ takes its minimal 
    value under the restriction 
    that the fraction of the validation sample size is not smaller than $\mathrm{val}_{\mathrm{part}} = 0.2$}.
    \item {Construct $S_{\mathrm{validation}}$ and} $S_{\mathrm{train}}$
\begin{align*}
S_{\mathrm{validation}} &= \left\{ \{\vec x, y = f(\vec x)\}: \vec x \in 
\bigcup\limits_{k=1}^K  s_k^{\mathrm{val}} \right \}\,; \\
S_{\mathrm{train}} &= \left\{ \{\vec x, y = f(\vec x)\}: \vec x \in 
\bigcup\limits_{k=1}^K  s_k^{\mathrm{tr}} \right \}\,.
\end{align*}
  \end{enumerate}


\medskip

The proposed algorithm contains two computationally expensive steps: 
construction of the regression tree (complexity is equal to 
$O(N_{\mathrm{learning}}\log(N_{\mathrm{learning}}))$)
and local optimization of the criterion $U(s_k^{\mathrm{val}}, s_k^{\mathrm{tr}})$ 
(complexity is equal to $O(K) = O(N_{\mathrm{learning}})$).
For the second step, the constant in
 $O(K)$ depends on the number of ways to decompose a leaf with 
 $\mathrm{leaf}_{\mathrm{num}}$\linebreak $\in [\mathrm{leaf}_{\min}, \mathrm{leaf}_{\max}]$ points into two parts. 
 Due to the restriction on the proportion
 between the sizes of the validation and the training samples,
  this number is equal to
 $C_{\mathrm{leaf}_{\mathrm{num}}}^{[\mathrm{leaf}_{\mathrm{num}}
 \cdot \mathrm{val}_{\mathrm{part}}]}$, i.\,e., it is bigger than~28 
 (for $\mathrm{leaf}_{\mathrm{num}} = \mathrm{leaf}_{\min} = 8$) and smaller than 560 (for 
  $\mathrm{leaf}_{\mathrm{num}} = \mathrm{leaf}_{\min} = 16$). 
  
\subsection{Initialization of the Model Parameters}
\label{init}

\noindent
Initialization of the dictionary functions parameters~$\Theta$ significantly 
influences the approximation construction process and the final approximation accuracy.
The random methods Nguyen--Widrow (NW)~\cite{initNW} and SCAWI
(statistically controlled activation weight initialization)~\cite{initSCAWI}
are the most widely used algorithm for $\Theta$ initialization.
These methods use some matrix of independent random variables,
   multiplied by a fixed factor defining smoothness of the dictionary functions.
   {\looseness=1
   
   }
   
Note that the random vectors generation in high-dimensional spaces
   leads to their clustering thus giving rise to clustering of the directions 
   $\left\{\theta_j\right\}_{j = 1}^p$.
Here, an initialization algorithm, which
generates a rich functional dictionary    
(in terms of a uniform distribution of the directions) is proposed.
The directions $\left\{\theta_j\right\}_{j = 1}^p $ are generated
uniformly on the unit 
sphere using the methods from~\cite{SpherRnd}. 
This method is based on a normalization of points generated by a multivariate normal distribution.
The method uses the invariance property of a normal density relative 
to an arbitrary rotation and efficiently generates points with uniform 
distribution on the unit sphere.
   {\looseness=1
   
   }

Let now consider how to select norms values (defined by some scaling multipliers) 
of the vectors
$\left\{\theta_j\right\}_{j=1}^p$.
The value of the norm influences the smoothness of the corresponding sigmoid:
for a sufficiently small value, the sigmoid is almost linear on the compact~D;  
for a big value, the sigmoid behaves like the step function.
If one fixed value is used for all norms, then all sigmoids will have equal smoothness 
and the dictionary will not be ``rich'' enough.
Therefore, in order to define the norms values, the multipliers generated 
by the uniform distribution in some range have been used. Thus, the vectors 
$\left\{\theta_j\right\}_{j=1}^p$ have different norms and, finally, the 
dictionary contains sigmoids with different smoothness.
{\looseness=1

}

\bigskip

\noindent
\textbf{Algorithm~3} (initialization of the parameters $\Theta$) %\label{alg:3}

\noindent
 \begin{enumerate}
    \item {Construct a matrix $S$ of size $p \times d$ containing $p$ vectors, generated by the uniform 
    distribution on a \mbox{$d$-dimensional} sphere of unit radius}. 
    \item {Let
      $r = \sqrt{d}\, p^{1 / N_{\mathrm{train}}}$ and generate values of scaling multipliers $\xi_j, j=1,\dots,p$, 
      uniformly randomly on $[0, r]$. Such definition of $r$ guarantees that the number of points belonging to the 
      domain of a sigmoid saturation is small~\cite{initNW}.
    \item {Let define the sigmoids direction vectors} 
    $\left\{\theta_j \right\}_{j=1}^p$ according to the formula
    $\theta_j = \xi_j S_j$, $j=1,\dots,p$, where ${S}_j$ 
    is the $j$th line of the matrix~S. The offset values 
    $\left\{\theta_j^0\right\}_{j=1}^p$ are defined in the same way as in~\cite{initNW}, 
    i.\,e., according to the uniform grid on the interval} [$-r,r$].
  \end{enumerate}

\medskip

In~\cite{itas11_Yerofeyev}, written by the present
authors, comparison of popular random initialization 
methods with the proposed method and several specially developed deterministic initialization methods 
can be found.

\subsection{Experimental Results}
\label{exp1}

\noindent
The proposed algorithms for the initialization step should be compared 
with the standard approaches in terms of the average error of approximation and its 
variations. For generation of test problems, a set of artificial multidimensional 
functions has been used for testing optimization algorithms.
This choice is due to the fact that in the framework of 
surrogate modeling, constructed approximation is often used as the 
objective function instead of original function.
Let distinguish two types of test problems:
\begin{enumerate}[(1)]
  \item test functions with fixed dimension of the input vector $\vec x$~--- 
  allinit, beale, hartmann, ishigami, wbd; and
  \item test functions with dimension of the input vector~$\vec x$ that can be 
  set to some predefined value~--- gSobol, michalewicz, rosenbrock, whitley, zdt3. 
  In experiments, the input dimension was varied from~3 to~10.
\end{enumerate}
Exact formulas for the test functions can be found in~\cite{data1, data2}.

As a relative approximation error, the root-mean-square error normed by the analogous 
error for the constant approximation was used:
\begin{equation}
  E\left(S_{\mathrm{test}}, \hat f\right) = 
  \sqrt{\fr{\sum\nolimits_{i=1}^{N_{\mathrm{test}}} 
  \left( y_i - \hat f \left( \vec x_i\right) \right)^2}{\sum\nolimits_{i=1}^{N_{\mathrm{test}}} 
  \left( y_i - \bar{y} \right)^2}}
    \label{errorDef}
  \end{equation}
  where
  \begin{equation*}
  \bar{y} = \fr{1}{N_{\mathrm{test}}} \sum\limits_{i=1}^{N_{\mathrm{test}}} y_i\,.
\end{equation*}
The error comparable with $1$ corresponds to a very inaccurate approximation 
and the error comparable with $10^{-3}$ corresponds to a very accurate approximation.
In order to calculate the error, a separate test set $S_{\mathrm{test}}$ has been used.

\begin{figure*} %fig1
\vspace*{1pt}
 \begin{center}
 \mbox{%
 \epsfxsize=162.923mm
 \epsfbox{bel-1.eps}
 }
 \end{center}
 \vspace*{-6pt}
  \Caption{Methods for solving problems of the initialization step (errors for some tests):
  (\textit{a})~Whitley, $d=3$, $N=350$; (\textit{b})~gSobol, $d=3$, $N=500$;
  (\textit{c})~wbd, $d=3$, $N=75$; 
  (\textit{d})~Rosenbrock, $d=3$, $N=350$;
  (\textit{e})~Hartmann, $d=3$, $N=500$; and
  (\textit{f})~Allinit, $d=3$, $N=75$}
  \label{boxplot_init}
\end{figure*}

For each function (or pair ``function-input dimension'' for test problems of 
the second kind),  the learning sample size was selected such that the approximation error~(\ref{errorDef}), 
obtained using a standard approximation method, belonged to the interval
0.01--0.2 since this range is the most interesting for practice (usually, smaller 
values are not required in practice).
As a standard approximation method, the realization of ANN from MatLab such that
NW algorithm is used for the initialization, the validation sample is extracted 
randomly, and the training is performed by the Levenberg--Marquardt algorithm. In order to select 
the optimal dictionary size (the number of functions $p$) in each experiment, the brute 
force algorithm has been used with the criterion defined by the approximation error, estimated using 
cross-validation. Each separate experiment (the test function, the input dimension, and the
learning sample size are fixed) has the following setup:
10~random learning sample $S_{\mathrm{learning}}$ are generated; for each sample,
10~approximators are constructed. Let compare the following algorithms:
\begin{itemize}
\item the standard ANN algorithm (the methods are denoted on plots by number~1); 
\item the standard ANN with the proposed method for the validation sample extraction
(method~2); 
\item the standard ANN with the proposed
method for parameters initialization (method~3); and 
\item the standard ANN with both proposed
methods for the initialization step (method~4).
\end{itemize}


In most cases, the proposed algorithms for solution the problems of the initialization 
step improve the final quality of the approximation (applied either independently or simultaneously). 
It is interesting that combination of the proposed algorithms (method~4) 
in most cases makes it possible to obtain the model with the superior accuracy 
compared with the accuracy of the model obtained using these algorithms independently.
Therefore, new algorithm is more effective, see examples of diagrams 
in Fig.~\ref{boxplot_init} and also, Dolan--More curves in section~\ref{experiments}.

\section{Approximation Training}
\label{stage2}
 
\subsection{Separability of Variables}
\label{separability}

\noindent
Let consider the error function on the training sample as a function of the parameters $\Theta$ and $\vec \alpha$:
\begin{multline*}
  Q\left( S_{\mathrm{train}}, \hat f\right) =
  Q\left( \Theta, {\vec \alpha} \right)\\
  {}=   \left( \vec y - \hat f \left( X, \Theta, \vec\alpha \right) \right)^{\mathrm{T}}
  \left( \vec y - \hat f \left( X, \Theta, \vec\alpha \right) \right)\,.
\end{multline*}

Note that the dependence of the error function~$Q$ on the dictionary 
functions parameters~$\Theta$ is nonlinear and very complex.
At the same time, the dependence of~$Q$ on expansion coefficients $\vec \alpha$ is quadratic.
For the fixed~$\Theta$, the optimal values of~$\vec\alpha$ can be found by the least squares 
method:
\begin{equation}
\label{alphaLsq}
\vec\alpha \left( \Theta \right) =
 \left( \Psi\left( \Theta \right)^{\mathrm{T}} \Psi\left( \Theta \right) \right)^{-1}
 \Psi\left( \Theta \right)^{\mathrm{T}} \vec y
 \end{equation}
  where  
  $$
  \Psi\left( \Theta \right) = \left\{{\vec \psi} \left( {\Theta}, {\vec x}_i \right),
  i = 1,\ldots,N_{\mathrm{train}}\right\}\,.
$$

Let take this fact into account when tuning parameters of the approximator. 
For this, let consider the objective function
  $R\left( \Theta \right) = Q\left( \Theta, \vec\alpha\left(\Theta\right) \right)$
  where $\vec\alpha\left(\Theta\right)$ is calculated according to~(\ref{alphaLsq}).
When calculating the expansion coefficient according to~(\ref{alphaLsq}), a 
nonlinear dependence 
$\vec\alpha =  \left( \Theta \right)$ should be taken into account when calculating 
the derivatives $R_\Theta$ and~$R_{\Theta\Theta}$.
An algorithm for such calculations was proposed in~\cite{golub} and its 
theoretical properties were investigated in~\cite{ruhe}.

However, this algorithm has significant shortcoming: in~(\ref{alphaLsq}), 
inversion of matrix $\Psi^{\mathrm{T}} \Psi$  which, in general, can be degenerated, was used. 
In such case, the inverse matrix does not exist and it is not reasonable to use the error 
function $R\left( \Theta \right)$.
This situation was investigated in details in the framework of the linear regression methods~\cite{demidenko}.
It can be shown that even if the matrix
$\Psi^{\mathrm{T}} \Psi$ does not degenerate but is ill-conditioned, then estimates of the coefficients
 $\vec \alpha$ are unstable (in statistical terms, this means that the estimate of
 $\vec \alpha$ has very big variance).
In such case, the calculated values of the gradient and the Hessian of the error function 
are also unstable: even with small variations of the parameters~$\Theta$, 
the first and the second derivatives of the error function change significantly 
resulting in a very low training speed.
 
Let consider a classical approach for regularization in linear regression 
problems, namely,  ridge regression~\cite{demidenko}.
Let add to the matrix $\Psi^{\mathrm{T}}\Psi$ a positively definite matrix $\lambda I_p$, 
where
 $I_p$ is a unit matrix with sizes $p\times p$ and $\lambda > 0$ is a some constant.
In such case, formula~(\ref{alphaLsq}) takes the form
\begin{equation}
\label{alphaRidge}
\vec\alpha \left( \Theta \right) =
 \left( \Psi\left( \Theta \right)^{\mathrm{T}} \Psi\left( \Theta \right) + 
 \lambda I_p\right)^{-1}
 \Psi\left( \Theta \right)^{\mathrm{T}} \vec y\,.
\end{equation}
It is obvious that any level of matrix 
  $\left( \Psi\left( \Theta \right)^{\mathrm{T}} \Psi\left( \Theta \right)\right.$\linebreak 
  $ \left.+\;\lambda I_p\right)$ 
  conditionality can be reached by increasing the value of $\lambda$.
Use of the ridge regression is equivalent to redefinition of the 
error function in the following way:
\begin{multline*}
%  \label{ridgeR}
  \widetilde R\left( \Theta \right) = 
  \widetilde Q\left( \Theta, \vec \alpha\left(\Theta\right) \right)\\ =
  \left( \vec y - \hat f \left( X, \Theta, \vec\alpha\left(\Theta\right) \right) \right)^{\mathrm{T}}
  \left( \vec y - \hat f \left( X, \Theta, \vec\alpha\left(\Theta\right) \right) \right)\\
{}  + \lambda \vec \alpha\left(\Theta\right)^{\mathrm{T}} \vec \alpha\left(\Theta\right)\,.
\end{multline*}

\noindent
\textbf{Statement 1.} %\label{derivCalc}
\textit{The gradient and the Hessian of the error function
 $\widetilde R$ can be calculated according to the following formulas}:
  \begin{align}
  \widetilde R_\Theta &= \widetilde Q_\Theta = \vec e^{\mathrm{T}} \mathrm{J}\,;\notag\\ 
    \widetilde R_{\Theta\Theta} &=  
      \mathrm{J}^{\mathrm{T}}\mathrm{J} + \vec e \odot \hat f_{\Theta \Theta}-
      \left({\vec e}^{\mathrm{T}} \odot \Psi_\Theta + \mathrm{J}^{\mathrm{T}}  \Psi\right)\notag\\
      &{}\times  \left( \Psi^{\mathrm{T}} \Psi  + \lambda \mathrm{I} \right)^{-1}
      \left({\vec e}^{\mathrm{T}} \odot \Psi_\Theta + \mathrm{J}^{\mathrm{T}}  
      \Psi\right)^{\mathrm{T}}\,.    \label{rHessBeforeNls}
  \end{align}

\noindent
P\,r\,o\,o\,f.\ \ 
Let find the first derivatives of the function~$\widetilde R\left( \Theta \right)$:
  \begin{equation}
    \label{gradR}
    \widetilde R_\Theta = \widetilde Q_\Theta + \widetilde Q_\alpha \alpha_\Theta = \widetilde Q_\Theta + \vec0 \alpha_\Theta = \widetilde Q_\Theta\,.
  \end{equation}
   Since coefficients 
  $\vec\alpha \left( \Theta \right)$, obtained using~(\ref{alphaRidge}), 
  are the minimizer of the function
 $\widetilde Q\left( \Theta, \vec \alpha\left(\Theta\right) \right)$,
 $\widetilde Q_\alpha = \vec 0$.
  Let  differentiate equality~(\ref{gradR}) with respect to $\Theta$:
  \begin{equation}
    \label{HessianR}
    \widetilde R_{\Theta\Theta} = \widetilde Q_{\Theta\Theta} + \widetilde Q_{\Theta\alpha} \alpha_\Theta\,.
  \end{equation}

Contrary to~(\ref{gradR}), the second summand is not equal to~0. 
Therefore, it is necessary to calculate $\alpha_\Theta$.
Taking into account the equality $\widetilde Q_\alpha = \vec 0$ as a consequence, 
one gets that
\begin{equation*}
    d{\widetilde Q}_\alpha = \widetilde Q_{\alpha \alpha}d\alpha  + 
    \widetilde Q_{\alpha \Theta}d\Theta  = 0\,.
\end{equation*}
Consequently,
$$
    \alpha_\Theta = \fr{d\alpha}{d\Theta} = - 
    \widetilde Q_{\alpha \alpha}^{-1} \widetilde Q_{\alpha \Theta}\,.
$$
Then formula~(\ref{HessianR}) takes the form
  $$
  \widetilde R_{\Theta\Theta} =  \widetilde Q_{\Theta\Theta} - \widetilde Q_{\Theta\alpha} \widetilde Q_{\alpha \alpha}^{-1} \widetilde Q_{\alpha \Theta}\,.
  $$

Now let write explicitly expressions for the derivatives of the function~$\widetilde Q$.
Let denote by $\mathrm{J} = {\hat f_\Theta(X)}$ the matrix of the derivatives 
of the model~$\hat f$ with respect to~$\Theta$ at the points~$S_{\mathrm{train}}$.
Therefore,
  \begin{equation}
    \left.
    \begin{array}{rl}
    \widetilde Q_{\Theta} &= {\vec e}^{\mathrm{T}} \mathrm{J}\,; \\[9pt]
    \widetilde Q_{\Theta \Theta} &= \mathrm{J}^{\mathrm{T}}\mathrm{J} + 
    \vec e \odot {\hat f_{\Theta \Theta}}\,; \\[9pt]
    \widetilde Q_{\alpha \alpha} &= \Psi^{\mathrm{T}} \Psi + \lambda \mathrm{I}\,;\\[9pt]
    \widetilde Q_{\Theta\alpha} &= {\vec e}^{\mathrm{T}} \odot \Psi_\Theta + 
    \mathrm{J}^{\mathrm{T}}  \Psi\,.
    \end{array}
    \right\}
        \label{qDeriv}
  \end{equation}

Final formula~(\ref{rHessBeforeNls}) can be obtained directly from 
  $$
  \widetilde R_{\Theta\Theta} =  \widetilde Q_{\Theta\Theta} - 
  \widetilde Q_{\Theta\alpha} \widetilde Q_{\alpha \alpha}^{-1} 
  \widetilde Q_{\alpha \Theta}
  $$ 
  using expressions for the derivatives from~(\ref{qDeriv}).

\medskip

\noindent
Assuming the residual vector 
${\vec e}$ to be small,   all terms with ${\vec e}$ in~(\ref{rHessBeforeNls}) can be neglected:
\begin{equation}
  \label{HessianRfinal}
  \widetilde R_{\Theta\Theta} \approx \mathrm{J}^{\mathrm{T}}\mathrm{J}  - 
  \left(\mathrm{J}^{\mathrm{T}}  \Psi\right)
    \left( \Psi^{\mathrm{T}} \Psi + \lambda \mathrm{I}\right)^{-1} \left( \mathrm{J}^{\mathrm{T}} 
    \Psi\right)^{\mathrm{T}}\,.
\end{equation}
Therefore, one gets explicit formulas for calculation of the gradient and 
the approximate Hessian matrix of the modified error function $\widetilde R(\Theta)$ 
that are necessary for optimization based on the Levenberg--Marquardt algorithm 
(see formulas~(\ref{nls}) and~(\ref{lm})).

Let note that the product
$\mathrm{J}^{\mathrm{T}} \mathrm{J} \approx \widetilde Q_{\Theta\Theta}$ is 
nonnegatively definite.
Let show that the Hessian $\widetilde R_{\Theta\Theta}$ also has this property. 
In such case, one can construct accurate local-quadratic approximations of the error function during its optimization.

\medskip

\noindent
\textbf{Statement~2.} %\label{nonNegDef}
\textit{The matrix 
$$
\mathrm{H} \mathrel{\stackrel{\mathrm{def}}=} \mathrm{J}^{\mathrm{T}}
\mathrm{J}  - \left(\mathrm{J}^{\mathrm{T}}  \Psi\right)
    \left( \Psi^{\mathrm{T}} \Psi + \lambda \mathrm{I}\right)^{-1} 
    \left( \mathrm{J}^{\mathrm{T}} 
    \Psi\right)^{\mathrm{T}}$$ 
    is nonnegatively definite for any} $\lambda \ge 0$.

\medskip

\noindent
P\,r\,o\,o\,f\,.\ \ 
  Let rewrite matrix~H in the following form:
\begin{multline*}
   \mathrm{H} = \mathrm{J}^{\mathrm{T}}\mathrm{J}  - \left(\mathrm{J}^{\mathrm{T}} \Psi\right)
     \left( \Psi^{\mathrm{T}} \Psi + \lambda \mathrm{I}_p \right)^{-1} 
     \left( \mathrm{J}^{\mathrm{T}}  \Psi\right)^{\mathrm{T}}\\
      {}=
     \mathrm{J}^{\mathrm{T}}\left( \mathrm{I}_{N} - \Psi \left( \Psi^{\mathrm{T}} \Psi + 
     \lambda \mathrm{I}_p\right)^{-1} \Psi^{\mathrm{T}}  \right)\mathrm{J}\,.
  \end{multline*}
Let $\Psi = \mathrm{V} \mathrm{Q} \mathrm{U}^{\mathrm{T}}$ be a singular value 
decomposition for the matrix of regressors, then
\begin{multline*}
 \Psi \left( \Psi^{\mathrm{T}} \Psi + \lambda \mathrm{I}_p\right)^{-1} \Psi^{\mathrm{T}} \\
{}=  \mathrm{V} \mathrm{Q} \mathrm{U}^{\mathrm{T}} \left( \mathrm{U} 
\mathrm{Q}^2 \mathrm{U}^{\mathrm{T}} + \lambda \mathrm{U} \mathrm{U}^{\mathrm{T}}  
\right)^{-1} \mathrm{U} \mathrm{Q} \mathrm{V}^{\mathrm{T}} \\
{}   = \mathrm{V} \mathrm{Q} \mathrm{U}^{\mathrm{T}} 
\mathrm{U} \left( \mathrm{Q}^2  + \lambda \mathrm{I}_p  \right)^{-1} \mathrm{U}^{\mathrm{T}} 
\mathrm{U} \mathrm{Q} \mathrm{V}^{\mathrm{T}}\\
{} =
\mathrm{V} \mathrm{Q}^2 \left( \mathrm{Q}^2  + \lambda \mathrm{I}_p  
\right)^{-1} \mathrm{V}^{\mathrm{T}}\,.
\end{multline*}

Let $\tilde q_j$ be eigenvalues of the matrix $\mathrm{V} \mathrm{Q}^2 \left( \mathrm{Q}^2  + 
\lambda \mathrm{I}_p  \right)^{-1} \mathrm{V}^{\mathrm{T}}$, then
  $\tilde q_j = {q^2_j}/({q^2_j + \lambda})$ where $q_j$ are the elements of the matrix~$Q$.
The eigenvalues of the matrix $\mathrm{P} = \mathrm{I}_{N} - \Psi \left( 
\Psi^{\mathrm{T}} \Psi + \lambda \mathrm{I}_p\right)^{-1} \Psi^{\mathrm{T}}$ 
are not smaller than the difference of the minimal eigenvalue of
  $\mathrm{I}_{N}$ and the maximal eigenvalue from the set $\tilde q_j$.
  It is obvious that this difference is nonnegative since 
  $$
  1 - \max_j \tilde q_j =  1 - \max\limits_j \left( \fr{q^2_j}{{q^2_j + \lambda}}\right) 
  \ge 0
  $$ 
  for $\lambda \ge 0$.
  Therefore, the matrix $\mathrm{P}$ is nonnegatively definite and the matrix 
  $\mathrm{H} = \mathrm{J}^{\mathrm{T}} \mathrm{P} \mathrm{J}$ is also 
  nonnegatively definite.


\medskip

Now let estimate the computational complexity of formula~(\ref{HessianRfinal}) 
for the Hessian calculation $\widetilde R_{\Theta\Theta}$.
The size of the Jacobian matrix
 $\mathrm{J}$ is equal to $N_{\mathrm{train}} \times p(d+1)$, the size of 
 the matrix with regressors $\Psi$ is equal to $N_{\mathrm{train}} \times p$.
It is necessary to perform $O(N_{\mathrm{train}}p^2d^2)$ operations in order 
to calculate the main term $\mathrm{J}^{\mathrm{T}}\mathrm{J}$ , 
which is needed also for calculation of the standard error function.
At the same time, additional summand
 $\left(\mathrm{J}^{\mathrm{T}}  \Psi\right)
    \left( \Psi^{\mathrm{T}} \Psi + \lambda \mathrm{I}\right)^{-1} \left( 
    \mathrm{J}^{\mathrm{T}}  \Psi\right)^{\mathrm{T}}$ can be calculated for 
    $$
    O(N_{\mathrm{train}} p^2 d + p^3 + p^3d + p^3d^2) = O(N_{\mathrm{train}} p^2 d + p^3d^2)
    $$ 
    operations. Since in the considered class of approximation problems
$N_{\mathrm{train}} \gg d$, $N_{\mathrm{train}} \gg p$, then calculation 
of the additional summand requires significantly smaller number of operations 
compared to the number of operations for calculation of the main summand.

The proposed error function $\widetilde R\left( \Theta \right)$ does not only 
increase approximation accuracy but also decreases training time 
compared to the training time when using the standard error function
 $Q\left( \Theta, \vec \alpha \right)$~\cite{itas11_Belyaev}.
This advantage can be explained by two reasons. Some part of the parameters 
are estimated optimally on each iteration of the training algorithm and adaptive 
regularization increases numerical stability of the training process. In this work,
it is assumed that the output $y$ dimension is equal to~1, but for many applied problems, 
the output~$y$ can be multidimensional and its dimension~$d_y$ can even be higher 
than the input dimension $d$. In such case, the number of parameters of the standard 
error function is $({d+d_y})/{d}$ times higher than that of the modified error function.
Thus, separability of the variables can significantly decrease the number of optimized 
parameters in some problems.
{ %\looseness=1

}

\subsection{Adaptive Regularization}
\label{regularization}

\noindent
Standard approaches for regularization of models with the structure
 $\hat f \left( {\vec x} \right) = {\vec \psi} \left( {\Theta}, {\vec x} \right) 
 {\vec \alpha}$ use the 
  $L_2$ penalty on all parameters of the model~\cite{elementsOfStatLearning} and 
  a regularization coefficient is determined experimentally using some additionally 
  extracted validation samples and multiple training of the surrogate model.
In~\cite{bayesianLearning}, some Bayesian approach is proposed for the regularization 
parameter selection and, again, the $L_2$ penalty on all parameters of the model are used.
This method has two key shortcomings: 
\begin{enumerate}[(1)]
\item selection of the regularization parameter does 
not take into account the error of approximation; and\\[-9pt]
\item  the penalty incorporates norms of 
the parameters $\Theta$ and $\vec\alpha$ with equal weights and does not take into 
account essentially different nature of these parameters.
\end{enumerate}

In the proposed approach,  only the expansion coefficients~$\vec \alpha$  have been penalized
and regularization parameter~$\lambda$ has been selected optimally (in some sense) with 
taking into account the error of approximation.
{ %\looseness=1

}

When tuning the regularization parameter $\lambda$ during the training process, 
the functional dependency  $\lambda = \lambda \left( \Theta \right)$ appears. In general 
case, one should take into account this dependency when calculating the derivatives 
of the error function with respect to~$\Theta$.
However, in the framework of the considered approximation problem, optimization of 
the error function on the set $S_{\mathrm{train}}$ can be considered as the process for 
generation of different models with the final aim to obtain the model with the smallest 
error on the independent test set $S_{\mathrm{test}}$ rather than for finding the minimum of the 
error function on the train set $S_{\mathrm{train}}$.
Due to this remark, the change of the regularization parameter value during the training process 
is allowed and  these changes can be neglected
when calculating the derivatives of the error  function.
{\looseness=1

}

\begin{figure*}[b] %fig2
\vspace*{6pt}
 \begin{center}
 \mbox{%
 \epsfxsize=162.923mm
 \epsfbox{bel-2.eps}
 }
 \end{center}
 \vspace*{-6pt}
    \Caption{Methods for solving problems of the training step (errors for some tests):
  (\textit{a})~Whitley, $d=4$, $N=750$; (\textit{b})~wbd, $d=4$, $N=125$;
  (\textit{c})~Beale, $d=3$, $N=100$; 
  (\textit{d})~Michalewicz, $d=5$, $N=250$;
  (\textit{e})~zdt, $d=3$, $N=500$; and
  (\textit{f})~Ishigami, $d=3$, $N=250$}
  \label{boxplot_train}
\end{figure*}

In order to select the regularization parameter~$\lambda$ on each iteration of 
the training algorithm, let minimize the GCV  (Generalized Cross 
Validation) criterion~\cite{elementsOfStatLearning} estimating the approximation error
on the test sample in linear regression problems (${\vec \alpha }\left( \lambda \right)$ 
is calculated according to~(\ref{alphaRidge})):

\noindent
\begin{multline*}
%\label{GCV}
  GCV(\Psi, \lambda) = %\left( {\Lambda} \right) =
    \fr{\sum\limits_{i=1}^{N_{\mathrm{train}}} \left( y_i - \hat f(x_i)\right)^2 }
    {\left( 1 - ({1}/N_{\mathrm{train}}) \mathrm{tr}\left( \mathrm{L}  \right) \right)^2  }\\
   = %{N_{train}
    \fr{\left(\vec y - \Psi \vec \alpha(\lambda)\right)^{\mathrm{T}} 
    \left(\vec y - \Psi \vec \alpha(\lambda)\right)}
    {\left( 1 - ({1}/{N_{\mathrm{train}}})\mathrm{tr}\left(  
     \left( \vec{\Psi}^{\mathrm{T}} \vec{\Psi} + \lambda \mathrm{I} \right)^{-1} 
     \vec{\Psi}^{\mathrm{T}} \vec{\Psi}  \right) \right)^2  }\,.
\end{multline*}
Let  note that when minimizing the criterion
GCV with respect to $\lambda$ it is necessary to control condition 
number of the matrix $\Psi^{\mathrm{T}}\Psi + \lambda I$ in order the 
training process to be stable~\cite{oldRegul}.
It is proposed to impose a lower bound on the value of $\lambda$ such that provides
necessary level of the conditionality ($10^{12}$ in the present realization of the algorithm).



\subsection{Experimental Results}
\label{exp2}

\noindent
Let use the testing methodology, described in subsection~\ref{exp1}.
Let compare the following methods: the standard method (method~1), the 
method incorporating algorithms from subsections~3.1 and~3.2 (method~4), 
the method incorporating only the modified error function (method~5),  
and the method incorporating all the proposed algorithms  (method~6).



The most indicative results are given in Fig.~\ref{boxplot_train}.
The proposed modification of the error function allows to significantly improve 
approximation quality for some problems (for example, function michalewicz).
If method~6, which incorporates all the proposed algorithms,   is considered, then one 
can see that this method does not only additionally increase approximation accuracy 
compared to the best of two methods~4 and~5, but also significantly decreases 
the approximation error in some cases (for example, zdt3 function).

\section{Experimental Results}
\label{experiments}

\noindent
In this section, the results of full experiments on artificial 
functions will be shown and the proposed approach will be compared with other similar approaches 
on some applied problems of surrogate modeling.
Let use Dolan--More curves $P_k(a)$~\cite{DolanMore} for visualization of the results.
The quantity $P_k(a)$ shows on which fraction of the problems the errors of the 
considered approximation method~$k$ are not $a\geq 1$ higher than the minimal (among 
all considered methods) approximation error for the corresponding approximation problems.
{ %\looseness=1

}

\begin{figure*} %fig3
\vspace*{1pt}
 \begin{center}
 \mbox{%
 \epsfxsize=162.066mm
 \epsfbox{bel-3.eps}
 }
 \end{center}
 \vspace*{-9pt}
  \Caption{Results for artificial problems: (\textit{a})~median values (accuracy)
  and (\textit{b})~standard deviation (scatter) 
  (\textit{1}~--- standard algorithm;
  \textit{2}~--- extraction of Svalidation; \textit{3}~--- initialization of $\theta$;
  \textit{4}~--- extraction\;+\;initialization; \textit{5}~--- training algorithm;
and  \textit{6}~--- all proposed algorithms)}
  \label{dm_artificial_median}
  \vspace*{3pt}
\end{figure*}

\begin{table*}[b]\small
\vspace*{-6pt}
\begin{center}
  \Caption{Relative approximation error
  \label{sampleTable}}
  \vspace*{2ex}
  
     \begin{tabular}{cccccc}
      \hline
      \multicolumn{2}{c}{Problem} & Composite structure & Wing characteristics & Sand  & Concrete \\
      \hline
      \multicolumn{2}{c}{Dimension of $\vec x$}   &16 &78 &3  &8\\ 
      \hline
      \multicolumn{2}{c}{Sample size} &50000  &65000  &10000  &1030\\ \hline
              \multicolumn{2}{c}{Proposed approach}
              &{0.092}  &{0.159}    &{0.091} & 0.320\\ 
              \hline
      & Linear regression & 0.616   &0.330      &0.698  &  \hphantom{9}0.6391\\ 
%      \cline{2-6}
  \multicolumn{1}{c}{\raisebox{-6pt}[0pt][0pt]{MatLab}}     & Quadratic regression
                &0.390      &---      &0.608& 0.485  \\ 
 %               \cline{2-6}
      &ANN      &0.194  &0.258      & 0.132     & 0.350  \\ 
 %     \cline{2-6}
      &Radial basis function (RBF)  &0.336  &0.628      &0.464&     0.371   \\ 
      \hline
      &$k$-nearest neighbors     &0.597      &1.115      &0.470& 0.529   \\ 
%      \cline{2-6}
      &Anisotronic kriging
        &0.528  & --- & 0.813& 2.521  \\ 
       % \cline{2-6}
  mode    &Kriging      &0.382 &1.031   &0.937& 0.889  \\ 
  %    \cline{2-6}
Frontier     &RBF          &0.363&9.392        &0.494  &0.367  \\ 
  %\cline{2-6}
      &ANN
                &0.299      &1.424& 0.356& 0.730  \\ 
   %             \cline{2-6}
      &Gaussian process   
                &0.807      &---      &0.561 & 2.088  \\ 
                \hline
    \end{tabular}
  \end{center}
\end{table*}

\subsection{Artificial Functions}

\noindent
Using Dolan--More curves, let compare the standard algorithm with all algorithms from 
subsections~3.3 and~4.3 on all problems used for testing.
As a ``separate problem,'' let consider all independently generated samples, i.\,e., 
10~problems correspond to each function. Let 
use the following criteria of approximation quality: median of the errors (accuracy) 
and standard deviation of the errors (scatter of the errors). For each problem,
 let run each method $10$ times (the error for each run is estimated using 
 formula~(\ref{errorDef})) and estimate the accuracy and the scatter using results of these 
 runs.
 { %\looseness=1
 
 }



The results of comparison are given in 
Fig.~\ref{dm_artificial_median}.
One can see that the main contribution into accuracy is obtained 
due to the modified error function with the adaptive regularization, 
but the algorithms of the initialization step 
also significantly improve the accuracy of the methods (see curves for 
the methods~5 and~6).

\subsection{Real Applied Problems}

\noindent
Let compare approximation quality of the proposed method (combining 
all the proposed algorithms)
with widely-used methods for approximation construction.
There was used realization of such methods in MatLab and modeFrontier.
This software systems are used by many of industrial companies.
There are a number of methods for approximation construction, implemented in MatLab and 
modeFrontier,
namely, ANN, regression based on Gaussian Process, etc.
Note that many of these methods have serious 
restrictions on possible characteristics of the sample (input dimension~$d$ and sample 
size $N_{\mathrm{learning}}$) which, in turn, limits the applicability of the methods and,
as a consequence, reduces the accuracy of approximation. In most of the cases, such 
restrictions are due to algorithmic peculiarities of the corresponding realizations.
{\looseness=1

}

Let consider results on some indicative problems covering a wide range 
of sample sizes and input dimensions:
\begin{itemize}
  \item the strength of the composite structure of the aircraft fuselage~\cite{copti};
  \item aerodynamic characteristics of the aircraft wing~\cite{quadpal};
  \item structure of the sand in the field~\cite{icfault}; and
  \item concrete compressive strength~\cite{concrete}.
\end{itemize}
Reference results (of approximation algorithms from MatLab and modeFrontier)
were obtained in 2010 during the work on the PhD thesis.
The approximation quality was measured using error~(\ref{errorDef}), 
calculated using the independent test set~$S_{\mathrm{test}}$.
The results of the comparison are given in Table~\ref{sampleTable} 
  (few methods do not work for the problem of approximation of the aircraft
  wing aerodynamic characteristics due to high input dimensionality).
  {\looseness=-1
  
  }



\section{Concluding Remarks}

\noindent
The problem of approximation of a multidimensional dependency has been considered
based on a
linear expansion in a dictionary of parametric functions.
The new methods have been proposed for solving subproblems that arise in the framework 
of approximation construction problem.
Each of these methods as well as their combination significantly increases the
approximation quality compared to the approximation quality obtained using standard methods.
Using the proposed algorithm, it was possible to solve important applied problems, 
(see, for example,~\cite{copti}).

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{}
\begin{thebibliography}{99}


\bibitem{surrogateModeling} %1
\Au{Forrester A., Sobester A., Keane~A.}
    Engineering design via surrogate modelling. A~practical guide.~---
    Wiley, 2008.

\bibitem{kuleshov2} %2
\Au{Kuleshov A., Bernstein A.}
  Cognitive technologies in adaptive models of complex plants~//
  Keynote Papers of 13th IFAC Symposium on Information Control Problems in Manufacturing (INCOM'09),
   2009. P.~70--81.

\bibitem{elementsOfStatLearning} %3
\Au{Hastie T., Tibshirani R., Friedman~J.}
  The elements of statistical learning: Data mining, inference, and prediction.~---
  Springer, 2008.

\bibitem{copti} %4
\Au{Grihon S., Alestra~S., Burnaev~E., Prikhodko~P.}
 Optimization of composite structure based on surrogate modelling of
   buckling analysis~//
Information Technologies and Systems Conference Proceedings, 2012. P.~41--47.

\bibitem{petrushev} %5
\Au{Petrushev~P.} 
{Approximation by ridge functions and neural networks}~// 
SIAM J.~Math. Anal. 30, 1998. P.~155--189.

\bibitem{sigmoidApprox1} %6
\Au{Pinkus A.}
  Approximation theory of the MLP model in neural networks~//
  Acta Numerica, 1999. Vol.~8. P.~143--195.
  

\bibitem{vapnik} %7
\Au{Vapnik V.\,N., Chervonenkis A.\,Ja.} {Ordered risk minimization (I and~II)}~// 
Autom. Remote Control, 1974. Vol.~34. P.~1226--1235; 1403--1412.

\bibitem{Nocedal} %8
\Au{Nocedal J., Wright~S.}
Numerical optimization.~--- 2nd ed.~---
  Springer, 2006. P.~664.

\bibitem{LM} %9
  \Au{Marquardt D.\,W.}
  An algorithm for least-squares estimation of nonlinear parameters~//
  J.~SIAM, 1963. Vol.~11. No.\,2. P.~431--441.

\bibitem{CART} %10
\Au{Breiman L.}
  Classification and regression trees.~--- Wadsworth, 1984.

\bibitem{initNW} %11
\Au{Nguyen D., Widrow B.}
  Improving the learning speed of 2-layer neural networks by choosing
      initial values of the adaptive weights~//
  IJCNN  Joint Conference (International), 1990. P.~21--26.

\bibitem{initSCAWI} %12
\Au{Drago G., Ridella S.}
  Statistically controlled activation weight initialization (SCAWI)~//
  Trans. Neur. Netw., IEEE Press, 1992. Vol.~3. No.\,4. P.~627--631.

\bibitem{SpherRnd} %13
\Au{Rubinstein R.\,Y.}
  Generating random vectors uniformly distributed inside and on the surface of different regions~//
  Eur. J.~Oper. Res., 1982. Vol.~10. No.\,2. P.~205--209.
  
  \bibitem{itas11_Yerofeyev} %14
\Au{Belyaev M.\,G., Burnaev E.\,V., Erofeev~P.\,D., Prikhodko~P.\,V.}
  Comparison of the efficiency of the initialization methods for non-linear regression models~//
  Information Technologies and Systems Conference Proceedings, 2011. P.~315--320.

\bibitem{data1} %15
\Au{Hedar A.-R.}
    Global optimization test problems~//
    {\sf http://www-optima.amp.i.kyoto-u.ac.jp/member/\linebreak student/hedar/Hedar\_files/TestGO.htm}.

\bibitem{data2} %16
\Au{Molga M., Smutnicki~C.}
    {Test functions for optimization needs}~//
    {\sf www.zsd.ict.pwr.wroc.pl/files/docs/\linebreak functions.pdf}.


\bibitem{golub} %17
\Au{Golub G.\,H., Pereyra  V.}
  The differentiation of pseudo-inverses and nonlinear least squares
  problems whose variables separate~//
  SIAM J.~Numer. Anal., 1973. Vol.~10. P.~413--432.

\bibitem{ruhe}
\Au{Ruhe A., Wedin P.\,A.}
  Algorithms for separable nonlinear least squares problems~//
  SIAM Review, 1980. Vol.~22. No.\,3. P.~318--337.

\bibitem{demidenko}
\Au{Demidenko E.\,Z. }
  Linear and non-linear regression.~---
  Finance and stochastics. 1981.

\bibitem{itas11_Belyaev}
\Au{Belyaev M.\,G., Lyubin A.\,D.}
Peculiarities of the optimization problem, which arises when constructing approximation of multidimensional function~//
Information Technologies and Systems Conference Proceedings, 2011. P.~415--422.

\bibitem{bayesianLearning}
\Au{Foresee D., Hagan M.}
  Gauss-Newton approximation to Bayesian learning~//
Conference (International) on Neural Networks Proceedings, 1997. Vol.~3. P.~1930--1935.

\bibitem{oldRegul}
\Au{Belyaev M.\,G., Burnaev E.\,V.}
  Adaptive regularization in the problem of multidimensional functions approximation~//
Information Technologies and Systems Conference Proceedings, 2009. P.~431--435.

\bibitem{DolanMore}
\Au{Dolan~E., More~J.}
  {Benchmarking optimization software with performance profiles}~//
    Math. Programming, Ser.~A, 2002. Vol.~91. P.~201--213.
  
  \bibitem{quadpal}
\Au{Chervonenkis A.\,Ya., Chernova S.\,S., Zykova~T.\,V.}
Applications of kernel ridge estimation to the problem of computing 
the aerodynamical characteristics of a passenger plane (in comparison 
with results obtained with artificial neural networks)~//  Automation Remote Control,
2011. Vol.~72. Iss.~5. P.~1061-1067.

  \bibitem{icfault}
  IC Fault dataset. 
{\sf  imperial.ac.uk/earthscienceand\linebreak engineering/research/perm/icfaultmodel}.


  \bibitem{concrete}
  Concrete Compressive Strength dataset.
{\sf   archive.ics.uci. edu/ml/datasets}.

\end{thebibliography} } }

\end{multicols}

%\vspace*{6pt}

%\hrule

%\vspace*{6pt}

\def\tit{        
}

\def\aut{.\,.~$^1$, .\,.~$^2$}

\titelr{\tit}{\aut}

\vspace*{6pt}

\noindent
$^1$    ,  - \\
$\hphantom{^1}$( );  , belyaev@iitp.ru\\[1pt]
$^2$    ,  - \\
$\hphantom{^1}$( );  , burnaev@iitp.ru


\vspace*{6pt}


\Abst{       
 <<>>\,--\,<<   >>.       ,
       .
 ,    ,      :
  ,    ,
    .     
.           
     .} 

\label{end\stat}

\vspace*{-3pt}

\KW{ ;   } 



\renewcommand{\figurename}{\protect\bf .}
\renewcommand{\tablename}{\protect\bf }
\renewcommand{\bibname}{\protect\rmfamily }