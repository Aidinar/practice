\def\stat{klimenkov}

\def\tit{ПОСТРОЕНИЕ НОВОСТНОГО РЕКОМЕНДАТЕЛЬНОГО СЕРВИСА РЕАЛЬНОГО 
ВРЕМЕНИ С ИСПОЛЬЗОВАНИЕМ NoSQL СУБД$^*$}

\def\titkol{Построение новостного рекомендательного сервиса реального 
времени с использованием NoSQL СУБД}

\def\autkol{П.\,А.~Клеменков}

\def\aut{П.\,А.~Клеменков$^1$}

\titel{\tit}{\aut}{\autkol}{\titkol}

{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1] {Статья рекомендована к публикации в журнале Программным комитетом конференции <<Электронные 
библиотеки: перспективные методы и технологии, электронные коллекции>> (RCDL-2012).}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский государственный университет им.\ М.\,В.~Ломоносова, parser@cs.msu.su}


\Abst{Обсуждаются вопросы анализа взаимодействия пользователя с 
веб-при\-ло\-же\-ни\-ем, методы проведения подобного анализа и их 
недостатки. Приведена реализация новостного рекомендательного сервиса с 
использованием существующих подходов. Описан новый подход к 
построению рекомендательных сис\-тем, работающих в режиме, близком к 
режиму реального времени, с использованием NoSQL (not only structured query language)
сис\-те\-мы управ\-ле\-ния базами данных (СУБД).}

\KW{рекомендательные системы; minhash; mapreduce; NoSQL}

 \vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}


\section{Введение}

   Основным отличием приложений Веб~2.0 от их более старых аналогов 
является анализ взаимодействия пользователя с приложением и использование 
результатов этого анализа для модификации контента и его представления. 
Темпы развития сети Интернет диктуют создателям современных 
   веб-при\-ло\-же\-ний необходимость очень быстро адап\-ти\-ро\-вать контент под 
предпочтения пользователей. Наиболее востребованным решением этой задачи 
стали рекомендательные сис\-те\-мы, способные анализировать поведение 
пользователя, его склон\-ности и предлагать наиболее интересное наполнение. 
Проблема с подобными системами заключается в том, что они недостаточно 
быстро реагируют на постоянно изменяющийся поток входных данных. 
Особенно подвержены этому новостные ресурсы. Такое поведение связано не 
столько с алгоритмами, применяемыми для выявления пользовательских 
предпочтений, сколько с архитектурными особенностями той инфраструктуры 
и библиотек, которые широко используются для подобного анализа. В~данной 
статье представлен подход к организации новостного рекомендательного 
сервиса, призванного максимально устранить задержки в пересчете 
рекомендаций и обеспечить работу в режиме, близком к режиму реального 
времени.
   
\section{Методы веб-анализа}

   Сегодня для анализа взаимодействия пользователя с веб-при\-ло\-же\-ни\-ем 
применяются два основных подхода:
   \begin{enumerate}[(1)]
\item аналитика в реальном времени;
\item отложенная пакетная обработка логов доступа к веб-при\-ло\-же\-нию.
   \end{enumerate}
   
   У каждого из этих подходов есть преимущества и недостатки, на которых 
стоит остановиться подробнее.

\subsection{Аналитика в~реальном времени}

   Суть подхода заключается в том, что в ответ на взаимодействие пользователя 
с веб-при\-ло\-же\-ни\-ем специально установленный фрагмент кода (счетчик) 
генерирует определенные события, обрабатываемые при\-ло\-же\-ни\-ем-ана\-ли\-за\-то\-ром 
в реальном времени. Очевидно, что основным преимуществом 
подобной парадигмы является немедленное получение результатов и их 
обновление. Однако методы, применяемые при анализе данных в реальном 
времени, наиболее подходят для различных статистических расчетов (CTR, 
Churn Rate). При этом целые классы приложений не могут быть реализованы 
предложенными средствами.

\begin{figure*}[b] %fig1
\vspace*{1pt}
\begin{center}
 \mbox{%
 \epsfxsize=133.566mm
 \epsfbox{kle-1.eps}
 }
 \end{center}
 \vspace*{-6pt}
 \Caption{Схема работы Hadoop-реализации на первом~(\textit{а}) и на втором~(\textit{б}) этапах}
\end{figure*}
   
\subsection{Отложенная пакетная обработка логов доступа к веб-приложению}

   Этот подход строится на сборе логов доступа к веб-при\-ло\-же\-нию и их 
последующей обработке большими частями. Имея срез данных о 
взаимодействии пользователей с приложением за определенный период, 
возможно строить сложные модели поведения и применять их, например, для 
выдачи рекомендаций. Современные фреймворки (например, Apache Hadoop) 
обеспечивают высокую производительность, реализуя потоковую обработку 
больших объемов данных с использованием метода параллельных вычислений 
MapReduce~[1, 2].

\section{Рекомендательный сервис проекта Рамблер-новости}

   Рекомендательный сервис проекта Рамблер-но\-вости основывается на 
объединении пользователей в группы по схожести интересов и вычислении 
наиболее популярных среди групп новостей в заданном временном окне.

\subsection{Реализация сервиса}

   Суть алгоритма заключается в том, что все пользователи идентифицируются 
уникальными идентификаторами. Эти идентификаторы связываются
 с каждым 
HTTP-за\-про\-сом к новостным ресурсам (если, конечно, запрос содержал 
заголовок Cookie с корректным значением). Таким образом, поведение 
пользователя на сайте характеризуется подмножеством логов доступа к 
   веб-сер\-ве\-рам. Подсчитав схожесть каждого подмножества со всеми 
другими, можно объединить пользователей в группы с похожими 
предпочтениями.


   
   В качестве меры схожести множеств естественно использовать коэффициент 
Жаккарда. Однако проблема заключается в том, что время работы алгоритма 
подсчета этого коэффициента на нескольких миллионах множеств с сотнями и 
тысячами элементов являeтся неприемлемо большим. В~качестве оптимизации 
широко применяется вероятностный\linebreak алгоритм MinHash~[3]. Основная идея 
этого алгоритма заключается в вычислении вероятности равенства 
минимальных значений хеш-функ\-ций элементов множеств. Очевидно, что чем 
больше одинако\-вых элементов в двух срав\-ни\-ва\-емых множествах, тем выше 
указанная вероятность. А~так как вычисление сигнатуры множества 
(минимумов используемых хеш-функ\-ций) происходит только один
 раз, а 
размер сигнатуры фиксирован, то вычислительная сложность решаемой задачи 
резко снижается.


   
   Для вычисления новостных рекомендаций было принято решение 
производить обработку логов доступа веб-сер\-ве\-ров Рамб\-лер-но\-во\-стей во 
временн$\acute{\mbox{о}}$м окне 5~дней. Средний объем логов за указанный период составляет 
примерно 7~ГБ. Для реализации алгоритма был выбран фреймворк Hadoop, 
являющийся де-фак\-то стандартом для потоковой обработки больших объемов 
данных.



   Алгоритм вычисления рекомендаций был реализован в виде 
последовательности MapReduce-за\-дач, разделенных на два этапа: подсчет групп 
пользователей во временн$\acute{\mbox{о}}$м окне 5~сут.\ и подсчет рекоменда\-ций для групп 
во временн$\acute{\mbox{о}}$м окне 5~ч. Первый этап составляют следующие ступени (рис.~1,\,\textit{а}).
   \begin{enumerate}[1.]
\item Фильтрация логов во временн$\acute{\mbox{о}}$м окне 5~сут.\ и генерация множества 
уникальных URL (uniform resource locator)
для каж\-до\-го идентификатора пользователя.
\item Подсчет значений хеш-функ\-ций для всех уникальных URL каждого 
пользователя и вычисление минимума, который становится 
идентификатором группы.
\item Подсчет численности групп и отсечение \mbox{$\sim100$}~групп с 
наибольшей численностью. Необходимо заметить, что порог отсечения 
вычисляется статистически, поэтому имеет место небольшая дисперсия 
числа групп. Однако на производительность и поведение алгоритма это 
влияет незначительно.
\end{enumerate}


   Также необходимо отметить, что первоначальная реализация алгоритма 
имела еще один шаг, который позволял строго отсечь необходимое число 
групп, но ради сокращения вычислений им было решено пренебречь.
   
   Второй этап разделен на следующие ступени (рис.~1,\,\textit{б}).
   \begin{enumerate}[1.]
\item Фильтрация логов во временн$\acute{\mbox{о}}$м окне 5~ч и генерация множества 
уникальных URL для каж\-до\-го идентификатора пользователя.
\item Подсчет кликабельности новостей во всех группах.
\item Отсечение заданного числа наиболее популярных новостей в каж\-дой 
группе.
\end{enumerate}

   Получающиеся в результате отображения идентификаторов в группы и групп 
в популярные ново\-сти загружаются в хранилище Redis, поз\-во\-ля\-ющее 
запрашивать список рекомендаций для данного пользователя в реальном 
времени.

\subsection{Производительность}

   Приведенная реализация алгоритма использовалась в продуктивном 
окружении проекта Рамб\-лер-но\-во\-сти более полугода, показывая 
приемлемое время работы. На Hadoop-клас\-те\-ре из 8~узлов первая ступень 
обсчитывалась примерно 7~мин, а вторая~--- 3,5--4~мин при условии, что 
другие задачи не выполнялись параллельно. Необходимо отметить, что важным 
фактором производительности MapReduce-за\-дач является верный выбор 
количества мапперов и редьюсеров. Выбор количества мапперов производился 
автоматически. Экспериментальным путем было выяснено, что оптимальное 
число редьюсеров в данной конфигурации~---~16.

\subsection{Проблемы}

   Внимательно изучив получившуюся архитектуру и приняв во внимание 
проблемы, возникшие при реализации рекомендательного сервиса, можно 
отметить следующие аспекты.
   \begin{enumerate}[1.]
\item Загрузка логов в HDFS (Hadoop Distributed File System) и их 
обработка~--- две не связанные задачи. В~данном случае синхронизация 
логов выполнялась с помощью утилиты {\sf rsync}, а вы\-чис\-ле\-ние разности между 
файлами в директории синхронизации и файлами в HDFS, а также загрузка 
новых файлов~--- с помощью специально написанного Makefile и 
shell-скрип\-тов.
\item В Hadoop отсутствует возможность получать \mbox{данные} из разных 
источников. В частности, резуль\-та\-ты работы первого этапа алгоритма 
приходилось передавать в окружение второй ступени второго этапа в виде 
файла в кеше Hadoop. Вследствие того что этот файл может иметь весьма 
внушительный размер, MapReduce-за\-да\-чи на всех узлах могут 
столкнуться с проблемой нехватки памяти.
\item Задачи подсчета рекомендаций и их использования также не являются 
связанными и выполняются разными инструментами. В~данном случае~--- 
Hadoop и Redis.
\item Ну и самое главное~--- пакетный потоковый режим работы Hadoop не 
позволяет хоть сколь\-ко-ни\-будь приблизиться к реальному времени 
пересчета результатов.
   \end{enumerate}
   
   Отсюда возникает вопрос: можно ли решить все вышеперечисленные 
проблемы, воспользовавшись другим подходом? В~следующей части статьи 
будет описана архитектура подобного решения с применением 
   NoSQL-хра\-ни\-лищ данных.
   
\section{Введение в~NoSQL}

   Термин NoSQL впервые был использован в 1998~г.\ для описания 
реляционной базы данных, не использовавшей SQL. Он был вновь подхвачен в 
2009~г.\ и использован на конференциях приверженцами нереляционных баз 
данных. Основной движущей силой развития NoSQL-хра\-ни\-лищ стали 
   веб-стартапы, для которых важнейшей задачей является поддержание 
постоянной высокой пропускной способности хранилища при неограниченном 
увеличении объема данных. Рассмотрим основные особенности 
   NoSQL-под\-хо\-да, делающие его таким привлекательным для 
высоконагруженных веб-про\-ек\-тов~[4,~5].
   \begin{enumerate}[1.]
\item \textbf{Исключение излишнего усложнения.} Реляционные базы 
данных выполняют огромное множество различных функций и 
обеспечивают строгую консистентность данных. Однако для многих 
приложений подобный набор функций, а также удовлетворение требованиям 
ACID (atomicity, consistency, isolation, durability)
являются излишними.
\item \textbf{Высокая пропускная способность.} Многие 
NoSQL-ре\-ше\-ния обеспечивают гораздо более высокую пропускную 
способность данных, нежели традиционные СУБД. Например, колоночное 
хранилище Hypertable, реализующее подход Google Bigtable, позволяет 
поисковому движку Zvent сохранять около миллиарда записей в день. 
В~качестве другого примера можно привести саму Bigtable~[6], способную 
обработать 20~ПБ информации в день.
\item \textbf{Неограниченное горизонтальное масштабирование.} 
В~противовес реляционным СУБД, NoSQL-ре\-ше\-ния проектируются для 
неограниченного горизонтального масштабирования. При этом добавление и 
удаление узлов в кластере никак не сказывается на работоспособности и 
производительности всей системы. Дополнительным преимуществом 
подобной архитектуры является то, что NoSQL-клас\-тер может быть 
развернут на обычном аппаратном обеспечении, существенно снижая 
стоимость всей системы.
\item \textbf{Консистентность в угоду производительности.} При 
описании подхода NoSQL нельзя не упомянуть теорему CAP (consistency,
availability, partition tolerance). Согласно этой 
теореме, многие NoSQL-хра\-ни\-ли\-ща реализуют доступность данных 
(availability) и устойчивость к разделению (partition tolerance), жертвуя 
консистентностью в угоду высокой производительности. И~действительно, 
для многих классов приложений строгая консистентность данных~--- это то, 
от чего вполне можно отказаться.
\end{enumerate}

\section{Классификация NoSQL-хранилищ}

   На сегодняшний день создано большое число NoSQL-хра\-ни\-лищ. Все они 
основываются на четырех принципах из предыдущего раздела, но могут 
довольно сильно отличаться друг от друга. Многие теоретики и практики 
создавали свои собственные классификации, но наиболее простой и 
общеупотребительной можно считать сис\-те\-му, основанную на используемой 
модели данных, предложенную Риком Кейтелем (см.\ табл.)~[7].

\begin{center}  %табл
{\small{Классификация NoSQL-хранилищ по модели данных}}

\vspace*{6pt}

{\small
\tabcolsep=11pt
\begin{tabular}{|l|l|}
\hline
\multicolumn{1}{|c|}{Тип}&\multicolumn{1}{c|}{Примеры}\\
\hline
Хранилища ключ--значение&\tabcolsep=0pt\begin{tabular}{l}Redis\\
Scalaris\\
Tokio Tyrant\\
Voldemort\\
Riak\end{tabular}\\
\hline
\tabcolsep=0pt\begin{tabular}{l}Документно-ориентированные\\ хранилища\end{tabular}&
\tabcolsep=0pt\begin{tabular}{l}SimpleDB\\
CouchDB\\
MongoDB
\end{tabular}\\
\hline
Колоночные хранилища&\tabcolsep=0pt\begin{tabular}{l}Bigtable\\
HBase\\
HyperTable\\
Cassandra\end{tabular}\\
\hline
Хранилища на графах&Neo4j\\
\hline
\end{tabular}}
\end{center}

\noindent
   \begin{enumerate}[1.]
\item \textbf{Хранилища ключ--значение.} Отличительной особенностью 
является простая модель данных~--- ассоциативный массив или словарь, 
поз\-во\-ля\-ющий работать с данными по ключу. \mbox{Основная} \mbox{задача} подобных 
хранилищ~--- максимальная производительность, поэтому никакая 
информации о структуре значений не сохраняется.
\item \textbf{Документно-ориен\-ти\-ро\-ван\-ные хранилища.} Модель 
данных подобных хранилищ позволяет объединять множество пар 
ключ--зна\-че\-ние в абстракцию, называемую <<документ>>. Документы 
могут иметь вложенную структуру и объединяться в коллекции. Однако это 
скорее удобный способ логического объединения, так как никакой жесткой 
схемы у документов нет и множества пар ключ--зна\-че\-ние даже в рамках 
одной коллекции могут быть абсолютно произвольными. Работа с 
документами производится по ключу, однако существуют решения, 
позволяющие осуществлять запросы по значениям атрибутов.
\item \textbf{Колоночные хранилища.} Этот тип кажется наиболее схожим 
с традиционными реляционными СУБД. Модель данных в хранилищах 
подобного типа подразумевает хранение значений как неинтерпретируемых 
байтовых массивов, адресуемых кортежами $\langle$ключ строки, ключ 
столбца, метка времени$\rangle$. Основой модели данных служит колонка, 
число колонок для одной таблицы может быть неограниченным. Колонки по 
ключам объединяются в семейства, обладающие определенным набором 
свойств.
\item \textbf{Хранилища на графах.} Подобные хранилища применяются 
для работы с данными, которые естественным образом представляются 
графами (например, социальная сеть). Модель данных состоит из вершин, 
ребер и свойств. Работа с данными осуществляется путем обхода графа по 
ребрам с заданными свойствами.
\end{enumerate}





\section{Построение рекомендательного сервиса Рамблер-новостей 
с~помощью NoSQL}
   
   Вспоминая недостатки реализации рекомендательного сервиса на 
фреймворке Hadoop, можно отметить, что NoSQL-хра\-ни\-ли\-ща кажутся 
приемлемым вариантом их устранения. NoSQL-хра\-ни\-ли\-ща обеспечивают 
высокую пропускную способность данных как при чтении, так и при записи. Из 
этого следует, что логи доступа к веб-при\-ло\-же\-нию можно записывать 
непосредственно в базу данных. Важно также отметить, что при использовании 
до\-ку\-мент\-но-ориен\-ти\-ро\-ван\-ных решений логам можно придавать 
произвольный вид, не создавая жесткую схему. Это позволяет решать довольно 
интересную задачу хранения и обработки структурированных логов. К~тому же 
механизм выборки документов по значениям атрибутов позволяет решать 
множество аналитических задач.
   
   Большинство современных NoSQL-ре\-ше\-ний ре\-а\-ли\-зу\-ют парадигму 
вычислений MapReduсe. Наря\-ду с фундаментальным свойством 
горизон\-таль\-но\-го масштабирования это дает \mbox{возможность} переносить 
алгоритмы, предназначенные для фреймворков типа Hadoop, на хранилища 
NoSQL, получая все дополнительные преимущества.
   
   Учитывая высокую пропускную способность операций чтения, задачи 
подсчета рекомендаций и их использования можно не разделять. 
Следовательно, обновленные рекомендации будут тут же доступны 
потребителям, что приближает сервис к требованиям реального времени.
   
   Далее следовало определиться с конкретным продуктом, который можно 
было бы использовать для реализации сервиса. Среди 
   до\-ку\-мент\-но-ориен\-ти\-ро\-ван\-ных баз данных первоначальный выбор 
пал на проект Apache CouchDB~\cite{8-kli}. CouchDB работает с документами, 
представленными в формате JSON (JavaScript Object Notation). Для работы с документами предоставляется 
REST API (REpresentation State Transfer Application Programming Interface). 
Для построения запросов к документам CouchDB и их анализа 
применяются так называемые <<представления>>. По сути представление 
является обычной MapReduce-за\-да\-чей, которая может сохранять результаты 
выполнения в базе. Интересной особенностью модели данных CouchDB 
является то, что для индексации документов и представлений используются 
модифицированные B-де\-ревья. Сохраняя все особенности и преимущества 
стандартного B-де\-ре\-ва, B-де\-ревья CouchDB реализуют режим <<только 
добавление>>. Это означает, что любые операции вставки, модификации и 
изменения записываются в конец файла, представляющего B-де\-ре\-во на 
диске. Такая архитектура дает два основных преимущества: высокую ско\-рость 
записи и возможность исполнять MapReduce-за\-да\-чи только на 
изменившихся данных. Однако при всех своих преимуществах CouchDB не 
подходила для решения поставленной задачи. Во-пер\-вых, проект не 
поддерживает никакого языка запросов, что сильно затрудняет выборку 
документов по определенным критериям. Во-вто\-рых, важным критерием 
выбора была поддержка ссылок на другие документы. Подобная возможность 
есть в CouchDB, но работает она только на этапе эмиссии документа из 
   map-за\-да\-чи. К~тому же нет возможности создания ссылок на документы 
из других баз. В-третьих, неоптимизированное JSON-представление 
документов приводит к увеличению трафика между клиентом и хранилищем, 
чего хотелось избежать.
 Окончательный выбор пал на проект MongoDB~\cite{9-kli}. Обладая всеми 
преимуществами CouchDB, это хранилище устраняет перечисленные 
недостатки и предоставляет дополнительные удобные возможности. Они будут 
упомянуты в следующем разделе, опи\-сы\-ва\-ющем реализацию 
рекомендательного сервиса.

\section{Реализация рекомендательного сервиса Рамблер-новости}
   
   Первая задача, которую предстояло решить,~--- это запись логов в базу 
данных MongoDB. Первым делом требовалось определить, какое число 
операций записи в секунду обеспечивала выбранная конфигурация. Стоит 
отметить, что тестовая конфигурация представляла собой кластер из двух 
узлов, на каждом их которых был запущен демон {\sf mongod} без репликации. На 
одном их хостов запускался демон mongos, обеспечивавший шардинг 
документов. Для определения скорости записи был разработан простой скрипт, 
производивший загрузку суточных логов новостей в базу MongoDB. Лог 
состоял из 2\,770\,695~записей. Среднее время записи составило 18~мин 
30~с. Таким образом, средняя скорость записи в представленной 
конфигурации~--- 2496~операций/с. Шардинг документов осуществлялся по 
атрибуту {\sf ruid} (уникальный идентификатор пользователя). Подобный результат 
более чем достаточен для рассматриваемого сервиса, так как среднее 
количество запросов в секунду к веб-сай\-ту Рамб\-лер-но\-вости существенно 
меньше. Однако загрузка логов из ротированных лог-фай\-лов разработчика не 
устраивала. Для удовлетворения требования реального времени необходимо 
было обеспечить загрузку логов в базу сразу после обработки запроса 
   веб-сер\-ве\-ром. Для этого с помощью библиотеки ZeroMQ был разработан 
специализированный демон, агрегировавший логи с нескольких фронт-эндов 
новостей в хранилище MongoDB. 

Необходимо отметить, что загрузчик логов не 
только производил их фильтрацию, представление в формате BSON (Binary JavaScript
Object Notation) и запись в 
базу, но и подсчет значений хеш-функ\-ций для каждого URL. Это было 
обусловлено двумя факторами: снижением времени вычислений и отсутствием 
приемлемых реализаций быстрого хеширования в языке JavaScript (на нем 
реализуются MapReduce задачи в MongoDB).
   
   После того как задача загрузки логов была решена, необходимо было 
перенести реализацию алгоритма подсчета рекомендаций с Hadoop на 
MongoDB. Возвращаясь к реализации первого этапа в под\-разд.~3.1, можно 
отметить, что задачи фильтрации логов и подсчета значений хеш-функ\-ций для 
них реализуются загрузчиком. Поэтому оставалось перенести только подсчет 
минимальных значений хешей и отсечение групп с заданной численностью 
(рис.~2).

   Стоит обратить внимание на то, что из новой реализации пропал этап 
отсечения групп по численности. В первоначальной реализации отсечение 
делалось главным образом для сокращения времени загрузки отображения 
$\langle$идентификатор\ пользователя\;$\rightarrow$\;группа$\rangle$ в Redis. При использовании NoSQL-хра\-ни\-ли\-ща 
подобной проблемы не возникало.
   
   Возвращаясь к цифрам, отметим, что задача подсчета минимального хеша 
для суточных логов (2\,770\,695~записей) заняла примерно 3~мин 
10~с. Это не сильно отличается от времени выполнения той же задачи на 
Hadoop-клас\-те\-ре, и почему это\linebreak\vspace*{-12pt}

\begin{center}  %fig2
\vspace*{-3pt}
 \mbox{%
 \epsfxsize=80mm %1.356mm
 \epsfbox{kle-3.eps}
 }
 \end{center}
% \vspace*{6pt}
{{\figurename~2}\ \ \small{Схема работы NoSQL-реализации на первом~(\textit{а}) и на втором~(\textit{б}) этапах}}


%\pagebreak

\vspace*{15pt}

\addtocounter{figure}{1}

\noindent
 происходит, вполне очевидно. Однако здесь 
на помощь приходит вся мощь MongoDB. Во-пер\-вых, результаты 
   MapReduce-за\-дач сохраняются в отдельной коллекции. Последующие 
вычисления можно производить только на добавленных с прошлого запуска 
логах, выполняя rereduce на получившихся результатах. Во-вто\-рых, мощный 
язык запросов MongoDB позволяет осуществить выборку логов, добавленных с 
момента последнего запуска задачи. В~предлагаемой архитектуре задача 
сохранения времени последнего выполнения и перезапуск вы\-чис\-ле\-ний 
возложена на загрузчик логов. Важно отметить, что высокая 
производительность библиотеки ZeroMQ позволила не масштабировать 
загрузчик логов, поэтому проблем с синхронизацией времени не возникало. 
   В-третьих, MongoDB поддерживает создание и поддержание индексов на 
атрибутах документов, что существенно ускоряет выборки. На основании всего 
вышесказанного было принято решение перезапускать задачу подсчета 
минимального хеша после записи одной тысячи новых логов с выборкой по 
атрибуту {\sf timestamp} документа. Данная задача без индекса завершалась в 
среднем через 3~с, а с индексом~--- через 400--500~мс, что уже существенно 
приблизило разработку к требованиям реального времени.
   
   Теперь перейдем ко второму этапу алгоритма~--- выработке рекомендаций
   (рис.~2,\,\textit{б}). 
Здесь возникают три основные проблемы: выборка логов в заданном 
временн$\acute{\mbox{о}}$м окне, дополнительная фильтрация и ввод данных из нескольких 
источников. Выборку логов в заданном временном окне можно, как и на первом 
этапе, осуществлять запросом по атрибуту {\sf timestamp}. Стоит отметить, что 
MongoDB реализует capped collections. Это коллекции с заранее определенным 
объемом. Если объем коллекции достиг заданного порога, то новые значения 
затирают старые. Это интересный подход к ротации, но для рассматриваемой 
задачи он не подходит, так как количество логов может меняться
день ото дня. Дополнительная фильтрация осуществляется регулярными 
выражениями JavaScript, здесь нет никаких сложностей. Проблема ввода 
данных из нескольких источников решается с помощью механизма DBRef 
MongoDB. Он позволяет создавать ссылки на связанные документы в виде 
вложенных документов и получать к ним доступ при выполнении map-за\-дач. 
Удобная особенность DBRef следует из отсутствия схемы документов и других 
ограничений~--- ссылаться можно на несуществующие документы и коллекции. 
Этим фактом пользуется загрузчик логов, создавая ссылки на группы, которых 
еще нет. 

Таким образом, первые две ступени второго \mbox{этапа} удалось объединить 
в одну: map-за\-да\-ча фильтрует выборку логов во временн$\acute{\mbox{о}}$м окне 5~ч и 
возвращает пару $\langle\mathrm{group}\_\mathrm{id:url}, \mathrm{1}\rangle$, а 
reduce-за\-да\-ча подсчитывает количество кликов по каждой новости всех 
групп. Среднее время выполнения этой ступени~--- 350~мс на той же тысяче 
логов. Третья ступень была прос\-то адаптирована для исполнения MongoDB. 
Надо, правда, отметить, что отсечение заданного количества популярных 
новостей не производится. Эту задачу с целью сокращения объема вычислений 
было решено возложить на потребителя. Также следует сказать, что на 
последней ступени используется функция {\sf finalize}, позволяющая видоизменить 
результаты reduce-за\-да\-чи. В~данном случае функция {\sf finalize} производит 
сортировку новостей в группах по числу кликов.


\section{Проблемы, возникшие при~реализации сервиса 
рекомендаций}

   Естественно, при реализации сервиса возник определенный набор 
трудностей, о которых важно упомянуть. Первая трудность~--- ротирование 
логов. Так как в MongoDB отсутствует механизм времени жизни ключей, 
задачу ротирования логов приходится решать периодическим запуском 
отдельной MapReduce-за\-да\-чи. К~тому же во всех документах, тре\-бу\-ющих 
удаления, приходится явно хранить метку времени жизни. Вторая труд\-ность 
заключается в том, что формат возвращаемых map-задачей значений должен 
совпадать с форматом значений, возвращаемых reduce-за\-да\-чей. Из-за этого 
приходится создавать довольно сложные структуры, чего хотелось бы 
избежать. Третья труд\-ность~--- это специфическое устройство шардинга в 
MongoDB. Ключи распределяются по узлам не равномерно, а группами. Из-за 
этого некоторые MapReduce-за\-да\-чи на небольшом числе документов 
выполняются на одном узле, содержащем все ключи.

\section{Заключение}

   В результате проведенного эксперимента удалось создать рекомендательный 
сервис, время пересчета рекомендаций в котором на каждую тысячу новых 
логов составляет 1,5--2~с. Для проекта Рамб\-лер-но\-вос\-ти подобный 
результат является удовлетворительным, так как 1000~новых запросов к сайту 
делается за чуть большее время. Стоит отметить, что алгоритм MinHash как 
таковой не предназначен для подсчета рекомендаций в режиме реального 
времени. Более того, эффективность новой реализации рекомендательного 
сервиса может оказаться ниже, чем предыдущая реализация с по\-мощью 
фреймворка Hadoop. Однако целью данной работы было показать 
целесообразность применения NoSQL-под\-хо\-да к построению сис\-тем 
анализа данных в режиме, близком к режиму реального времени. Сделанные 
выводы позволят реализовать на описанной платформе более подходящие 
рекомендательные алгоритмы, например Covisitation~\cite{5-kli}. Важным 
свойством приведенной реализации является то, что задачи хранения и анализа 
данных удалось объединить с задачей предоставления доступа к результатам в 
единой системе, избежав накладных расходов на перемещение данных из 
одного источника в другой и улучшив общую производительность сервиса. 
Кроме того, предложенный подход упрощает решение повседневных задач 
сбора статистики о взаимодействии пользователя с веб-при\-ло\-же\-ни\-ем 
путем анализа структурированных логов мощным языком запросов СУБД 
MongoDB. Можно утверждать, что применение NoSQL-под\-хо\-да к решению 
подобного класса задач весьма перспективно и может быть использовано в 
продуктивном окружении высоконагруженных веб-при\-ло\-жений.

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{9}

\bibitem{1-kli}
\Au{Dean J., Ghemawat S.} MapReduce: Simplified data processing on large 
clusters~// OSDI'04:  6th Symposium on Operating System Design and 
Implementation Proceedings.~--- Berkeley, CA, USA: USENIX Association, 
2004. P.~137--149.
\bibitem{2-kli}
\Au{Venner J.} Pro Hadoop.~--- N.Y.: Apress, 2009.
\bibitem{3-kli}
\Au{Das A.\,S., Datar M., Garg~A., Rajaram~Sh.} Google news personalization: 
Scalable online collaborative filtering~// 16th Conference (International) on World 
Wide Web Proceedings, 2007. P.~271--280.
\bibitem{4-kli}
\Au{Pokorny J.} NoSQL databases: A~step to database scalability in web 
environment~//  13th Conference (International) on Information Integration and 
Web-Based Applications and Services Proceedings, 2011. P.~278--283.
\bibitem{5-kli}
\Au{Strauch C.} NoSQL databases. {\sf http://www.christof-strauch.de/nosqldbs.pdf}.
\bibitem{6-kli}
\Au{Chang F., Dean J., Ghemawat~S., Hsieh~W.\,C., Wallach~D.\,A., 
Burrows~M., Chandra~T., Fikes~A., Gruber~R.\,E.} Bigtable: A~distributed 
storage system for structured data~//  7th USENIX Symposium on Operating 
Systems Design and Implementation Proceedings.~--- Berkeley, CA, USA: 
USENIX Association, 2006. Vol.~7. P.~205--218.
\bibitem{7-kli}
\Au{Cattel R.} Scalable SQL and NoSQL data stores~// ACM SIGMOD Record, 
2010. Vol.~39. No.\,4. P.~12--27.


\bibitem{8-kli}
\Au{Anderson J.\,C., Lehnardt~J., Slater~N.} CouchDB: The definitive guide.~--- 
Sebastopol: O'Reilly Media, 2010.

\label{end\stat}


\bibitem{9-kli}
\Au{Chodorow K., Dirolf~M.} MongoDB: The definitive guide.~--- Sebastopol: 
O'Reilly Media, 2010. 
\end{thebibliography}
} }

\end{multicols}