\def\stat{torshin}

\def\tit{О ЗАДАЧАХ ОПТИМИЗАЦИИ, ВОЗНИКАЮЩИХ ПРИ~ПРИМЕНЕНИИ 
ТОПОЛОГИЧЕСКОГО АНАЛИЗА ДАННЫХ К~ПОИСКУ АЛГОРИТМОВ 
ПРОГНОЗИРОВАНИЯ С~ФИКСИРОВАННЫМИ КОРРЕКТОРАМИ$^*$}

\def\titkol{О задачах оптимизации, возникающих при~применении 
топологического анализа данных к~поиску алгоритмов} 
%прогнозирования с~фиксированными корректорами}

\def\aut{И.\,Ю.~Торшин$^1$}

\def\autkol{И.\,Ю.~Торшин}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Торшин И.\,Ю.}
\index{Torshin I.\,Yu.}


{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Работа выполнена при поддержке гранта РНФ (проект №\,23-21-00154) с~использованием инфраструктуры 
Центра коллективного пользования <<Высокопроизводительные вычисления и~большие данные>> (ЦКП 
<<Информатика>>) ФИЦ ИУ РАН (г.~Москва).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{tiy135@yahoo.com}}

\vspace*{6pt}


 

\Abst{Корректирующие операции (корректоры) в~мультиалгоритмических конструкциях 
алгебраического подхода могут строиться на основе известных физических моделей и/или 
многоуровневых описаний физических объектов. В~рамках топологического подхода 
к~анализу плохо формализованных задач поиск включаемых в~корректор алгоритмов может 
рассматриваться как задача комбинаторной оптимизации либо как задача минимизации 
некой функции потерь. Исследование окрестностей цепей в~решетке подмножеств объектов 
позволило получить ряд критериев ранговой оптимизации, перспективных для решения 
задач прогнозирования числовых таргетных переменных. Формализм апробирован на задаче 
взаимодействия лиганд--рецептор в~рамках хемокиномного анализа лекарств (данные 
\mbox{ProteomicsDB}). Наилучшие результаты прогнозирования констант EC$_{50}$ наблюдались 
именно при использовании полученных ранговых критериев: при усреднении по 
300~биологическим активностям коэффициент корреляции на контроле составил 
$0{,}86\pm0{,}20$.}

\KW{топологический анализ данных; теория решеток; задачи оптимизации; регрессия; 
хемоинформатика}


\DOI{10.14357/19922264230201}{IGSPEW}
  
\vspace*{6pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}

\section{Введение}

    В рамках алгебраического подхода исследуются конструкции вида 
$\hat{{A}}_{(\theta_A)} \hm= \hat{{D}}_{(\theta_D)} \circ 
\hat{{C}}_{(\theta_C)}\circ \hat{{B}}_{(\theta_B)}$, где 
$\hat{{B}}$~--- распознающий оператор; $\hat{C}$~--- 
корректирующая операция (корректор); $\hat{D}$~--- решающее 
правило; $\theta_D$, $\theta_C$, $\theta_B$ и~$\theta_A\hm= (\theta_D, \theta_C, 
\theta_B)$~--- векторы параметров~[1]. 
Алгоритмы~$\hat{{A}}_{(\theta_A)}$ применяются к~входной 
\textit{матрице информации} ${M}_{\mathrm{вх}}$ для получения 
выходной \textit{информационной матрицы} ${M}_{\mathrm{вых}}$, 
причем в~случае корректного алгоритма ${M}_{\mathrm{вых}}\hm= 
\hat{{A}}_{(\theta_A)} {M}_{\mathrm{вх}}$. Обуче\-ние 
алгоритма по множеству прецедентов $Q\hm= 
({M}_{\mathrm{вх}},{M}_{\mathrm{вых}})$ рас\-смат\-ри\-ва\-ет\-ся 
как способ вычисления вектора $\theta_A(Q)$. Алгоритм, обучен\-ный по $Q$, 
$\varepsilon$-\textit{кор\-рек\-тен относительно контрольного} $Q^\prime \hm= 
({M}^\prime_{\mathrm{вх}}, {M}_{\mathrm{вых}}^\prime)$, 
если $L({M}^\prime_{\mathrm{вых}}, \hat{{A}}_{(\theta_A(Q))} 
{M}^\prime_{\mathrm{вх}})\hm\leq \varepsilon$, где $L$~--- та или иная 
функция потерь. Для оценки обоб\-ща\-ющей спо\-соб\-ности используются 
разнообразные комбинаторные функционалы~[2, 3].

     Важным направлением исследований в~научной школе  
Ю.\,И.~Журавлёва\,--\,К.\,В.~Рудакова стало изучение разрешимости 
и~регулярности задач, где множества прецедентов $Q \hm\subset I_i \times I_f$ 
определены над множествами \textit{начальных} ($I_i$) и~\textit{конечных 
информаций} ($I_f$)~[4]. При поиске $\varepsilon$-кор\-рект\-ных алгоритмов 
$\hat{{A}}_{(\theta_A)}$ для решения разрешимых задач утверждается 
возможность настройки векторов~$\theta_C$ и~$\theta_B$ с~получением  
$\varepsilon$-кор\-рект\-но\-го алгоритма при 
произвольном~$\hat{{D}}_{(\theta_D)}$~[1]. 
     
     В некоторых задачах возможна фиксация корректора $\hat{{C}}$ в~соответствии с~проблемной областью. Например, в~физической химии и~в 
биохимии для описания взаимодействия ли\-ганд--ре\-цеп\-тор используется 
уравнение Хил\-ла--Ленг\-мю\-ра, в~котором фигурирует концентрация 
лиганда~$C$:
     \begin{equation}
     \fr{E_{\max}}{E(C)} =1+\left( \fr{\mathrm{EC}_{50}}{C}\right)^s,
\label{e1-t}
\end{equation}
где $E$~--- измеряемое в~эксперименте значение отклика, оценивающего 
связывание (например, интенсивность свечения флуоресцентной метки);\linebreak 
$E_{\max}$~--- максимальное значение отклика, EC$_{50}$~--- константа 
процесса (концентрация вещества,\linebreak вызывающая 50\% от максимального 
отклика, т.\,е.\ точка перегиба $S$-образ\-ной кривой $E(C)$).
Выражение~(\ref{e1-t})~--- термодинамическое описание равновесного 
связывания лиганда~$L$ рецептором~$R$ в~соответствии с~уравнением 
квазихимической реакции 
$$
R+ nL\leftrightarrow RL_n.
$$
Приведение~(\ref{e1-t}) к~виду
\begin{equation*}
\ln \left( \fr{E_{\max}}{E(C)}-1 \right) = -s \ln(C) +s \ln (\mathrm{EC}_{50}),
%\label{e1.1-t}
\end{equation*}
где
 $s$~--- 
коэффициент Хилла (угол наклона касательной в~точке~EC$_{50}$),  
указывает на возможность линейной аппроксимации вида 
$$
y_i(x_i)= bx_i+a\,,\enskip b= -s\,,\enskip a= s\ln (\mathrm{EC}_{50}),
$$
 что позволяет вычислять 
значения констант EC$_{50}$ и~$s$ для~$n_e$ экспериментальных точек 
(например, методом наименьших квадратов):
\begin{align*}
b&= \fr{n_e\sum\nolimits_{i=1}^{n_e} y_i x_i -\sum\nolimits_{i=1}^{n_e} y_i 
\sum\nolimits_{i=1}^{n_e} x_i}{n_e \sum\nolimits_{i=1}^{n_e} x_i^2 -\left( 
\sum\nolimits_{i=1}^{n_e} x_i\right)^2}\,;\\
a&=\fr{1}{n}\left( \sum\limits_{i=1}^{n_e} y_i -b\sum\limits_{i=1}^{n_e} 
x_i\right).
%\label{e2-t}
\end{align*}
    
Предположим, что молекулы лигандов заданы в~виде множества 
хемогр$\acute{\mbox{а}}$фов $\{G_j\}$, $j\hm= 1,\ldots ,N$, а~для набора 
концентраций $\{C_i\}$, $i\hm= 1,\ldots,n_e$, из фи\-зи\-ко-хи\-ми\-че\-ских 
экспериментов получены значения $E_j(C_i)$ и~вычислены значения констант 
EC$_{50}(j)$. Если для такого набора данных можно построить алгоритмы 
хемометрического анализа~[5, 6], которые на основании~$G_j$ позволяют 
прогнозировать $E_j(C_i)$, то выражение~(\ref{e1-t}) может быть использовано 
как фиксированный <<физический>> корректор $\hat{{C}}$ алгоритма 
$\hat{{A}}$ при ${D}\hm\equiv 1$. Для реализации этого 
<<имитационного>> алгоритма прогнозирования необходимо построить 
$\varepsilon$-кор\-рект\-ные распознающие операторы 
$\hat{{B}}_{(\theta_{B_i}),i}$, $\vert E_j(C_i)\hm- 
\hat{{B}}_{(\theta_{B_i}),i}   G_j \vert \hm\leq \varepsilon$~[5].
     
     Схема порождения алгоритма $\hat{{A}} \hm= 
\hat{{D}}\circ \hat{{C}}\circ \hat{{B}}$\linebreak может 
использоваться не только для решения <<финальных>> задач 
$Z({M}_{\mathrm{вх}},{M}_{\mathrm{вых}})$, но и~для 
важных промежуточных задач, таких как порождение более информативных 
<<синтетических>> признаковых \mbox{описаний} объектов (например, вида 
$\hat{{B}}_{(\theta_{B_i}),i}G_j)$. В~результате получаются 
вложенные алгоритмические структуры, которые могут описываться 
алгоритмами $\alpha$-го уровня: 
$$
\hat{{A}}^{(\alpha)}_{(\theta^\alpha_A)} \hm= 
\hat{{D}}^{(\alpha)}_{(\theta^\alpha_D)} \circ 
\hat{{C}}^{(\alpha)}_{(\theta^\alpha_C)} \circ
     \hat{{B}}^{(\alpha)}_{(\theta^\alpha_B)}.
     $$
      Построение 
операторов $\hat{{B}}_{(\theta_{B_i}),i}$, 
$\hat{{B}}^{(\alpha}_{(\theta^\alpha_B)}$, 
$\hat{{C}}^{(\alpha)}_{(\theta_C^\alpha)}$ и~др.\ целесообразно 
осуществлять в~рамках топологического подхода к~анализу данных~[4, 7]. 

\section{Исследование окрестностей цепей в~решетке подмножеств 
объектов}
 
     В рамках топологического подхода алгоритм прогнозирования $k$-й 
таргетной переменной (например, представленный распознающим оператором 
вида $\hat{{B}}_{(\theta_{B_k}),k}$) находится в~результате перебора 
цепей решетки в~окрестности цепи, заданной $k$-й переменной~[5], который 
может рассматриваться (1)~как задача комбинаторной оптимизации (поиск 
множеств, формирующих соответствующую цепь решетки) или (2)~задача 
минимизации того или иного функционала или <<функции потерь>> (невязка 
и~др.). При задании метрики на элементах решетки ($\rho_L$) и~определении 
расстояния между цепями ($\rho_A$) рассмотрим возможность сведения задачи 
комбинаторной оптимизации к~задаче минимизации особой формы 
функционала (так называемая ранговая оптимизация).
     
     Основы разрабатываемого топологического формализма изложены 
в~\cite{5-t, 6-t}. Вкратце: заданы\linebreak множество исходных описаний объектов 
$\mathbf{X}\hm= \{x_1,\ldots ,x_{N_0}\}$, $\mathbf{X} \hm\subseteq S$, 
множества значений\linebreak признаков $I_k\hm= \{\lambda_{k_1}, \lambda_{k_2}, \ldots , 
\lambda_{k_b}, \ldots , \lambda_{k_{\vert I_k\vert}}, \Delta\}$,\linebreak $b\hm= 
1,\ldots , \vert I_k\vert$, функции $\Gamma_k: S\hm\to I_k$, $k\hm=1,\ldots , 
n\hm+ l$, где $n$~--- число признаков; $l$~--- число таргетных 
(прогнозируемых) переменных; $\Delta$~--- неопределенность. Тогда 
определены пространство допустимых признаковых описаний объектов 
$J_{\mathrm{ob}}\hm\subseteq I_i\times I_f$ ($I_i\hm\subseteq 
I_1\times\cdots\times I_n$, $I_f\hm\subseteq I_{n+1} \times\cdots\times I_{n+1}$), 
функции $D: S\hm\to J_{\mathrm{ob}}$, $D(x_\alpha)\hm= \left( 
\Gamma_1(x_\alpha) \times\cdots\times \Gamma_k(x_\alpha)\times\cdots\times 
\Gamma_{n+1}(x_\alpha)\right)_\Delta$ и~$\varphi(\mathbf{X}) 
\hm=\{D(x_\alpha)\vert x_\alpha \hm\in \mathbf{X}\}$. Принимается, что 
множество~$\mathbf{X}$ и~\textit{множество объектов} 
$Q\hm=\varphi(\mathbf{X})$, $\vert Q\vert \hm= N$, \textit{регулярны} ($\exists \, 
\varphi^{-1}: \mathbf{X} \hm= \varphi^{-1} (Q)$)~\cite{5-t}.
     
     Множество $\mathrm{U}(\mathbf{X}) \hm= \{ \Gamma_k^{-1} 
(\lambda_{k_b})\}$ рассматривается как предбаза \textit{топологии} 
$$
{T}(\mathbf{X})= \{ \varnothing, I, a\cup b, a\cap b: a,b \in 
\mathrm{U}(\mathbf{X})\},
$$
 где $I\hm=\{ \mathbf{X}\}$~--- единичный 
элемент. Топологии ${T}(\mathbf{X})$ соответствует \textit{решетка} 

\vspace*{-6pt}

\noindent
\begin{multline*}
L({T}(\mathbf{X}))= \left\{ a\vee b, a\wedge b: a,b\hm\in 
{T}(\mathbf{X}),\right.\\
 \left.(a\geq b)\ \mbox{или } (a\leq b)\right\}.
\end{multline*}

\vspace*{-3pt}

\noindent
При регулярности 
$\mathbf{X}/Q$ решетка $L({T}(\mathbf{X}))$~--- булева, так что 
\textit{булевы} признаки~--- вершины, \textit{категориальные} признаки~--- 
антицепи, а~\textit{числовые}~--- цепи 
 в~$L({T}(\mathbf{X}))$~\cite{7-t}. Тогда $k$-му числовому \mbox{признаку} 
с~множеством значений $I_k$, $\lambda_{k_{b-1}}\hm\leq 
\lambda_{k_b}\hm\leq \lambda_{k_{b+1}}$, соответствует цепь ${A}_k 
(\mathbf{X}) \hm= {A}(I_k,\mathbf{X})\hm=$\linebreak\vspace*{-12pt}

\pagebreak

\noindent
${}= \langle u(\lambda_{k_1}), 
\ldots , u(\lambda_{k_b}), \ldots\rangle$ в~$L({T}(\mathbf{X}))$, 
образованная множествами 
$$
u(\lambda_{k_b}) = \mathop{\bigcup}\limits^b_{\beta=1} 
\Gamma_k^{-1} (\lambda_{k_\beta});\enskip {A}_k(\mathbf{X})\in  \mathbf{A}(\mathbf{X}),
$$
 где $\mathbf{A}(\mathbf{X})$~--- множество всех 
цепей решетки $L({T}(\mathbf{X}))$. \textit{Эмпирическая функция 
распределения} (э.\,ф.\,р.)\ $k$-го признака определяется через совокупность 
точек $\mathbf{cdf} ({A}_k(\mathbf{X})) \hm= \{ (\lambda_{k_b}\hm\in 
I_k, \vert u(\lambda_{k_b})\vert /N)\}$, а~значение э.\,ф.\,р.\ в~точке~$\lambda$ 
вычисляется как $\mathrm{cdf} (\lambda, {A}_k(\mathbf{X}))\hm= \vert 
u(\lambda_{k_b})\vert /N$, $\lambda_{k_{b-1}}\hm\leq \lambda\hm\leq \lambda_{k_b}$ 
методами ку\-соч\-но-ли\-ней\-ной аппроксимации и~т.\,п.
     
     Булевой решетке $L({T}(\mathbf{X}))$ со\-по\-став\-ле\-но 
\textit{мет\-ри\-че\-ское пространство значений признаков} 
$M_L(L({T}(\mathbf{X})), \rho_L)$ с~мет\-ри\-кой $\rho_L: L^2\hm\to 
R^+$. Если $v: L\hm\to R^+$~--- \textit{изотонная оценка} 
($\forall_L\,a,b: v[a]\hm+ v[b]\hm= v[a\wedge b] +v[a\vee b], 
\underset{L}{\forall}\,a,b: a\supseteq b \hm\Rightarrow v[a]\hm\geq v[b]$), то 
функция $\rho(x,y)\hm= v[x\vee y]\hm- v[x\wedge y]$~---  
$\rho_L$-мет\-ри\-ка~[7]. При заданной~$\rho_L$ \textit{расстояние} $\rho_A: 
\mathbf{A}(\mathbf{X})^2\hm\to R^+$ \textit{между цепями} $a\hm= \langle a_1, 
\ldots , a_i, \ldots\rangle$ {и} $b\hm= \langle b_1, \ldots , b_j, \ldots\rangle$ 
может быть определено метрикой Хаусдорфа или как функционал от 
совокупности расстояний между ближайшими элементами цепей: 
\begin{multline*}
\rho_A(a,b)\hm= \min\Bigg( \sum\limits_{i=1,\vert a\vert} \rho_L(a_i, 
\argmin\limits_{b_j\in b} \rho_L(a_i,b_j)),\\
\sum\limits_{i=1,\vert b\vert} 
\rho_L(b_j, \argmin\limits_{a_i\in a} \rho_L(b_j,a_i))\Bigg).
\end{multline*}
 Важно, что при 
любом определении~$\rho_A$ подразумевается однозначное соответствие 
элементов цепей~$a$ и~$b$. При заданных ${A}_k(\mathbf{X})$ 
и~множестве допустимых цепей ${A}(\mathbf{X})_{1,n}$ искомый 
$\varepsilon$-кор\-рект\-ный алгоритм соответствует решению задачи 
оптимизации~\cite{5-t}:
     \begin{equation}
     \argmin\limits_{a\in \mathrm{A}(\mathbf{X})_{1,n}} \rho_A \left( 
{A}_k(\mathbf{X}),a\right)\vert {A}(\mathbf{X})_{1,n}\subset 
\mathbf{A}(\mathbf{X}).
     \label{e3-t}
     \end{equation}
Выражение~(\ref{e3-t}) описывает задачу комбинаторной оптимизации, при 
решении которой перебираются цепи из множества цепей 
${A}(\mathbf{X})_{1,n}$. Для решения~(\ref{e3-t}) необходимо 
определить метрики $\rho_L$ и~$\rho_A$, множество 
${A}(\mathbf{X})_{1,n}$ и~способ перебора цепей, как это делается при 
прогнозировании классов значений числовых переменных~[4]. В~настоящей 
работе рассмотрен подход, в~котором $\hat{{B}}_{(\theta_{B_k}),k} 
\hm= f_{\theta_k}: I_i \hm\to I_k$, а~$\theta_k$ вычисляются в~результате 
минимизации некоторой <<функции потерь>> на выборке обучения. 

     В рамках такого <<регрессионного>> подхода будем считать, что 
$f_{\theta_k}$ вычисляет значения из некоторого $I_{\theta_k}\hm\subseteq 
I_k$, что соответствует цепи ${A}(I_{\theta_k}, \mathbf{X})\hm= \langle 
A_1^{\theta_k}, \ldots, A_\beta^{\theta_k},\ldots\rangle$, $\beta \hm= 1,\ldots , \vert 
I_{\theta_k}\vert$, т.\,е.\ \mbox{подцепи} ${A}(I_k,\mathbf{X})\hm= \langle 
A_1^k, \ldots , A_b^k, \ldots \rangle$, $b\hm= 1,\ldots , \vert I_k\vert$. 
При $I_{\theta_k}\hm\subseteq I_k$ существует функция перенумерации $\delta: 
\mathbf{N}\hm\to \mathbf{N}$, так что $b\hm=\delta(\beta)$ и~э.\,ф.\,р.\ для 
$y\hm= f_{\theta_k}(x)$ вычисляется как $\mathrm{cdf}(y, 
{A}_k(\mathbf{X}))$. Множество цепей 
${A}(\mathbf{X})_{1,n}$ в~(\ref{e3-t}) зададим как 
$\{{A}(I_{\theta_k},\mathbf{X})\}$ для всех $\theta_k \hm\in \Theta_k$. 
Введем дополнительное понятие \textit{мощностн$\acute{\mbox{о}}$й функции 
расстояния} и~рассмотрим задачу~(\ref{e3-t}) в~контексте анализа  
э.\,ф.\,р.\ $k$-й таргетной переменной.
     
     \smallskip
     
     \noindent
\textbf{Определение~1.} Пусть ${A},{B}\hm\in 
L({T}(\mathbf{X}))$~--- два произвольных множества. Выражение 
$r({A}, {B})\hm=\left\vert \left\vert {A}\right\vert \hm- 
\left\vert {B}\right\vert \right\vert$ назовем мощностн$\acute{\mbox{о}}$й 
функцией расстояния между множествами~$A$ и~$B$.

\smallskip

\noindent
\textbf{Теорема~1.} $r({A}, {B})$ \textit{является метрикой}. 

\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \ Для метрической функции 
расстояния должны быть выполнены аксиомы тож\-дест\-ва, симметричности 
и~треугольника. Выполнение аксиомы тождества 
$r({A},{A})=0$ очевидно вследствие тождественности 
множества~$A$ самому себе, а~аксиомы симметричности 
$r({A},{B})\hm=r({B},{A})$~--- вследствие 
операции модуля в~определении $r(\,)$. Докажем выполнимость аксиомы 
треугольника. Рассмотрим случай $\vert {A}\vert \hm\leq \vert 
{B}\vert \hm\leq \vert {C}\vert$, в~котором длины трех сторон 
треугольника равны $\vert {B}\vert \hm- \vert {A}\vert $, $\vert 
{C}\vert \hm- \vert {B}\vert$ и~$\vert {C}\vert \hm- 
\vert {A}\vert$. Тестируя выполнение аксиомы для треугольника, 
вершины которого соответствуют множествам~$A$, $B$ и~$C$, запишем три 
неравенства: $\vert {B}\vert \hm- \vert {A}\vert \hm+\vert {C}\vert \hm- \vert {B}\vert \hm\geq 
\vert {C}\vert \hm- \vert {A}\vert$ (т.\,е.\ $\vert {C}\vert \hm 
\geq \vert {C}\vert$), $\vert {C}\vert \hm- \vert {B}\vert 
\hm+\vert {C}\vert \hm- \vert {A}\vert \hm\geq \vert {B}\vert 
\hm- \vert {A}\vert$ (т.\,е.\ $\vert {C}\vert \hm\geq 
\vert {B}\vert$) и~$\vert {C}\vert \hm- \vert {A}\vert 
\hm+\vert {B}\vert \hm- \vert {A}\vert \hm\geq \vert {C}\vert 
\hm- \vert {B}\vert$ (т.\,е.\ $\vert {B}\vert \hm\geq 
\vert {A}\vert$). Первое из неравенств выполнено всегда, а~второе 
и~третье соответствуют рассматриваемому случаю ($\vert {A}\vert 
\hm\leq \vert {B}\vert \hm\leq \vert {C}\vert$). Остальные 
варианты соотношений $\vert {A}\vert$, $\vert {B}\vert$ 
и~$\vert {C}\vert$ сводятся к~рассмотренному посредством подстановки 
переменных, так что аксиома треугольника выполнена и~$r(\,)$~--- метрика. 
Тео\-ре\-ма доказана.

\smallskip

\noindent
\textbf{Следствие~1.} \textit{Метрика $r({A}, {B})$ отражает 
расстояния между слоями решетки, в~которую входят рас\-смат\-ри\-ва\-емые 
множества~${A}$ и~${B}$}. По определению в~слое решетки 
расположены элементы одной высоты в~$L$. 

\smallskip

\noindent
\textbf{Следствие~2.} \textit{Пусть в~решетке~$L$ задана метрика 
$\rho_L({A},{B})\hm= v({A}\cup{B}\hm- 
v({A}\cap {B})$ на основе изотонной оценки $v(\,)$, рав\-ной 
высоте элемента в~$L$, $v({A})\hm= h({A})\hm=\vert 
{A}\vert$. Тогда $r({A},{B})\hm= \vert \rho_L 
({A},\varnothing)\hm- \rho_L({B},\varnothing)\vert$, 
где~$\varnothing$~--- нулевой элемент решетки~$L$}. Соответствует 
следствию~1.

\smallskip

\noindent
\textbf{Следствие~3.} \textit{В отличие от метрик на основе изотонных 
оценок $r({A}, {B})$ не зависит от совместного вхождения 
объектов в~множества~А и~В.} В~определении~1 отсутствуют  
тео\-ре\-ти\-ко-мно\-жест\-вен\-ные операции <<$\cup$>>, <<$\cap$>> и~др.

\smallskip

\noindent
\textbf{Следствие~4.} \textit{Значения метрик 
$\rho_L({A},{B})$ и~$r({A}, {B})$ равны для 
двух произвольных элементов одной цепи решетки~$L$}. Очевидно из 
следствия~2 и~того, что каж\-дый элемент цепи соответствует определенному 
слою решетки.

\smallskip

\noindent
\textbf{Следствие~5.} \textit{Пусть метрика $\rho_L({A},{B})$ 
определена как в~следствии~2, 
$\rho_L({A},{B})\hm\leq\varepsilon$, а~множества~$A$ и~$B$ 
принадлежат разным цепям. Тогда $r({A},{B})\hm\leq 
\rho_L({A},{B})$ и~$r({A},{B})\hm\leq\varepsilon$}. При заданных условиях 
$\rho_L({A},{B}) \hm= \vert {A}\Delta {B}\vert 
\hm= \vert {A}\backslash {B}\vert \hm+ \vert {B}\backslash 
{A}\vert \hm\leq \varepsilon$. Очевидно, что $\vert {A}\vert \hm= 
\vert {A}\cap {B}\vert \hm+ \vert {A}\backslash 
{B}\vert$ и~$\vert {B}\vert \hm= \vert 
{A}\cap {B}\vert \hm+ \vert {B}\backslash 
{A}\vert$, так что $r({A},{B})\hm= \vert \vert 
{A}\backslash {B}\vert \hm- \vert {B}\backslash 
{A}\vert\vert$. Так как сумма двух неотрицательных чисел $\vert 
{A}\backslash {B}\vert$ и~$\vert {B}\backslash 
{A}\vert$ в~$\rho_L({A},{B})\hm\leq\varepsilon$ не 
может быть больше их разности в~$r({A},{B})$, то и~$r({A},{B}) \hm\leq\varepsilon$.

\smallskip

\noindent
\textbf{Следствие~6.} \textit{$r({A},{B})\hm\leq 
\varepsilon$~--- необходимое условие $\rho_L({A},{B})\hm\leq 
\varepsilon$}.

\smallskip

\noindent
\textbf{Следствие~7.} \textit{Пусть $A, B \hm\subset \mathrm{X}$. Если 
$r({A},{B})\hm\leq\varepsilon$, то и~$r({X}\backslash {A}, {X}\backslash {B}) \hm\leq 
\varepsilon$}. Из дистри\-бу\-тив\-ности~$L$ и~принципа двойственности очевидно, 
что $\rho_L({A},{B}) \hm= \rho_L({X}\backslash 
{A}, {X}\backslash {B})$, поэтому при 
$\rho_L({A},{B}) \hm\leq \varepsilon$ и~$r({A},{B})\hm\leq \varepsilon$, и~$r({X}\backslash 
{A}, {X}\backslash {B})\hm\leq\varepsilon$.

\smallskip

\noindent
\textbf{Следствие~8.} \textit{Верхняя оценка $\rho_L({A},{B})$ 
равна $\vert {A}\vert \hm+ \vert {B}\vert$, а~среднее верхней 
и~нижней оценок}~--- $\max(\vert {A}\vert,\vert {B}\vert)$.


\smallskip

\noindent
\textbf{Теорема~2.} \textit{Задача комбинаторной оптимизации}~(\ref{e3-t}) 
\textit{сводима к~задаче минимизации различий между э.\,ф.\,р.\ таргетной 
переменной и~э.\,ф.\,р.\ искомого алгоритма $f_{\theta_k}$ при использовании 
нижней оценки~$\rho_L$ на основе высоты элемента и~задании функции 
потерь посредством неравенств} $\rho_L({A},{B}) \hm\leq 
\varepsilon$.

\smallskip

\noindent
     Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о.\ \ В~(\ref{e3-t}) фигурируют 
расстояния~$\rho_L$ между множествами, входящими в~цепи 
${A}(I_k,\mathbf{X})$ и~${A}(I_{\theta_k}, \mathbf{X})$. Для 
прогнозирования $k$-й\linebreak переменной заданы множество исходных 
описаний~$\mathbf{X}$, множество прецедентов 
$Q\hm=\varphi(\mathbf{X})\hm=\{(x_i,  y_i^k),\ x_i\hm\in I_i,\ y_i^k\hm\in 
I_k\hm\subset R$, $i\hm=1,\ldots ,N\}$, $f_{\theta_k}$ и~набор векторов 
$\theta_k\hm\in \Theta_k$, причем при любом $\theta_k$ из~$\Theta_k$ об\-ласть 
значений~$f_{\theta_k}$ остается равной~$I_{\theta_k}$. Объекты из~$Q$ 
формируют цепь ${A}(I_k,\mathbf{X})$, а~для $f_{\theta_k}$ 
и~$\theta_k$ определена цепь $\mathrm{A}(I_{\theta_k},\mathbf{X})$. 
     
     При любых $\rho_A$ и~$\rho_L$ множества в~составе цепей однозначно 
сопоставимы. Для произвольного $\beta\hm= 1,\ldots, \vert I_{\theta_k}\vert$ 
рассмотрим два множества $A^k_{\delta(\beta)}\hm\in 
{A}(I_k,\mathbf{X})$ и~$A_\beta^{\theta_k} \hm\in 
{A}(I_{\theta_k},\mathbf{X})$. $\varepsilon$-кор\-рек\-тно\-му 
алгоритму соответствует условие 
$$
\forall\,\beta: \rho_L\left(A^k_{\delta(\beta)}, 
A_\beta^{\theta_k}\right)\hm\leq \varepsilon,
$$

\vspace*{-3pt}

\noindent
 т.\,е.\ 
 
 \vspace*{-3pt}

\noindent
$$
\sum\limits_{\beta=1}^{\vert I_{\theta_k}\vert} \rho_L \left( 
A^k_{\delta(\beta)}, A^{\theta_k}_\beta\right) \leq \varepsilon\vert 
I_{\theta_k}\vert.
$$
 В~соответствии с~теоремой~1 и~ее следствиями при 
использовании~$\rho_L$ на основе изотонной оценки, равной высоте элемента, 
$r(\,)$~--- нижняя оценка~$\rho_L$. Заменим~$\rho_L$ на $r(\,)$ и~получим
$$
     \sum\limits_{\beta=1}^{\vert I_{\theta_k}\vert}\left\vert\left\vert 
A^k_{\delta(\beta)} \right\vert - \left\vert A_\beta^{\theta_k}\right\vert \right\vert 
\leq \varepsilon\left\vert I_{\theta_k}\right\vert.
$$

\vspace*{-3pt}

\noindent
 Поделив обе части 
неравенства на $\vert Q \vert \hm= \vert\mathbf{X}\vert \hm= N$, 
получим 

\vspace*{-6pt}

\noindent
\begin{multline*}
\sum\limits_{\beta=1}^{\left\vert I_{\theta_k}\right\vert} \left\vert 
\mathrm{cdf}\left( \lambda_{k_{\delta(\beta)}}, 
{A}_k(\mathbf{X})\right)- \mathrm{cdf}\left( \lambda_{k_\beta}, 
{A}(I_{\theta_k}, \mathbf{X})\right)\right\vert \leq{}\\
{}\leq \fr{\varepsilon\vert 
I_{\theta_k} \vert }{N}\,.
\end{multline*}

\vspace*{-3pt}

\noindent
 При фиксированных~$I_{\theta_k}$ и~$N$ это условие 
$\varepsilon$-кор\-рект\-но\-го алгоритма можно рассматривать как 
регрессионную задачу, подразумевающую минимизацию 
значения~$\varepsilon$ по~$\theta_k$:

\vspace*{-6pt}

\noindent
     \begin{multline}
     \argmin\limits_{\theta_k\in \Theta_k} \sum\limits_{\beta=1}^{\left\vert 
I_{\theta_k} \right\vert} \left\vert \mathrm{cdf}\left( \lambda_{k_{\delta(\beta)}}, 
{A}_k(\mathbf{X})\right) - {}\right.\\
\left.{}- \mathrm{cdf}\left( \lambda_{k_\beta}, 
{A}( I_{\theta_k},\mathbf{X})\right)\right\vert.
     \label{e4-t}
     \end{multline}
     
     \vspace*{-3pt}

\noindent
Теорема доказана.

\smallskip
     
     Заметим, что выражение~(\ref{e4-t}) описывает параметрический 
критерий задачи оптимизации, где исследователь фиксирует значение 
параметра~$I_{\theta_k}$. В~простейшем случае, когда $I_{\theta_k} \hm= 
[0,\lambda]$, задача~(\ref{e4-t}) редуцируется к~задаче прогнозирования классов 
значений $k$-й числовой переменной~[4].
     
     По определению функции $\mathrm{cdf}(\,)$ ее значения соответствуют 
некоторой доле объектов множества~$\mathbf{X}$, так что в~(\ref{e4-t}) 
разность значений $\mathrm{cdf}(\,)$ для заданного $\lambda_{k_\beta}$ равна 
доле объектов из~$\mathbf{X}$, ошибочно классифицированных относительно 
класса значений $u(\lambda_{k_\beta})$. Поэтому можно перейти от 
задачи~(\ref{e4-t}) к~аналогичной задаче, в~которой ошибка 
алгоритма~$f_{\theta_k}$ оценивается не суммированием по значениям 
в~$I_{\theta_k}$, а~суммированием ошибок в~$\mathrm{cdf}(\,)$ по 
индивидуальным объектам:

\vspace*{-6pt}

\noindent
     \begin{multline}
     \argmin\limits_{\theta_k\in \Theta_k} \sum\limits^N_{i=1} \left\vert 
\mathrm{cdf} \left( y_i^k, {A}_k(\mathbf{X})\right) -{}\right.\\
\left.{}-\mathrm{cdf} \left( 
f_{\theta_k} (x_i), {A}(I_{\theta_k},\mathbf{X})\right)\right\vert.
     \label{e4.1-t}
     \end{multline}
     
     \vspace*{-3pt}

\noindent
     Поскольку $I_{\theta_k}\subseteq I_k$, удобней оценивать значения 
э.\,ф.\,р.\ от $f_{\theta_k}$ используя э.\,ф.\,р.\ таргетной переменной:

\vspace*{-6pt}

\noindent
     \begin{multline}
     \argmin\limits_{\theta_k\in \Theta_k} \sum\limits^N_{i=1} \left\vert 
\mathrm{cdf} \left( y_i^k, {A}_k(\mathbf{X})\right) -{}\right.\\
\left.{}-\mathrm{cdf}\left( 
f_{\theta_k}(x_i),{A}_k(\mathbf{X})\right)\right\vert.
     \label{e4.2-t}
     \end{multline}
     
     \vspace*{-3pt}

\noindent
Очевидно, что в~задачах~(\ref{e4-t})--(\ref{e4.2-t}) 
подразумевается минимизация отклонений ран\-гов/про\-цен\-ти\-лей значений 
функции~$f_{\theta_k}$ с~функцией потерь в~виде модуля. При выборе 
в~качестве~$\rho_L$, например, квад\-ра\-та $r(\,)$ в~задаче типа~(\ref{e4.2-t}) 
будет минимизироваться сумма квадратов невязок этих рангов/процентилей. 
Назовем~(\ref{e4-t}), (\ref{e4.1-t}) и~др.\ задачами \textit{ранговой 
оптимизации}. Рассмотрим описанный сценарий, полученный в~рамках 
топологического подхода к~анализу данных, в~контексте  
ре\-грес\-сии/ап\-прок\-си\-ма\-ции функций.

\section{Ранговая оптимизация и~задачи регрессии/аппроксимации}

    Рассмотрим случай одномерной вещественной функции, заданной 
набором точек $\mathrm{Pr}\hm= \{ (x_i, y_i)\}$, $i\hm=1,\ldots,N$, $x_i\hm\in 
[a,b]$, $y_i\hm\in [c,d]$. Пусть Pr соответствует некоторой <<истинной>> 
функции~$f_t$, $y_i\hm= f_t(x_i)$. Будем аппроксимировать набор Pr функцией 
$f_\theta$, $y_i\hm= f_\theta(x_i) \hm+o(x_i,\theta)$. Пусть функции~$f_t$ 
и~$f_\theta$ непрерывны, дифференцируемы и~интегрируемы на интервале 
$[a,b]$. Необходимо найти вектор параметров~$\theta$, минимизирующий 
абсолютные значения $o(x_i,\theta)$ в~соответствии с~заданным критерием 
оптимизации. 

    Критерии оптимизации можно формулировать исходя из идеи 
минимизации площади $S(f_t,f_\theta)$, соответствующей суммарному 
отличию~$f_t$ и~$f_\theta$ на~$[a,b]$. В~идеальном случае $S\hm=0$ 
($o(x)\hm\equiv 0$), иначе $f_t(x)\hm= f_\theta(x)\hm+ o(x)$, $o(x)\hm>0$, 
и~площадь~$S$ может быть оценена корнем из интеграла $\int\nolimits_a^b 
(f_\theta\,dx \hm- f_t\,dx)^2$, соответствующего критерию $\min\nolimits_\theta 
\sum\nolimits_{i=1}^N (y_i\hm- f_\theta(x_i))^2$. Аналогично можно получить 
критерии минимизации взвешенной суммы невязок, критерий метода 
наименьших модулей и~др. Также возможна оценка площади~$S$ взятием 
интеграла по Лебегу, когда суммируются ошибки в~$x$ при заданном~$y$, 
и~т.\,п.

    Пусть при заданном Pr площадь~$S$ оценивается как сумма некоторых 
вкладов <<$w$>> отдельных точек, $S\hm= \sum\nolimits^N_{i=1} w(x_i,y_i) 
\hm+ o(\mathrm{Pr})$. Примем, что каждой точке сопоставлен одинаковый 
вклад~$\mu$ в~площадь~$S$ (с~точ\-ностью до $o(\mathrm{Pr})/N$), так что 
$S\sim \mu N$. Такое допущение может быть оправдано при достаточно\linebreak 
большом~$N$ и~при достаточно равномерном распределении точек вдоль 
соответствующих осей (ситуация, характерная для <<больших данных>>, 
производимых современными фи\-зи\-ко-хи\-ми\-че\-ски\-ми \mbox{технологиями} 
сбора данных). Тогда можно рас\-смот\-реть приближенные оценки площади~$S$ 
(и~соответствующие критерии минимизации), основанные не на 
\textit{разностях} в~значениях~$y_i$ и~$f_\theta(x_i)$, а~на \textit{подсчете 
числа точек} (\textit{объектов}) \textit{в} Pr \textit{и~в~его подмножествах}.

    Вернемся к~случаю произвольного множества~$\mathbf{X}$, $Q\hm= 
\varphi(\mathbf{X}) \hm=\{(x_i, y_i^k), x_i\hm\in I_i, y_i^k\hm\in I_k\}$, $I_k\hm= 
(\lambda_{k_b})$, $k\hm=1,\ldots,n$. Пусть задано подмножество 
$\zeta\hm=(\lambda_{k_\alpha})\hm\subseteq I_k$, $\alpha\hm=1,\ldots ,m$, 
$m\hm=\vert I_k \vert$. В~одномерном случае каждому 
значению~$\lambda_{k_\alpha}$ соответствует горизонтальная линия, 
параллельная оси абсцисс, а~в~случае произвольного $x_i\hm\in I_i$~--- 
гиперплоскость. Для заданного $\lambda_{k_\alpha}$ вычислим число объектов 
со значениями~$y_i^k$ ниже $\lambda_{k_\alpha}$, $n_\alpha^{t\leq} \hm= \vert 
u(\lambda_{k_\alpha})\vert$, и~$y_i^k$ выше~$\lambda_{k_\alpha}$, 
$n_\alpha^{t>} \hm= \vert \mathbf{X}\backslash u(\lambda_{k_\alpha})\vert$. 
Определим аналогичные числа для $\lambda_{k_\alpha}$ 
в~цепи~${A}(I_{\theta_k}, \mathbf{X})$, производимой 
алгоритмом~$f_{\theta_k}$, $n_\alpha^{\theta_k \leq} \hm= \vert \{ (x,y)\hm\in 
Q\vert f_{\theta_k}(x)\leq \lambda_{k_\alpha}\}\vert$ и~$n_\alpha^{\theta_k >} 
\hm= \vert \{ (x,y)\hm\in Q\vert f_{\theta_k}(x)\hm> \lambda_{k_\alpha}\}\vert$. 
При вкладе каждой из точек, равном~$\mu$, оценим значение 
площади~$S_\alpha$ для выбранного~$\lambda_{k_\alpha}$ как разность 
в~чис\-ле точек (объектов), у~которых значение~$y_i^k$ ниже порогового 
значения $\lambda_{k_\alpha}$, и~объектов, у~которых значение~$y_i^k$ 
выше~$\lambda_{k_\alpha}$:
$$
S_\alpha= \left(\left\vert n_\alpha^{t\leq} - 
n_\alpha^{\theta_k \leq} \right\vert + \left\vert n_\alpha^{t>} - n_\alpha^{\theta_k 
>}\right\vert \right) \mu\,.
$$
 По построению 
 $$
 n_\alpha^{t\leq} + n_\alpha^{t>} = 
n_\alpha^{\theta_k \leq} + n_\alpha^{\theta_k >} = \vert Q\vert,
$$
 так что 
$$
S_\alpha= 2\left\vert n_\alpha^{t\leq} - n_\alpha^{\theta_k \leq}\right\vert \mu\,,
$$
 что 
эквивалентно 
\begin{multline*}
S_\alpha ={}\\
{}= 2\mu N\left\vert \mathrm{cdf} \left( 
\lambda_{k_{\delta(\alpha)}},{A}_k(\mathbf{X})\right)- \mathrm{cdf} 
\left( \lambda_{k_\alpha}, {A}(I_{\theta_k},\mathbf{X})\right)\right\vert.\hspace*{-4.67494pt}
\end{multline*}
Оценим площадь $S(f_t,f_\theta)$ как математическое ожидание~$S_\alpha$ по 
всем элементам множества~$\zeta$:
$$
S= \fr{1}{m}\sum\limits^m_{\alpha=1} S_\alpha.
$$
 Считая~$\mu$, $N$ и~$m$ константами и~минимизируя~$S$ 
по~$\theta_k$, приходим к~задаче~(\ref{e4-t}). 
    
Таким образом, задачи ранговой оптимизации в~рамках 
топологического подхода (минимизация расстояния между цепями решетки) 
также могут быть получены исходя из специфического способа оценки 
различий $S(f_t, f_\theta)$ между <<истинной>> функцией~$f_t$ и~ее 
аппроксимацией~$f_\theta$. Перспективно использовать комбинации 
критериев~(\ref{e4-t})--(\ref{e4.2-t}), что позволит одновременно 
минимизировать и~отличия индивидуальных объектов, и~отличия значений 
э.\,ф.\,р.\ в~паре <<пе\-ре\-мен\-ная--ал\-го\-ритм>>.

     Получаемые критерии оптимизации относятся к~параметрическим~--- 
в~качестве параметра выступает подмножество множества~$I_k$. При 
определенном выборе подмножества~$\zeta$ получаются\linebreak \mbox{конструкции}, 
идеологически близкие к~задачам квантильной регрессии~[8]. При назначении 
весов значениям~$\lambda_{k_\alpha}$ и~исследовании э.\,ф.\,р.\ 
значений~$S_\alpha$ можно получить более сложные критерии.
     
\section{Результаты экспериментального тестирования формализма}

    Формализм апробирован на задаче взаимодействия лиганд--рецептор, 
    в~которой значения EC$_{50}(j)$ прогнозируются исходя из химической 
структуры молекул.  Решения задач в~постановках~(\ref{e4-t}), (\ref{e4.2-t}) 
позволяют прогнозировать не только сами значения EC$_{50}(j)$, но 
и~значения откликов $E_j(C_i)$, для которых затем используется корректор 
в~виде~(\ref{e1-t}). При прогнозировании EC$_{50} (j)$ и~$E_j(C_i)$ на основе 
хемогр$\acute{\mbox{а}}$фа $G_j$ в~качестве множества начальных 
информаций~$I_i$ использовалось множество хемоинвариантов над алфавитом 
специальных меток (см.\ ниже). Алгоритмы $f_{\theta_k}: I_i\hm\to R$ 
строились в~виде композиций вложенных корректирующих функций нижнего 
уровня (порождение синтетических признаков) для фиксированного числа 
моделей $n_{\mathrm{mod}} : f_{\theta_k}\hm= g(f_1(\sum \omega_k^j x_k), \ldots , f_l(\sum 
\omega_k^j x_k),\ldots )$, $l\hm=1,\ldots,n_{\mathrm{mod}}$, где $g$~--- внешняя 
корректирующая функция; $f_l$~--- внутренние корректирующие функции 
(модели порождения синтетических числовых признаков); $n_{\mathrm{mod}}$~--- их 
число. Суммирование $\sum\omega_j^k x_j$ проводится по компонентам 
вектора $\mathbf{x}\hm\in I_i$,\linebreak
 $k\hm=1,\ldots,\vert \mathbf{x}\vert$. 
Использовались линейные, нелинейные, монотонные и~немонотонные  
функ\-ции-кор\-рек\-то\-ры~$g$ и~$f_l$ (более~20~монотонных 
и~немонотонных преобразований, в~том числе \mbox{описанных} в~\mbox{работе}~\cite{6-t}). 
Векторы параметров настраивались мультистартовой стохастической 
оптимизацией в~рамках кросс-ва\-ли\-да\-ци\-он\-но\-го дизайна~\cite{6-t}.

     При прогнозировании EC$_{50}$ исходя из $E_j(C_i)$ использовались 
вложенные алгоритмические структуры, описываемые алгоритмами 2-го 
уровня: 
$$
\hat{{A}}^{(2)}_{(\theta^2_A)} =
     \hat{{C}}^{(2)}_{(\theta^2_C)}\circ
     \hat{{B}}^{(2)}_{(\theta^2_B)}.
     $$
      В~качестве корректирующей 
операции $\hat{{C}}^{(2)}_{(\theta^2_C)}$ использовалось уравнение 
Хилла~(\ref{e1-t}), а~в~качестве распознающих операторов 
$\hat{{B}}^{(2)}_{(\theta^2_B)}$~--- функции $g(f_1(\sum \omega_k^j x_k),\ldots)$, настраиваемые на множествах откликов $E_j(C_i)$.

     
     Для хемографа $X\hm\in \bm{\Gamma}$ ($\bm{\Gamma}$~--- множество 
всех\linebreak хемографов, основанное на алфавите меток~$Y$) хемоинварианты 
порождались на основании множеств  
$\chi$-це\-пей длины $\tilde{{Y}}^m(X)$ и~$\chi$-уз\-лов~$\hat{Y}(X)$  ~\cite{6-t}. 
Вкратце: пусть задано множество подграфов\linebreak ($\chi$-це\-пей и~$\chi$-уз\-лов) 
$\bm{\pi}\hm= \{ \bm{\pi}_1, \bm{\pi}_2, \ldots, \bm{\pi}_n\} \hm\subset 
\bm{\Gamma}$. Определим оператор вхождения подграфа~$\pi$ 
в~хемограф~$X$ как 
$$
\hat{\beta}[X]\pi\hm= \left( \vert \pi \cap \bm{\Pi}(X)\vert 
>0\right),\ \bm{\Pi}(X)\hm= \tilde{{Y}}^m (X)\cup 
\hat{{Y}}(X),
$$

\vspace*{-12pt}

\columnbreak

\noindent
 а~последовательное применение~$\hat{\beta}$ 
к~$\bm{\pi}$~--- булев \mbox{вектор }

\noindent
$$
\hat{\bm{\beta}}[X]\bm{\pi} \hm= \left( 
\hat{\beta}[X]\bm{\pi}_1, \hat{\beta}[X]\bm{\pi}_2, \ldots , 
\hat{\beta}[X]\bm{\pi}_n\right).
$$

\vspace*{-3.5pt}

\noindent
 Для множества хемографов~$\mathbf{X}$ 
множество начальных информаций 

\vspace*{1pt}

\noindent
$$
I_i= \mathop{\bigcup}\limits_{k=1}^{\vert \mathbf{X}\vert} 
\hat{\bm{\beta}}[X_k]\left( \tilde{{Y}}^m(X_k) \cup 
\hat{{Y}}(X_k)\right),\ m=5
$$

\vspace*{-3.5pt}

\noindent
 (соответствует оптимальным 
результатам тестирования регулярности по Журавлёву~\cite{6-t}).
     
     Тестирование алгоритмов $f_{\theta_k}$ и~$\hat{{A}}^{(2)}_{(\theta^2_A)}$ проводилось на выборке данных из 
ProteomicsDB ({\sf https://www.proteomicsdb.org}), содержащей данные 
по~$C_i$ ($C_i\hm=1$, 3, 10, 100, 1000, 3000, 30\,000~нмоль/л), $E_j(C_i)$ 
и~EC$_{50} (j)$ для~300~фер\-мен\-тов-ки\-наз (так называемый 
кин$\acute{\mbox{о}}$м человека, часть протеома) и~ряда лекарств. Киназы 
представляют собой таргетные белки известных и~перспективных 
лекарственных средств. Наилучшие результаты прогнозирования EC$_{50} (j)$ 
получались при (1)~пренебрежении эффектами атомов водорода (т.\,е.\ при 
использовании более простых $Y$-ал\-фа\-ви\-тов), (2)~использовании линейного 
распознающего оператора в~сочетании с~немонотонными корректорами 
(нейронные сети, решающие деревья, полиномиальные функции и~др.), 
3)~совместном использовании критериев~(\ref{e4-t}) и~(\ref{e4.2-t}). 
Результаты экспериментов суммированы в~таблице.
     


     
     Как при использовании линейной, так и~нейросетевой $g(\,)$, применение 
критериев ранговой регрессии~(\ref{e4-t}) и~(\ref{e4.2-t}) способствовало 
снижению различий между значениями коэффициента корреляции на обучении 
и~контроле. Наиболее выраженный эффект наблюдался для~(\ref{e4.2-t}), в~то 
время как минимизация отклонений э.\,ф.\,р.\ по~(\ref{e4-t}) имела 
вспомогательное значение. Наилучший результат получен при использовании 
нейросетевой~$g$, настраиваемой в~соответствии с~обоими ранговыми 
критериями ($r_c\hm= 0{,}86\pm0{,}20$).
     
     В отличие от описанного выше <<прямого>> 
прогнозирования~EC$_{50}$ прогнозирование $E_j(C_i)$ с~использованием 
корректора~(\ref{e1-t}) оказалось менее успешным (см.\ рисунок). Точ\-ность 
прогнозирования отдельных значений $E_j(C_i)$ была сопоставима 
с~приведенной в~таблице ($r_c\sim 0{,}85\pm0{,}21$), но данная схема 
прогнозирования отличалась существенно более низким качеством на контроле 
($r_c\sim 0{,}63\pm0{,}24$). 


     
     
     В целом критерии~(\ref{e4.2-t}) и~(\ref{e4-t}) могут успешно 
использоваться не только для хемокиномного анализа, но и~для 
хемотранскриптомного анализа лигандов, поиска эффективных и~безопасных 
средств для фармакотерапии COVID-19, в~хемомикробиомном анализе и~др.\ 
(см.\ ресурс {\sf www.chemoinformatics.ru}). 

\end{multicols}

\begin{table*}\small
\begin{center}
\begin{tabular}{|l|c|c|c|c|}
\multicolumn{5}{c}{Тестирование расчетов EC$_{50}(j)$ для 300 киназ человека}\\
\multicolumn{5}{c}{\ }\\[-6pt]
\hline
\multicolumn{1}{|c|}{Эксперимент}&$r$&$r_c$&СО&СО$_c$\\
\hline
Обычная регрессия, $g$~--- линейная&$0{,}67\pm0{,}25$&$0{,}45\pm 0{,}26$&$0{,}24\pm 
0{,}15$&$0{,}25\pm 0{,}14$\\
Ранговая регрессия по~(\ref{e4.2-t}), $g$~--- линейная&$0{,}68\pm 0{,}23$&$0{,}48\pm 
0{,}25$&$0{,}20\pm 0{,}19$&$0{,}22\pm 0{,}20$\\
Ранговая регрессия по~(\ref{e4-t}), $g$~--- линейная&$0{,}67\pm 0{,}25$&$0{,}47\pm 
0{,}25$&$0{,}23\pm 0{,}21$&$0{,}22\pm 0{,}22$\\
Ранговая регрессия по~(\ref{e4-t}) и~(\ref{e4.2-t}), $g$~--- линейная&$0{,}68\pm 
0{,}23$&$0{,}47\pm 0{,}25$&$0{,}20\pm 0{,}20$&$0{,}21\pm 0{,}20$\\
Обычная регрессия, $g$~--- нейросеть&$0{,}89\pm 0{,}13$&$0{,}79\pm 0{,}13$&$0{,}18\pm 
0{,}12$&$0{,}13\pm 0{,}11$\\
\textbf{Ранговая регрессия по~(\ref{e4.2-t}), $g$~--- нейросеть}&\boldmath{$0{,}88\pm 
0{,}15$}&\boldmath{$0{,}83\pm 0{,}28$}&\boldmath{$0{,}05\pm 
0{,}03$}&\boldmath{$0{,}05\pm 0{,}03$}\\
Ранговая регрессия по~(\ref{e4-t}), $g$~--- нейросеть&$0{,}89\pm 0{,}13$&$0{,}81\pm 
0{,}16$&$0{,}18\pm 0{,}17$&$0{,}17\pm 0{,}17$\\
\textbf{Ранговая регрессия по~(\ref{e4.2-t}) и~(\ref{e4-t}), $g$~--- 
нейросеть}&\boldmath{$0{,}88\pm 0{,}15$}&\boldmath{$0{,}86\pm 
0{,}20$}&\boldmath{$0{,}03\pm 0{,}02$}&\boldmath{$0{,}04\pm 0{,}03$}\\
     \hline
\multicolumn{5}{p{162mm}}{\footnotesize \hspace*{2mm}\textbf{Примечания:} $r$~--- коэффициент ранговой корреляции на обучении, $r_c$~--- на контроле; СО~--- 
стандартное отклонение на обучении, СО$_c$~--- на контроле; кросс-ва\-ли\-да\-ци\-он\-ный 
дизайн (10~разбиений, <<случай--контроль>> $6:1$). В~качестве нейросети использовалась 
2-слой\-ная сеть с~функцией активации softmax.}
     \end{tabular}
     \end{center}
     %\end{table*}
         % \begin{figure*}[b] %fig1
\vspace*{1pt}
\begin{center}
   \mbox{%
\epsfxsize=163mm 
\epsfbox{tor-1.eps}
}

\end{center}
\vspace*{-3pt}

{\small Прогнозирование EC$_{50}$ с~использованием схемы <<прямого>> 
прогнозирования ($y\hm= 0{,}67x\hm+ 0{,}0706$, $R^2\hm= 0{,}622$)~(\textit{а}) и~схемы прогнозирования $E_j(C_i)$ с~корректором в~виде 
уравнения Хил\-ла--Ленг\-мю\-ра ($y\hm= 0{,}5959x\hm+0{,}018$, $R^2\hm= 0{,}4027$)~(\textit{б}). Приведены результаты для контрольной 
выборки}
\end{table*}


\begin{multicols}{2}

\section{Заключение}
    
Перспективным направлением повышения точ\-ности работы алгоритмов 
машинного обучения стала разработка математического инструментария, 
позволяющего порождать проб\-лем\-но-ори\-ен\-ти\-ро\-ван\-ные тео\-рии для решения 
конкретных прикладных задач. В~част\-ности, топологический подход 
к~распознаванию позволяет систематически анализировать различные способы 
порождения признаковых описаний плохо формализованных задач  
рас\-по\-зна\-ва\-ния/клас\-си\-фи\-ка\-ции. Как показали результаты настоящей 
работы, выбор определенных метрик $\rho_L$ и~$\rho_A$ в~рамках 
топологического подхода соответствует порождению специфических критериев 
рангового характера, оптимизация которых позволяет улучшить показатели 
обучения соответствующих алгоритмов. С~разработанными критериями 
обучение моделей и~оценка качества прогнозирования проводятся на основе 
сохранения отношений порядка значений, а~не самих значений таргетной 
переменной (что крайне важно, например, с~точки зрения теоретической 
химии). В~зависимости от конкретных задач э.\,ф.\,р.\ могут быть представлены в~дискретной форме (как в~настоящей работе) либо в~виде аппроксимаций 
посредством непрерывных функций. Возможна разработка более сложных 
ранговых критериев на основе статистических функционалов.

{\small\frenchspacing
 {%\baselineskip=10.8pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9}
  \bibitem{1-t}
  \Au{Журавлёв Ю.\,И.} Избранные научные труды.~--- М.: Магистр, 1998. 420~с. 
  \bibitem{2-t}
  \Au{Torshin I.\,Y., Rudakov~K.\,V.} Combinatorial analysis of the solvability of the problems of 
recognition, completeness of algorithmic models. Part~1: Factorization approach~// Pattern 
Recognition Image Analysis, 2017. Vol.~27. No.\,1. P.~16--28. doi: 10.1134/S1054661817010151.
  \bibitem{3-t}
  \Au{Torshin I.\,Y., Rudakov~K.\,V.} Combinatorial analysis of the solvability properties of the 
problems of recognition and completeness of algorithmic models. Part~2: Metric approach within 
the framework of the theory of classification of feature values~// Pattern Recognition Image Analysis, 
2017. Vol.~27. No.\,2. P.~184--199.  doi: 10.1134/ S1054661817020110.
  \bibitem{4-t}
  \Au{Torshin I.\,Y., Rudakov~K.\,V.} On the procedures of generation of numerical features over 
partitions of sets of objects in the problem of predicting numerical target variables~// Pattern 
Recognition Image Analysis, 2019. Vol.~29. No.\,3. P.~654--667. doi: 10.1134/S1054661819040175.
  \bibitem{5-t}
  \Au{Торшин И.\,Ю.} О~применении топологического подхода к~анализу плохо 
формализуемых задач для построения алгоритмов виртуального скрининга  
кван\-то\-во-ме\-ха\-ни\-че\-ских свойств органических молекул I: Основы проблемно 
ориентированной теории~// Информатика и~её применения, 2022. Т.~16. Вып.~1. С.~39--45. 
doi: 10.14357/19922264220106.
  \bibitem{6-t}
  \Au{Торшин И.\,Ю.} О~применении топологического подхода к~анализу плохо 
формализуемых задач для построения алгоритмов виртуального скрининга  
кван\-то\-во-ме\-ха\-ни\-че\-ских свойств органических молекул II: Со\-по\-став\-ле\-ние 
формализма с~конструктами квантовой механики и~экспериментальная апробация 
предложенных алгоритмов~// Информатика и~её применения, 2022. Т.~16. Вып.~2. С.~35--43. 
doi: 10.14357/19922264220205. 
  \bibitem{7-t}
  \Au{Torshin I.\,Y., Rudakov~K.\,V.} On the theoretical basis of metric analysis of poorly 
formalized problems of recognition and classification~// Pattern Recognition Image Analysis, 2015. 
Vol.~25. No.\,4. P.~577--587.  doi: 10.1134/ S1054661815040252.
  \bibitem{8-t}
  \Au{Koenker R., Bassett~G.} Regression quantiles~// Econometrica, 1978. Vol.~46. No.\,1. 
P.~33--50. doi: 10.2307/1913643.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 05.10.22}}

\vspace*{8pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{-2pt}

\def\tit{ON OPTIMIZATION PROBLEMS ARISING FROM~THE~APPLICATION 
OF~TOPOLOGICAL DATA ANALYSIS TO~THE~SEARCH FOR~FORECASTING 
ALGORITHMS WITH~FIXED CORRECTORS}


\def\titkol{On optimization problems arising from~the~application 
of~topological data analysis to~the~search for~forecasting 
algorithms} % with~fixed correctors}


\def\aut{I.\,Yu.~Torshin}

\def\autkol{I.\,Yu.~Torshin}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-15pt}


\noindent
Federal Research Center ``Computer Science and Control'' of the Russian Academy 
of Sciences, 44-2~Vavilov Str., Moscow 119333, Russian Federation


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 2}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 2
\hfill \textbf{\thepage}}}

\vspace*{3pt}
  


\Abste{Corrective operations (correctors) in multialgorithmic constructions of the 
algebraic approach can be based on known physical models and/or multilevel 
descriptions of physical objects. At the same time, within the framework of the 
topological approach to the analysis of poorly formalized problems, the search for 
algorithms included in the corrector can be considered as a~combinatorial 
optimization problem or as a~problem of minimizing a~certain loss function. The 
study of the neighborhoods of chains in the lattice of subsets of objects made it 
possible to obtain a number of rank optimization criteria that are promising for 
solving the problems of predicting numerical target variables. The formalism was tested 
on the problem of ligand--receptor interaction within the framework of the chemokine 
analysis of drug molecules (data from ProteomicsDB). The best results of predicting 
constants were observed when using the obtained rank criteria (correlation coefficient 
on a~sliding control $0.86\pm0.20$ averaging over~300~biological activities).}

\KWE{topological data analysis; lattice theory; optimization problems; regression; chemoinformatics}



\DOI{10.14357/19922264230201}{IGSPEW}

\vspace*{-22pt}


\Ack

\vspace*{-4pt}


\noindent
The research was funded by the Russian Science Foundation, project 23-21-00154. The research 
was carried out using the infrastructure of the Shared Research Facilities ``High Performance 
Computing and Big Data'' (CKP ``Informatics'') of FRC CSC RAS (Moscow).
  

%\vspace*{9pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {\baselineskip=11.6pt
% \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9}
 
 \vspace*{-3pt}
 
  \bibitem{1-t-1}
\Aue{Zhuravlev, Yu.\,I.} 1998. \textit{Izbrannye nauchnye trudy} [Selected scientific works]. 
Moscow: Magistr. 420~p.
  \bibitem{2-t-1}
\Aue{Torshin, I.\,Y., and K.\,V.~Rudakov.} 2017. Combinatorial analysis of the solvability of the 
problems of recognition, completeness of algorithmic models. Part~1: Factorization approach. 
\textit{Pattern Recognition Image Analysis} 27(1):16--28. doi: 10.1134/S1054661817010151.
  \bibitem{3-t-1}
\Aue{Torshin, I.\,Y., and K.\,V.~Rudakov.} 2017. Combinatorial analysis of the solvability 
properties of the problems of recognition and completeness of algorithmic models. Part~2: Metric 
approach within the framework of the theory of classification of feature values. \textit{Pattern Recognition Image Analysis}
 27(2):184--199. doi: 10.1134/ S1054661817020110.
  \bibitem{4-t-1}
\Aue{Torshin, I.\,Yu., and K.\,V.~Rudakov.} 2019. On the procedures of generation of numerical 
features over partitions of sets of objects in the problem of predicting numerical target variables. 
\textit{Pattern Recognition Image Analysis} 29(4):654--667. doi: 10.1134/S1054661819040175.
  \bibitem{5-t-1}
\Aue{Torshin, I.\,Yu.} 2022. O~primenenii topologicheskogo podkhoda k~analizu plokho 
formalizuemykh zadach dlya postroeniya algoritmov virtual'nogo skrininga  
kvantovo-mekhanicheskikh svoystv organicheskikh molekul I: Osno\-vy problemno 
orientirovannoy teorii [On the application of a~topological approach to analysis of poorly 
formalized problems for constructing algorithms for virtual screening of quantum-mechanical 
properties of organic molecules I: The basics of the problem-oriented theory]. \textit{Informatika 
i~ee Primeneniya~--- Inform Appl.} 16(1):39--45. doi: 10.14357/19922264220106.


  \bibitem{6-t-1}
\Aue{Torshin, I.\,Yu.} 2022. O~primenenii topologicheskogo podkhoda k~analizu plokho 
formalizuemykh zadach dlya po\-stro\-e\-niya algoritmov virtual'nogo skrininga  
kvantovo-mekhanicheskikh svoystv organicheskikh molekul II: So\-po\-stav\-le\-nie formalizma 
s~konstruktami kvan\-to\-voy me\-kha\-ni\-ki i~eksperimental'naya aprobatsiya predlozhennykh algorit\-mov 
[On the application of a topological approach to analysis of poorly formalized problems for 
constructing algorithms for virtual screening of quantum-mechanical properties of organic 
molecules II: Comparison of formalism with constructions of quantum mechanics and experimental 
approbation of the proposed algorithms]. \textit{Informatika i~ee Primeneniya~--- Inform Appl.} 
16(2):35--43. doi: 10.14357/19922264220205. 
  \bibitem{7-t-1}
\Aue{Torshin, I.\,Y., and K.\,V.~Rudakov.} 2015. On the theoretical basis of metric analysis of 
poorly formalized problems of recognition and classification. \textit{Pattern Recognition Image Analysis} 
25(4):577--587. doi: 10.1134/ S1054661815040252.
\bibitem{8-t-1}
\Aue{Koenker, R., and G.~Bassett.} 1978. Regression quantiles. \textit{Econometrica}  
46(1):33--50. doi: 10.2307/1913643.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received October 5, 2022}} 

\Contrl

\noindent
  \textbf{Torshin Ivan Y.} (b.\ 1972)~--- Candidate of Science (PhD) in physics and mathematics, 
Candidate of Science (PhD) in chemistry, senior scientist, A.\,A.~Dorodnicyn Computing Center, 
Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, 
40~Vavilov Str., Moscow 119333, Russian Federation; \mbox{tiy135@yahoo.com}
  

   
\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 