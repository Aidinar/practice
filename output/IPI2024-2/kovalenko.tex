\def\stat{kovalenko}

\def\tit{ПРИМЕНЕНИЕ РАЗЛОЖЕНИЯ ИЗОБРАЖЕНИЯ С~ПОМОЩЬЮ~ДИСКРЕТНОГО ВЕЙВЛЕТ-ПРЕОБРАЗОВАНИЯ ДЛЯ~ПОСТРОЕНИЯ АРХИТЕКТУРЫ ШУМОПОДАВЛЯЮЩЕЙ НЕЙРОННОЙ СЕТИ}

\def\titkol{Применение разложения изображения с~помощью дискретного вейвлет-преобразования для построения архитектуры}
% шумоподавляющей нейронной сети}

\def\aut{А.~С.~Коваленко$^1$}

\def\autkol{А.~С.~Коваленко}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Коваленко А.~С.}
\index{Kovalenko A.\,S.}


%{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
%{Исследование выполнено за счет гранта Российского научного фонда №\,22-28-00588, {\sf 
%https://rscf.ru/project/22-28-00588/}. Работа проводилась с~использованием инфраструктуры Центра 
%коллективного пользования <<Высокопроизводительные вычисления и~большие данные>> (ЦКП 
%<<Информатика>> ФИЦ ИУ РАН, Москва).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Южный федеральный университет, Институт математики, 
механики и~компьютерных наук им.~И.\,И.~Воровича, \mbox{akov@sfedu.ru}}

\vspace*{-12pt}






\Abst{Подавление шума на цифровых изображениях~--- одна 
из самых распространенных задач в~области обработки изображений. На данный 
момент широкое применение имеют подходы подавления шума, основанные на 
применении сверточных нейронных сетей (CNN, convolutional neural network). При этом, как правило, обучение модели 
строится на минимизации функции ошибки между результатом работы сети и~ожидаемым 
эталонным изображением и~дополнительно не используются различные представления 
двумерного сигнала изображения и~их свойства для оптимизации обучения
архитектур шумоподавляющих сетей. Предложен подход к~обуче\-нию 
нейронных сетей подавлять шум. Описанный подход основан на применении N-крат\-но\-го 
быст\-ро\-го вейв\-лет-пре\-обра\-зо\-ва\-ния Хаара (БВПХ). Такое представление дискретного сигнала 
изображения позволяет отказаться от классической архитектуры автоэнкодера 
и~использовать только его часть, кодирующую сигнал, что приводит к~значительному 
сокращению параметров модели и~ускоряет работу сети.}

\KW{нейронные сети; глубокое обучение; 
шумоподавление изображений; методы обработки изображений}

\DOI{10.14357/19922264240209}{UEQSXP}
  
%\vspace*{-6pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}

\section{Введение}



Наилучшие результаты решения задачи по\-дав\-ле\-ния шума на цифровых изображениях 
демонстрируют подходы, основанные на применении глубоких сверточных нейронных 
сетей. Как правило, данные сети имеют архитектуры, схожие с~мо\-делью 
U-Net~\cite{UNET_ORIGINAL}, где сеть представлена в~виде автокодировщика со 
сквозной передачей сигнала между слоями кодировщика входного сигнала и~его 
декодера. Общая схема модели U-Net изображена на рис.~\ref{fig:unet_scheme}. 
Авторы работы~\cite{UNETS_COMPARISON} рассматривают различные модификации 
архитектуры U-Net для подавления шума на входном изображении и~подходы 
к~обуче\-нию таких моделей.

\begin{figure*} %fig1
 \vspace*{1pt}
      \begin{center}
     \mbox{%
\epsfxsize=163mm 
\epsfbox{kov-1.eps}
}
\end{center}
\vspace*{-6pt}
    \Caption{Общая схема архитектуры U-Net: \textit{1}~--- понижение разрешения в~2~раза;
    \textit{2}~--- повышение разрешения в~2~раза;
    \textit{3}~--- конкатенация матриц по каналам; \textit{4}~--- передача выходных значений блока}
    \label{fig:unet_scheme}
\end{figure*}

Изображение, передаваемое в~нейронную сеть, можно рассматривать как сумму 
значений элементов матрицы чистого изображения~$I$ с~матрицей, содержащей шум, 
получаемый из некоторого распределения~$\mathit{P}$, и~может быть записано 
выражением:
\begin{equation*}
\label{eq:input_image_def}
    \tilde{I} = I + \alpha,\enskip \alpha \sim \mathit{P}\,.
\end{equation*}

Поскольку погрешность приема оптического\linebreak сигнала зависит от физических свойств 
КМОП-сен\-со\-ра (КМОП~--- комплементарная структура \mbox{ме\-талл}--ок\-сид--по\-лу\-про\-вод\-ник), 
то для каждой модели существует некоторое уникальное распределение~$\mathit{P}$, 
генерирующее шумовую составляющую сигнала. Также на уровень шума 
будут иметь значительное влияние настройки камеры и~условия 
съемки~\cite{IMAGE_NOISE_CONDITIONS}, при увеличении уровня 
светочувствительности сенсора будет возрастать и~отношение шума к~чистому 
сигналу.

Задача обучения нейронной сети~$f$ заключается в~поиске оптимального набора 
весов слоев сети~$\mathnormal{w}$, при котором будет достигнут минимум 
аппроксимированного эмпирического риска:

\vspace*{-2pt}

\noindent
\begin{equation*}
\label{eq:main_problem}
\tilde{Q}(w, X^{l}) = \sum\limits_{i=1}^{l}\mathcal{L}(I_i, 
f(\tilde{I}_i, w)) \rightarrow \min\limits_{w}\,.
\end{equation*}

\vspace*{-4pt}

В качестве функции ошибки для обучения модели могут быть выбраны меры схожести 
изображений~$L_{1}$ и~$L_{2}$, функция показателя индекса структурного сходства 
(SSIM, structure simularity)~\cite{SSIM} или комбинация нескольких мер сходства изображений, как 
предлагаемая авторами работы~\cite{MIX_LOSS} функция ошибки MIX, которая 
представляет собой взвешенную сумму нормы~$L_{1}$ и~многомасштабной SSIM (MS-SSIM, multiscale SSIM).

Для повышения качества работы U-Net-по\-доб\-ных моделей в~их архитектуру 
интегрируют слои межканального и~пространственного внимания~\cite{CBAMCB}. Эти 
дополнительные слои позволяют модели извлекать не только локальные признаки 
изоб\-ра\-же\-ния, но и~работать с~глобальными особенностями 
изображения~\cite{CBAM_USAGE}. Также для улучшения шумоподавляющих свойств 
обучаемой модели могут использоваться различные преобразования значений скрытого 
пространства слоев сети. Авторы архитектуры Multilevel Wavelet-CNN 
(MWCNN)~\cite{MWCNN} используют дискретное вейв\-лет-пре\-обра\-зо\-ва\-ние Хаара для 
разложения сигнала, передаваемое между слоями модели. Это позволяет улучшить 
качество восстановления высокочастотной компоненты входного изображения и~минимизировать эффект размытия обработанного сетью изображения.

Авторы работы~\cite{WaveletPooling} используют вейв\-лет-пре\-обра\-зо\-ва\-ния 
в~комбинации с~методом объединения признаков, извлеченных разными блоками модели 
для сохранения информации в~восстанавливаемом изоб\-ра\-же\-нии о~текстурах и~границах 
объектов. Повышение разрешения карт признаков путем применения вейв\-лет-пре\-обра\-зо\-ва\-ний также используют авторы работы~\cite{MDIWT}. Подход, схожий 
с~применением вейв\-лет-пре\-обра\-зо\-ва\-ния для обработки признаков входного сигнала, 
применяется в~работе~\cite{WINNet}.

Перечисленные выше подходы используют вейв\-лет-пре\-обра\-зо\-ва\-ния для улучшения 
извлечения скрытыми слоями сети более устойчивых признаков из изображения, но не 
используются в~построении функции ошибки. Если рассматривать\linebreak задачу повышения 
разрешения изображения, то существуют работы, где функция ошибки при обуче\-нии 
модели основывается на применении преобразовании Хаара. Так, в~работе~\cite{DWB} 
сеть\linebreak изучает \mbox{матрицы} коэффициентов, полученные преобразованием Хаара, которые 
необходимо добавить к~вейв\-лет-мат\-ри\-цам входного изображения для уточнения его 
границ. Данный подход уже использует обратное вейв\-лет-пре\-обра\-зо\-ва\-ние для 
получения итогового изображения.

Также существуют подходы, использующие специальные функции ошибок, которые 
учитывают значения скрытых пространств слоев нейронной сети. Для решения задачи 
удаления фона на изображении авторы работы~\cite{IS_NET} разработали собственную 
U-Net-подобную архитектуру~--- IS-Net, а также функцию ошибки для ее обуче\-ния, 
которая требует от глубоких слоев модели строить результирующую матрицу маски 
главного объекта в~разных масштабах, далее результаты работы всех слоев 
объединяются для построения финальной маски объекта.

На основе идей повышения разрешения изоб\-ра\-же\-ния с~помощью предсказываемых матриц 
высокочастотных коэффициентов~\cite{DWB} и~по\-стро\-ения функции ошибки, 
учи\-ты\-ва\-ющей скрытое со\-сто\-яние слоев модели~\cite{IS_NET}, предлагается подход 
к~обуче\-нию архитектур, подобных ResNet~\cite{ResNet}, без не\-об\-хо\-ди\-мости до\-бав\-ле\-ния 
обучаемого декодера для преобразования скрытого пространства модели в~изоб\-ра\-же\-ние.


\section{Предлагаемый подход}

\subsection{Модификация архитектуры классификации}

Классические архитектуры для решения задачи классификации изображений, как 
правило, состоят из блоков, содержащих сверточные слои, слои нормализации 
и~операций объединения~\cite{POOLOPS}. Операции объединения максимумов (Max 
Pooling) вычисляют максимальное значение для предсказанных матриц признаков 
предыдущими сверточными слоями и~используют их для создания матриц признаков 
с~пониженной дискретизацией. Эти операции используются в~архитектуре 
ResNet~\cite{ResNet} и~позволяют извлекать наиболее устойчивые признаки из 
предыдущих предсказаний при уменьшении их размера в~2~раза. Последними слоями 
в~архитектурах для решения задач классификации служат полносвязные слои, которые 
строят распределение вероятностей классов, содержащихся на входном изображении. 
Для построения шумоподавляющей архитектуры сети, рассматриваемой в~данной 
работе, слои классификации не используются и~удаляются из применяемых моделей 
классификации. Удаление последних слоев из модели ResNet делает ее 
полносверточной архитектурой~\cite{FULLYCONV}, и~она становится инвариантной к~размеру входного изоб\-ра\-же\-ния.

Из выбранной архитектуры для задачи классификации рассматриваются промежуточные 
мат\-ри\-цы признаков, полученные после применения каж\-до\-го из сверточных блоков. 
Обозначим набор данных значений $P \hm= \{p_{i}\}_{i=1}^{5}$. К~каждой матрице 
признаков $p_{i}$ применим сверточный слой $\mathrm{Conv}_{i}$ с~размером ядра $\mathrm{dim}\,(K_i) 
\hm= 9 \times C_{i} \times 3 \times 3$ при $i \hm\leq 2$ или $\mathrm{dim}\,(K_i) \hm= 9 \times 
C_{i} \times 1 \times 1$ для остальных уровней блоков, где $C_{i}$~--- число 
каналов у~выходной матрицы соответствующего блока модели. Выбор разного размера 
ядер сверточных слоев обуслов\-лен различной размерностью мат\-риц признаков. 
У~мат\-риц с~более глубоких уровней размерность ниже. После применения сверточных 
слоев к~набору значений~$P$ получается новый набор $F \hm= \{f_{i}\}_{i=1}^5$, где 
$f_i\hm = \mathrm{Conv}_i(p_i)$. Дополнительно к~сверточным слоям $\mathrm{Conv}_{i}$ был добавлен 
механизм канального и~пространственного внимания CBAM (Convolutional Block Attention Module)~\cite{CBAMCB}.  
Модифицированную архитектуру с~параметрами внутренних слоев $\mathnormal{w}$ 
обозначим $\Phi(\tilde{I}, {w})$.

Схема предлагаемой архитектуры нейронной сети~$\Phi$ для предсказания чистого 
изображения~$I$ по входному изображению с~шумом~$\tilde{I}$ изображена на 
рис.~\ref{fig:wpn_scheme}.



\subsection{Вейвлет-преобразование Хаара}

Вейвлет-преобразование Хаара (ВПХ) позволяет декомпозировать сигнал на две 
компоненты: аппроксимацию сигнала и~детализацию сигнала~\cite{WAVELETS_PAPER}. 
Для получения следующего уровня разложения ВПХ применяется к~полученному 
аппроксимационному сигналу. При условии, что первоначальный дискретный сигнал 
представлен массивом их $2^n$~чисел, можно рекурсивно применить дискретное ВПХ~$n$~раз 
к~данному сигналу, получая $n$-крат\-ное применение дискретного вейв\-лет-пре\-обра\-зо\-ва\-ние Хаара.

При рассмотрении одномерного сигнала в~виде набора значений $F \hm= \{ f_i \}_{i = 1}^{N}$ коэффициенты Хаара для аппроксимации~$a_{i}$ и~детализации~$d_{i}$ 
вычисляются по формулам:
\begin{equation*}
\label{eq:raw_haar}
a_{i} = \fr{f_{2i} + f_{2i + 1}}{\sqrt{2}}\,;\enskip d_{i} = \fr{f_{2i} - f_{2i + 
1}}{\sqrt{2}}\,,\enskip  i \in \left[1, \fr{N}{2}\right].
\end{equation*}

В случае использования БВПХ формулы для 
вычисления коэффициентов будут иметь сле\-ду\-ющий вид:
\begin{equation*}
\label{eq:fast_haar}
a_{i} = \fr{f_{2i} + f_{2i + 1}}{2}\,;\ d_{i} = \fr{f_{2i} - f_{2i + 1}}{2}\,,\ 
i \in \left[1, \fr{N}{2}\right].
\end{equation*}
%
Данная модификация преобразования является вычислительно более быстрым по 
сравнению с~оригинальным.

Обратное БВПХ для получения первоначальных значений сигнала из коэффициентов 
БВПХ можно получить по формуле
\begin{equation*}
\label{eq:inv_fast_haar}
f_{i} = a_{\lfloor {i}/{2}\rfloor} + (-1)^{i - 1 \bmod{2}} 
d_{\lfloor {i}/{2}\rfloor}.
\end{equation*}

Так как в~данной работе происходит обработка\linebreak цифровых изображений, то необходимо 
использовать БВПХ для дискретного двумерного сигнала. В~случае двумерного 
сигнала БВПХ \mbox{сначала} применяется к~строкам матрицы изображения~$I$. Обозначим 
матрицы получаемых коэффициентов~$a_j^{\mathrm{row}_i}$ и~$d_{j}^{\mathrm{row}_i}$, а~далее 
повторно применим БВПХ к~столбцам матриц, полученных после первого разложения. 
В~результате данных преобразований будут получены матрицы коэффициентов
$A \hm= \{a_{i,j}\}_{i=1, j=1}^{H, W}$, $H \hm= \{h_{i,j}\}_{i=1, j=1}^{H, W}$,
$V \hm= \{v_{i,j}\}_{i=1, j=1}^{H, W}$, $D \hm= \{d_{i,j}\}_{i=1, j=1}^{H, W}$. 
Матрица~$A$ содержит ин\-фор\-мацию об аппроксимации двумерного сигнала,\linebreak мат\-ри\-цы 
$H$, $V$ и~$D$~--- о~горизонтальных, вертикальных и~диагональных различиях 
значений со\-от\-вет\-ст\-венно.

\subsection{Применение вейвлет-преобразования Хаара для~обучения сети}

При применении $n$-кратного ВПХ к~квадратному изображению размером $N \times N$ 
матрицы коэффициентов будут иметь размер ${N}/2^{n} \times 
{N}/{2^{n}}$, \mbox{поскольку} с~каждым применением ВПХ к~изоб\-ра\-же\-нию или 
последующей аппроксимационной мат\-ри\-це размер будет уменьшаться ровно в~2~раза.\linebreak\vspace*{-12pt}

\pagebreak

\end{multicols}

\begin{figure*} %fig2
\vspace*{1pt}
      \begin{center}
     \mbox{%
\epsfxsize=142.115mm 
\epsfbox{kov-2.eps}
}
\end{center}
\vspace*{-3pt}
    \Caption{Схема предлагаемой архитектуры модели по\-дав\-ле\-ния шума на 
изоб\-ра\-же\-нии: \textit{1}~--- мат\-ри\-цы коэффициентов $n$-кратного ВПХ;
\textit{2}~--- передача выходных значений блока; \textit{3}~--- конкатенация мат\-риц по каналам}
    \label{fig:wpn_scheme}
    \vspace*{3pt}
\end{figure*}

\begin{multicols}{2}

\noindent 
Применяя ВПХ к~многоканальному изображению, коэффициенты надо рассчитывать 
для каждого канала отдельно. Если объединить разложения для всех каналов 
изображения, получится матрица размера $12 \times {N}/{2} \times 
{N}/{2}$, содержащая в~себе конкатенацию матриц~$A$, $H$, $V$ и~$D$, при 
условии, что используемое изображение~$I$ имеет три канала и~размер $N \times 
N$, где~$N$ представляет собой некоторую степень~2, причем эта степень $q \hm\ge 5$.

Во время обучения модель учится предсказывать изоб\-ра\-же\-ние без шума~$I$ по 
входной матрице изоб\-ра\-же\-ния~$\tilde{I}$. Для сокращения параметров сети 
предлагается учить слои сети предсказывать матрицы~$f_i$, равные объединениям 
матриц коэффициентов деталей $(H^i, V^i, D^i)$ $i$-крат\-но\-го БВПХ, примененного к~$I$. 
Данная оптимизация позволяет отказаться от построения слоев декодировки 
результирующего изображения из скрытого состояния сети.

Для построения итогового изображения по высокочастотным коэффициентам необходимо 
применять обратное БВПХ к~соответствующим матрицам коэффициентов. Обозначив 
прямое БВПХ как~DWT, а~обратное~--- IWT, формулы для расчета матриц 
коэффициентов можем записать в~виде

\noindent
\begin{equation*}
A^i, H^i, V^i, D^i = \mathrm{DWT}\left(A^{i-1}\right),\enskip A^0 = I\,,
\end{equation*}
\begin{equation*}
A^i =\mathrm{IWT}\left(A^{i-1}, H^{i-1}, V^{i-1}, D^{i-1}\right).
\end{equation*}

Таким образом, нейронная сеть $\Phi$ будет учиться предсказывать наборы 
коэффициентов БВПХ $\{H^i, V^i, D^i\}_{i=1}^5$, но для восстановления 
изображения $I$ необходима аппроксимация изображения \mbox{5-крат}\-но\-го применения ВПХ~--- 
$A^5$, поскольку она необходима для вычисления~$A^4$. Для получения $A^5$ предлагается применить $5$-кратное БВПХ ко входному изображению с~шумом~$\tilde{I}$ 
и~использовать его коэффициенты приближения изображения~$\tilde{A}^5$. Матрица~$\tilde{A}^5$ будет близка к~матрице приближения чистого 
изображения~$A^5$, поскольку с~каждым применением БВПХ уровень шума в~каждом 
последующем приближении~$\tilde{A}^i$ снижается~\cite{WAVELETS_APPROX}, при этом 
информация о шуме~$\alpha$ будет содержаться в~матрицах $\tilde{H}^i$, 
$\tilde{V}^i$ и~$\tilde{D}^i$~\cite{WAVELETS_NOISE}.

Для сокращения вычислений при расчете мат\-ри\-цы~$\tilde{A}^5$ необходимо применять 
БВПХ только к~коэффициентам приближения~$\{\tilde{A}^q\}_{q=1}^4$. Так, 
коэффициенты матрицы~$\tilde{A}^q$ будут вычисляться по формуле:
\begin{multline*}
\tilde{A}_{i,j}^q = \fr{\tilde{A}_{2i, 2j}^{q-1} + \tilde{A}_{2i, 2j+1}^{q-1} + 
\tilde{A}_{2i+1, 2j}^{q-1} + \tilde{A}_{2i+1, 2j+1}^{q-1}}{4},\\
 i,j \in \left[1, \fr{N}{2^q}\right].
\end{multline*}

Если выразить $\tilde{A}^q$ через значения пикселей изоб\-ра\-же\-ния~$\tilde{I}$, 
формула примет вид:
\begin{equation}
\label{eq:fulltai}
\tilde{A}_{i,j}^q = \sum\limits_{m=1}^{2q}\sum\limits_{s=1}^{2q}\fr{\tilde{I}_{2qi+m, 
2qj+s}}{4q^2},\enskip i,j \in \left[1, \fr{N}{2^q}\right].
\end{equation}

Выражение~(\ref{eq:fulltai}) совпадает с~формулой вычисления пикселя при 
масштабировании изображения с~коэффициентом ${1}/{2^q}$ с~по\-мощью метода 
передискретизации с~использованием отношения площади пикселя. Данный метод 
интерполяции изображения называется {Area} в~терминологии библиотеки 
обработки изображений OpenCV~\cite{OPENCV_LIB}. Матрицу~$\tilde{A}^5$ можно 
напрямую вычислить, применяя данный метод интерполяции к~изображению~$\tilde{I}$.


\subsection{Сравнение с~существующими подходами к~внедрению вейвлет-преобразований в~архитектуры шумоподавляющих моделей}

Архитектура MWCNN, разработанная авторами 
работы~\cite{MWCNN}, основана на применении вейв\-лет-пре\-обра\-зо\-ва\-ний для понижения 
размерности карт признаков при увеличении числа каналов. Это позволило 
отказаться от операций пулинга (Pooling) при проектировании модели. Модель 
построена\linebreak на последовательном применении ВПХ и~сверточных слоев к~коэффициентам 
ВПХ. В~качестве операций обратного пулинга или повышения раз\-мер\-ности карт 
признаков авторами применяется \mbox{обратное} ВПХ. Также в~модели применяется сквозная 
передача признаков из кодирующей части модели в~декодирующую, что делает ее 
схожей в~общем виде с~классической архитектурой U-Net.

Авторы работы~\cite{MDIWT} применяют вейв\-лет-пре\-обра\-зо\-ва\-ния для выделения 
высокочастотной пространственной информации сигнала. К~выделенной 
высокочастотной компоненте применяется блок сверточных слоев для улучшения 
вы\-со\-ко\-час\-тот\-ных признаков сигнала.

На основе идеи разложения сигнала на компоненты с~помощью вейв\-лет-пре\-обра\-зо\-ва\-ний 
основан подход, описанный в~работе~\cite{WINNet}. Авторы \mbox{применяют} 
преобразование с~обучаемым ядром, которое позволяет в~процессе обучения модели 
эффективно разделять сигнал на две компоненты. Данные преобразования по аналогии с~работой~\cite{MDIWT} применяются вместе со сверточными слоями для извлечения 
признаков из сигнала.

В отличие от подходов~\cite{MWCNN, MDIWT, WINNet} пред\-ла\-га\-емая архитектура не 
использует ВПХ для разложения сигнала изображения на компоненты с~\mbox{целью} 
последующей обработки сверточными слоями. Обратное ВПХ используется для 
повышения разрешения изображения по предсказанным коэффициентам ВПХ аналогично 
подходу~\cite{DWB}. Но используется не однократное ВПХ, а~$5$-крат\-ное, что 
позволяет преобразовать изображение размера $32 \times 32$ в~$256 \times 256$. 
Таким образом, по входному зашумленному изображению модель предсказывает 
коэффициенты для каждого уровня ВПХ, позволяя по ним восстанавливать изображение 
исходного размера без шума. Использование описанного способа получения 
результирующего изображения заменяет применение декодирующей части U-Net 
подобных архитектур~\cite{MWCNN, MDIWT}.

\section{Эксперименты по обучению моделей}

\subsection{Обучающий набор данных}

Обучающая выборка состояла из объединения нескольких наборов данных. Для 
обучения на изоб\-ра\-же\-ни\-ях с~шумом, полученных с~реальных сенсоров камер, 
использовался открытый набор данных Smartphone Image Denoising Dataset 
(SIDD)~\cite{SIDD_2018_CVPR}. Набор SIDD предоставляет реальные зашумленные 
изображения и~соответствующие им чистые изображения. Обучающая часть набора 
содержит 320~изображений высокого разрешения, а~проверочная часть содержит 
1280~пар изображений, имеющих размер $256\times 256$~точек. Съемка проводилась авторами на 
5 мобильных устройств с~КМОП-сен\-со\-рами.

Также для обучения использовались изображения из наборов Set5, Set14, Sun-Hays 
80~\cite{FOR_ADD_NOISE_DATASETS} и~DIV2K~\cite{DIV2KDataset}. Данные наборы 
содержат изображения в~двух масштабах и,~как правило, используются для обуче\-ния 
моделей, повышающих разрешение изображения. Так как изображения в~наборах не 
содержат шума~\cite{FOR_ADD_NOISE_DATASETS}, они могут использоваться в~задаче 
обучения шумоподавляющих моделей. Авторы работ~\cite{MWCNN, MDIWT} 
используют перечисленные наборы для обучения моделей подавлять шум на 
изображениях. Для получения изображений с~шумом авторы до\-бав\-ля\-ют к~мат\-ри\-цам 
дополнительный гауссовский шум. Таким образом получаются пары изображений для 
обучения шумоподавляющих нейронных сетей.

В проводимых экспериментах к~чистым изоб\-ра\-же\-ни\-ям из 
наборов~\cite{FOR_ADD_NOISE_DATASETS, DIV2KDataset} попиксельно до\-бав\-лял\-ся 
дополнительный гауссовский шум с~фиксированным параметром математического 
ожидания, равным нулю, и~изменяемым значением среднеквадратичного отклонения 
$\sigma$. При каждой загрузке изображения параметр~$\sigma$ выбирался случайным 
образом из равномерного распределения $R(\sigma|a, b)$ с~диапазоном $a \hm= 0$, $b \hm= 
90$. Шум для каждого пикселя изображения семплировался независимо от остальных 
пикселей. Получение изображения с~шумом приводится в~формуле:
\begin{multline*}
\tilde{I}_{i,j} = I_{i,j} + \alpha_{i,j},\enskip \alpha_{i,j} \sim \mathit{N}(0, \sigma|\mathit{R}(0, 90)),\\ 
i \in [1, H],\ j \in [1, W].
\end{multline*}

Для тестирования работы обученных моделей использовалась валидационная часть 
набора данных SIDD, а~также набор BSD68~\cite{BSD_set} с~заранее наложенным 
шумом для корректного сравнения с~результатами работ~\cite{MWCNN, MDIWT, WINNet}. Дополнительно модель тестировалась на изображениях из набора The 
Darmstadt Noise Dataset (DND)~\cite{DNDSet}.


\subsection{Исследуемые архитектуры}

Предлагаемая архитектура, использующая предсказания коэффициентов матриц ВПХ, 
в~приведенных исследованиях обозначается как Wavelets Prediction Network~(WPNet), 
а~указанная в~скобках архитектура используется в~качестве базовой мо\-дели.

Для сравнения результатов дополнительно строился декодер, использующийся 
в~классической архитектуре U-Net~\cite{UNET_ORIGINAL}. В~оригинальной реализации 
декодера использовались два варианта слоев для повышения разрешения: слои 
деконволюции и~операции билинейной интерполяции с~последующим применением 
сверточных слоев. В~экспериментах обучались оба варианта декодеров. В~качестве 
кодировщика для модели U-Net была выбрана архитектура ResNet10.

Для обучения моделей U-Net использовалась функция ошибки 
$\mathcal{L}_{\mathrm{MIX}}$~\cite{MIX_LOSS}.

\subsection{Параметры обучения}

Архитектура модели и~код обучения реализованы на фреймворке глубокого обучения 
PyTorch~\cite{PYTORCH_LIB}. Реализации архитектур моделей классификации для 
интеграции в~предлагаемый подход использовались из библиотеки 
timm~\cite{TIMMLIB}.

Модели обучались на случайных срезах из изоб\-ра\-же\-ний размером $256 \times 256$ 
пикселей. Вырезанные части изображений конвертировались в~цветовое пространство 
YC$_{\mathrm{r}}$C$_{\mathrm{b}}$, где наибольший вклад в~детализацию изображения вкладывает компонента 
изображения~Y, по которой происходит оценка качества работы моделей 
в~работе~\cite{UFORMER}. Для обучения параметров модели ${w}$ 
применялся метод стохастической оптимизации с~адаптивным параметром скорости 
обучения AdaSmooth~\cite{ADASMOOTH}. Начальное значение параметра ско\-рости 
обучения задавалось равным~0,001. В~качестве функции ошибки использовалась 
$\mathcal{L}_{\mathrm{MIX}}$~\cite{MIX_LOSS}.

Модель запускалась на входном изображении и~на преобразованных изображениях. 
В~качестве преобразований использовались повороты на~90$^\circ$, 180$^\circ$ и~270$^\circ$, 
а~также отражения изображения по вертикали и~горизонтали. После применения модели к~этим изображениям использовались соответствующие обратные преобразования. 
Итоговое изображение получалось после усреднения результатов работы модели на 
преобразованных матрицах.

Для валидации использовалась метрика пикового отношения сигнала к~шуму PSNR (peak signal-to-noise ratio). 
Обучение модели останавливалось при выходе графика результата валидационной 
метрики на плато.

\begin{figure*}[b] %fig3
\vspace*{1pt}
      \begin{center}
     \mbox{%
\epsfxsize=134.1mm 
\epsfbox{kov-3.eps}
}
\end{center}
\vspace*{-9pt}
    \Caption{Пример предсказанных моделью коэффициентов $4$-кратного БВПХ}
    \label{fig:wavelets_prediction}
\end{figure*}

Эксперименты проводились на вычислительной машине с~графическим ускорителем 
Nvidia RTX~4090, процессором Intel i9-10920X и~объемом оперативной памяти 64~ГБ. 
При размере входных изображений $256 \times 256$ в~процессе обучения 
использовались пакеты размером~128 (batch size).

\section{Результаты}

Предлагаемая архитектура, использующая предсказания коэффициентов матриц ВПХ, 
в~приведенных результатах обозначается как WPNet, 
а~указанная в~скобках архитектура используется в~качестве базовой модели.

Для сравнения результатов использовались мет\-ри\-ки пикового отношения сигнала к~шуму (PSNR) и~структурного сходства изображений (SSIM).

Оценка качества подавления шума оценивалась как на реальных изображениях из 
валидационной части набора SIDD~\cite{SIDD_2018_CVPR}, содержащих шум, так и~на 
изображениях из набора BSD68~\cite{BSD_set} с~добавочным гауссовским шумом.

При оценке отклонения предсказываемых моделью коэффициентов ВПХ от эталонных 
значений использовалась мет\-ри\-ка Smooth $L_1$~\cite{SMOOTHL1}. Для оценки 
строились сред\-ние значения и~сред\-не\-квад\-ра\-тич\-ные отклонения по множеству всех 
рас\-смат\-ри\-ва\-емых изображений из набора. Данные, по\-стро\-ен\-ные на валидационной 
части набора SIDD приведены в~табл.~1, все значения 
умножены на~$10^4$. В~табл.~1 не приведены 
коэффициенты аппроксимации~$A$,\linebreak\vspace*{-12pt}

%\begin{table*}\small %tabl1

\vspace*{-3pt}

\begin{center}
\parbox{79mm}{{{\tablename~1}\ \ \small{Сравнение отклонения коэффициентов БВПХ модели WPNet
}}

}

\vspace*{2ex}


{\small \tabcolsep=4pt
\begin{tabular}{ |l r|c|c|c|c|c| }
\hline
 \multicolumn{2}{|c|}{Коэффициенты} & 
\multicolumn{5}{c|}{Уровень модели} \\ 
\cline{3-7}
 \multicolumn{2}{|c|}{БВПХ}  & 1 & 2 & 3 & 4 & 5 \\ 
 \hline
$H$ & $\mathbb{E}$ & 2,105 & 1,132 & 0,589 & 0,176 & 0,0424 \\
 & STD & 2,175 & 1,395 & 0,583 & 0,175 & 0,0426 \\ 
 \hline
 $V$ & $\mathbb{E}$ & 2,108 & 1,393 & 0,586 & 0,174 & 0,0417 \\
 & STD & 2,177 & 1,394 & 0,580 & 0,172 & 0,0421 \\ 
 \hline
$D$ & $\mathbb{E}$ & 1,131 & 0,939 & 0,474 & 0,165 & 0,0446 \\
 & STD & 1,183 & 0,955 & 0,471 & 0,164 & 0,0446 \\ 
 \hline
\end{tabular}
}
\end{center}
%\end{table*}

\noindent
 поскольку они строятся по входному изображению 
в~соответствии с~формулой~(\ref{eq:fulltai}). Коэффициенты на первых уровнях 
модели имеют большее отклонение, чем выходы более глубоких слоев, поскольку 
результат более глубоких уровней модели получен применением большего числа 
слоев. Но в~предлагаемой архитектуре результат напрямую строится из всех уровней 
коэффициентов ВПХ. И~коэффициенты первых применений ВПХ меньше влияют на 
предсказываемое изображение, чем коэффициенты дальнейших применений ВПХ.



Пример предсказанных матриц с~коэффициентами $n$-крат\-но\-го БВПХ приведен на 
рис.~\ref{fig:wavelets_prediction}.

\pagebreak

\end{multicols}


\setcounter{table}{1}
\begin{table*}\small %tabl2
\begin{center}
\parbox{400pt}{\Caption{Сравнение качества и~размера предлагаемой архитектуры с~другими 
моделями на наборе данных BSD68}
}

\label{tab:comparison_BSD68}
\vspace*{2ex}

\begin{tabular}{|l|l|c|l|c|l|c|c|}  %\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{
 \hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Название модели}} 
& \multicolumn{2}{c|}{$\sigma = 15$} & 
\multicolumn{2}{c|}{$\sigma = 25$} & \multicolumn{2}{c|}{$\sigma = 50$} &
\tabcolsep=0pt\begin{tabular}{c} 
Число\\ параметров \end{tabular} \\ 
\cline{2-7}
 & PSNR & SSIM & PSNR & SSIM & PSNR & SSIM & модели $\times 10^{6}$\\
 \hline
 BM3D~\cite{BM3D} & 31,08 & 0,872 & 28,57 & 0,802 & 25,62 & 0,687 & --- \\
 % \hline
 DnCNN~\cite{DnCNN} & 31,73 & 0,891 & 29,23 & 0,828 & 26,23 & 0,719 & 0,56 \\ 
%\hline
 MWCNN~\cite{MWCNN} & 31,86 & 0,895 & 29,41 & 0,836 & 26,53 & 0,737 & 24,92\hphantom{9} \\ 
%\hline
 MWDCNN~\cite{MDIWT} & 31,77 & --- & 29,28 & --- & 26,29 & --- & 5,24 \\ 
 %\hline
 WINNet~\cite{WINNet} & 31,7 & --- & 29,24 & --- & 26,31 & --- & 0,17 \\ 
% \hline
 U-Net(ResNet10) & 31,26 & 0,898 & 30,29 & 0,872 & 29,06 & 0,83\hphantom{9} & 6,47 \\ 
% \hline
 U-Net(ResNet10) + Bilinear & 32,16 & 0,906 & 30,79 & 0,874 & 29,3 & 0,827 & 7,28 \\ 
% \hline
 \textbf{WPNet(MobileNetV2)} & 31,65 & 0,894 & 30,2 & 0,861 & 28,6 & 0,81\hphantom{9} & 1,83 \\ 
 %\hline
 \textbf{WPNet(ResNet10)} & 31,5 & 0,901 & 30,33 & 0,87\hphantom{9} & 28,87 & 0,824 & 4,99 \\ 
 \hline
\end{tabular}
\end{center}
%\end{table*}
%\begin{table*}\small %tabl3
\begin{center}
\parbox{330pt}{\Caption{Сравнение качества и~размера предлагаемой архитектуры с~другими 
моделями на валидационном наборе SIDD}
}

\label{tab:comparison_sidd}
\vspace*{2ex}

\begin{tabular}{|l|l|l|l|l|c| }
 \hline
\multicolumn{1}{|c|}{\raisebox{-6pt}[0pt][0pt]{Название модели}} & \multicolumn{2}{c|}{SIDD} & 
\multicolumn{2}{c|}{DND} & \tabcolsep=0pt\begin{tabular}{c} 
Число\\ параметров \end{tabular}\\ 
\cline{2-5}
 & {PSNR} & {SSIM} & {PSNR} & {SSIM} & модели $\times 10^{6}$\\
\hline
 BM3D~\cite{BM3D} & 25,65 & 0,685 & 34,51 & 0,851 & --- \\
 % \hline
 DnCNN~\cite{DnCNN} & 35,13 & 0,896 & 37,03 & 0,932 & 0,56 \\ 
 %\hline
 U-Former~\cite{UFORMER} & 39,89 & 0,96 & 39,98 & 0,955 &  26,87\hphantom{9}  \\ 
 %\hline
 U-Net(ResNet10) & 37,65 & 0,897 & 37,62 & 0,947 & 6,47 \\ 
 %\hline
 U-Net(ResNet10)\;+\;Bilinear & 37,79 & 0,891 & 38,03 & 0,946 & 7,28 \\ 
 %\hline
 \textbf{WPNet(MobileNetV2)} & 36,77 & 0,913 & 36,14 & 0,937 & 1,83 \\ 
 %\hline
 \textbf{WPNet(ResNet10)} & 37,28 & 0,927 & 36,6 & 0,944 & 4,99 \\
 \hline
\end{tabular}
\end{center}
\end{table*}

\begin{multicols}{2}

На наборе BSD68 с~добавочным шумом предлагаемая модель сравнивалась 
с~результатами широко распространенных работ BM3D~\cite{BM3D}, DnCNN~\cite{DnCNN}, 
а также с~подходами, использующими вейв\-лет-пре\-обра\-зо\-ва\-ния~\cite{MWCNN, MDIWT, 
WINNet}. Результаты сравнения на изображениях с~разным параметром $\sigma$ 
добавочного шума приведены в~табл.~2, где шум 
генерировался из нормального распределения $\mathit{N}(0, \sigma)$. Для подхода 
BM3D не указывается число параметров, поскольку он не основан на использовании 
обучаемых нейронных сетей.



Для сравнения на наборе SIDD использовались подходы~\cite{BM3D, DnCNN} 
и~современная архитектура, основанная на механизме самовнимания U-
Former~\cite{UFORMER}. Авторы работ~\cite{MWCNN, MDIWT, WINNet} не проводили 
исследований по обучению и~тестированию
моделей на наборе SIDD. Результаты сравнения качества подавления шума на 
изображениях из набора SIDD приведены в~табл.~3.



Также оценивалась производительность предлагаемой архитектуры в~сравнении 
с~другими архитектурами, использующими ВПХ, и~с~U-Net вариантами модели. Замеры 
времени работы моделей\linebreak производились на процессоре Intel i9-10920X. Каж\-дая 
модель запускалась 100~раз на изображении раз-\linebreak\vspace*{-12pt}



%\begin{table*}\small %tabl4
\begin{center}
\parbox{58mm}{{{\tablename~4}\ \ \small{Сравнение скорости работы предлагаемой архитектуры с~другими моделями
}}

}

\label{tab:time_comparison}
\vspace*{2ex}

{\small 
\tabcolsep=12pt
\begin{tabular}{ |l|c|}
\hline
\multicolumn{1}{|c|}{Название модели} & Время, мс \\
\hline
{MWCNN~\cite{MWCNN}} & 109\\
{MWDCNN~\cite{MDIWT}} & 292\\
{WINNet~\cite{WINNet}} & 2297\hphantom{9}\\ 
U-Net (ResNet10) & 72\\
WPNet (ResNet10)& 56\\
\hline
\end{tabular}
}
\end{center}
%\end{table*}

\vspace*{6pt}



\noindent
мером $256 \times 256$, и~время 
запусков усреднялось. Для запуска тестов использовалась версия~2.2.1 фреймворка 
PyTorch и~операционная система Ubuntu 22.04. Результаты сравнения приведены 
в~табл.~4. По результатам сравнения предлагаемая 
архитектура показала меньшее время работы, чем аналогичная U-Net-по\-доб\-ная 
архитектура, и~превзошла по ско\-рости работы модели~\cite{MWCNN, MDIWT, WINNet}.


Полученные модели достигают схожего качества в~сравнении с~современными 
архитектурами\linebreak при меньшем чис\-ле па\-ра\-мет\-ров. При сравнении с~архитектурами, 
использующими вейв\-лет-пре\-обра\-зо\-ва\-ния~\cite{MWCNN, MDIWT, WINNet}, удалось 
добиться лучшего качества
подавления до\-ба\-воч\-но\-го шума. Если рассматривать пред\-ла\-га\-емый подход 
к~декодированию пред\-ска\-зан\-ных признаков в~изоб\-ра\-же\-ние, достигается качество, 
схожее с~использованием де\-ко\-ди\-ру\-ющей час\-ти архитектуры U-Net.

\section{Заключение}

Реализованный подход позволяет строить архитектуру шумоподавляющей сети из 
модифицированной модели для задачи классификации. При таком построении нет 
необходимости использовать слои для декодирования скрытого пространства, 
построенного кодировщиком входного изображения, что позволяет сократить число 
параметров модели. Обученные модели демонстрируют высокую скорость обработки 
изображений при достижении качества подавления шума, сопоставимого с~современными подходами.

Программный код с~реализацией подхода и~запуска обучения предлагаемой модели 
содержится в~GitHub-ре\-по\-зи\-то\-рии по следующей URL-ссыл\-ке: 
{\sf https://github.com/AlexeySrus/WPNet}.

{\small\frenchspacing
 { %\baselineskip=10.6pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
    \bibitem{UNET_ORIGINAL}
\Au{Ronneberger~O., Fischer~P., Brox~T.}
    U-Net: Convolutional networks for biomedical image segmentation~// Medical 
Image     Computing and Computer-Assisted Intervention Proceedings.~--- Cham: 
Springer International Publishing, 2015. P.~234--241.

    \bibitem{UNETS_COMPARISON}
    \Au{Komatsu~R., Gonsalves~T.} Comparing U-Net based  models
    for denoising color images~// AI, 2020. Vol.~1. Iss.~4. P.~465--486. doi:  10.3390/ai1040029.

    \bibitem{IMAGE_NOISE_CONDITIONS}
    \Au{Hasinoff~S.\,W.} Saturation (imaging)~// Computer vision: A~reference
guide.~--- Boston, MA, USA: Springer, 2014. P.~699--701. doi: 10.1007/978-0-387-31439-6\_483.
    
    \bibitem{SSIM} %4
    \Au{Wang~Z., Bovic~A., Sheikh~H., Simoncelli~E.}
    Image quality assessment: From error visibility to structural similarity~//
    IEEE T. Image Process., 2004. Vol.~13. Iss.~4. P.~600--612. 
doi: 10.1109/TIP.2003.819861.
    
    \bibitem{MIX_LOSS}
    \Au{Zhao~H., Gallo~O., Frosio~I.,  Kautz~J.}
    Loss functions for image restoration with neural networks~// IEEE
    Transactions Computational Imaging, 2017. Vol.~3. Iss.~1. P.~47--57. 
doi: 10.1109/TCI.2016.2644865.
    
    \bibitem{CBAMCB} %6
    \Au{Woo~S., Jongchan~P., Joon-Young~L., In-So~K.}
    CBAM: Convolutional block attention module.~--- Cornell University, 2018. 
17~p.  arXiv:1807.06521. 
    
    \bibitem{CBAM_USAGE}
    \Au{Jiang~J., Xiangming~H., Zhao~Y.,  Xu~X., Cui~Y.}
    SDAUNet: A~simple dual attention mechanism UNet for mixed noise removal~// 
IET Image Process., 2023. Vol.~17. Iss.~13. P.~3884--3896. doi: 
10.1049/IPR2.12905.
    
    \bibitem{MWCNN} %8
    \Au{Liu~P., Zhang~H., Zhang~K.,  Lin~L., Zuo~W.}
    Multi-level wavelet-CNN for image restoration~// IEEE/CVF Conference 
on Computer Vision and Pattern Recognition Workshops Proceedings.~--- Los Alamitos, 
CA, USA: IEEE Computer Society, 2018. P.~886--895. doi: 
10.1109/CVPRW.2018.00121.
    
    \bibitem{WaveletPooling} %9
    \Au{Batziou~E., Ioannidis~K., Patras~I., Vrochidis~S., Kompatsiaris~I.} Low-light image 
enhancement based on U-Net and Haar wavelet pooling~//  MultiMedia modeling.~--- Cham: Springer Nature Switzerland, 2023. P.~510--522.
 
    \bibitem{MDIWT}
    \Au{Tian~C., Zheng~M., Zuo~W., Zhang~B., Zhang~Y., Zhang~D.}
    Multi-stage image denoising with the wavelet transform~// Pattern
    Recogn., 2023. Vol.~134. Art.~109050. doi: 
10.1016/j.patcog.2022.109050.
  
    \bibitem{WINNet} %11
    \Au{Huang~J.-J., Dragotti~P.\,L.} WINNet: Wavelet-inspired     invertible network for image denoising~//
     IEEE T.  Image Process., 2021. Vol.~31. P.~4377--4392.
    
    \bibitem{DWB} %12
    \Au{Guo~T., Mousavi~H., Vu~T.,  Monga~V.}  Deep wavelet prediction for image super-resolution~// 
 Conference on Computer Vision and Pattern Recognition Workshops 
Proceedings.~--- Los Alamitos, CA, USA: IEEE Computer Society, 2017. P.~1100--1109. 
doi: 10.1109/CVPRW.2017.148.
    
    \bibitem{IS_NET}
    \Au{Qin~X., Dai~H., Hu~X.,
Fan~D.-P., Shao~L., Van~G.}
    Highly accurate dichotomous image segmentation~// Computer vision.~--- Cham: Springer Nature Switzerland, 2022. P.~38--56.
    
    \bibitem{ResNet}
    \Au{He~K., Zhang~H., Ren~S.,  Sun~J.}
    Deep residual learning for image recognition~// Conference on 
Computer Vision and Pattern Recognition Proceedings.~--- Los Alamitos, CA, USA: IEEE 
Computer Society, 2016. P.~770--778. doi: 10.1109/CVPR.2016.90.
    
    \bibitem{POOLOPS}
    \Au{Scherer~D., Muller~A., Behnke~S.}
    Evaluation of pooling operations in convolutional architectures for object 
recognition~// Artificial neural networks.~--- Berlin, Heidelberg: 
Springer,   2010. P.~92--101. doi: 10.1007/978-3-642-15825-4\_10.
 
    \bibitem{FULLYCONV}
  \Au{Макаренко~А.\,В.} Глубокие нейронные сети: за\-рож\-де\-ние, 
становление,     современное состояние~// Проб\-ле\-мы управ\-ле\-ния, 2020. Т.~2. 
С.~3--19. doi: 10.25728/pu.2020.2.1.
  
    \bibitem{WAVELETS_PAPER} %17
    \Au{Буй~Т.\,Т.\,Ч., Спицын В.\,Г.} Разложение 
цифровых     изоб\-ра\-же\-ний с~по\-мощью двумерного дискретного вейв\-лет-пре\-обра\-зо\-ва\-ния и~быст\-ро\-го   преобразования \mbox{Хаара}~// Известия Томского 
политехнического университета, 2011. Т.~318. №\,5. С.~73--76.
    
    \bibitem{WAVELETS_APPROX} %18
    \Au{Павлов~А.\,Н.} Детектирование информационных сигналов на 
основе   реконструкции динамических сис\-тем и~дискретного вейв\-лет-пре\-обра\-зо\-ва\-ния~//\linebreak
 Известия  высших учебных заведений. Прикладная нелинейная 
динамика, 2008. Т.~16. №\,6. С.~3--17.

   \bibitem{WAVELETS_NOISE}
\Au{Пронькин~А.} Оценивание уровня шума в~составе изоб\-ра\-же\-ния с~использованием вейвлетов Хаара~// Труды 22-й Международной 
конференции по  компьютерной графике и~зрению.~---    М.: ИПМ им.\ М.\,В.~Келдыша, 2022.
 Т.~32. С.~442--448. doi: 
10.20948/graphicon-2022-442-448.
   
    \bibitem{OPENCV_LIB}
    \Au{Bradski~G.} The OpenCV Library~// Dr. Dobbs~J., 2000. Vol.~25. Iss.~11. P.~120--125.
    
    \bibitem{SIDD_2018_CVPR}
    \Au{Abdelhamed~A., Lin~S., Brown~M.\,S.} A~high-quality denoising dataset for smartphone cameras~// 
    IEEE/CVF Conference on Computer Vision and Pattern Recognition Proceedings.~--- Los Alamitos, 
CA, USA: IEEE Computer Society, 2018. P.~1692--1700.
    doi: 10.1109/CVPR.2018.00182.
    
    \bibitem{FOR_ADD_NOISE_DATASETS}
    \Au{Huang~J.-B., Singh~A., Ahuja~N.} 
Single     image super-resolution from transformed self-exemplars~// Conference 
on Computer Vision and Pattern Recognition.~--- Los Alamitos, CA, USA: 
IEEE Computer Society, 2015. P.~5197--5206.
    
    \bibitem{DIV2KDataset} %23
    \Au{Agustsson~E., Timofte~R.} NTIRE 2017 challenge 
on single    image super-resolution: Dataset and study~//  Conference 
on Computer Vision and Pattern Recognition Workshops Proceedings.~--- Los Alamitos, 
CA, USA: IEEE Computer Society, 2017. P.~1110--1121. doi: 
10.1109/CVPRW.2017.149.
    
    \bibitem{BSD_set} %24
    \Au{Martin~D., Fowlkes~C., Tal~D.,  Malik~J.}
    A~database of human segmented natural images and its application to 
evaluating
    segmentation algorithms and measuring ecological statistics~//  
8th  Conference (International) on Computer Vision Proceedings.~--- 
Piscataway, NJ, USA: IEEE, 2001. Vol.~2. P.~416--423. doi: 10.1109/ICCV.2001.937655.
    
    \bibitem{DNDSet} %25
    \Au{Plotz~T., Roth~S.} Benchmarking denoising 
algorithms  with     real photographs~// Conference on Computer Vision 
and Pattern Recognition Proceedings.~--- Los Alamitos, CA, USA: IEEE Computer Society, 
2017. P.~2750--2759. doi: 10.1109/CVPR.2017.294.
    
    \bibitem{PYTORCH_LIB} %26
    \Au{Paszke~A., Gross~S., Massa~F.,  Lerer~A.}
    PyTorch: An Imperative style, high-performance deep learning library~//
    Adv. Neur. Inf., 2019. Vol.~32. P.~8024--8035.
   
    \bibitem{TIMMLIB} %27
    \Au{Wightman~R.} PyTorch image models, 2019.
    {\sf  https://github.com/rwightman/pytorch-image-models}.
    
    \bibitem{UFORMER}
    \Au{Wang~Z., Cun~X., Bao~J., Zhou~W., Liu~J., Li~H.}
    Uformer: A~general U-shaped transformer for image restoration~// 
IEEE/CVF Conference on Computer Vision and Pattern Recognition Proceedings.~--- Los 
Alamitos, CA, USA: IEEE Computer Society, 2022. P.~17683--17693. doi: 
10.1109/CVPR52688.2022.01716/
    
    \bibitem{ADASMOOTH}
    \Au{Lu~J.} AdaSmooth: An adaptive learning rate method based on 
effective    ratio~// Sentiment analysis and deep learning.~--- Singapore: 
Springer Nature Singapore,   2023. P.~273--293.
    
    \bibitem{SMOOTHL1}
    \Au{Girshick~R.\,B.} Fast {R-CNN}.~--- Cornell University, 2015. 9~p.
arXiv:1504.08083. 
    
    \bibitem{BM3D} %31
    \Au{Dabov~K., Foi~A., Katkovnik~V.,  Egiazarian~K.}
    Image denoising by sparse 3-D transform-domain collaborative filtering~// 
IEEE T.  Image Process., 2007. Vol.~16. P.~2080--2095.
    
    \bibitem{DnCNN}
    \Au{Zhang~K., Zuo~W., Chen~Y., Meng~D., Zhang~L.}
    Beyond a~Gaussian denoiser: Residual learning of deep CNN for image 
denoising~// IEEE T. Image Process., 2017. Vol.~26. Iss.~7. 
P.~3142--3155.
    doi: 10.1109/TIP.2017.2662206.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 21.12.23}}

\vspace*{10pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule



\def\tit{IMAGE DECOMPOSITION WITH~DISCRETE WAVELET TRANSFORM TO~DESIGN A~DENOISING NEURAL NETWORK}


\def\titkol{Image decomposition with discrete wavelet transform to~design a~denoising neural network}


\def\aut{A.\,S.~Kovalenko}

\def\autkol{A.\,S.~Kovalenko}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-8pt}


\noindent 
Institute of Mathematics, Mechanics, and Computer Science named after I.\,I.~Vorovich, 
Southern Federal University, 
105/42 Bolshaya Sadovaya Str.,  Rostov-on-Don 344006, Russian Federation


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2024\ \ \ volume~18\ \ \ issue\ 2}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2024\ \ \ volume~18\ \ \ issue\ 2
\hfill \textbf{\thepage}}}

\vspace*{4pt}









\Abste{Reducing noise in digital images is one of the most common tasks in image processing. 
At the moment, noise reduction approaches based on the applying of convolutional neural networks are widely 
used. In this case, as a~rule, model training is based on minimizing the error function between the result 
of the network operation and the expected reference image and, additionally, various representations of 
the two-dimensional image signal and their properties are not used to optimize the training of noise 
reduction network architectures.
The paper proposes an approach to training neural networks to suppress noise. The described approach is 
based on the usage of the N-fold fast Haar wavelet transform. This representation of a discrete image 
signal allows one to discard the classical architecture of the autoencoder and to use only its part that 
encodes the signal which leads to a significant reduction in model parameters and speeds up the network.}

\KWE{neural networks; deep learning; image denoising; image processing}


\DOI{10.14357/19922264240209}{UEQSXP}

%\vspace*{-12pt}

%\Ack

\vspace*{4pt}


    % \noindent
   


  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99} 
 
 \vspace*{-6pt}
 
    \bibitem{UNET_ORIGINAL-1} %1
    \Aue{Ronneberger,~O., P.~Fischer, and T.~Brox.} 2015.
    U-Net: Convolutional networks for biomedical image segmentation. \textit{Medical Image
    Computing and Computer-Assisted Intervention Proceedings}.  Cham: Springer
    International Publishing. 234--241.
    
    \bibitem{UNETS_COMPARISON-1} %2
    \Aue{Komatsu, R., and T.~Gonsalves.} 2020. Comparing U-Net based models
    for denoising color images.  \textit{AI} 1(4):465--486. doi: 10.3390/ai1040029.
    
    \bibitem{IMAGE_NOISE_CONDITIONS-1} %3
    \Aue{Hasinoff, S.\,W.} 2014.
    Saturation (imaging). \textit{Computer vision: A~reference
    guide}. Boston, MA: Springer. 699--701. doi: 10.1007/978-0-387-31439-6\_483.
    
    \bibitem{SSIM-1} %4
    \Aue{Wang,~Z., A.~Bovic, H.~Sheikh, and E.~Simoncelli.}  2004.
    Image quality assessment: From error visibility to structural similarity.
    \textit{IEEE T. Image Process.} 13(4):600--612. doi: 10.1109/TIP.2003.819861.
    
    \bibitem{MIX_LOSS-1} %5
    \Aue{Zhao, H., O.~Gallo, I.~Frosio, and J.~Kautz} 2017.
    Loss functions for image restoration with neural networks. \textit{IEEE
    Trans. Computational Imaging} 3(1):47--57. doi: 10.1109/TCI.2016.2644865.
  
    \bibitem{CBAMCB-1} %6
    \Aue{Woo, S., P.~Jongchan, L.~Joon-Young, and K.~In-So.} 2018.
    CBAM: Convolutional block attention module. 17~p. 
    Available at: {\sf  https://arxiv.org/abs/1807.06521} (accessed April~28, 2024).
    
    \bibitem{CBAM_USAGE-1} %7
    \Aue{Jiang, J., H.~Xiangming, Y.~Zhao, X.~Xu,  and Y.~Cui.} 2023.
    SDAUNet: A~simple dual attention mechanism UNet for mixed noise removal. \textit{IET Image Process.}
 17(13):3884--3896. doi: 10.1049/IPR2.12905.
   
    \bibitem{MWCNN-1} %8
    \Aue{Liu, P., H.~Zhang, K.~Zhang, L.~Lin,  and W.~Zuo.} 2018.
    Multi-level wavelet-CNN for image restoration. \textit{IEEE/CVF  Conference on
    Computer Vision and Pattern Recognition Workshops Proceedings}.  Los Alamitos, CA:
    IEEE Computer Society. 886--895. doi: 10.1109/CVPRW. 2018.00121.
    
    \bibitem{WaveletPooling-1} %9
    \Aue{Batziou, E., K.~Ioannidis, I.~Patras, S.~Vrochidis, and I.~Kompatsiaris.} 2023.
    Low-light image enhancement based on U-Net and Haar wavelet pooling. 
    \textit{MultiMedia modeling}.  Cham: Springer Nature Switzerland.  510--522.
  
    \bibitem{MDIWT-1} %10
    \Aue{Tian, C., M.~Zheng, W.~Zuo,  B.~Zhang, Y.~Zhang, and D.~Zhang.} 2023.
    Multi-stage image denoising with the wavelet transform. \textit{Pattern
    Recogn.} 134:109050. doi: 10.1016/j.patcog.2022.109050.
    
    \bibitem{WINNet-1} %11
    \Aue{Huang, J.-J., and P.\,L.~Dragotti.} 2021. WINNet: Wavelet-inspired
    invertible network for image denoising. \textit{IEEE T. Image Process.} 
31:4377--4392.
    
    \bibitem{DWB-1} %12
    \Aue{Guo, T., H.~Mousavi, T.~Vu, and V.~Monga.} 2017.
    Deep wavelet prediction for image super-resolution. \textit{Conference on
    Computer Vision and Pattern Recognition Workshops Proceedings}.  Los Alamitos, CA: IEEE Computer Society. 
    1100--1109. doi: 10.1109/CVPRW.2017.148.
   
    \bibitem{IS_NET-1} %13
    \Aue{Qin, X., H.~Dai, X.~Hu, D.-P.~Fan, L.~Shao, and G.~Van.} 2022.
    Highly accurate dichotomous image segmentation. \textit{Computer vision}.
     Cham: Springer Nature Switzerland.\linebreak 38--56.
    
    \bibitem{ResNet-1} %14
    \Aue{He, K., H.~Zhang, S.~Ren, and J.~Sun.} 2016.
    Deep residual learning for image recognition. \textit{Conference on
    Computer Vision and Pattern Recognition Proceedings}.  Los Alamitos, CA.  770--778.
   
    \bibitem{POOLOPS-1} %15
    \Aue{Scherer, D., A.~Muller, and S.~Behnke.} 2010.
    Evaluation of pooling operations in convolutional architectures for object recognition.
    \textit{Artificial neural networks}.  Berlin, Heidelberg: Springer.  92--101. doi: 10.1007/978-3-642-15825-4\_10.
    
    \bibitem{FULLYCONV-1} %16
    \Aue{Makarenko, A.\,V.} 2020.
    Glubokie neyronnye seti: zarozhdenie, stanovlenie, sovremennoe sostoyanie
    [Deep neural networks: Origins, development, and current status]. 
\textit{Problemy upravleniya} [Control Sciences] 2:3--19. doi: 10.25728/pu.2020.2.1.

\columnbreak
    
    \bibitem{WAVELETS_PAPER-1} %17
    \Aue{Buy, T.\,T.\,C., and V.\,G.~Spitsyn.} 2011. Razlozhenie tsifrovykh 
    izobrazheniy s~po\-moshch'yu dvumernogo diskretnogo veyvlet-preobrazovaniya i~bystrogo preobrazovaniya 
    Khaara
    [Digital image decomposition using two-dimensional discrete wavelet transform and fast Haar transform].
\textit{Izvestiya Tomskogo politekhnicheskogo universiteta} [Bulletin of the Tomsk Polytechnic University] 318(5):73--76.
  
    \bibitem{WAVELETS_APPROX-1} %18
    \Aue{Pavlov, A.\,N.} 2008. Detektirovanie informatsionnykh signalov na osnove rekonstruktsii 
    dinamicheskikh sistem i~diskretnogo veyvlet-preobrazovaniya
    [Detection of information signals based on reconstruction of dynamical systems and discrete wavelet-transform]. 
    \textit{Izvestiya vysshikh uchebnykh zavedeniy. 
    Prikladnaya nelineynaya dinamika} [Bulletin of Higher Educational Institutions. Applied Nonlinear Dynamics] 16(6):3--17.
    
    \bibitem{WAVELETS_NOISE-1}
    \Aue{Pronkin, A.\,V.} 2022. Otsenivanie urovnya shuma v~sostave izobrazheniya s~ispol'zovaniem veyvletov Khaara
    [Noise level estimation in images using Haar wavelets].
\textit{22nd Conference (International) on Computer Graphics and Computer Vision Proceedings}.  Moscow:  IPM im.\ M.\,V.~Keldysha. 32:442--448. 
    doi: 10.20948/graphicon-2022-442-448.
 
    \bibitem{OPENCV_LIB-1}
    \Aue{Bradski, G.} 2000. The OpenCV Library. \textit{Dr. Dobbs J.}  25(11):120--125.
    
    \bibitem{SIDD_2018_CVPR-1} %21
    \Aue{Abdelhamed, A., S.~Lin, and M.\,S.~Brown.} 2018. 
    A~high-quality denoising dataset for smartphone cameras. \textit{IEEE/CVF Conference on Computer Vision and Pattern Recognition Proceedings.} 
    Los Alamitos, CA: IEEE Computer Society. 1692--1700. 
    doi: 10.1109/CVPR. 2018.00182.
   
    \bibitem{FOR_ADD_NOISE_DATASETS-1}
    \Aue{Huang, J.-B., A.~Singh, and N.~Ahuja.} 2015. Single
    image super-resolution from transformed self-exemplars. \textit{Conference on Computer Vision and Pattern Recognition Proceedings}. 
    Los Alamitos, CA: IEEE Computer Society. 5197--5206.
   
    \bibitem{DIV2KDataset-1}
    \Aue{Agustsson, E., and R.~Timofte.} 2017. NTIRE 2017 challenge on single
    image super-resolution: Dataset and study. \textit{Conference on Computer Vision and
    Pattern Recognition Workshops Proceedings}. Los Alamitos, CA: IEEE Computer Society. 1110--1121. doi: 10.1109/ CVPRW.2017.149. 
   
    \bibitem{BSD_set-1} %24
    \Aue{Martin, D., C.~Fowlkes, D.~Tal, and J.~Malik.} 2001.
    A~database of human segmented natural images and its application to evaluating
    segmentation algorithms and measuring ecological statistics. \textit{8th Conference (International) on Computer Vision 
    Proceedings}. Piscataway, NJ: IEEE Computer Society. 2:416--423. doi: 10.1109/ICCV.\linebreak 2001.937655.
    
    
    \bibitem{DNDSet-1} %25
    \Aue{Plotz, T., and S.~Roth.} 2017. Benchmarking denoising algorithms with
    real photographs. 2017. \textit{Conference on Computer Vision and Pattern Recognition Proceedings}. 
Los Alamitos, CA: IEEE Computer Society. 
2750--2759. doi: 10.1109/CVPR.2017.294.
    
    \bibitem{PYTORCH_LIB-1}
    \Aue{Paszke, A., S.~Gross, F.~Massa, and A.~Lerer.} 2019.
    PyTorch: An imperative style, high-performance deep learning library.
\textit{Adv. Neur. Inf.} 32:8024--8035.

\pagebreak
   
    \bibitem{TIMMLIB-1}
    \Aue{Wightman, R.} 2019. PyTorch image models.
    Available at: {\sf https://github.com/rwightman/pytorch-image-models} (accessed April~28, 2024).
   
    \bibitem{UFORMER-1}
    \Aue{Wang, Z., X.~Cun, J.~Bao,
W.~Zhou, J.~Liu, and H.~Li.} 2022.
    Uformer: A~general U-shaped transformer for image restoration. 
\textit{IEEE/CVF Conference on Computer Vision and Pattern Recognition Proceedings}. Los Alamitos, CA:
 IEEE Computer Society. 17683--17693.
    
    \bibitem{ADASMOOTH-1}
    \Aue{Lu, J.} 2023. AdaSmooth: An adaptive learning rate method based on effective
    ratio. \textit{Sentiment analysis and deep learning}.  Singapore: Springer Nature Singapore. 273--293.
    

   
    \bibitem{SMOOTHL1-1}
    \Aue{Girshick, R.\,B.} 2015.
    Fast {R-CNN}. 9~p.  
    Available at: {\sf https://arxiv.org/abs/1504.08083} (accessed April~28, 2024).
    
    \bibitem{BM3D-1}
    \Aue{Dabov, K., A.~Foi, V.~Katkovnik, and K.~Egiazarian.} 2007.
    Image denoising by sparse 3-D transform-domain collaborative filtering. 
    \textit{IEEE T. Image Process.}  16:2080--2095.
    
    \bibitem{DnCNN-1}
    \Aue{Zhang, K., W.~Zuo, Y.~Chen, D.~Meng, and L.~Zhang.} 2017.
    Beyond a~Gaussian denoiser: Residual learning of deep CNN for image denoising. 
\textit{IEEE T. Image Process.}  26(7):3142--3155. 
    doi: 10.1109/TIP.2017.2662206.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received December 21, 2023}} 

\vspace*{-12pt}


\Contrl

\vspace*{-3pt}


\noindent 
\textbf{Kovalenko Alexey S.} (b.\ 1996)~--- assistant, Department of Applied Mathematics and Programming, 
Institute of Mathematics, Mechanics, and Computer Science named after I.\,I.~Vorovich, 
Southern Federal University, 105/42~Bolshaya Sadovaya Str., Rostov-on-Don 344006, Russian Federation; 
\mbox{akov@sfedu.ru}




\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 