\def\stat{grusho}

\def\tit{ВЫЯВЛЕНИЕ ПРИЧИННО-СЛЕДСТВЕННЫХ СВЯЗЕЙ ПРИ~ПОКРЫТИИ ПРИЧИН}

\def\titkol{Выявление причинно-следственных связей при~покрытии причин}

\def\aut{А.\,А.~Грушо$^1$, Н.\,А.~Грушо$^2$, М.\,И.~Забежайло$^3$,  
В.\,В.~Кульченков$^4$, Е.\,Е.~Тимонина$^5$}

\def\autkol{А.\,А.~Грушо, Н.\,А.~Грушо, М.\,И.~Забежайло и~др.}  
%В.\,В.~Кульченков$^4$, Е.\,Е.~Тимонина$^5$}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Грушо А.\,А.}
\index{Грушо Н.\,А.}
\index{Забежайло М.\,И.}  
\index{Кульченков В.\,В.}
\index{Тимонина Е.\,Е.}
\index{Grusho A.\,A.}
\index{Grusho N.\,A.}
\index{Zabezhailo M.\,I.}
\index{Kulchenkov V.\,V.}
\index{Timonina E.\,E.}


%{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
%{Исследование выполнено за счет гранта Российского научного фонда №\,22-28-00588, {\sf 
%https://rscf.ru/project/22-28-00588/}. Работа проводилась с~использованием инфраструктуры Центра 
%коллективного пользования <<Высокопроизводительные вычисления и~большие данные>> (ЦКП 
%<<Информатика>> ФИЦ ИУ РАН, Москва).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{grusho@yandex.ru}}
\footnotetext[2]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, \mbox{info@itake.ru}}
\footnotetext[3]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{m.zabezhailo@yandex.ru}}
\footnotetext[4]{Банк ВТБ (ПАО), vlad.kulchenkov@gmail.com}
\footnotetext[5]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{eltimon@yandex.ru}}

%\vspace*{-8pt}


  

  
  \Abst{Задачи поиска причинно-следственных связей имеют большое значение в~медицинской 
диагностике, поиске первопричин сбоев в~про\-грам\-мно-тех\-ни\-че\-ских сис\-те\-мах, информационной 
безопас\-ности. Объяснимость формируемых заключений, получаемых в~результате слож\-ных 
вычислений с~по\-мощью методов искусственного интеллекта (ИИ), чаще всего реализуется с~по\-мощью при\-чин\-но-след\-ст\-вен\-ных связей. 
  В~работе исследована возможность выявления при\-чин\-но-след\-ст\-вен\-ных связей 
в~случаях, когда причина находится в~неразделимом объекте, доступном наблюдению. В~таких 
случаях говорят, что свойство <<причина>> покрыто объектом, в~котором присутствуют и~другие свойства данных. Следствия причин проявляются в~других информационных 
пространствах. Задача выявления при\-чин\-но-след\-ст\-вен\-ных связей исследуется 
в~присутствии других случайных данных, не относящихся к~зависимости, по\-рож\-да\-емой  
при\-чин\-но-след\-ствен\-ной связью. 
  Рассматривается модель детерминированной при\-чин\-но-след\-ст\-вен\-ной связи при 
наличии значительного числа случайно возникающих свойств, которые не связаны  
с~при\-чин\-но-след\-ст\-вен\-ным влиянием одних свойств на другие.}

  \KW{искусственный интеллект; компьютерный анализ данных; при\-чин\-но-след\-ст\-вен\-ные 
связи; покрытие причин}

\DOI{10.14357/19922264240208}{MKXMZY}
  
%\vspace*{4pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}
  
  \section{Введение }
  
 % \vspace*{-6pt}
  
  Центральным компонентом прикладных сис-\linebreak тем ИИ и~решений выступает их процедурный <<инструментарий>>~---  
проб\-лем\-но-ори\-ен\-ти\-ро\-ван\-ные математические модели, методы 
и~алгоритмы, способные отразить как общие принципы интеллектуального 
анализа данных, так и~специфику конкретных областей приложения. В~свою 
очередь, среди такого рода <<инструментов>> анализа данных и~поддержки 
принятия решений особое место отводится средствам восстановления  
при\-чин\-но-след\-ст\-вен\-ных связей, неявным образом представленных 
в~обрабатываемых эмпирических данных.
  
  Например, в~системах обеспечения ки\-бер\-безопас\-ности именно  
при\-чин\-но-след\-ст\-вен\-ные зависимости, изначально скрытые 
в~ана\-ли\-зи\-ру\-емых данных, позволяют строить результативные математические 
модели и~методы фильт\-ра\-ции Big Data на предмет идентификации в~них 
аномальных (например,  вредоносных) фрагментов <<малого>> размера~[1].
  
  Дополнительные возможности для принятия выводов и~рекомендаций, 
формируемых системами ИИ, дает формирование содержательных, 
использующих термины и~понятия анализируемой предметной области 
интерпретаций и~объяснений. Обычно объяснение~--- это ответ на вопрос 
ПОЧЕМУ? Именно по этой причине ключевая роль в~работе прикладных сис\-тем 
ИИ отводится использованию при\-чин\-но-след\-ст\-вен\-ных связей, изначально 
скрытых в~анализируемых данных, однако восстанавливаемых из них 
соответствующей сис\-те\-мой~ИИ.
  
  Итак, задачи поиска при\-чин\-но-след\-ст\-вен\-ных связей имеют большое 
значение в~целом ряде значимых приложений~--- в~медицинской диагностике~[2, 
3], поиске первопричин сбоев в~про\-грам\-мно-тех\-ни\-че\-ских сис\-те\-мах~[4], 
информационной безопас\-ности~[1, 5] и~др. При поиске причинно-следственных 
связей часто использовались методы статистики~[6--8], однако в~основном речь 
шла об анализе при\-чин\-но-след\-ст\-вен\-ных связей в~условиях статистически 
об\-на\-ру\-жи\-ва\-емой не\-за\-ви\-си\-мости или, наоборот, зависимости случайных ве\-ли\-чин. 
{\looseness=1

}
  
  В данной работе исследуется задача выявления  
при\-чин\-но-след\-ст\-вен\-ных связей на фоне других случайных данных, не 
относящихся к~ис\-сле\-ду\-емой за\-ви\-си\-мости. При этом рассмотрены условия, когда 
причина спрятана (покрыта) в~объекте наряду с~другими свойствами данных~[9].
  
  \section{Математическая модель условий поиска  
причинно-следственных связей}
  
  Пусть $A=\{x_1, \ldots, x_n\}$~---  это множество наблюдаемых свойств данных. 
Объектом называется набор свойств из~$A$. Рассмотрим простейший случай, 
когда каж\-дый объект содержит $s$ свойств и~по\-рож\-да\-ет\-ся случайно и~независимо 
с~вероятностью $1/\begin{pmatrix} n \\ s\end{pmatrix}$. 
  
  Исходные данные представляют собой последовательность объектов 
длины~$M$. Случайность по\-сле\-до\-ва\-тель\-ности объектов вводится с~по\-мощью 
равновероятной полиномиальной схемы из~$M$~испытаний с~известными 
вероятностями $1/\begin{pmatrix} n\\ s\end{pmatrix}$. Построенную модель будем 
называть информационным пространством IS$_1$. Далее информационные 
пространства будем отож\-дест\-влять с~последовательностями, которые построены 
по соответствующим этим пространствам вероятностным схе\-мам.

  
  Вместе с~IS$_1$ построим другое информационное пространство IS$_2$, 
в~котором множество свойств $B\hm= \{y_1, \ldots , y_N\}$, на которых 
построена  полиномиальная схема длины~$M$ с~вероятностями исходов $\{ 
p(y_j)\}$. Пусть свойство~$x$ из~$A$ служит причиной свойства~$y$ из~$B$. 
Это значит, что при наличии связи IS$_1$ и~IS$_2$ (далее предполагаем ее 
наличие) при появлении в~последовательности объектов IS$_1$ объекта~$O$ со 
свойством~$x$ в~последовательности~IS$_2$ в~тот же момент возникает 
свойство~$y$, и~от данного свойства оставшаяся часть последовательности IS$_2$ 
сдвигается на~1 вправо. Далее появление свойств в~IS$_2$ соответствует 
независимой полиномиальной схеме, определенной выше для IS$_2$, до 
следующего появления в~IS$_1$ объекта со свойством~$x$.


  
  \section{Случай выявления одной причинно-следственной связи}
  
  В условиях построенной модели можно статистически определять при\-чин\-но-след\-ст\-вен\-ные 
  связи. Предположим, что $M$ достаточно велико, чтобы 
относительные частоты свойств в~полиномиальной схеме IS$_2$ с~достаточной 
степенью уверенности однозначно идентифицировали различные вероятности 
этой схемы. 
  
  Пусть свойство $x_i$ служит причиной появления свойства~$y_j$. Вероятность 
того, что в~данном объекте есть~$x_i$, равна 
  $$
  \fr{\begin{pmatrix}
  n-1\\ s-1
  \end{pmatrix}}{\begin{pmatrix}
  n\\ s
  \end{pmatrix}} =\fr{s}{n}\,.
  $$
  
  Обозначим частоты свойств, встретившихся в~IS$_1$, через~$v$  (что 
равносильно числу появлений объектов, содержащих соответствующее свойство), 
а~частоты свойств  в~последовательности IS$_2$ через~$\mu$. Если~$x_i$ служит 
причиной появления~$y_j$, то в~IS$_2$ реальная длина последовательности равна 
$$
M^*= M+ v(x_i),
$$
 где $v(x_i)$~--- число появлений объектов со 
свойством~$x_i$, что также соответствует числу появлений~$x_i$ в~IS$_1$. 
Тогда частота встречаемости~$y_i$ будет равна 
$$
\mu^*(y_j) = v(x_i) +  \mu(y_j).
$$

 При фиксированных значениях всех па\-ра\-мет\-ров в~IS$_1$ и~IS$_2$ 
(кроме условия  $M\hm\to \infty$) получим сле\-ду\-ющие соотношения для 
относительных час\-тот:
  $$
  \fr{v(x_i)}{M} \to \fr{s}{n}\,,\enskip \fr{\mu(y_j)}{M}\to p(y_j)\,,
  $$
и
$$
\fr{\mu^*(y_j)}{M}=\fr{v(x_i)}{M} +\fr{\mu(y_j)}{M} > p(y_j).
$$
  %
  Отсюда делаем вывод, что~$y_j$~--- это следствие ка\-кой-то причины 
из~IS$_1$.
  
  Для определения причины~$x_i$ сделаем преобразование данных IS$_1$, 
которое назовем операцией \textit{синхронизации}. Пусть символ~$\alpha$ не 
используется в~обозначениях объектов и~$x$~--- произвольное фиксированное 
свойство из~$A$. Тогда в~последовательности IS$_1$ после каждого случая 
появления объекта со свойством~$x$ вставим символ~$\alpha$. Если 
в~последовательности IS$_1$ встретились подряд несколько объектов со 
свойством~$x$, то после них в~последовательность вставляется такое же число 
символов~$\alpha$. Построенную последовательность объектов будем обозначать 
IS$_1^*(x)$.
  
  \smallskip
  
  \noindent
  \textbf{Лемма~1.} \textit{Если~$x_i$ служит причиной~$y_j$, то 
последовательность  $\mathrm{IS}_1^*(x_i)$ синхронизируется с~последовательностью 
$\mathrm{IS}_2$ в~том смысле, что каждое новое появление объекта  с~$x_i$ 
в~$\mathrm{IS}_1^*(x_i)$  порождает в~тот же момент появление нового свойства~$y_j$ 
с~тем же порядковым номером в~последовательности $\mathrm{IS}_1^*$. При этом длины 
последовательностей $\mathrm{IS}_2$ и~$\mathrm{IS}_1^*(x_i)$ совпадают так, что не происходит 
смещения~$x_i$ и~порожденных ими~$y_j$, т.\,е.\ они находятся на местах 
с~одинаковыми номерами во вновь образованных последовательностях}.
  
  \smallskip
  
  \noindent
  Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \  В~IS$_2$ синхронно с~вкраплением 
объекта~$y_j$ происходит смещение остальной части последовательности вправо 
на один шаг. Аналогичное вкрапление на один шаг вправо в~IS$_1$ делается 
каждый раз с~по\-мощью вставки элемента~$\alpha$ сразу после появления объекта 
со свойством~$x_i$. Из того, что появление объектов  и~свойств в~IS$_2$ 
происходит одновременно, получаем, что очередное появление объекта со 
свойством~$x_i$ в~IS$_1^*(x_i)$ совпадает с~появлением нового встроенного 
свойства~$y_j$ в~IS$_2$ на том же месте (с~тем же номером места). Таким 
образом, число вставок элемента~$\alpha$ совпадает с~числом вставок 
свойства~$y_j$, а~места появления объектов со свойством~$x_i$ синхронно 
появляются с~вкраплениями~$y_j$. Лемма доказана.
  
  \smallskip
  
  \noindent
  \textbf{Лемма~2.} \textit{В~последовательности $\mathrm{IS}_1^*(x_i)$ свойство~$x_i$ 
встречается только в~сочетании с~$\alpha$, а~во всех остальных объектах 
свойства~$x_i$ нет}.
  
  \smallskip
  
  \noindent
  Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \  Каждое появление объекта со 
свойством~$x_i$ порождает вкрапление~$y_j$ в~последовательность IS$_2$. 
Отсюда следует утверждение леммы.
  
  \bigskip
  
  
  \noindent
  \textbf{Лемма~3.} \textit{Необходимым условием того, что свойство~$x$ 
служит причиной~$y_j$, является то, что в~$\mathrm{IS}_1^* (x)$ всем объектам с~$x$ 
синхронно поставлено в~соответствие~$y_j$}.
  
  \bigskip
  
  \noindent
  Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \  Если~$x$ служит причиной~$y_j$, то 
каждая встреча~$x$ порождает в~IS$_2$ свойство~$y_j$, а~вне 
детерминированного порождения~$y_j$ свойство~$x$ в~IS$_1^* (x)$ появляться 
не может. IS$_1^* (x)$ в~случае, когда~$x$ служит причиной~$y_j$, синхронизирует 
появления~$x$ и~$y_j$. Поэтому появление~$x$ в~этой последовательности вне 
сочетания с~$y_j$ невозможно. Лемма доказана.
  
  \bigskip
  
  Используем алгоритм синхронизации для каж\-до\-го свойства~$x$. Решение 
о~принятии~$x$ в~качестве возможной причины для~$y_j$ принимается (при 
выполнении необходимого условия леммы~3) по максимальному соответствию 
относительных частот~$x$ и~$y_j$ соответствующим вероятностям.
  
  Рассмотрим задачу поиска в~объектах истинной причины следствия~$y_j$. Для 
каждого~$x$ из встретившихся в~объектах IS$_1$ построим последовательность 
объектов из IS$_1^* (x)$. Если предположить, что~$x$ служит причиной~$y_j$, 
то в~этой последовательности все объекты с~$x$ появляются тогда, когда 
свойство~$x$ соответствует~$y_j$. Если~$x$ не служит причиной~$y_j$, то в~этой 
последовательности IS$_1^* (x)$ будут объекты, содержащие неизвестную 
причину, и~объекты~$x$, соответствующие случайным появлениям~$y_j$ 
в~последовательности IS$_2$ (см.\ необходимое условие). 
  
  Для любого~$x$ среднее число появлений~$x$ равно $Ms/n$, 
а~в~последовательности IS$_2$ по-преж\-не\-му будет $v(x_i)$ свойств~$y_j$, 
порожденных реальной причиной,  и~$\mu(y_j)$ свойств~$y_j$ без участия 
свойства~$x_i$. По теореме Му\-ав\-ра--Лап\-ласа
\begin{align*}
  v(x_i) &=\fr{Ms}{n}+o\left(\ln M\sqrt{M}\right);
\\
\mu(y_j)&= Mp(y_j) +o\left( \ln M\sqrt{M}\right).
\end{align*}
%  
  В то же время 
  $$
  v(x)=\fr{Ms}{n}+o\left( \ln M\sqrt{M}\right),
  $$
и разница с~$v(x_i)$ априори может быть компенсирована 
колебаниями~$\mu(y_j)$. 

  Отсюда следует, что для любого объекта со свойством $x\not= x_i$ необходимо 
изучить число случайных появлений объектов, которые случайно получаются 
в~IS$_1^* (x)$ под возникшими  свойствами~$y_j$. Для понимания проблемы 
приведем два примера.
  
  
  \bigskip
  
  \noindent
  \textbf{Пример~1.} Предположим, что $p(y_j)\hm=0$. Тогда 
в~последовательности IS$_2$ следствие~$y_j$ появляется только в~результате 
появления в~IS$_1$ причины~$x_i$. Тогда для произвольного $x\not= x_i$ 
математическое ожидание числа объектов на местах появления~$y_j$ равно 
  $$
  \fr{Ms(s-1)}{n(n-1)} < \fr{Ms}{n}\,.
  $$
Доказательство будет приведено далее. Тогда остальные объекты со 
свойством~$x$ не соответствуют~$y_j$, что по лемме~3 означает, что~$x$ не 
может быть причиной~$y_j$.

  Таким образом, приведенный выше алгоритм позволяет однозначно выявить 
причину.
  
  \bigskip
  
  \noindent
  \textbf{Пример~2.} Предположим, что $p(y_j)\hm=1$. Тогда 
в~последовательности IS$_2$ свойство~$y_j$ появляется на каждом месте 
последовательности IS$_2$.  Отсюда для произвольного $x\not= x_i$ в~IS$_1^* 
(x)$ может случайно иметь больше объектов с~$x$, чем последовательность 
IS$_1^* (x_i)$ имеет объектов с~$x_i$. В~этом случае алгоритм, основанный на 
максимизации числа выявленных вкраплений, порождающих~$y_j$, заведомо 
выберет ложное решение. Поэтому принятие правильного решения потребует 
выявления дополнительных условий.
  
  С этой целью будем вычислять все частоты сочетаний свойств $x\not= x_i$ 
и~$x_i$ в~появившихся объектах. Вероятность появления объектов  со 
свойствами~$x$ и~$x_i$ равна 
  $$
  \fr{\begin{pmatrix}
  n-2\\ s-2\end{pmatrix}}{\begin{pmatrix}
  n\\ s \end{pmatrix}
  } =\fr{s(s-1)}{n(n-1)}\,.
  $$
  
  Математическое ожидание числа таких объектов~--- $Ms(s-1)/(n(n-1))$. 
Вероятность появления объекта со свойством~$x_i$, но без свойства~$x$ равна 
  $\begin{pmatrix}
  n-2\\ s-1 \end{pmatrix}/\begin{pmatrix}
  n\\ s\end{pmatrix}.
  $
     Тогда число~$y_j$, возникших детерминированно, но не соответствующих 
объектам со свойством~$x$, равно в~среднем
  $M\begin{pmatrix}
  n-2\\ s-1
  \end{pmatrix}/ \begin{pmatrix}
  m\\ s\end{pmatrix}.$

Отметим, что 
$$
\begin{pmatrix}
n-2\\ s-1\end{pmatrix} +
\begin{pmatrix}
n-2\\ s-2\end{pmatrix} =
\begin{pmatrix}
n-1\\ s-1\end{pmatrix}.
$$
Отсюда вероятность появления~$x_i$ равна~$s/n$, что соответствует 
полученному раньше выражению. 

  Вероятность появления объекта со свойством~$x$, но без свойства~$x_i$ равна 
  ${\begin{pmatrix}
  n-2\\ s-1
  \end{pmatrix}}/{\begin{pmatrix} n\\ s \end{pmatrix}}.$
Отсюда следует, что для подтверждения~$x$ в~качестве причины~$y_j$ 
необходимо, чтобы область случайного появления~$y_j$, а~это в~среднем 
$Mp(y_j)$, смогла покрыть в~сред\-нем 
${M\begin{pmatrix} n-2\\ s-1\end{pmatrix}}/{\begin{pmatrix} n\\ s\end{pmatrix}}$
объектов со свойством~$x$. Исходя из того что недетерминированные появления 
свойств~$y_j$ не зависят от появления объектов со свойством~$x$ в~IS$_1^* (x)$, 
математическое ожидание числа <<покрытых>>~$y_j$ объектами со 
свойством~$x$ удовлетворяет неравенству 
$$
\fr{Mp(y_j) \begin{pmatrix} n-2\\ s-1 \end{pmatrix}}{\begin{pmatrix} n\\ 
s\end{pmatrix}} < \fr{M\begin{pmatrix} n-2\\ s-1 \end{pmatrix}}{\begin{pmatrix} n\\ 
s\end{pmatrix}}\,.
$$
При $p(y_j)<1$ разность математических ожиданий имеет порядок~$M$, поэтому 
из теоремы Му\-ав\-ра--Лап\-ла\-са следует, что необходимое число 
<<покрытий>> невозможно с~вероятностью, стремящейся к~1. Отсюда по 
лемме~3 получаем следующую теорему.

  \smallskip
  
  \noindent
  \textbf{Теорема~1.} \textit{При $M\hm\to \infty$, $p(y_j)\hm<1$ 
с~ве\-ро\-ят\-ностью, стремящейся к~единице, причина  появления~$y_j$ 
определяется однозначно}. 
  
  \smallskip
  
  Если в~IS$_2$ в~схеме серий допустить $n\hm\to \propto$ , то $\mu(y_j)/M \hm\to 
0$ по вероятности. Тогда из соотношения
  $$
  \fr{\mu^*(y_j)}{M} =\fr{v(x_i)}{M} +\fr{\mu(y_j)}{M}
  $$
сразу следует, что $y_j$~--- это следствие некоторой причины из IS$_1$. 
Приведенный выше пример~1  также позволяет в~этом случае выделить~$x_i$ как 
причи-\linebreak ну~$y_j$.
  
  \section{Случай выявления нескольких причинно-следственных 
связей в~разных информационных пространствах }
  
  Предположим, что  условия построения случайных последовательностей IS$_1,  
\mathrm{IS}_2, \ldots, \mathrm{IS}_{k+1}$, $k\hm \leq n$,  таковы, что 
существуют~$k$ свойств, которые служат причинами в~IS$_1$, и~порождающих 
одиночные следствия в~соответствующих пространствах $\mathrm{IS}_2, \ldots , 
\mathrm{IS}_{k+1}$. 
  
  Для простоты рассмотрим случай двух причин и~их следствий в~IS$_2$ 
и~в~IS$_3$, где IS$_3$ основано на свойствах $C\hm= \{z_1, \ldots , z_S\}$ 
и~определяется полиномиальной схемой длины~$M$ и~вероятностями $\{ p(z_i)\}$. Пусть для простоты объект со свойством~$x_1$ порождает 
следствие~$y_1$ в~IS$_2$, а~объект со свойством~$x_2$ порождает 
следствие~$z_1$ в~IS$_3$. В~условиях построения  
при\-чин\-но-след\-ст\-вен\-ных связей в~исходной модели необходимо решить 
задачу на\-хож\-де\-ния всех причин и~следствий. 
  
  Предположим, что $M$ достаточно велико, чтобы относительные частоты 
свойств в~полиномиальных схемах IS$_2$ и~IS$_3$ с~достаточной степенью 
уверенности однозначно идентифицировали различные неравные вероятности 
каждой схемы. 
  
  Если в~IS$_1$ присутствуют только две причины, то реальная длина 
последовательности IS$_2$ увеличилась  и~стала равной 
  $$
  M_1^* =M+v(x_1).
  $$
   
В~IS$_3$ реальная длина последовательности также увеличилась и~стала равной 
$$
M_2^* =M+v(x_2).
$$
При этом 
$$
\mu^*(y_1) = v(x_1)+ \mu(y_1);\ \eta^*(z_1) \hm= v (x_2) 
+ \eta(z_1).
$$
 Отсюда следует, что $y_1$ и~$z_1$ стали следствиями ка\-ких-то 
причин из~IS$_1$. Осталось определить причины этих следствий.
  
  \smallskip
  
  \noindent
  \textbf{Лемма~4.} \textit{Алгоритмы теоремы~$1$ поиска причин~$y_1$ 
и~$z_1$ в~пространстве $\mathrm{IS}_1$ функционируют независимо и~не влияют на 
последовательность их выполнения}.
  
  \smallskip
  
  \noindent
  Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \  Пространства IS$_1^* (x)$ для IS$_2$ 
и~для IS$_3$ могут быть использованы независимо, так как они будут 
соотноситься с~разными независимыми последовательностями в~IS$_2$ 
и~в~IS$_3$. Аналогично отсев по необходимому условию леммы~3 также 
основан на независимо построенных последовательностях IS$_2$ и~IS$_3$. 
Лемма доказана.
  
  \smallskip
  
  Суммируем результаты в~следующей теореме.
  
  \smallskip
  
  \noindent
  \textbf{Теорема~2.} \textit{Пусть для произвольного $k\hm\leq n$ определены 
информационные пространства $\mathrm{IS}_1, \mathrm{IS}_2, \ldots, 
\mathrm{IS}_{k+1}$, где $\mathrm{IS}_1$ содержит последовательность длины~$M$ 
равновероятных объектов, а~$\mathrm{IS}_2, \ldots , \mathrm{IS}_{k+1}$~--- 
последовательности полиномиальных испытаний длины~$M$ с~разными 
вероятностными схемами, в~которых все вероятности больше~$0$. Если все 
пространства связаны с~$\mathrm{IS}_1$ так, что находящиеся в~$\mathrm{IS}_1$ k выделенных 
свойств служат причинами появления в~соответствующих пространствах 
уникальных следствий (каждое следствие может появляться случайно или под 
воздействием причины из $\mathrm{IS}_1$), то все при\-чин\-но-след\-ст\-вен\-ные связи 
однозначно определяются с~вероятностью, стремящейся к~единице}.
  
  \smallskip
  
  \noindent
  Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \  По лемме~4 поиск каждой пары  
при\-чи\-на--след\-ст\-вие может осуществляться независимо друг от друга 
в~любом порядке. При этом сначала на  каждом $\mathrm{IS}_2, \ldots , 
\mathrm{IS}_{k+1}$ определяются свойства, ставшие следствиями неизвестных 
причин свойств из IS$_1$, а~затем  с~по\-мощью построенного алгоритма 
выявляются свойства причины найденных следствий. Теорема доказана.

\vspace*{-9pt}
  
  \section{Заключение }
  
  В работе исследована возможность выявления причинно-следственных связей 
  в~случаях, когда причина находится в~неразделимом объекте, доступном 
наблюдению. Следствия причин проявляются в~других информационных 
пространствах. Шум, препятствующий простому решению задачи, состоит из 
свойств данных, окру\-жа\-ющих причины и~следствия, не относящихся  
к~при\-чин\-но-след\-ст\-вен\-ным связям. Такие условия моделируют ситуации, 
когда в~рассматриваемых данных возможна декомпозиция и~выделение 
фрагментов при\-чин\-но-след\-ст\-вен\-ных связей, пред\-став\-ля\-ющих интерес для 
исследователя.
  
  Методика частично апробирована в~решении задач поиска <<следов>> 
определенных типов инсайдеров в~больших данных мониторинга безопас\-ности 
одного из российских банков. 

\vspace*{-9pt}
  
{\small\frenchspacing
 { %\baselineskip=10.6pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9}
\bibitem{1-gr}
\Au{Смирнов Д.\,В.} Методика проб\-лем\-но-ори\-ен\-ти\-ро\-ван\-но\-го анализа Big Data 
в~режиме ограниченного времени~// Int. J. Open Information Technologies, 2021. Vol.~9. Iss.~9. 
P.~88--94. EDN: NKHHGS.

\bibitem{2-gr}
\Au{H$\ddot{\mbox{o}}$fler M.} Causal inference based on counterfactuals~// BMC Med. Res. 
Methodol., 2005. Vol.~5. Art.~28. 12~p. doi: 10.1186/1471-2288-5-28.
\bibitem{3-gr}
\Au{Richens J.\,G., Lee C.\,M., Johri~S.} Improving the accuracy of medical diagnosis with causal 
machine learning~// Nat. Commun., 2020. Vol.~11. Art.~3923. 9~p. doi:  
10.1038/s41467-020-17419-7.
\bibitem{4-gr}
\Au{Reimer J., Wang Y., Laridi~S., Urdich~J., Wilmsmeier~S., Palmer~G.} Identifying  
cause-and-effect relationships of manufacturing errors using sequence-to-sequence learning~// Sci. 
Rep.~--- U.K., 2022. Vol.~12. Art.~22332. 11~p. doi: 10.1038/s41598-022-26534-y.
\bibitem{5-gr}
\Au{Grusho A., Grusho~N., Zabezhailo~M., Timonina~E.} Evaluation of trust in computer-computed 
results~// Comm. Com.  Inf. Sc., 2022. Vol.~1552. P.~420--432. doi:  
10.1007/978-3-030-97110-6\_33.

\bibitem{7-gr} %6
\Au{Pearl J.} Causal inference~// Causality: Objectives and assessment~/ Eds. I.~Guyon, D.~Janzing, B.~Scholkopf.~--- Proceedings of machine learning research 
ser.~--- Whistler, Canada, 2010. Vol.~6. P.~39--58. 
\bibitem{8-gr} %7
\Au{Pearl J.} The mathematics of causal inference~// Joint Statistical Meetings Proceedings.~--- ASA, 
2013. P.~2515--2529.

\bibitem{6-gr} %8
\Au{Zhang X., Hu W., Yang~F.} Detection of cause-effect relations based on information granulation 
and transfer entropy~// Entropy, 2022 Jan 28. Vol.~24. Art.~212. 18~p. doi: 10.3390/e24020212.
\bibitem{9-gr}
\Au{Грушо А.\, А., Грушо Н.\,А., Забежайло~М.\,И., Тимонина~Е.\,Е., Шоргин~С.\,Я.} Сложные  
при\-чин\-но-след\-ст\-вен\-ные связи~// Информатика и~её применения, 2023. Т.~17. Вып.~2. 
С.~84--89. doi: 10.14357/19922264230212. EDN: TGXQIW.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-8pt}

\hfill{\small\textit{Поступила в~редакцию 09.04.24}}

\vspace*{6pt}

%\pagebreak

%\newpage

%\vspace*{-28pt}

\hrule

\vspace*{2pt}

\hrule



\def\tit{IDENTIFICATION OF CAUSE-AND-EFFECT RELATIONSHIPS WHEN COVERING CAUSES}


\def\titkol{Identification of cause-and-effect relationships when covering causes}


\def\aut{A.\,A.~Grusho$^1$, N.\,A.~Grusho$^1$, M.\,I.~Zabezhailo$^1$, V.\,V.~Kulchenkov$^2$, 
and~E.\,E.~Timonina$^1$}

\def\autkol{A.\,A.~Grusho, N.\,A.~Grusho, M.\,I.~Zabezhailo, et al.}
%V.\,V.~Kulchenkov$^2$,  and~E.\,E.~Timonina}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-13pt}


\noindent
$^1$Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, 
44-2~Vavilov\linebreak
$\hphantom{^1}$Str., Moscow 119133, Russian Federation

\noindent
$^2$VTB Bank, 43-1 Vorontsovskaya Str., Moscow 109147, Russian Federation

\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2024\ \ \ volume~18\ \ \ issue\ 2}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2024\ \ \ volume~18\ \ \ issue\ 2
\hfill \textbf{\thepage}}}

\vspace*{3pt}


\Abste{The tasks of identification of cause-and-effect relationships are of great importance in medical 
diagnostics, finding the root causes of failures in software and hardware systems, and information 
security. The explainability of the formed conclusions obtained as a result of complex calculations 
using artificial intelligence methods is most\linebreak\vspace*{-12pt}}

\Abstend{often realized using causal relationships. The paper 
investigated the possibility of identification of cause-and-effect relationships in cases where the cause 
is in an inseparable object available for observation. In such cases, it is said that the "cause" property is 
covered by an object in which other data properties are present. Effects of causes appear in other 
information spaces. The cause-and-effect identification problem is investigated in the presence of other 
random data not related to the relationship generated by the cause-and-effect relationship. The model 
of deterministic cause-and-effect relationship is considered in the presence of a significant number of 
randomly occurring properties that are not related to the causal effect of some properties on others.}

\KWE{artificial intelligence; computer data analysis; cause and effect; covering causes}

\DOI{10.14357/19922264240208}{MKXMZY}

%\vspace*{-12pt}

%\Ack

%\vspace*{-3pt}


    % \noindent
   


  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9} 
\bibitem{1-gr-1}
\Aue{Smirnov, D.\,V.} 2021. Metodika problemno-orientirovannogo analiza Big Data v~rezhime 
og\-ra\-ni\-chen\-no\-go vremeni [Methodology of problem-oriented Big Data analysis in limited time mode]. 
\textit{Int. J. Open Information Technologies} 9(9):88--94. EDN: \mbox{NKHHGS}.
{ %\looseness=1

}
\bibitem{2-gr-1}
\Aue{H$\ddot{\mbox{o}}$fler, M.} 2005. Causal inference based on counterfactuals. \textit{BMC 
Med. Res. Methodol.} 5:28.  
12~p. doi: 10.1186/1471- 2288-5-28.
\bibitem{3-gr-1}
\Aue{Richens, J.\,G., C.\,M.~Lee, and S.~Johri.} 2020. Improving the accuracy of medical diagnosis 
with causal machine learning. \textit{Nat. Commun.} 11(1):3923. 9~p. doi:  
10.1038/s41467-020-17419-7.
\bibitem{4-gr-1}
\Aue{Reimer, J., Y.~Wang, S.~Laridi, J.~Urdich, S.~Wilmsmeier, and G.~Palmer.} 2022. Identifying 
cause-and-effect relationships of manufacturing errors using sequence-to-sequence learning. 
\textit{Sci. Rep.~--- U.K.} 12:22332. 11~p. doi: 10.1038/s41598-022-26534-y.
\bibitem{5-gr-1}
\Aue{Grusho, A., N.~Grusho, M.~Zabezhailo, and E.~Timonina.} 2022. Evaluation of trust in 
computer-computed results. \textit{Comm. Com. Inf. Sc.} 1552:420--432. doi:  
10.1007/978-3-030-97110-6\_33.

\bibitem{7-gr-1} %6
\Aue{Pearl, J.} 2010. Causal inference. \textit{Causality: Objectives and assessment}. Eds. I.~Guyon, 
D.~Janzing, and B.~Scholkopf. Proceedings of machine learning research ser. Whistler, Canada.  
6:39--58. 
\bibitem{8-gr-1} %7
\Aue{Pearl, J.} 2013. The mathematics of causal inference. \textit{Joint Statistical Meetings 
Proceedings}. ASA. 2515--2529.

\bibitem{6-gr-1} %8
\Aue{Zhang, X., W.~Hu, and F.~Yang.} 2022. Detection of cause-effect relations based on information 
granulation and transfer entropy. \textit{Entropy} 24(2):212. 18~p. doi: 10.3390/ e24020212.
 
\bibitem{9-gr-1}
\Aue{Grusho, A.\,A., N.\,A.~Grusho, M.\,I.~Zabezhailo, E.\,E.~Timonina, and S.\,Ya.~Shorgin}. 2023. 
Slozhnye prichinno-sledstvennye svyazi [Complex cause-and-effect relationships]. 
\textit{Informatika i ee Primeneniya~--- Inform. \mbox{Appl.}} 17(2):84--89. doi: 10.14357/19922264230212. 
EDN: TGXQIW.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received April 9, 2024}} 


\vspace*{-12pt}


\Contr

\vspace*{-3pt}


\noindent
\textbf{Grusho Alexander A.} (b.\ 1946)~--- Doctor of Science in physics and mathematics, professor, 
principal scientist, Federal Research Center ``Computer Science and Control'' of the Russian Academy 
of Sciences, 44-2~Vavilov Str., Moscow 119333, Russian Federation; \mbox{grusho@yandex.ru}


\vspace*{3pt}

\noindent
\textbf{Grusho Nikolai A.} (b.\ 1982)~--- Candidate of Science (PhD) in physics and mathematics, 
senior scientist, Federal Research Center ``Computer Science and Control'' of the Russian Academy of 
Sciences, 44-2~Vavilov Str., Moscow 119133, Russian Federation; \mbox{info@itake.ru}



\vspace*{3pt}

\noindent
\textbf{Zabezhailo Michael I.} (b.\ 1956)~--- Doctor of Science in physics and mathematics, principal 
scientist, Federal Research Center ``Computer Science and Control'' of the Russian Academy of 
Sciences, 40~Vavilov Str., Moscow 119333, Russian Federation; \mbox{m.zabezhailo@yandex.ru}



\vspace*{3pt}

\noindent
\textbf{Kulchenkov Vladislav V.} (b.\ 1989)~--- deputy head, Portfolio Analysis Department, VTB 
Bank, 43-1~Vorontsovskaya Str., Moscow 109147, Russian Federation; 
\mbox{vlad.kulchenkov@gmail.com}



\vspace*{3pt}

\noindent
\textbf{Timonina Elena E.} (b.\ 1952)~--- Doctor of Science in technology, professor, leading scientist, 
Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences,  
44-2~Vavilov Str., Moscow 119133, Russian Federation; \mbox{eltimon@yandex.ru}




\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 