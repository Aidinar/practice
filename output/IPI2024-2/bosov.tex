\def\stat{bosov}

\def\tit{О ПРИМЕНЕНИИ ГЕНЕРАТИВНЫХ МОДЕЛЕЙ В~СИСТЕМЕ~ЭЛЕКТРОННОГО 
ОБУЧЕНИЯ\\ МАТЕМАТИЧЕСКИМ~ДИСЦИПЛИНАМ$^*$}

\def\titkol{О применении генеративных моделей в~системе электронного 
обучения математическим дисциплинам}

\def\aut{А.\,В.~Босов$^1$, А.\,В.~Иванов$^2$}

\def\autkol{А.\,В.~Босов, А.\,В.~Иванов}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Босов А.\,В.}
\index{Иванов А.\,В.}
\index{Bosov A.\,V.}
\index{Ivanov A.\,V.}


{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
{Исследование выполнено за счет гранта Российского научного фонда №\,22-28-00588, {\sf 
https://rscf.ru/project/22-28-00588/}. Работа выполнялась с~использованием инфраструктуры Центра 
коллективного пользования <<Высокопроизводительные вычисления и~большие данные>> (ЦКП 
<<Информатика>>) ФИЦ ИУ РАН (г.\ Москва).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{avbosov@ipiran.ru}}
\footnotetext[2]{Федеральный исследовательский центр <<Информатика и~управление>> Российской академии наук, 
\mbox{aivanov@ipiran.ru}}

\vspace*{-12pt}

  

  
   \Abst{Существующие инструменты динамического формирования 
индивидуальной траектории обучения дополнены технологией генерации 
аттестационных заданий и~экзаменационных билетов. В~качестве источника 
качественных, сбалансированных наборов заданий использован комплект 
экзаменационных билетов, специально подготовленный экспертами по 
вузовскому курсу теории функций комплексного переменного. Этот 
значительный обучающий массив качественных аттестационных заданий 
существенно расширил имеющиеся данные, созданные на предыдущих этапах. 
Цель выполненного исследования состояла в~создании методов, позволяющих 
учитывать знания экспертов, заложенные в~имеющемся комплекте заданий. 
Реализованная модель генерации при обработке образовательного контента 
использует в~качестве параметров атрибуты, назначенные экспертами задачам: 
тематику, сложность, формируемые компетенции. Предложены два метода 
генерации. Первый~--- вероятностный~--- использует только частотные 
характеристики обучающего комплекта, аппроксимируя распределение 
вероятностей. Второй базируется на ге\-не\-ра\-тив\-но-со\-стя\-за\-тель\-ных 
нейронных сетях. Особое внимание уделено обсуждению трудностей реализации 
сети, связанных в~числе прочего со специфическим характером генеративной 
модели.}
   
   \KW{электронная обучающая система; образовательный контент; машинное 
обучение; генеративные модели; имитационное компьютерное моделирование;  
ге\-не\-ра\-тив\-но-со\-стя\-за\-тель\-ные сети}

\DOI{10.14357/19922264240210}{UWKQLN}
  
\vspace*{-3pt}


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}
  
\section{Введение}

%\vspace*{-6pt}

  Электронные обучающие системы (ЭОС) по\-мимо того, что стали типовым 
инструментом обра\-зовательного процесса, оказались богатым источником 
постановок задач для прикладных и~\mbox{фундаментальных} исследований. 
Общеизвестный пример~--- управ\-ле\-ние тестированием обуча\-емых, 
оформившееся в~самостоятельное на\-прав\-ле\-ние (тео\-рия тес\-ти\-ро\-ва\-ния, item 
response theory, IRT)~[1--6], небольшой вклад в~которое внесен и~авторами~[7, 8]. Практическим результатом методов IRT становится 
индивидуальная траектория обуче\-ния, сформированная из подобранных 
системой заданий~--- образовательного контента, адап\-ти\-ро\-ван\-но\-го под 
контингент обучаемых. Не будет ошибкой считать тео\-рию тес\-ти\-ро\-ва\-ния 
частью более широкого на\-прав\-ле\-ния рекомендательных сис\-тем~[9, 10], 
известных приложениями не только в~об\-ласти электронного обуче\-ния. 
Методы рекомендаций, в~част\-ности са\-мо\-обуча\-ющи\-еся карты, так\-же 
исследовались в~связи с~применениями в~ЭОС как авторами~[11], так 
и~другими исследователями~[12, 13]. Если инструментами IRT, как правило, 
служат методы тео\-рии вероятностей, то рекомендательным сис\-те\-мам в~целом 
более свойственны методы машинного обуче\-ния.

\begin{figure*}[b] %fig1
   \vspace*{1pt}
      \begin{center}
     \mbox{%
\epsfxsize=158.467mm 
\epsfbox{bos-1.eps}
}
\end{center}
\vspace*{-9pt}
  \Caption{Билеты, подготовленные сетью ChatGPT~3.5}
  \end{figure*}
  
   \begin{table*}[b]\small
\vspace*{6pt}
  \begin{center}
  \tabcolsep=5.5pt
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
  \multicolumn{9}{c}{Частотные характеристики обучающей выборки билетов}\\
  \multicolumn{9}{c}{\ }\\[-6pt]
  \hline
\multicolumn{2}{|c|}{Задача 1}&Задача 2&\multicolumn{2}{c|}{Задача 3}&\multicolumn{2}{c|}{Задача 4}&\multicolumn{2}{c|}{Задача 5}\\
\hline
Тема 1&Тема 2&Тема 3&Тема 4&Тема 5&Тема 6&Тема 7&Тема 8&Тема 9\\
\hline
\tabcolsep=0pt\begin{tabular}{c}11\\ 
(из 56)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}89 (74)\\ 
(из 99)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}100\\ 
(из 151)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}50\\ 
(из 92)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}50\\ 
(из 72)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}16\\ 
(из 30)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}84\\ 
(из 109)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}39\\ 
(из 39)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}61\\ 
(из 102)\end{tabular}\\
\hline
\multicolumn{9}{|c|}{Сложность по корпусу 100 билетов}\\
\hline
\tabcolsep=0pt\begin{tabular}{c}1, 2\\ 
(2, 9)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}2\\ 
(89)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}2, 3\\ 
(28, 72)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}2, 3, 4\\ 
(4, 35, 11)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}4, 5\\ 
(6, 44)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}3, 4\\ 
(4, 12)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}5, 6\\ 
(78, 6)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}4, 5, 6\\ 
(1, 19, 19)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}5, 6, 7\\ 
(2, 33, 26)\end{tabular}\\
\hline
\multicolumn{9}{|c|}{Сложность по корпусу 750 заданий}\\
\hline
\tabcolsep=0pt\begin{tabular}{c}1, 2\\ 
(39, 17)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}2\\ 
(99)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}2, 3\\ 
(69, 82)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}2, 3, 4\\ (7, 63, 22)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}4, 5\\ 
(6, 66)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}3, 4\\  (17, 13)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}5, 6\\ 
(99, 10)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}4, 5, 6\\ 
(1, 19, 19)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}5, 6, 7\\ 
(2, 61, 39)\end{tabular}\\
\hline
\multicolumn{9}{|c|}{Компетенции по корпусу 100 билетов}\\
\hline
\tabcolsep=0pt\begin{tabular}{c}1, 2, 3\\ 
(3, 3, 9)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}1, 2, 3, 4\\ 
(23, 3, 63, 86) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}1, 3, 4,\\ 
5, 6\\ 
(52, 4, 36,\\ 79, 32) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}7, 8, 9,\\ 
10, 14\\ 
(27, 26, 4, 20, 2) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}11\\ 
50\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}11, 12\\ 
(5, 16) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}11, 12,\\ 13, 14\\ 
(21, 79,\\ 84, 71) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}15, 16\\ 
(27, 12) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}17, 18, 19\\ 
(49, 10, 2)\end{tabular}\\
\hline
\multicolumn{9}{|c|}{Компетенции по корпусу 750 заданий}\\
\hline
\tabcolsep=0pt\begin{tabular}{c}1, 2, 3\\ 
(13, 23, 40) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}1, 2, 3, 4\\ 
(28, 3, 63, 96) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}1, 3, 4,\\ 
5, 6\\ 
(71, 8, 42,\\ 114, 52) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}7, 8, 9,\\ 
10, 14\\ 
(45, 46, 7,\\ 40, 4) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}11\\ 
72\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}11, 12\\ 
(7, 30) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}11, 12,\\ 13, 14\\ 
(31, 100,\\ 109, 89) \end{tabular}&\tabcolsep=0pt\begin{tabular}{c}15, 16\\ 
(27, 12)\end{tabular}&\tabcolsep=0pt\begin{tabular}{c}17, 18,\\ 
19, 20\\ 
(72, 11, \\
4, 15)\end{tabular}\\
\hline
\end{tabular}
\end{center}
\end{table*}
 
  
  Индивидуальная траектория, вне зависимости от того, какой конкретный 
смысл в~нее вкладывается и~какие инструменты ее формируют, несет еще 
и~специфическую окраску уникальности, новизны. Используя име\-ющий\-ся 
образовательный контент, взаимодействуя со средой, с~обуча\-емы\-ми 
и~преподавателями, система формирует новый контент, до сих пор не 
существовавший. Это может быть очень простой контент, например 
последовательность тес\-тов очередного зачета, или более сложный~--- 
прогноз результатов обучения группы из сотни учащихся. Но это контент 
новый, а~значит, в~об\-ласти электронного обуче\-ния есть место для 
применения современных инструментов машинного обуче\-ния, 
генерирующих контент. Классификаторы, реализующие упомянутый выше 
функционал индивидуального обучения как методики, имеют выраженный 
дискриминационный характер, так как результат классификации определен 
однозначно, никакой вариативности решений не предусматривается. 
Действительно, генеративные методы порождают новый контент <<из 
ничего>>, без ограничений, без очевидных повторений. Простые модели~--- 
гауссовские смеси, скрытые марковские\linebreak процессы, скрытое распределение 
Дирихле~--- и~вычислительно сложные~--- ограниченные машины\linebreak 
Больцмана и~глубокие сети доверия, а~также самые совершенные 
ге\-не\-ра\-тив\-но-со\-стя\-за\-тель\-ные сети~[14]~--- концептуально направлены не на 
выбор\linebreak из име\-ющих\-ся альтернатив, а~на создание новой, другой 
альтернативы. Процесс создания такого контента имеет характер 
креативный, что под\-тверж\-да\-ют и~приложения, в~которых эти модели 
применяются. Это искусство, синтез текс\-тов и~речи, дизайн, игры и~т.\,п. 
Сейчас всему этому уделяется внимания едва ли не больше, чем 
традиционным приложениям нейронных сетей, компьютерному зрению, 
обработке текс\-тов, био\-мет\-рии. Цель данной статьи~--- исследовать 
применимость генеративных моделей в~при\-клад\-ной об\-ласти электронного 
обуче\-ния и~провести эксперимент с~теми данными, что были сформированы 
в~предыдущих работах~[15, 16].

\section{Генеративная модель экзаменационного билета}

  Формально ставится задача из имеющегося комплекта наборов заданий~--- 
задач для самостоятельного решения~--- сформировать экзаменационный 
билет (аттестационное задание). Используется подготовленный ранее набор 
заданий по курсу <<Теория функций комплексного  
переменного>>~\cite{15-bos} (ТФКП, 750~задач, 9~тематических разделов, 
числовая разметка по уровням слож\-ности от~1 до~7 и~набор формируемых 
компетенций~--- множество компетенций пронумеровано числовыми 
значениями от~1 до~20, каждое задание имеет набор из нескольких 
компетенций, всего получается 109~уникальных комбинаций). Нужно 
сгенерировать билет, состоящий из 5~задач. Набор задач билета должен быть 
<<сбалансированным>>, а~в~качестве описания сбалансированности 
экспертами (авторами пособия~[17]) подготовлены 100~образцов билетов.

\subsection{Применение языковой модели}

  На первый взгляд довольно легко получить требуемый результат, 
воспользовавшись готовыми технологическими решениями. Например, 
известной языковой моделью и~генеративной сетью ChatGPT ({\sf 
https://chat.openai.com}). Версия~3.5 общедоступна и~обучена на огромном 
объеме текстов, содержащем и~много математических пособий, в~том числе 
по ТФКП. Итоги экспериментирования с~ChatGPT по вопросу подготовки 
экзаменационных билетов из пяти задач иллюстрирует рис.~1. На этом 
рисунке показаны два (первый и~четвертый) образцы, подготовленные 
в~диалоге с~ChatGPT. Как видно, первый результат выглядит вполне 
содержательным билетом по ТФКП, по крайней мере содержит задачи 
именно по этой дисциплине, и~они достаточно разнообразны. Можно 
обсуждать, что билет не слишком сложный, хотя понятие <<слож\-ность 
билета>> требует уточнения. Задание усложнить и~разнообразить задачи 
быстро привело к~результату~--- второму билету на рис.~1. Здесь сразу 
обращает на себя внимание то, что это уже билет не по ТФКП.
  
  
  
  Таким образом, несмотря на колоссальный объем обучающей выборки, на 
грандиозный размер сети, на тематические <<подкрепления>> 
в~формируемых запросах, предложить билеты чат-бот не смог. Возможная 
проблема здесь состоит том, что в~распоряжении сети нет размеченного 
набора образцов заданий. Но более глубокой и~слож\-ной проб\-ле\-мой 
оказалось то, что сеть не обучена (и,~наверное, с~используемой ею языковой 
моделью, основанной на частотном анализе, не может быть обуче\-на) 
пониманию <<сбалансированного билета>>.
  
  Вместе с~тем данная иллюстрация не дает основания отказаться от самой 
идеи применять в~рас\-смат\-ри\-ва\-емой задаче генеративные модели. В~тех 
приложениях, где эти модели дают хороший результат, можно увидеть общее 
свойство~--- отсутствие четкого критерия оценки результата генерации. 
Новый текст, новое изображение, новая мелодия одинаково ценны 
и~новизной, и~<<сбалансированностью>>. Объективной оценки результата 
не~может быть, решающий вклад вносит дискриминационный компонент, 
обученный на <<удачных>> примерах. Ровно такая же ситуация, хотя 
и~с~гораздо более скромными объемными характеристиками, имеет место 
и~в~рассматриваемой задаче. Поэтому генеративные модели, способные 
обучаться <<сбалансированности>> на подготовленных экспертами 
примерах билетов, должны давать гораздо лучший результат.

\vspace*{-3pt}

\subsection{Применение вероятностной модели}

  К рассматриваемой задаче можно применить традиционные методы 
статистического моделирования типа гауссовской смеси. Непосредственно 
гауссовские распределения применить нельзя из-за дискретного характера 
реализаций всех имеющихся атрибутов, но аналогичные частотные методы 
технологически дадут такое же решение. Для построения вероятностной 
модели проиллюстрируем имеющиеся образцы <<сбалансированных>> 
билетов некоторыми статистическими показателями (см.\ таблицу).
  
  
  В таблице указаны: (1)~число заданий по теме, использованных в~билетах, и~общее число заданий по теме в~имеющемся наборе~750 (в~задаче~1 по 
теме~2 дополнительно число уникальных, неповторяющихся заданий); 
(2)~сложности, встречающиеся в~билетах, и~в~скобках~--- сложности по всем 
заданиям набора~750 по данной теме; (3)~компетенции, встречающиеся 
в~билетах, и~в~скобках~--- все компетенции по теме по всем заданиям 
набора~750. Отметим, что все задания, выбранные экспертами по темам~1,  
3--9, встречаются ровно по одному разу. Повторное использование заданий 
встречается только по теме~2 в~первой задаче билета.
  
  Показанные характеристики можно уточнять далее. Так, интерес 
представляют распределения заданий в~рамках каждой темы по отдельным 
ком-\linebreak\vspace*{-9.8pt}

{ \begin{center}  %fig2
 \vspace*{-3pt}
    \mbox{%
\epsfxsize=79mm 
\epsfbox{bos-2.eps}
}

\end{center}



\noindent
{{\figurename~2}\ \ \small{Распределение билетов обучающей выборки по сложности
}}}

\vspace*{6pt}
\addtocounter{figure}{1}


  
  \noindent
  петенциям: можно сравнивать эти распределения на всех заданиях, 
имеющихся в~корпусе, и~на заданиях, вошедших в~билеты. Также интересно 
общее распределение билетов по суммарной слож\-ности задач, которое 
можно считать сложностью билета (рис.~2).
  
 
  
  Для моделирования билета сначала нужно определить весь набор 
определяющих билет атрибутов, т.\,е.\  
те\-ма\-ти\-ку--слож\-ность--ком\-пе\-тен\-ции всех пяти задач. Для этого 
строится случайный вектор. Для каждой $i$-й задачи билета имеем атрибуты 
  $T_i$, $D_i$\linebreak и~$C_i$, $i\hm= \overline{1, 5}$. Здесь
  $T_i\hm\in \{t_j\}^9_{j=1}=\{1,\ldots , 9\}$~--- одна из  
име\-ющих\-ся~9~тематик;
  $D_i\hm\in \{d_j\}^7_{j=1}\hm= \{1,\ldots , 7\}$~--- один из имеющихся 
7~уровней слож\-ности;
  $C_i\hm\in \{c_j\}^{109}_{j=1}\hm= \{1, \ldots , 109\}$~--- одна из\linebreak  
име\-ющих\-ся 109~групп компетенций (данный параметр представлен  
20-мер\-ным вектором, каждый компонент которого, принимая значение~1 
или~0, определяет при\-над\-леж\-ность задачи к~соответствующей 
компетенции).
  
  Предполагая все эти атрибуты случайными, получим модель билета~--- 
случайный вектор
  \begin{equation}
  \mathrm{E\_{ticket}} =\mathrm{col}\left( T_1, D_1, C_1, T_2, \ldots, C_5\right).
  \label{e1-bos}
  \end{equation}
  
  В качестве упрощенной альтернативы можно будет при необходимости 
использовать упрощенную модель без компетенций
  \begin{equation}
  \mathrm{E\_{simple}\_ticket} =\mathrm{col}\left( T_1, D_1, T_2, \ldots , D_5\right).
  \label{e2-bos}
  \end{equation}
  
  Набор возможных значений E\_ticket обозначим $\{e_j\}^{L_e}_{j=1}$, 
$\mathrm{E\_simple\_ticket}$~--- через $\{s_j\}_{j=1}^{L_s}$. Величины~$L_e$ и~$L_s$ 
определяются име\-ющей\-ся обуча\-ющей выборкой, т.\,е.\ набором билетов, 
подготовленных экспертами. Имеющийся набор дает $L_e\hm=81$ и~$L_s\hm= 
26$. Далее очевидным образом вычисляем частоты $p_j^e$, $j\hm= \overline{1,L_e}$,  и~$p_j^s$, $j\hm= \overline{1, L_s}$, реализации значений~$e_j$ и~$s_j$ 
в~обуча\-ющем наборе билетов. Соответственно, алгоритм генерации нового 
билета состоит из трех шагов.
  
\textbf{Шаг~1.} Моделирование реализации случайного вектора, имеющего 
распределение $\{ (e_j,p_j^e)\}^{L_e}_{j=1}$ или $\{( s_j,p_j^s)\}^{L_s}_{j=1}$.
  
  \textbf{Шаг~2.} Отбор заданий, удовлетворяющих смоделированной реализации. 
Для этого по значению~$e_j$ или~$s_j$ определяются реализовавшиеся 
значения~$T_i$, $D_i$ и~$C_i$, затем из имеющегося блока 750~заданий 
выбираются множества возможных заданий последовательно для $i$-й 
задачи билета.
  
  \textbf{Шаг~3.} Случайным образом выбираются задания для задач билета из 
определенного на шаге~2 множества возможных заданий.
  
  На шаге~3 используется равновероятное распределение, во-пер\-вых, из-за 
того, что иных оснований вероятностный подход предоставить не может,  
во-вто\-рых, затем, чтобы использовать весь корпус 750~заданий и~не 
ограничиваться только примерами, выбранными экспертами.
  
  При такой генерации билетов учитываются статистические зависимости 
между тематиками, сложностями, компетенциями, т.\,е.\ предполагается, 
что эти зависимости~--- это именно те знания, которые выразили эксперты 
в~обуча\-ющем наборе 100~билетов, и~то, что выявлено частотами~$p_j^e$, 
$j\hm= \overline{1, L_e}$, и~$p_j^s$, $j\hm= \overline{1, L_s}$.
  
  Несомненным достоинством здесь выглядят\linebreak простота и~объяснимость 
метода. Ключевым недостатком~--- ограниченность интерпретации знаний 
экспертов в~отношении понятия <<сбалансированности>> только 
размеченными атрибутами \mbox{те\-ма\-ти\-ка}--слож\-ность--ком\-пе\-тен\-ции. На 
самом деле, даже для неспециалиста в~ТФКП при изучении 100~образцов 
билетов становится очевидным, что при их формировании эксперт вкладывал 
много <<смыслов>>, не формализуемых в~терминах  
те\-ма\-ти\-ка--слож\-ность--ком\-пе\-тен\-ции, и~извлечь эти смыслы 
вероятностный подход не способен. Поэтому большего ожидается от 
применения более креативных методов.
  
\subsection{Генеративно-состязательная сеть}

  Как известно~[18], архитектура ге\-не\-ра\-тив\-но-со\-стя\-за\-тель\-ной сети состоит из двух 
взаимодействующих подсетей. Первая реализует собственно генеративную 
модель, вторая~--- дискриминационную модель. Исходными образцами для 
генеративной модели выступают все 100~подготовленных экспертами 
билетов. Модель состоит в~свертке смоделированного образца до вектора 
атрибутов~(1) (модель~(2) для этого метода представляется совсем 
малоинтересной).
  
  Для реализации использовалась библиотека Keras ({\sf https://keras.io}), 
предоставляющая удобную надстройку над фреймворком Tenzorflow, 
и~описание ее автора~[19]. И~генеративная, и~дискриминационная сети 
представлены сверточными сетями. Обращает внимание то, что в~Keras 
в~сравнении\linebreak с~использованной в~предыдущих работах~[15, 16]\linebreak более простой 
библиотекой Scikit-learn ({\sf https://\linebreak scikit-learn.org}) уровень абстракции 
ниже, так что реализация сети требует существенных усилий разработчика.
  
  После проведения серии экспериментов раз\-мер\-ность вектора скрытого 
пространства была определена равной~5, значения получаются от генератора 
псевдослучайных чисел со стандартным нормальным распределением. 
Попытки увеличения числа латентных переменных до~20 не привели 
к~сколь-ни\-будь значимому улучшению качества модели.
  
  В отличие от вероятностной модели, ис\-поль\-зу\-ющей в~модели~(1)  
20-мер\-ный вектор для пред\-став\-ле\-ния атрибутов компетенций, обучающие 
данные и~данные на выходе генеративной сети пред\-став\-ле\-ны пятью  
12-мер\-ны\-ми векторами (каждый вектор соответствует одному заданию 
билета). Первый элемент вектора соответствует теме~$T_i$, второй~--- 
сложности задания~$D_i$, а~для третьего использована свертка: каждая пара 
соседних бинарных элементов вектора компетенций заменена одним 
четырехзначным числом по формуле:
$$
C_k= 0{,}25C_i+  0{,}5C_{i+1},\enskip k= \overline{1,10}\,.
$$
 Это сделано, чтобы уменьшить 
размерность, что очень важно для генеративной сети. После подготовки все 
элементы обучающей выборки были нормализованы.
  
  Поскольку значения элементов обуча\-ющей выборки фактически 
дискретны, а значения на выходе генератора непрерывны, для последующей 
интерпретации результатов работы модели требуется дискретизация 
выходных значений генератора.
  
  Генератор содержит 4~слоя:
  \begin{enumerate}[(1)]
\item полносвязный слой с~60~выходами и~функцией активации <<линейный 
выпрямитель с~утечкой>> (LeakyReLU, leaky rectified linear unit)~[20];
\item одномерный сверточный слой с~размером ядра свертки~2, содержащий 
12~фильт\-ров и~использующий функцию активации LeakyReLU (для связи 
с~предыдущим слоем полученный от него 60-мер\-ный вектор преобразуется 
в~пять 12-мер\-ных векторов);
\item одномерный слой транспонированной свертки с~размером 
ядра~5, содержащий 12~фильт\-ров и~использующий функцию 
активации LeakyReLU;
\item одномерный слой транспонированной свертки с~размером ядра~5, 
содержащий 12~фильтров и~использующий в~качестве функции активации 
гиперболический тангенс.
\end{enumerate}

  Дискриминатор содержит три~слоя:
\begin{enumerate}[(1)]
\item одномерный сверточный слой с~размером ядра свертки~2, содержащий 
48~фильтров и~использующий функцию активации LeakyReLU;
\item одномерный сверточный слой с~размером ядра свертки~5, содержащий 
16~фильт\-ров и~использующий функцию активации LeakyReLU;
\item полносвязный слой с~одним выходом, использующий сигмоидную 
функцию активации.
\end{enumerate}

  В ходе работы с~сетью проявились две наиболее известные трудности, 
характерные для обучения генеративных моделей~[21, 22]:
  \begin{itemize}
\item отказ сходимости модели, проявляющийся в~постоянном росте потерь 
генератора по мере роста числа эпох обуче\-ния при крайне низком качестве 
генерируемых данных;
\item коллапс режима, проявляющийся в~низкой вариативности 
генерируемых данных, а~именно: склонности модели генерировать одни и~те 
же данные при разных значениях вектора скрытого пространства.
\end{itemize}

  Наибольшую эффективность при борьбе с~отказом сходимости модели 
показали следующие при\-емы:
  \begin{enumerate}[(1)]
\item замена оптимизатора с~RMSProp ({\sf https://\linebreak keras.io/api/optimizers/rmsprop}) 
на Adam ({\sf https://keras.io/api/optimizers/adam});
\item замена инициализатора весов модели с~Glorot\-Uniform~[22] на 
HeNormal~[23];
\item применение прореживания в~дискриминаторе~[24];
\item ограничение общей сложности модели (эксперименты показали, что на 
имеющихся данных крайне трудно обеспечить сходимость модели, если 
число параметров превышает~8000).
\end{enumerate}
  
  Также можно отметить, что попытка применить  
$l_1$-ре\-гу\-ля\-ри\-за\-цию к~каждому слою хотя и~обеспечивает 
сходимость модели, но одновременно приводит к~коллапсу режима и~генерации моделью одного единственного задания.
  
  Наибольшая трудность была связана с~возникновением полного или 
частичного коллапса режима модели. Это может быть обусловлено как 
особенностями обуча\-ющих данных, так и~выбранной\linebreak\vspace*{-12pt}

{ \begin{center}  %fig3
 \vspace*{-3pt}
    \mbox{%
\epsfxsize=78.952mm 
\epsfbox{bos-3.eps}
}

\end{center}



\noindent
{{\figurename~3}\ \ \small{Потери генератора~(\textit{1}) и~дискриминатора (\textit{2}~--- сгенерированные данные;  
\textit{3}~--- обуча\-ющие данные)
}}}

\vspace*{6pt}

{ \begin{center}  %fig4
 \vspace*{-3pt}
    \mbox{%
\epsfxsize=78.898mm 
\epsfbox{bos-4.eps}
}

\end{center}



\noindent
{{\figurename~4}\ \ \small{Распределение билетов смоделированных выборок по сложности
}}}

\vspace*{6pt}


 
 
 \noindent
  архитектурой модели. 
В~качестве приемов, помогающих повысить вариативность выходных 
данных модели, можно отметить:
  \begin{enumerate}[(1)]
\item использование в~генераторе слоев транспонированной свертки;
\item увеличение числа слоев генератора;
\item увеличение числа эпох обучения, что, в~свою очередь, требует 
обеспечения высокой устойчивости модели в~целом и~предотвращения ее 
переобучения.
\end{enumerate}

  На рис.~3 приведены графики потерь генератора и~дискриминатора на 
обучающих и~сгенерированных данных для наиболее <<продуктивного>> 
варианта модели. Видно, что после первоначальной сходимости на 
500-м цикле обуче\-ния (100~эпох) наблюдается медленный рост потерь 
генератора, т.\,е.\ данная модель оказывается неустойчивой. Тем не менее 
ее <<про\-дук\-тив\-ность>> растет. Поведение, схожее демонстрируемому 
генеративной моделью в~ходе обуче\-ния, имеет один известный 
радиотехнический прибор~--- регенеративный радиоприемник. Такой 
приемник содержит один усилительный каскад, охваченный положительной 
обратной связью. Этот каскад может быть настолько же эффективен, как 
несколько усилительных каскадов без обратной связи. Однако его 
устойчивость крайне низка, так как определенная глубина обратной связи 
превращает усилитель в~генератор. При этом наибольшая эффективность 
такого усилителя достигается именно на пороге генерации.
  
  
  
  В итоге, используя имеющийся обучающий набор из 100~билетов 
и~размеченный набор 750~задач, удается получить рабочую генеративную 
модель. Обсуждать ее качество, по-ви\-ди\-мо\-му, имеет смысл только 
экспертам. Некоторые вспомогательные показатели обсуждаются 
в~следующем разделе статьи. Для примера и~сравнения с~вероятностной 
моделью подразд.~2.2 для смоделированного генеративной моделью набора 
билетов на рис.~4 приведена гистограмма распределения суммарной 
сложности билетов. Ее надо сравнивать с~рис.~2, и~отличия очевидны. 
Генеративная модель не дает свойственного вероятностной модели 
равномерного распределения сложностей. Вообще диапазон сложностей 
заужен и~в~<<середине>> есть сгущение. Объяснить причины, по которой 
генеративная модель игнорирует самые простые задания и~увеличивает 
частоту заданий <<сред\-ней>> слож\-ности, не представляется возможным. 
Но такое поведение выглядит более <<чест\-ным>> по отношению 
к~студентам, хотя понять, как об этом <<догадалась>> сеть, не 
представляется возможным.
  
  
 
  
\section{Варианты экспертной интерпретации результатов}

  Последним этапом для генерации должна быть оценка качества 
сгенерированных билетов. Формально этот этап должен проанализировать 
два набора: 
\begin{enumerate}[(1)]
\item реализации обуча\-ющей выборки 
$\{\mathrm{E\_ticket}_k^{(1)}\}_{k=1}^{100}$;
\item смоделированные билеты 
$\{\mathrm{E\_ticket}_k^{(2)}\}^N_{k=1}$ чис\-лен\-ностью~$N$, потенциально много 
большей, чем~100.
\end{enumerate}
 Уже упоминалось, что объективных сравнительных 
показателей для этих наборов нет. Но можно предложить ряд типовых 
статистических характеристик, которые могут помочь в~оценке. При 
необходимости будем считать, что $\mathrm{E\_ticket}_k^{(1)}$ и~$\mathrm{E\_ticket}_k^{(2)}$ 
заменены соответствующими скалярами $\{ e_j\}_{j=1}^{L_e}$.
  
  \textbf{Непарные корреляции}~--- самый простой способ качественной оценки 
результатов моделирования с~точки зрения сохранения важных 
зависимостей. Коэффициенты корреляции можно вычислять для значений 
любых двух атрибутов, например между компетенциями пятой задачи~$C_5$ 
и~сложностями первой~$T_1$: 
  \begin{multline}
 \mathrm{корр}(C_5,T_1) ={}\\
 {}=\left(
\sum\limits_{k=1}^K \langle C_5\rangle_k \langle T_1\rangle_k - \left( 
\sum\limits^N_{i=1}\langle C_5\rangle_k\right) \left( \sum\limits^N_{i=1} 
\langle T_1\rangle_k\right)\right)\times\\
{}\times
\left(
  \left( \sum\limits^K_{k=1}\left(\langle C_5\rangle_k\right)^2 -
\left(\sum\limits^K_{k=1} \langle C_5\rangle_k\right)^2\right) \times{}\right.\\
\left.{}\times\left( 
\sum\limits^K_{k=1} \left(\langle T_1\rangle_k\right)^2 -\left(\sum\limits^K_{k=1} 
\langle T_1\rangle_k\right)^2\right)\right)^{-1/2}\,.
  \label{e3-bos}
  \end{multline}
  Здесь $K=100$, если корреляция $\mathrm{корр}^{(1)}(C_5, T_1)$ считается на 
обучающем наборе, тогда $\langle C_5\rangle_k$ и~$\langle T_1\rangle_k$~--- 
реализации соответствующих компонентов векторов $\mathrm{E\_ticket}_k^{(1)}$. Для 
смоделированного набора $K\hm= N$ и~корреляция $\mathrm{корр}^{(2)}(C_5, 
T_1)$ считается на значениях $\langle C_5\rangle_k$ и~$\langle T_1\rangle_k$~--- 
реализациях компонентов векторов $\mathrm{E\_ticket}_k^{(2)}$. Такие парные 
корреляция могут быть вычислены для любых пар атрибутов $T_i$, $D_i$ 
и~$C_i$, $i\hm=\overline{1, 5}$. Эти величины, принимающие значения от~0 до~1, 
характеризуют степень линейной зависимости значений, принимаемых 
атрибутами (в~приведенном примере $C_5$ и~$T_1$). Вы\-чис\-лен\-ные на двух 
наборах величины $\mathrm{корр}^{(1)}(C_5, T_1)$ и~$\mathrm{корр}^{(2)}(C_5, 
T_1)$ долж\-ны сравниваться, их бли\-зость можно интерпретировать как 
подтверждение сба\-лан\-си\-ро\-ван\-ности смоделированного набора билетов по 
отношению к~обуча\-ющему.
  %
  Таких парных корреляций можно выбрать много. Каким отдавать\linebreak 
предпочтение, не вполне понятно, поэтому предлагается использовать 
в~анализе непарные корреляции, а~именно: из значений тематик 
сформировать вектор тематик $T\hm= \mathrm{col}\,(T_1, \ldots , T_5)$, 
\mbox{аналогично} сложностей $D\hm= \mathrm{col}\,(D_1, \ldots , D_5)$ и~компетенций $C\hm= \mathrm{col}\,(C_1, \ldots , C_5)$. Далее определить 
множества возможных значений каждого из трех векторов и~заменить их 
ну\-ме\-ру\-ющи\-ми скалярами $\{t_j\}$, $\{d_j\}$ и~$\{c_j\}$ так же, как при 
формировании скалярного варианта $\mathrm{E\_ticket}$. Теперь мож\-но снова 
вернуться к~парным корреляциям~(\ref{e3-bos}) и~вы\-чис\-лить 
$\mathrm{корр}^{(1)}(T,D)$, $\mathrm{корр}^{(1)}(T,C)$ 
и~$\mathrm{корр}^{(1)}(D,C)$ и~сравнить с~$\mathrm{корр}^{(2)}(T,D)$, 
$\mathrm{корр}^{(2)}(T,C)$ и~$\mathrm{корр}^{(2)}(D,C)$.
  
  \textbf{Расстояние между распределениями.} Более интегрированный 
анализ дает расстояние Куль\-ба\-ка--Лейб\-ле\-ра~\cite{25-bos}, которое 
традиционно используют как числовую оценку меры  
сход\-ст\-ва/раз\-но\-об\-ра\-зия между распределениями вероятностей двух 
случайных векторов.
  
  Распределение по обучающему набору билетов $\mathrm{E\_ticket}_k^{(1)}$ дает 
значения и~частоты $\{(e_j, p_j^{(1)})\}^{L_e}_{j=1}$, $p_j^{(1)} \hm= p_j^e$, 
распределение смоделированного набора $\mathrm{E\_ticket}_k^{(2)}$ дает значения 
и~частоты $\{ ( e_j, p_j^{(2)})\}^{Le}_{j=1}$, частоты~$p_j^{(2)}$ 
определяются аналогично~$p_j^e$, но уже после моделирования 
и~изменяются от эксперимента к~эксперименту, зависят от объема~$N$ 
смоделированных данных так, что возможно для некоторых~$j$ 
$p_j^{(2)}\hm=0$, в~то время как $p_j^{(1)}\not= 0$ $\forall\,j$.
  
  Расстоянием Кульбака--Лейб\-ле\-ра %$\mathrm{раст}\left(E\_ticket^{(2)},  E\_ticket^{(1)}\right) \{ ( e_j, p_j^{(2)})\}_{j=1}^{Le}$
   по отношению 
к~распределению $\{ (e_j, p_j^{(1)})\}^{L_e}_{j=1}$ называется величина
  \begin{multline}
  \mathrm{раст}\left(\mathrm{E\_ticket}^{(2)},  \mathrm{E\_ticket}^{(1)}\right) 
={}\\
{}=\sum\limits_{l=0}^{L-1} p_j^{(2)} \ln \left( \fr{p_j^{(2)}}{p_j^{(1)}}\right).
  \label{e4-bos}
  \end{multline}
  
\noindent
  Заметим, что эта величина несимметрична, неотрицательна и~равенство 
\begin{multline*}
\mathrm{раст}\left(\mathrm{E\_ticket}^{(2)},  \mathrm{E\_ticket}^{(1)}\right) = {}\\
{}=
\mathrm{раст}\left(\mathrm{E\_ticket}^{(1)},  \mathrm{E\_ticket}^{(2)}\right)
\end{multline*}
 означает 
$p_j^{(1)}\hm= p_j^{(2)}$ $\forall\,j$ и~равенство расстояния нулю. 
Масштабной характеристики величина~(\ref{e4-bos}) не имеет, так что 
степень близости к~0 определяется экспериментально.
  
  В качестве показателя качества смоделированного набора билетов можно 
использовать в~дополнение к~$\mathrm{раст}\,(\mathrm{E\_ticket}^{(2)},  
\mathrm{E\_ticket}^{(1)})$ и~ве\-ли\-чину $\mathrm{раст}\,( \mathrm{E\_simple\_ticket}^{(2)}, 
\mathrm{E\_simple\_ticket}^{(1)})$,\linebreak вы\-чис\-ля\-емую по набору $\{ (s_j, 
p_j^s)\}_{j=1}^{L_s}$.
  
  В отношении любых предложенных показателей качественной оценки 
результатов моделирования надо учитывать их ограниченность. В~случае 
использования вероятностной модели подразд.~2.2 эти величины просто 
показывают качество компьютерного моделирования заданного дискретного 
распределения, т.\,е.\ дадут заведомо хорошие результаты, превосходящие 
генеративную модель разд.~2.3. С~другой стороны, потенциал 
и~учитываемые <<смыс\-лы>> генеративной модели значительно больше, 
поэтому основной объективный вывод, который дадут эти расчеты,~--- 
насколько важно для генеративной модели учитывать частотные 
зависимости, вложенные экспертами, составившими обуча\-ющий набор.
  
{\small\frenchspacing
 { %\baselineskip=10.6pt
 %\addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
 
 \bibitem{2-bos} %1
\Au{Rasch G.} Probabilistic models for some intelligence and attainment tests.~--- Chicago, IL, 
USA: The University of Chicago Press, 1980. 224~p.
\bibitem{1-bos} %2
\Au{Van der Linden W.\,J., Scrams D.\,J., Schnipke~D.\,L., \textit{et al.}} Using response-time 
constraints to control for differential speededness in computerized adaptive testing~// Appl. 
Psych. Meas., 1999. Vol.~23. Iss.~3. P.~195--210. doi: 10.1177/01466219922031329.
\bibitem{6-bos} %3
\Au{Chen C.-M., Lee~H.-M., Chen~Y.-H.} Personalized \mbox{e-learning} system using Item Response 
Theory~// Computers  Education, 2005. Vol.~44. No.\,3. P.~237--255.
\bibitem{4-bos}
\Au{Кибзун А.\,И., Иноземцев~А.\,О.} Оценивание уровней сложности тестов на основе 
метода максимального правдоподобия~// Автоматика и~телемеханика, 2014. №\,4.  
С.~20--37.
\bibitem{3-bos} %5
\Au{Kuravsky L.\,S., Margolis A.\,A., Marmalyuk~P.\,A., Panfilova~A.\,S., Yuryev~G.\,A., 
Dumin~P.\,N.} A~probabilistic model of adaptive training~// Applied Mathematical Sciences, 2016. 
Vol.~10. Iss.~48. P.~2369--2380. doi: 10.12988/ams.2016.65168.


\bibitem{5-bos} %6
\Au{Наумов А.\,В., Мхитарян~Г.\,А.} О~задаче вероятностной оптимизации для 
ограниченного по времени тестирования~// Автоматика и~телемеханика, 2016. №\,9. 
С.~124--135.

\bibitem{7-bos}
\Au{Босов А.\,В., Мхитарян~Г.\,А., Наумов~А.\,В., Сапунова~А.\,П.} Использование модели  
гам\-ма-рас\-пре\-де\-ле\-ния в~задаче формирования ограниченного по времени теста 
в~сис\-те\-ме дистанционного обуче\-ния~// Информатика и~её применения, 2019. Т.~13. 
Вып.~4. С.~12--18. doi: 10.14357/19922264190402. EDN: XUBLZX.

\bibitem{8-bos}
\Au{Босов А.\,В., Мартюшова Я.\,Г., Наумов~А.\,В., Сапунова~А.\,П.} Байесовский подход 
к~построению индивидуальной траектории пользователя в~сис\-те\-ме дистанционного 
обуче\-ния~// Информатика и~её применения, 2020. Т.~14. Вып.~3. С.~89--96. doi: 
10.14357/ 19922264200313. EDN: WAKFJR.
\bibitem{9-bos}
\Au{Adomavicius G., Tuzhilin~A.} Toward the next generation of recommender systems: 
A~survey of the state-of-the-art and possible extensions~// IEEE T. Knowl.  Data 
En., 2005. Vol.~17. No.\,6. P.~734--749. doi: 10.1109/TKDE.2005.99.

\bibitem{10-bos}
\Au{Verbert K., Manouselis~N., Ochoa~X., Wolpers~M., Drachsler~H., Bosnic~I., Duval~E.} 
Context-aware recommender systems for learning: A~survey and future challenges~// IEEE 
T. Learn. Technol., 2012. Vol.~5. No.\,4. P.~318--335. doi: 10.1109/TLT.2012.11.

\bibitem{11-bos}
\Au{Босов А.\,В.} Применение самоорганизующихся нейронных сетей к~процессу 
формирования индивидуальной траектории обучения~// Информатика и~её применения, 
2022. Т.~16. Вып.~3. С.~7--15. doi: 10.14357/19922264220302. . EDN: HJQANN.

\bibitem{12-bos}
\Au{Tai D.\,W.\,S., Wu~H.\,J., Li~P.\,H.} Effective e-learning recommendation system based on 
self-organizing maps and association mining~// Electron. Libr., 2008. Vol.~26. No.\,3. 
P.~329--344.
\bibitem{13-bos}
\Au{Bhaskaran S., Marappan~R., Santhi~B.} Design and analysis of a~cluster-based intelligent 
hybrid recommendation system for e-learning applications~// Mathematics, 2021. Vol.~9. 
Art.~197. 21~p. doi: 10.3390/math9020197.
\bibitem{14-bos}
\Au{Harshvardhan G.\,M., Gourisaria~M.\,K., Pandey~M., Rautaray~S.\,S.} A~comprehensive 
survey and analysis of generative models in machine learning~// Computer Science Review, 2020. 
Vol.~38. Art.~100285. 29~p. doi: 10.1016/j.cosrev.2020.100285.

\bibitem{15-bos}
\Au{Босов А.\,В., Иванов А.\,В.} Технология классификации типов контента электронного 
учебника~// Информатика и~её применения, 2022. Т.~16. Вып.~4. С.~63--72. doi: 
10.14357/19922264220410. EDN: YERCNH.

\bibitem{16-bos}
\Au{Босов А.\,В., Иванов А.\,В.} Технология многофакторной классификации 
математического контента электронной сис\-те\-мы обуче\-ния~// Информатика и~её 
применения, 2023. Т.~17. Вып.~4. С.~32--41. doi: 10.14357/19922264230405. EDN: LISHHZ.

\bibitem{17-bos}
\Au{Битюков Ю.\,И., Мартюшова~Я.\,Г.} Решение задач по теории функций 
комплексного переменного.~--- М.: МАИ, 2022. 87~с.
\bibitem{18-bos}
\Au{Goodfellow I., Pouget-Abadie~J., Mirza~M., Xu~B., Warde-Farley~D., Ozair~S., 
Bengio~Y.} Generative adversarial nets~// Adv. Neur. Inf., 
2014. Vol.~27. No.\,3. P.~2672--2680. doi: 10.1007/978-3-658-40442-0\_9.
\bibitem{19-bos}
\Au{Chollet F.} Deep learning with Python.~--- 2nd ed.~--- Shelter Island, NY, USA: Manning, 
2021. 504~p.
\bibitem{20-bos}
\Au{Maas A.\,L., Hannun~A.\,Y., Ng~A.\,Y.} Rectifier nonlinearities improve neural network 
acoustic models~// Proc. ICML, 2013. Vol.~30. No.\,1. Art.~3. 6~p.
\bibitem{21-bos}
\Au{Arjovsky M., Bottou~L.} Towards principled methods for training generative adversarial 
networks.~--- Cornell University, 2017. 17~p. arXiv:1701.04862 [stat.ML]. 
\bibitem{22-bos}
\Au{Saatci Y., Wilson~A.\,G.} Bayesian GAN.~--- Cornell University, 2017.  16~p. arXiv:1705.09558 
[stat.ML]. 
\bibitem{23-bos}
\Au{Glorot X., Bengio~Y.} Understanding the difficulty of training deep feedforward neural 
networks~// J.~Mach. Learn. Res., 2010. Vol.~9. P.~249--256.
\bibitem{24-bos}
\Au{He K., Zhang~X., Ren~S., Sun~J.} Delving deep into rectifiers: Surpassing human-level 
performance on ImageNet Classification~// Conference (International ) on Computer 
Vision Proceedings.~--- Piscataway, NJ, USA: IEEE, 2015. P.~1026--1034. doi: 10.1109/ICCV.2015.123.

\bibitem{25-bos}
\Au{Srivastava N., Hinton~G., Krizhevsky~A., Sutskever~I., Salakhutdinov~R.} Dropout: 
A~simple way to prevent neural networks from overfitting~// J.~Mach. Learn. Res., 
2014. Vol.~15. No.\,56. P.~1929--1958.
\bibitem{26-bos}
\Au{Kullback S., Leibler R.\,A.} On information and sufficiency~// Ann. Math. Stat., 1951. 
Vol.~22. No.\,1. P.~79--86. doi: 10.1214/aoms/1177729694.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 06.02.24}}

%\vspace*{10pt}

%\pagebreak

\newpage

\vspace*{-28pt}

%\hrule

%\vspace*{2pt}

%\hrule



\def\tit{ON THE APPLICATION OF~GENERATIVE MODELS IN~THE~E-LEARNING SYSTEM 
OF~MATHEMATICAL DISCIPLINES}


\def\titkol{On the application of~generative models in~the~e-learning system 
of~mathematical disciplines}


\def\aut{A.\,V.~Bosov and A.\,V.~Ivanov}

\def\autkol{A.\,V.~Bosov and A.\,V.~Ivanov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-8pt}


\noindent
Federal Research Center ``Computer Science and Control'' of the Russian Academy of 
Sciences, 44-2~Vavilov Str., Moscow 119333, Russian Federation

\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2024\ \ \ volume~18\ \ \ issue\ 2}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2024\ \ \ volume~18\ \ \ issue\ 2
\hfill \textbf{\thepage}}}

\vspace*{4pt}




\Abste{The existing tools for individual learning trajectory dynamic design are 
complemented by the generating technology of certification tasks and exam tickets. 
A~set of exam tickets specially prepared by experts in the university course of the 
theory of functions of a~complex variable was used as a source of high-quality, 
balanced sets of tasks. This significant training array of high-quality attestation tasks 
has significantly expanded the available data created at previous stages. The 
purpose of the performed research was to create methods that allow taking into 
account the experts' knowledge embedded in the available set of tasks. The implemented 
generation model when processing educational content uses as parameters the
attributes assigned by experts to tasks: topic, complexity, and formed competencies. 
Two generation methods are proposed. The first one, probabilistic, uses only the 
frequency characteristics of the training set, approximating the probability 
distribution. The second one is based on generative-adversarial neural networks. 
Particular attention is paid to the discussion of the difficulties of the network 
implementation, including those related to the specific nature of the generative 
model.}

\KWE{e-learning system; educational content; machine learning; generative models; computer 
simulation; generative-adversarial networks}



\DOI{10.14357/19922264240210}{UWKQLN}

\vspace*{-12pt}

\Ack

\vspace*{-3pt}


     \noindent
     The research was supported by the Russian Science Foundation, project No.\,22-28-00588,
     {\sf 
https://rscf.ru/\linebreak project/22-28-00588/}. The research 
was carried out using the infrastructure of the Shared Research Facilities ``High Performance Computing 
and Big Data'' (CKP ``Informatics'') of FRC CSC RAS (Moscow).


  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99} 
\bibitem{2-bos-1} %1
\Aue{Rasch, G.} 1980. \textit{Probabilistic models for some intelligence and attainment tests}. Chicago, 
IL: University of Chicago Press. 224~p.

\bibitem{1-bos-1} %2
\Aue{Van der Linden, W.\,J., D.\,J.~Scrams, and D.\,L.~Schnipke.} 1999. Using response-time 
constraints to control for differential speededness in computerized adaptive testing. \textit{Appl. Psych. 
Meas.} 23(3):195--210. doi: 10.1177/ 01466219922031329.

\bibitem{6-bos-1} %3
\Aue{Chen, C.-M., H.-M. Lee, and Y.-H.~Chen.} 2005. Personalized e-learning system using Item 
Response Theory. \textit{Computers Education} 44(3):237--255. doi: 10.1016/ j.compedu.2004.01.006.

\bibitem{4-bos-1}
\Aue{Kibzun, A.\,I., and A.\,O.~Inozemtsev.} 2014. Using the maximum likelihood method to estimate 
test complexity levels. \textit{Automat. Rem. Contr.} 75(4):607--621. doi: 10.1134/S000511791404002X. 
EDN: SKRJCX.

\bibitem{3-bos-1} %5
\Aue{Kuravsky, L.\,S., A.\,A.~Margolis, P.\,A.~Marmalyuk, A.\,S.~Panfilova, G.\,A.~Yuryev, and 
P.\,N.~Dumin.} 2016. A~probabilistic model of adaptive training. \textit{Applied Mathematical Sciences} 
 10(48):2369--2380. doi: 10.12988/ ams.2016.65168.

\bibitem{5-bos-1} %6
\Aue{Naumov, A.\,V., and G.\,A.~Mkhitaryan.} 2016. On the problem of probabilistic optimization of 
time-limited testing. \textit{Automat. Rem. Contr.} 77(9):1612--1621. doi: 10.1134/ S0005117916090083. 
EDN: XFMWHF.

\bibitem{7-bos-1}
\Aue{Bosov, A.\,V., G.\,A.~Mkhitaryan, A.\,V.~Naumov, and A.\,P.~Sapunova.} 2019. Ispol'zovanie 
modeli gamma-raspredeleniya v~zadache formirovaniya ogranichennogo po vremeni testa v~sisteme 
distantsionnogo obucheniya [Using the model of gamma distribution in the problem of forming  
a~time-limited test in a distance learning system]. \textit{Informatika i~ee Primeneniya~--- Inform. 
Appl.} 13(4):12--18. doi: 10.14357/19922264190402. EDN: XUBLZX.
\bibitem{8-bos-1}
\Aue{Bosov, A.\,V., Ya.\,G.~Martyushova, A.\,V.~Naumov, and A.\,P.~Sapunova.} 2020. Bayesovskiy 
podkhod k~po\-stro\-eniyu individual'noy traektorii pol'zovatelya v~sisteme dis\-tan\-tsi\-on\-no\-go obuche\-niya 
[Bayesian approach to the construction of an individual user trajectory in the system of distance learning]. 
\textit{Informatika i~ee Primeneniya~--- Inform. Appl.} 14(3):89--96. doi: 10.14357/19922264200313. 
EDN: WAKFJR.
\bibitem{9-bos-1}
\Aue{Adomavicius, G., and A.~Tuzhilin.} 2005. Toward the next generation of recommender systems: 
A~survey of the state-of-the-art and possible extensions. \textit{IEEE T. Knowl. Data En.}  
17(6):734--749. doi: 10.1109/TKDE.2005.99.
\bibitem{10-bos-1}
\Aue{Verbert, K., N. Manouselis, X.~Ochoa, M.~Wolpers, H.~Drachsler, I.~Bosnic, and E.~Duval.} 
2012. Context-aware recommender systems for learning: A survey and future challenges. \textit{IEEE T. 
Learn. Technol.} 5(4):318--335. doi: 10.1109/TLT.2012.11.
\bibitem{11-bos-1}
\Aue{Bosov, A.\,V.} 2022. Primenenie sa\-mo\-or\-ga\-ni\-zu\-yushchikh\-sya neyronnykh setey k~protsessu 
for\-mi\-ro\-va\-niya individual'noy traektorii obucheniya [Application of self-organizing neural networks to 
the process of forming an individual learning path]. \textit{Informatika i~ee Primeneniya~--- Inform. 
Appl.} 16(3):7--15. doi: 10.14357/19922264220302. EDN: HJQANN.
\bibitem{12-bos-1}
\Aue{Tai, D.\,W.\,S., H.\,J.~Wu, and P.\,H.~Li.} 2008. Effective \mbox{e-learning} recommendation system 
based on self-organizing maps and association mining. \textit{Electron. Libr.} 26(3):329--344.
\bibitem{13-bos-1}
\Aue{Bhaskaran, S., R.~Marappan, and B.~Santhi}. 2021. Design and analysis of a cluster-based 
intelligent hybrid recommendation system for e-learning applications. \textit{Mathematics} 9:197. 21~p. 
doi: 10.3390/math9020197.
\bibitem{14-bos-1}
\Aue{Harshvardhan, G.\,M., M.\,K.~Gourisaria, M.~Pandey, and S.\,S.~Rautaray.} 2020. 
A~comprehensive survey and analysis of generative models in machine learning. \textit{Computer Science 
Review} 38:100285. 29~p. doi: 10.1016/j.cosrev.2020.100285.
\bibitem{15-bos-1}
\Aue{Bosov, A.\,V., and A.\,V.~Ivanov.} 2022. Tekhnologiya klassifikatsii tipov kontenta elektronnogo 
uchebnika [Technology for classification of content types of e-textbooks]. \textit{Informatika i~ee 
Primeneniya~--- Inform. Appl.} 16(4):63--72. doi: 10.14357/19922264220410. EDN: YERCNH.
\bibitem{16-bos-1}
\Aue{Bosov, A.\,V., and A.\,V.~Ivanov.} 2023. Tekhnologiya mnogofaktornoy klassifikatsii 
matematicheskogo kontenta elektronnoy sistemy obucheniya [Multifactor classification technology of 
mathematical content of e-learning system]. \textit{Informatika i~ee Primeneniya~--- Inform. Appl.} 
17(4):32--41. doi: 10.14357/19922264230405. EDN: LISHHZ.
\bibitem{17-bos-1}
\Aue{Bityukov, Yu.\,I., and Ya.\,G.~Martyushova.} 2022. \textit{Reshenie zadach po teorii funktsiy 
kompleksnogo peremennogo} [Solving problems on the theory of functions of a complex variable]. 
Moscow: MAI. 87~p.
\bibitem{18-bos-1}
\Aue{Goodfellow, I., J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair, and 
Y.~Bengio}. 2014. Generative adversarial nets. \textit{Adv. Neur. Inf.} 
27(3):2672--2680.  doi: 10.1007/978-3-658-40442-0\_9.
\bibitem{19-bos-1}
\Aue{Chollet, F.} 2021. \textit{Deep learning with Python}. 2nd ed. Shelter Island, NY: Manning. 504~p.
\bibitem{20-bos-1}
\Aue{Maas, A.\,L., A.\,Y.~Hannun, and A.\,Y.~Ng.} 2013. Rectifier nonlinearities improve neural 
network acoustic models. \textit{Proc. ICML} 30(1):3. 6~p.
\bibitem{21-bos-1}
\Aue{Arjovsky, M., and L.~Bottou.} 2017. Towards principled methods for training generative 
adversarial networks. Cornell University. 17~p. Available at: {\sf https://arxiv.org/\linebreak abs/1701.04862} (accessed 
May~6, 2024).
\bibitem{22-bos-1}
\Aue{Saatci, Y., and A.\,G.~Wilson.} 2017. Bayesian GAN. Cornell University. 16~p. Available at: {\sf 
https://arxiv.org/\linebreak abs/1705.09558} (accessed May~6, 2024).
\bibitem{23-bos-1}
\Aue{Glorot, X., and Y.~Bengio.} 2010. Understanding the difficulty of training deep feedforward neural 
networks. \textit{J.~Mach. Learn. Res.} 9:249--256.
\bibitem{24-bos-1}
\Aue{He, K., X.~Zhang, S.~Ren, and J.~Sun.} 2015. Delving deep into rectifiers: Surpassing  
human-level performance on ImageNet classification. \textit{Conference (International) on Computer 
Vision Proceedings.} Piscataway, NJ: 
IEEE. 1026--1034. doi: 10.1109/\mbox{ICCV}.2015.123.
\bibitem{25-bos-1}
\Aue{Srivastava, N., G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.} 2014. Dropout: 
A~simple way to prevent neural networks from overfitting. \textit{J.~Mach. Learn. Res.} 
15(56):1929--1958.
\bibitem{26-bos-1}
\Aue{Kullback, S., and R.\,A.~Leibler.} 1951. On information and sufficiency. \textit{Ann. 
Math. Stat.} 22(1):79--86. doi: 10.1214/aoms/1177729694.

\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Received February 6, 2024}} 

\vspace*{-12pt}


\Contr

\vspace*{-3pt}

\noindent
\textbf{Bosov Alexey V.} (b.\ 1969)~--- Doctor of Science in technology, principal scientist, Federal 
Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, 44-2~Vavilov 
Str., Moscow 119333, Russian Federation; \mbox{avbosov@ipiran.ru}

\vspace*{3pt}

\noindent
\textbf{Ivanov Alexey V.} (b.\ 1976)~--- Candidate of Science (PhD) in technology, leading scientist, 
Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences,  
44-2~Vavilov Str., Moscow 119333, Russian Federation; \mbox{aivanov@ipiran.ru}





\label{end\stat}

\renewcommand{\bibname}{\protect\rm Литература} 