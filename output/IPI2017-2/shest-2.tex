
\newcommand{\It}{\mathbf{1}}

\def\stat{shestakov-2}

\def\tit{УНИВЕРСАЛЬНАЯ ПОРОГОВАЯ ОБРАБОТКА В~МОДЕЛЯХ~С~НЕГАУССОВЫМ ШУМОМ}

\def\titkol{Универсальная пороговая обработка в моделях с~негауссовым шумом}

\def\aut{О.\,В.~Шестаков$^1$}

\def\autkol{О.\,В.~Шестаков}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Шестаков О.\,В.}
\index{Shestakov O.\,V.}


%{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
%{Работа выполнена при частичной финансовой поддержке РФФИ (проект 15-07-02652).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский государственный университет им.\ М.\,В.~Ломоносова, кафедра 
математической статистики факультета вычислительной математики и кибернетики; 
Институт проб\-лем информатики Федерального исследовательского центра 
<<Информатика и~управ\-ле\-ние>> Российской академии наук, \mbox{oshestakov@cs.msu.su}}

%\vspace*{-18pt}


\Abst{В~задачах непараметрического оценивания сигнала обычно предполагается, 
что функция сигнала принадлежит некоторому специальному классу. Например, она 
может быть ку\-соч\-но-не\-пре\-рыв\-ной или 
ку\-соч\-но-диф\-фе\-рен\-ци\-ру\-емой и~иметь компактный носитель. Эти 
предположения, как правило, позволяют экономно представить функцию сигнала 
в~некотором специально подобранном базисе таким образом, что полезный сигнал 
оказывается сосредоточенным в относительно небольшом количестве больших по 
абсолютному значению коэффициентов разложения. Затем осуществляется пороговая 
обработка с целью удаления шумовых коэффициентов. Обычно распределение шума 
предполагается гауссовым. Эта модель хорошо изучена в~литературе, и для разных 
классов функций сигналов вычислены оптимальные параметры пороговой обработки. 
В~данной работе рассматривается задача построения оценки функции сигнала по 
наблюдениям, содержащим аддитивный шум, распределение которого принадлежит 
достаточно широкому классу. Вычисляются значения универсальных параметров 
пороговой обработки, при которых среднеквадратичный риск близок 
к~минимальному.}

\KW{пороговая обработка; негауссовый шум; среднеквадратичный риск}

%\vspace*{-6pt}

\DOI{10.14357/19922264170214} 


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}

\section{Введение}

Современные методы построения оценок функции сигнала по зашумленным наблюдениям 
часто основаны на разложении этой функции по базису, обеспечивающему <<экономное>> 
представление данных, т.\,е.\ коэффициенты такого разложения убывают достаточно 
быстро (примерами подобных базисов могут служить различные классы вейвлетов). 
Затем происходит обнуление части коэффициентов, которые по предположению содержат 
в~основном шум. В~предположении о гауссовском распределении шума эти методы хорошо 
разработаны~[1--3]. В~данной работе рассматривается модель с аддитивным шумом, 
который необязательно имеет гауссово распределение, и вычисляются 
универсальные параметры диагональных методов подавления шума, при которых 
среднеквадратичный риск близок к минимальному.

\section{Модель данных и~методы подавления шума}

Предположим, что данные имеют вид:
\begin{equation*}
%\label{data_model}
X_i=f_i+z_i\,, \enskip i=1,\ldots,N\,,
\end{equation*}
где $f_i$~--- <<чистый>> сигнал, а~$z_i$~--- 
<<шумовые>> коэффициенты, относительно которых предполагается, что они 
независимы и имеют распределение с симметричной дифференцируемой плотностью~$h(x)$. 
Также предположим, что $\sup\limits_{x\in {\mathbf R}}\abs{h'(x)}\hm<A$ 
с~некоторой константой $A\hm>0$ и что
$$
h(x)\asymp x^\alpha e^{-\theta x^\beta}\ \mbox{при } x\to\infty\,, \enskip
\alpha\in {\mathbf R}\,, \  \theta>0\,, \  \beta>0\,.
$$
Дисперсию $z_i$ обозначим через~$\sigma^2$. Класс распределений такого вида 
достаточно широк. Распределения из этого класса могут иметь как более легкие, 
так и более тяжелые хвосты, чем гауссово распределение.

При построении оценки сигнала будем рас\-смат\-ри\-вать только диагональные методы, 
т.\,е.\ когда для получения оценки~$\hat{f}_i$ коэффициента~$f_i$ используется 
только величина~$X_i$. Определим среднеквадратичный риск оценки:
\begin{equation}
\label{MSE}
R(\hat{f})=\sum\limits_{i=1}^{N}\e\left(\hat{f}_i-f_i\right)^2\,.
\end{equation}
Рассмотрим метод построения оценки, который заключается в том, 
что каждый коэффициент либо обнуляется, либо остается неизменным:
$$
\hat{f}_i=\rho_\delta\left(X_i\right)=\delta_i X_i\,, \enskip
\delta_i\in\{0,1\}\,,\ i=1,\ldots,N\,.
$$
Предположим, что известны <<идеальные>> па\-ра\-мет\-ры~$\delta_i$, которые 
минимизируют риск~\eqref{MSE}. Поскольку слагаемые в~\eqref{MSE} равны~$f^2_i$, 
если $\delta_i\hm=0$, и~$\sigma^2$, если $\delta_i\hm=1$, минимальный 
среднеквадратичный риск равен

\vspace*{-2pt}

\noindent
\begin{equation}
\label{MSE_Min}
R_{\mathrm{Min}}(\hat{f})=\sum\limits_{i=1}^{N}\min\left(f_i^2,\sigma^2\right)\,,
\end{equation}
а <<идеальные>> параметры равны $\delta_i\hm=\It(\abs{f_i}\hm>\sigma)$. На практике 
вычислить эти параметры нельзя и невозможно построить оценку, риск которой 
равен~\eqref{MSE_Min}. Однако в работе~\cite{DonJ94} показано, что при 
использовании процедуры пороговой обработки в~модели с~гауссовым можно обеспечить 
порядок сред\-не\-квад\-ра\-тич\-но\-го риска, который близок к~\eqref{MSE_Min} с точностью до 
логарифмического множителя.

Пороговая обработка является одним из самых популярных методов подавления шума. 
Ее смысл заключается в обнулении коэффициентов, чьи абсолютные значения не превышают 
заданного порога. Оценка~$\hat{f}_i$ вычисляется с помощью пороговой 
функции $\rho_T(x)$ с порогом~$T$. Наиболее популярными являются функция жесткой 
пороговой обработки $\rho_T^{(h)}(x)\hm=x \cdot\mathbf{1} (|x|>T)$ и мягкой пороговой 
обработки $\rho_T^{(s)}(x)\hm={\mbox{sign}}(x)(|x|-T)_+$. Сред\-не\-квад\-ра\-тич\-ный риск 
пороговой обработки обозначим через~$R_T(\hat{f})$.

\vspace*{-2pt}

\section{Универсальный порог}

\vspace*{-2pt}

Одной из основных проблем при пороговой обработке является стратегия выбора порога. 
В~работе \cite{DonJ94} предложен так называемый универсальный порог для модели 
с~гауссовским шумом. Этот порог является в~некотором смысле максимальным среди 
<<разумных>> порогов, и~среднеквадратичный риск при таком пороге близок 
к~\eqref{MSE_Min}. Более точные значения порога для различных функций потерь при 
дополнительных условиях на гладкость функции сигнала получены в работах~[3--6]. 
В~данной работе предлагается аналог универсального порога для определенной выше 
более общей модели шума и~показывается, что он обладает практически такими же 
свойствами, как в~модели с~гауссовским шумом.

Пусть $T_U\hm=\left(\theta^{-1}\ln N\right)^{1/\beta}$. 
По аналогии с гауссовской моделью шума назовем этот порог универсальным.

\smallskip

\noindent
\textbf{Теорема~1.}\ \textit{Существует такая константа $C\hm>0$, 
зависящая только от~$h(x)$, что начиная с некоторого~$N$ при жесткой пороговой 
обработке}
\begin{equation}
\label{MSE_Hard}
R_{T_U}\left(\hat{f}\right)\leq C(\ln N)^{\delta(\alpha,\beta)}
\left(\sigma^2+R_{\mathrm{Min}}\left(\hat{f}\right)\right),
\end{equation}
где $\delta(\alpha,\beta)=\max({2}/{\beta},({3+\alpha-\beta})/{\beta})$.

\columnbreak

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\,.\ \ 
Рассмотрим $\e(\rho_{T_U}^{(h)}(X_i)\hm-f_i)^2$. Пусть $\abs{f_i}\hm>T_U$. Тогда
\begin{multline*}
\e\left(\rho_{T_U}^{(h)}\left(X_i\right)-f_i\right)^2=\sigma^2-{}\\
{}-
\e\left(X_i-f_i\right)^2\It\left(\abs{X_i}\leq T_U\right)+f_i^2\e\It
\left(\abs{X_i}\leq T_U\right) \leq{}\\
{}\leq \sigma^2+f_i^2\e\It\left(\abs{X_i}\leq T_U\right)\,.
\end{multline*}

В силу конечности второго момента плот\-ности~$h(x)$ существует 
такая положительная константа~$C^{(h)}$, зависящая от~$h(x)$, что 
$f_i^2\e\It(\abs{X_i}\hm\leq T)\hm\leq C^{(h)}T^2$ при любом $T\hm>0$. Следовательно, 
существует такая константа $C_1\hm>0$, что
\begin{multline*}
\e\left(\rho_{T_U}^{(h)}\left(X_i\right)-f_i\right)^2\leq {}\\
{}\leq
\sigma^2+C^{(h)}T_U^2\leq C_1\left(\fr{\sigma^2}{N}+\sigma^2\right)
(\ln N)^{2/\beta}\,.
\end{multline*}
Пусть теперь $\abs{f_i}\hm\leq T_U$. Тогда
$$
\e\left(\rho_{T_U}^{(h)}\left(X_i\right)-f_i\right)^2\leq\e\left(X_i-f_i\right)^2\It
\left(\abs{X_i}> T_U\right)+f_i^2\,.
$$
Обозначим
$$
g\left(f_i\right)=\e\left(X_i-f_i\right)^2\It\left(\abs{X_i}> T_U\right)\,.
$$
Поскольку $g(f_i)$ симметрична относительно~0 и~$\abs{h'(x)}$ ограничена,
$$
g\left(f_i\right)\leq g(0)+\fr{1}{2}\left(\sup\limits_{f\in{\mathbf R}}
\abs{g''(f)}\right)f_i^2\,.
$$
В силу определения~$h(x)$ существует такая константа $C_0\hm>0$, что
$$
g(0)\leq C_0T_U^{3+\alpha-\beta}e^{-\theta T_U^{\beta}}\,.
$$
Следовательно, существует такая константа $C_2\hm>0$, что
$$
\e\left(\rho_{T_U}^{(h)}\left(X_i\right)-f_i\right)^2\leq 
C_2 \left(\!\fr{\sigma^2(\ln N)^{({3+\alpha-\beta})/{\beta}}}{N}+f_i^2\!\right).
$$
Таким образом, начиная с некоторого~$N$
\begin{multline*}
\e\left(\rho_{T_U}^{(h)}\left(X_i\right)-f_i\right)^2\leq {}\\
{}\leq
C (\ln N)^{\delta(\alpha,\beta)}\left(\fr{\sigma^2}{N}+\min(f_i^2,\sigma^2)\right)\,,
\end{multline*}
где $C$ зависит только от~$h(x)$. Суммируя по~$i$, получаем~\eqref{MSE_Hard}. 
Теорема доказана.

\smallskip

\noindent
\textbf{Теорема~2.}\ \textit{Существует такая константа $C\hm>0$, зависящая только 
от~$h(x)$, что начиная с некоторого~$N$ при мягкой пороговой обработке}
\begin{equation}
\label{MSE_Soft}
R_{T_U}\left(\hat{f}\right)\leq C(\ln N)^{\delta(\alpha,\beta)}\left(\sigma^2+R_{\mathrm{Min}}
\left(\hat{f}\right)\right)\,,
\end{equation}
\textit{где} $\delta(\alpha,\beta)\hm=\max({2}/{\beta},({3+\alpha-3\beta})/{\beta})$.

\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о\ \ 
этой теоремы аналогично доказательству теоремы~1. Основное отличие заключается в том, 
что при мягкой пороговой обработке в силу определения~$h(x)$ выполнено
\begin{multline*}
g(0)=\e\left(X_i-T_U\right)^2\It\left(X_i>T_U\right)+{}\\
{}+
\e\left(X_i+T_U\right)^2\It\left(X_i<-T_U\right)\leq 
C_0T_U^{3+\alpha-3\beta}e^{-\theta T_U^{\beta}}
\end{multline*}
с некоторой константой $C_0\hm>0$.

\smallskip

Таким образом, оценки~\eqref{MSE_Hard} и~\eqref{MSE_Soft} демонстрируют, 
что в рассматриваемой модели универсальный порог обеспечивает порядок 
среднеквадратичного риска, который отличается от минимального лишь 
наличием логарифмического множителя в степени, зависящей от 
характеристик распределения шума.

Установим теперь еще одно свойство порога~$T_U$, 
которое показывает, что, как и в случае гауссовского шума, универсальный порог 
является в некотором смысле максимальным среди разумных порогов.

\smallskip

\noindent
\textbf{Теорема~3.} \textit{Пусть случайные величины~$z_i$, $i\hm=1,\ldots,N$, 
независимы и имеют плотность распределения~$h(x)$, удовлетворяющую перечисленным 
выше условиям. Тогда}
\begin{equation}
\label{Prob_T}
{\sf P}\left(T^{-}_{U}\leq\max\limits_{1\leq i\leq N}
\abs{z_i}\leq T^{+}_{U}\right)\to 1 \mbox{ при } N\to\infty\,.
\end{equation}
Здесь
$$
T^{-}_{U}=\left(\fr{\ln N+\gamma'\ln\ln N}{\theta}\right)^{1/\beta}\,,
$$
\textit{где $\gamma'$~--- произвольное число, удовлетворяющее}
 $\gamma'\hm<\beta^{-1}(1\hm+\alpha\hm-\beta)$; 
\begin{equation*}
T^{+}_{U}=\begin{cases}
\left(\fr{\ln N+\gamma''\ln\ln N}{\theta}\right)^{\!\!1/\beta} &
\!\!\mbox{при } 1+\alpha-\beta\geq0\,; \\ 
T_U  & \!\!\mbox{при } 1+\alpha-\beta<0\,,
\end{cases}
\end{equation*}
\textit{где $\gamma''$~--- произвольное число, удовлетворяющее} $\gamma''\hm>
\beta^{-1}(1\hm+\alpha\hm-\beta)$.

\smallskip

\noindent
Д\,о\,к\,а\,з\,а\,т\,е\,л\,ь\,с\,т\,в\,о.\ \ 
Утверждение~\eqref{Prob_T} является простым следствием более общих утверждений 
о~распределениях экстремумов случайных последовательностей. Легко видеть, 
что $NH(T^{-}_{U})\hm\to\infty$ и $NH(T^{+}_{U})\hm\to 0$ при $N\hm\to\infty$, 
где $H(x)$~--- функция распределения, соответствующая плотности~$h(x)$. 
Следовательно, в силу теоремы~1.5.1 из~\cite{Lidb89} при $N\hm\to\infty$
\begin{align*}
{\sf P}\left(\max\limits_{1\leq i\leq N}\abs{z_i}\leq T^{-}_{U}\right)&\to 0\,;\\
{\sf P}\left(\max\limits_{1\leq i\leq N}\abs{z_i}\leq T^{+}_{U}\right)
&\to 1\,,
\end{align*}
т.\,е.\ выполнено~\eqref{Prob_T}. Теорема доказана.

\smallskip

Утверждение теоремы~3 означает, что макси\-маль\-ная амплитуда шума с~вероятностью, 
стре\-мящейся к~единице, находится в~некоторой\linebreak окрест\-ности~$T_U$. Следовательно, при 
достаточно большом~$N$ нет смысла выбирать порог, превосходящий~$T_U$.


{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9}
\bibitem{DonJ94}
\Au{Donoho D., Johnstone I.\,M.} Ideal spatial adaptation via wavelet shrinkage~// 
Bio\-met\-ri\-ka, 1994. Vol.~81. No.\,3. P.~425--455.


\bibitem{DJ98}
\Au{Donoho D., Johnstone~I.\,M.} Minimax estimation via wavelet shrinkage~// 
Ann. Stat., 1998. Vol.~26. No.\,3. P.~879--921.

\bibitem{Jan01}
\Au{Jansen M.} Noise reduction by wavelet thresholding.~--- 
Lecture notes in statistics ser.~--- 
New York, NY, USA: Springer Verlag, 2001.  Vol.~161. 217~p.

\bibitem{SH12}
\Au{Шестаков О.\,В.} Асимптотическая нормальность оценки риска пороговой обработки 
вейв\-лет-ко\-эф\-фи\-ци\-ен\-тов при выборе адаптивного порога~// Докл. 
РАН, 2012. Т.~445. №\,5. С.~513--515.

\bibitem{KS16-1} 
\Au{Кудрявцев А.\,А., Шестаков~О.\,В.} Асимптотическое поведение порога, 
минимизирующего усредненную вероятность ошибки вычисления вейв\-лет-ко\-эф\-фи\-ци\-ен\-тов~// 
Докл. РАН, 2016. Т.~468. №\,5. С.~487--491.

\bibitem{KS16-2}
\Au{Кудрявцев А.\,А., Шестаков~О.\,В.} 
Асимптотически оптимальная пороговая обработка вейв\-лет-ко\-эф\-фи\-ци\-ен\-тов 
в~моделях с негауссовым распределением шума~// Докл. РАН, 2016. Т.~471. №\,1. С.~11--15.

\bibitem{Lidb89}
\Au{Лидбеттер М., Линдгрен~Г., Ротсен~Х.} 
Экстремумы случайных последовательностей и процессов~/
Пер с~англ.~--- М.:~Мир, 1989. 392~с.
(\Au{Leadbetter~M., Lindgren~G., Rootzen~H.} 
{Extremes and related properties of random sequences and processes.}~--- 
New York, NY, USA: Springer-Verlag, 1983. 336~p.)

 \end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-3pt}

\hfill{\small\textit{Поступила в~редакцию 01.03.17}}

%\vspace*{8pt}

\newpage

\vspace*{-24pt}

%\hrule

%\vspace*{2pt}

%\hrule

%\vspace*{8pt}


\def\tit{UNIVERSAL THRESHOLDING IN~THE~MODELS WITH~NON-GAUSSIAN NOISE}

\def\titkol{Universal thresholding in the models with non-Gaussian noise}

\def\aut{O.\,V.~Shestakov$^{1,2}$}

\def\autkol{O.\,V.~Shestakov}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-9pt}


\noindent
$^1$Department of Mathematical Statistics, Faculty of Computational Mathematics 
and Cybernetics, M.\,V.~Lo-\linebreak
$\hphantom{^1}$monosov Moscow State University, 1-52~Leninskiye Gory,
 GSP-1, Moscow 119991, Russian Federation
 
 \noindent
 $^2$Institute of Informatics Problems, Federal Research Center 
 ``Computer Science and Control'' of the Russian\linebreak
 $\hphantom{^1}$Academy of Sciences, 44-2~Vavilov Str., 
 Moscow 119333, Russian Federation



\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2017\ \ \ volume~11\ \ \ issue\ 2}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2017\ \ \ volume~11\ \ \ issue\ 2
\hfill \textbf{\thepage}}}

\vspace*{3pt}



\Abste{A common assumption in nonparametric signal estimation 
is that the signal function belongs to a certain class. For example, 
it may be piecewise continuous or piecewise differentiable and have 
a~compact support. These assumptions, as a~rule, make it possible to economically 
represent a~signal function in a~specially selected basis in such 
a~way that the useful signal is concentrated in a~relatively small number of 
large expansion coefficients. Then, threshold processing removes noisy coefficients. 
Typically, the noise distribution is assumed to be Gaussian. This model has been 
well studied in the literature and optimal thresholding parameters have been 
calculated for different classes of signal functions. The paper considers 
the problem of constructing an estimate for the signal function from the 
observations containing additive noise, whose distribution belongs to quite 
a~wide class. The authors calculate the values of universal thresholding 
parameters for which the mean-square risk is close to the minimum.}

\KWE{thresholding; non-Gaussian noise; mean-square risk} 
 
\DOI{10.14357/19922264170214} 

%\vspace*{-18pt}

%\Ack
%\noindent




%\vspace*{3pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{9}



\bibitem{DonJ94-1}
\Aue{Donoho, D., and I.\,M.~Johnstone}. 1994. Ideal spatial adaptation via wavelet 
shrinkage. \textit{Biometrika} 81(3):425--455.

\bibitem{DJ98-1}
\Aue{Donoho, D., and I.\,M.~Johnstone}. 1998. Minimax estimation via wavelet
 shrinkage \textit{Ann. Stat.}  26(3):879--921.

\bibitem{Jan01-1}
\Aue{Jansen, M.} 2001. \textit{Noise reduction by wavelet thresholding.} 
Lecture notes in statistics ser.
New York, NY: Springer Verlag.  Vol.~161. 217~p.

\bibitem{SH12-1}
\Aue{Shestakov, O.\,V.} 2012. Asymptotic normality of adaptive wavelet 
thresholding risk estimation. \textit{Dokl. Math.} 86(1):556--558.

\bibitem{KS16-1-1}  
\Aue{Kudryavtsev, A.\,A., and O.\,V.~Shestakov.} 2016. 
Asymptotic behavior of the threshold minimizing the average probability of error 
in calculation of wavelet coefficients. \textit{Dokl. Math.} 93(3):295--299.

\bibitem{KS16-2-1} 
\Aue{Kudryavtsev, A.\,A., and O.\,V.~Shestakov.} 2016. Asymptotically optimal 
wavelet thresholding in the models with non-Gaussian noise distributions. 
\textit{Dokl. Math.} 94(3):615--619.

\bibitem{Lidb89-1}
\Aue{Leadbetter, M., G.~Lindgren, and H.~Rootzen.} 1983. 
\textit{Extremes and related properties of random sequences and processes.} 
New York, NY: Springer-Verlag. 336~p.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-3pt}

\hfill{\small\textit{Received March 1, 2017}}

\Contrl

\noindent
\textbf{Shestakov Oleg V.} (b.\ 1976)~--- 
Doctor of Science in physics and mathematics, associate professor, 
Department of Mathematical Statistics, Faculty of Computational Mathematics 
and Cybernetics, M.\,V.~Lomonosov Moscow State University, 1-52~Leninskiye Gory,
 GSP-1, Moscow 119991, Russian Federation; senior scientist, 
 Institute of Informatics Problems, Federal Research Center 
 ``Computer Science and Control'' of the Russian Academy of Sciences, 44-2~Vavilov Str., 
 Moscow 119333, Russian Federation; \mbox{oshestakov@cs.msu.su}
\label{end\stat}


\renewcommand{\bibname}{\protect\rm Литература} 