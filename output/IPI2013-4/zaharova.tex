\def\stat{zaharova}

\def\tit{О МЕТОДЕ ПРОГНОЗИРОВАНИЯ И КЛАССИФИКАЦИИ ДЛЯ~ЦЕНЗУРИРОВАННЫХ ДАННЫХ}

\def\titkol{О методе прогнозирования и классификации для цензурированных данных}

\def\autkol{Т.\,В.~Захарова, Е.\,М.~Абрамова}

\def\aut{Т.\,В.~Захарова$^1$, Е.\,М.~Абрамова$^2$}

\titel{\tit}{\aut}{\autkol}{\titkol}

%{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnotetext[1] {Статья 
%рекомендована к публикации в журнале Программным комитетом конференции 
%<<Электронные библиотеки: перспективные методы и технологии, электронные 
%коллекции>> (RCDL-2012).}}

\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Московский государственный университет им.\ М.\,В.~Ломоносова, 
факультет вычислительной математики и кибернетики, lsa@cs.msu.ru} 
\footnotetext[2]{Московский государственный университет им.\ М.\,В.~Ломоносова, 
факультет вычислительной математики и кибернетики, houselake@gmail.com} 



\Abst{В данной работе решалась задача классификации пациентов с
инсулинонезависимым сахарным диабетом (ИНСД) и выявления
признаков, по которым у пациентов можно предположить наличие
данного диагноза. В~первоначальном виде
медицинские данные не удалось классифицировать. Основной помехой
для использования классического метода дискриминации стала
недостаточность и неполнота данных.
Для обработки таких данных предлагается метод классификации, в
котором определенным образом выбираются различные наборы
дискриминантных признаков и строятся классификационные функции для
каждого набора. Число таких наборов зависит от степени неполноты
данных: чем больше потерянных данных, тем больше число различных
наборов. Пациент классифицируется каждой дискриминантной системой и
относится к той группе, для которой было получено максимальное число
совпадений классификации. Такая многоступенчатая классификация
компенсирует малый объем выборки и максимально использует информацию
о каждом пациенте.}


\KW{гипотеза; цензурированные данные;
дискриминантные переменные; классификационные функции;
прогнозирование}

\DOI{10.14357/19922264130411}

\vskip 14pt plus 9pt minus 6pt

      \thispagestyle{headings}

      \begin{multicols}{2}

            \label{st\stat}

\section{Введение}

Задачи классификации и прогнозирования являются достаточно важными
и актуальными проб\-лемами, решаемыми методами математической
статистики. Задачи подобного рода в медицинских исследованиях
имеют дополнительную значимость. Правильно поставленный диагноз на
начальных стадиях болезни может значительно облегчить само лечение
и продлить жизнь человека, тем более если это опасное
заболевание.

ФГУ РЦСМЭ Росздрава (Российский центр су\-деб\-но-ме\-ди\-цин\-ской
экспертизы, г.~Москва) предоставил авторам статьи данные,
характеризующие такое тяжелое заболевание, как сахарный диабет.
Число больных сахарным диабетом в России составляет около 10~млн человек. 
Из них почти 80\% страдают ИНСД, или диабетом 2-го типа. Приблизительно у
половины всех больных ИНСД заболевание не распознается вовремя.
Перед авторами была поставлена задача выявления пациентов с
подозрением на заболевание.

Существенной особенностью анализируемых данных было отсутствие
у каких-то пациентов одних данных, у ка\-ких-то~--- других,
т.\,е.\ налицо была различная неполная информация о каждом пациенте. 
В~таких случаях данные принято называть многократно
цензурированными. Как строить выборку? Естественно, не хотелось
терять никакую полезную информацию о пациентах, тем более что
число наблюдаемых пациентов было невелико.

Задачи оценивания, связанные с медициной, часто приходится решать
по неполной выборке. Для таких задач разработаны специальные
методы, наиболее известными из них являются методы анализа
выживаемости, например построение таблиц времен жизни. Отметим,
что анализ выживаемости применяется к многомерным непрерывным
величинам, в данном же случае большинство переменных наблюдения
были дискретными. Специфика всех применяемых при этом методов
определяется наличием цензурированных наблюдений.

Исследование, проведенное авторами в сотрудничестве с РЦСМЭ Росздрава, было
основано на методах дискриминантного анализа. Дискриминантный
анализ позволяет решать многие прикладные статистические задачи,
связанные с распознаванием~\cite{book2}. Его методы широко применяются и в
медицинских исследованиях~[2--4]. %\cite{book4, book5, book1}.

В данной работе решалась задача классификации пациентов с
ИНСД (далее~--- СД) и выявления
признаков, по которым у человека можно предположить наличие данного
диагноза. Авторам были предоставлены данные по группам людей, так
называемые <<обучающие выборки>>: 
\begin{description}
\item[\,] группа~1--- с недиагностированным
СД (при жизни диагноз СД не выставлялся); 
\item[\,] группа~2--- с выявленным СД; 
\item[\,] группа~3 -- здоровые.
\end{description}
 В~первоначальном виде медицинские данные
не удалось классифицировать. Основной помехой для использования
классического метода дискриминации служила недостаточность и
неполнота данных. Также работа осложнялась малым объемом выборки,
некоторыми неточностями заполнения медицинских карт и различием
регистрируемых па\-ра\-мет\-ров.

Для обработки таких данных предлагается эвристический метод
классификации, в котором определенным образом выбираются различные
наборы дискриминантных признаков и строятся классификационные
функции для каждого набора. Чис\-ло таких наборов зависит от степени
неполноты данных: чем больше потерянных данных, тем больше чис\-ло
различных наборов. Каждый набор определяет свои классификационные
функции для каж\-дой из трех групп (такую совокупность назовем
дискриминантной сис\-те\-мой). Новый пациент со своим набором признаков
классифицируется каж\-дой дискриминантной системой и относится к той
группе, для которой было получено максимальное число совпаде\-ний
классификации.  Такая многоступенчатая классификация в некотором
смысле компенсирует малый объем выборки и максимально использует
информацию о каждом пациенте. Подробное описание метода приведено ниже.

В сходной постановке задачи классификации решались в~[5--7]. %\cite{book7, book8, book9}.

Исследование, проведенное в данной работе, позволяет установить
некоторые совокупности медицинских измерений, которые являются
информативными и впоследствии смогут помочь при постановке и
выявлении диагноза~СД.

\section{Постановка задачи}

Классификация больных проводилась на основе медицинских
показателей при помощи диск\-ри\-ми\-нант\-но\-го анализа в пакете STATISTICA.

Пусть задано пространство измерений (в рассматриваемой задаче это
патологоанатомические измерения), обладающее  размерностью $m \hm>
1$. Элементами данного пространства являются векторы  $x\hm = (x_1,
\ldots ,x_i, \ldots , x_m)$ , где $x_i$~--- значение признака номер~$i$ 
для конкретного пациента. Кроме того, заданы $n$ групп
(классов). Для каждого больного необходимо указать группу, к
которой он принадлежит.

В пространстве измерений можно выделить множество векторов обучающей
выборки, т.\,е.\ векторов, для которых известна принадлежность к
конкретной группе. Символом~$\alpha_k$  обозначим число измерений
обучающей выборки, принадлежащих группе~$k$, пусть $x^{(j,k)}$~---
вектор из обучающей выборки, соответствующий $j$-му пациенту из
группы~$k$.

В основе линейного дискриминантного анализа лежит нахождение такой
линейной комбинации переменных, которая бы оптимально разделила
рассматриваемые группы. Семейство линейных функций
\begin{multline*}
 d^{(k)} = a_0^{(k)} +  a_1^{(k)}*x_1 + a_2^{(k)}*x_2 + 
 \cdots + a_m^{(k)}*x_m\,,\\
  k = \overline{1,n}
 \end{multline*}
называется дискриминантной функцией. Ее аргументом служат
компоненты вектора~$x$, принадлежащего пространству измерений.
Коэффициенты $a_j^{(i)}$ подлежат определению на основе обучающей
выборки. В~задаче, рассматриваемой в настоящей работе, число
групп равно трем. Поэтому необходимо рассчитать 3~линейные дискриминантные функции.

Для расчета коэффициентов дискриминантных функций нужен
статистический критерий, оценивающий различия между группами.
Задачу поиска наилучшей дискриминации данных можно свести к поиску
таких дискриминантных функций~$d^{(k)}$, которые были бы основаны
на максимуме отношения межгрупповой вариации к внутригрупповой.
Предположим, что все наблюдения являются реализацией некоторой
случайной величины~$X$, имеющей многомерное нормальное
распределение. Такое предположение является общим для большинства
методов дискриминантного анализа.

Введем некоторые обозначения.

Символом $\overline{x_i^{(k)}} $ обозначим среднее значение признака~$i$, 
рас\-счи\-тан\-но\-го для представителей группы~$k$, символом
$\overline{\overline{x_i}}$~--- среднее значение признака~$i$ по всем
пациентам сразу из всех групп. Через $x_i^{(l,k)}$ обозначим $i$-й
признак у $l$-го пациента в группе~$k$.

Используя введенные осреднения, определим квадратные матрицы~$W$ и~$T$:
\begin{align*}
W_{ij}&= \sum\limits_{k=1}^n\sum\limits_{l=1}^{\alpha_k}{(x_i^{(l,k)} -
\overline{x_i^{(k)}} )( x_j^{(l,k)} - \overline{x_j^{(k)}})} \,;\\
T_{ij}&= \sum_{k=1}^n\sum_{l=1}^{\alpha_k}{(x_i^{(l,k)} -
\overline{\overline{x_i}} )( x_j^{(l,k)} -
\overline{\overline{x_j}})} \,.
\end{align*}

Матрица $W$ называется внутригрупповой выборочной вариационной
матрицей признаков~$i$ и~$j$. Матрица~$T$ называется матрицей
рассеяния объединенных данных.

Пусть $B = T - W$. Величины элементов~$B$ по отношению к величинам
элементов~$W$ дают меру различия между группами.

Коэффициенты разделяющих функций могут быть найдены по методу
дискриминантного анализа Фишера как элементы матрицы, обратной к~$W$, 
что соответствует общей вычислительной процедуре множественной линейной регрессии.

Для нахождения $p$ наборов коэффициентов канонических
дискриминантных функций необходимо решить обобщенную задачу на
собственные значения:
$$
B \nu^{(k)} = \lambda_k W \nu^{(k)} \,,\quad \left\| \nu^{(k)} \right\| = 1\,,\quad
 j=\overline{1,k}\,.
$$

Найденные $\nu^{(k)}$ используются для подсчета коэффициентов дискриминантной функции:
$$
a_i^{(k)}\hm= \nu^{(k)} \sqrt{\alpha_k - n}\,.
$$

Для проверки <<качества>> найденных коэффициентов  возьмем
статистическую гипотезу $H_0 : m_1 \hm= m_2 \hm= \cdots\hm = m_p$,
заключающуюся в проверке отсутствия различий между групповыми средними.

Для принятия или отклонения гипотезы $H_0$ используется
критерий, основанный на  $U$-ста\-ти\-сти\-ке Уилкса, которая
вычисляется как отношение определителей (детерминантов) матрицы
внутригрупповой вариации~$W$ и полной вариационной матрицы~$T$:
$$
U = \fr{\det(W)}{\det(T)}\,.
$$

Если значения статистики $U$ близки к единице, то вероятность ошибки дискриминации близка к~1.

После того как функции построены, можно провести классификацию любого
произвольного измерения. Алгоритм классификации следующий.

В каждую функцию в качестве аргументов подставляются компоненты вектора наблюдений~$x$ 
и вычисляются значения функции. За номер группы, к которой
принадлежит наблюдение, берется номер той функции, значение которой оказалось наибольшим.

\section{Решение задачи}

\subsection{Первичная обработка данных. Разведочный статистический анализ}

На первых этапах работы делались попытки представить имеющиеся
исходные данные в наиболее удобной и наглядной форме. Все данные были собраны в таблицу.

Изначально данные состояли из наблюдений над 272~пациентами по 132~признакам. 
Кроме того, что объем выборки был небольшим, обработка
осложнялась неполнотой данных: практически у каждого пациента
отсутствовал ряд наблюдений вследствие утери данных, которые не
подлежали восстановлению. Таким образом, имелись наблюдения над
пациентами со своими наборами признаков у каждого. Отметим, что
исходная матрица данных была заполнена менее чем на четверть, по
большинству признаков наблюдения имелись не более чем у 10~пациентов.

Очевидно, что входные данные должны быть различимы в каждой группе.
Но часть пред\-остав\-лен\-ных признаков равнялась константе (в основном
это были бинарные признаки) и не могла \mbox{служить} материалом для
исследования. Часть признаков относилась к типу качественных и была
переведена в числовой вид путем разумного упорядочивания и последующей кодировки цветов.

После первичной обработки было отобрано 90~пациентов из первой
группы и 62~пациента из второй. Затем при помощи модуля Discriminant
Analysis пакета STATISTICA с использованием обучающих выборок была
проведена классификация данных, результаты которой представлены на
рис.~1.


Из рис.~1 видно, что данные не удалось раз\-делить по совокупности
всех предоставленных\linebreak признаков. Требовалось снизить размерность
пространства признаков, оставив наиболее информативные. Поэтому
следующим этапом стал подбор значимых
 признаков из имеющихся 
132~признаков и отсеивание пациентов, не имеющих данных признаков.
Выборка признаков производилась так: измерения должны были
присутствовать не менее чем
 у половины пациентов, признаки внутри
групп должны были различаться, пациенты с данными\linebreak\vspace*{-12pt}
\begin{center}  %fig1
\vspace*{9pt}
\mbox{%
 \epsfxsize=64.413mm
 \epsfbox{zah-1.eps}
 }
  \end{center}
% \vspace*{6pt}
{{\figurename~1}\ \ \small{Деление начальных данных на 3~группы:
   \textit{1}~--- недиагностированные;
   \textit{2}~--- диагностированные;
   \textit{3}~--- отсутствие диагноза}}


%\pagebreak

%\vspace*{6pt}

\addtocounter{figure}{1}   
 
 
 
\noindent
 менее чем по 10~признакам 
не вносились в таб-\linebreak лицу.
 

\subsection{Алгоритм классификации}

Для построения адекватной модели были выбраны 32~признака, которые
считались наиболее значимыми по медицинским показаниям. Следующим
этапом было нахождение дискриминантных функций. Результаты,
полученные в подразд.~3.1, показали, что при использовании всех 
32~признаков теряется существенная часть наблюдений. Пациенты с не
полностью заполненными векторами наблюдений не учитываются при
нахождении коэффициентов дискриминантных функций, это становится
причиной потери точности расчетов. Вследствие отсутствия у
большинства пациентов наблюдений по всем 32 признакам и желания
сохранить как можно больше наблюдений, было принято решение о
построении нескольких систем дискриминантных функций. Построение
каждой из 32~комбинаций происходило следующим образом: сначала из
матрицы наблюдений удалялись все пациенты, не имеющие наблюдений по
данному признаку, затем удалялись признаки, не заполненные целиком
для каждого из оставшихся пациентов. Проделав данную операцию 32
раза, авторы получили 32~комбинации признаков (по одной комбинации
на каждый признак). Были учтены все пациенты и не потеряно ни одно
измерение. При сохранении максимального объема данных было получено
32 системы дискриминантных функций, что позволило в дальнейшем
проводить более точную дискриминацию пациентов, увеличивая размер
выборки. При помощи 32 дискриминантных систем стало возможным 32
раза проводить дискриминацию пациентов и более точно определять
номер группы пациента.

%\subsection{Проверка данных на нормальность}

Для определения возможности использования дикриминантного анализа
необходимо было проверить данные на принадлежность к нормальному
распределению.

В процессе проверки на нормальность были произведены следующие измерения:

\begin{itemize}
 \item проверка матрицы данных для дискриминации групп~1 и~2;
 \item проверка матрицы данных по совокупности групп~1 и~2 с группой~3;
 \item проверка матрицы данных для каждой из совокупностей признаков, 
 найденных в предыдущем пункте.
\end{itemize}

Результаты в каждом случае оказались разными. Многие признаки не
были распределены нормально, что видно из табл.~1. Буквой~N 
отмечался\linebreak\vspace*{-12pt}
 
 
%\begin{table*}
\begin{center}
{{\tablename~1}\ \ \small{Типы распределения признаков}}
                \vspace*{2ex}
        
{\small        \tabcolsep=18pt
        \begin{tabular}{|l|c|}
            \hline
        \multicolumn{1}{|c|}{Признак} &        \multicolumn{1}{c|}{ Распределение}\\
            \hline
            НО-02А & N \\ 
            ОБ-02 &    \\ 
            ССС-06 &   \\ 
            ССС-07С &  \\ 
            ССС-14 &   \\ 
            П-3 & N    \\ 
            ПЖ-2 & N   \\ 
            ПЖ-6a &    \\ 
             НО-47А & N\\  
             ОБ-03 &   \\  
             ССС-07   & \\ 
             ССС - 07D &\\ 
             ССС-15 & \\   
             П-5а* & N \\  
             ПЖ-3 & \\       
             ПЖ-7 & \\ 
              ССС-01А & \\  
              ССС-04А & \\  
              ССС-07Аа* &N\\ 
              ССС-12*& N\\  
              П-1а& N\\       
              П-6А& \\          
              ПЖ-4&N\\ 
              ПЖ-7А &N\\  
              ССС-02 &\\            
               ССС-05А & \\         
              ССС-07Ва & N\\     
               ССС-13* & \\         
               П-2а & N \\          
               ПЖ-1 & N\\           
               ПЖ-5 & N\\ 
               ПЖ-8 &N\\ 
               \hline              
        \end{tabular}}
\end{center} 

\vspace*{6pt}


\addtocounter{table}{1}  

\noindent
 признак, для которого выполнялась гипотеза о нормальном
распределении. Символом~$\ast$  отмечены численные признаки.



В табл.~1 приведены данные для общей матрицы данных по
трем группам. Оставшиеся признаки были перекодированы из
качественных. При проверке данных для каждой подгруппы на
нормальность результаты оказались следующими: в подгруппах,
построенных для дискриминации групп~1 и~2, около 80\%  признаков
были распределены нормально. В~подгруппах, построенных для
дискриминации совокупностей групп~1 и~2 с группой~3, около 40\%
признаков обладали нормальным распределением. Следует отметить, что
нормальность признаков не является критической для правильной работы
дискриминантного анализа~[1, 2].

\setcounter{table}{2}
 \begin{table*}[b]\small
 \vspace*{-12pt}
\begin{center}
\Caption{Разделение между группами по наборам параметров}
        \label{tabl4}
        \vspace*{2ex}
        
        \begin{tabular}{|l|c|}
            \hline
\multicolumn{1}{|c|}{ Комбинация параметров}   & \tabcolsep=0pt\begin{tabular}{c}Значение\\ $U$-статистики\end{tabular}\\
            \hline
            $X_1, X_8, X_{17}, X_{18}$ &  0,74961\hphantom{9}  \\
%            \hline
            $X_1, X_2, X_8, X_{17}, X_{18}$ &  0,732198   \\
 %           \hline
            $X_1, X_3, X_4, X_8, X_{17}, X_{18}$ &  0,726553   \\
 %           \hline
            $X_1, X_5, X_6, X_7, X_8, X_{12} -  X_{20}, X_{22}$ &  0,210394   \\
%            \hline
            $X_1, X_6, X_7, X_8, X_{12} - X_{18}, X_{20}, X_{22} $ &  0,349879   \\
%            \hline
            $X_1, X_7, X_8, X_{17}, X_{18}$ & 0,669331   \\
 %           \hline
            $X_1, X_8, X_9, X_{12}, X_{14}, X_{17}, X_{18} $ & 0,527898    \\
 %           \hline
            $ X_1, X_8, X_{10}, X_{17}, X_{18} $ & 0,630852  \\
 %           \hline
            $X_1, X_8, X_{12}, X_{13}, X_{14}, X_{17}, X_{18} $ &  0,708013   \\
 %           \hline
            $X_1, X_8, X_{17}, X_{18}, X_{19}, X_{22} $ &     0,688674   \\
 %           \hline
            $ X_1, X_8, X_{12}, X_{13}, X_{14}, X_{17}, X_{18}, X_{21}, X_{22} $ & 0,604662  \\
%            \hline
            $X_1, X_8, X_{17}, X_{18}, X_{23}  $ & 0,684530   \\
%            \hline
            $ X_1, X_8, X_{12}, X_{13}, X_{14}, X_{17}, X_{18}, X_{24} $ & 0,548464  \\
%            \hline
            $ X_1, X_8, X_{12}, X_{13}, X_{14}, X_{17}, X_{18}, X_{24}, X_{25}, X_{26} $ & 0,518108  \\
 %           \hline
            $ X_1, X_8, X_{12}, X_{13}, X_{14}, X_{17}, X_{18}, X_{26} $ & 0,525807  \\
 %           \hline
            $ X_1, X_3, X_4, X_8, X_{11} - X_{18}, X_{20}, X_{22}, X_{27}, X_{30}, X_{31}   $ & 0,128547  \\
 %           \hline
            $X_1, X_8, X_{17}, X_{18}, X_{22}, X_{29}  $ & 0,674781     \\
 %           \hline
            $ X_8, X_{14}, X_{17}, X_{18}, X_{22}, X_{30}, X_{31}    $ & 0,668601  \\
  %          \hline
            $ X_1, X_3, X_4, X_8, X_{11} - X_{14}, X_{17}, X_{18}, X_{22}, X_{30}, X_{31}   $ & 0,646518  \\
 %           \hline
            $ X_3, X_4, X_8, X_{13}, X_{14}, X_{17}, X_{18}, X_{22}, X_{30}, X_{31}  $ & 0,652206  \\
            \hline
        \end{tabular}
\end{center}
        \end{table*}


\vspace*{-4pt}

\subsection{Исследование различий пациентов групп~1~и~2}

После обработки данных было получено пространство из 32~признаков, в
котором была про-\linebreak\vspace*{-12pt}



\noindent
{{\tablename~2}\ \ \small{Разделение 1-й и 2-й групп по наборам параметров}}
                
{\small\begin{center}
                       \tabcolsep=14pt
                        \begin{tabular}{|l|c|}
            \hline
        Комбинация параметров   & \tabcolsep=0pt\begin{tabular}{c}Значение\\ $U$-статистики\end{tabular} \\
            \hline
            $X_1~X_8~X_{17}~X_{18}$ &  0,945466   \\
%            \hline
            $X_1~X_2~X_8~X_{17}~X_{18}$ &  0,940606   \\
 %           \hline
            $X_1~X_3~X_4~X_8~X_{17}~X_{18}$ &  0,911782   \\
  %          \hline
            $X_1~X_7~X_8~X_{17}~X_{18}$ &  0,945990   \\
   %         \hline
            $X_1~X_8~X_{10}~X_{17}~X_{18} $ &  0,948152   \\
    %        \hline
            $X_1~X_8~X_{11}~X_{17}~X_{18}$ & 0,942741   \\
     %       \hline
            $X_1~X_8~X_{12}~X_{14}~X_{17}~X_{18} $ &     0,930141   \\
      %      \hline
            $ X_1~X_8~X_{12}~X_{13}~X_{14}~X_{17}~X_{18} $ & 0,929915  \\
       %     \hline
            $X_1~X_8~X_{12}~X_{14}~X_{17}~X_{18} $ &     0,930141   \\
        %    \hline
            $X_1~X_8~X_{15}~X_{16}~X_{17}~X_{18} $ &     0,924349   \\
         %   \hline
            $ X_1~X_8~X_{16}~X_{17}~X_{18} $ & 0,939543  \\
          %  \hline
            $X_1~X_8~X_{17}~X_{18}~X_{19}~X_{22}  $ & 0,958094   \\
           % \hline
            $ X_1~X_8~X_{17}~X_{18}~X_{20}~X_{22} $ & 0,944039  \\
          %  \hline
            $ X_1~X_8~X_{17}~X_{18}~X_{22} $ & 0,945476  \\
          %  \hline
            $ X_1~X_8~X_{17}~X_{18}~X_{23} $ & 0,938776  \\
          %  \hline
            $ X_1~X_8~X_{17}~X_{18}~X_{28} $ & 0,912175  \\
          %  \hline
            $ X_1~X_8~X_{17}~X_{18}~X_{22}~X_{29} $ &    0,945256  \\
          %  \hline
            $ X_1~X_8~X_{17}~X_{18}~X_{31} $ & 0,929865  \\
          %  \hline
            $ X_1~X_8~X_{17}~X_{18}~X_{22}~X_{32} $ & 0,946031  \\
            \hline
        \end{tabular}
\end{center}}

\vspace*{9pt}


\addtocounter{table}{1}  

        

\noindent
ведена дискриминация по методу, описанному в подразд.~3.2. 
Было видно, что полученные группы не разделяются статистически.
Приведем средние значения статистики Уилкса для некоторых комбинаций
признаков (табл.~2). В~табл.~2 признаки перекодированы.



Видно, что все значения статистики превосходят~0,9. Таким образом,
группы 1 и 2 по выбранным признакам оказались схожи. Это
соответствовало действительности: исследуемые категории лиц были
больны СД.

\subsection{Решение задачи разделения совокупностей групп~1~и~2 и~группы~3 }

Для проверки предлагаемого метода разделения были использованы
данные пациентов, не име\-ющих СД. Алгоритм классификации был описан в
подразд.~3.2. 

В~табл.~\ref{tabl4} приведены значения статистики Уилкса
для различных комбинаций па\-ра\-метров.


На рис.~2 приведена дискриминация данных на 3~группы. Из
рисунка можно видеть, что группы~1 и~2 не отличимы, 
но заметно разделение на больных СД и здоровых.

\subsection{Пример классификационных функций и~верификация предложенного метода}

Проверка результатов проходила при помощи нового массива данных
пациентов 1-й, 2-й и~3-й групп. Процент верного прогноза составил 75\%--80\%. 
Таким образом, полученная классификация при помощи обучающей
выборки на реальных данных показала хорошие результаты. Была
существенно снижена размерность дискриминантных\linebreak\vspace*{-12pt}
\begin{center}  %fig2
%\vspace*{9pt}
\mbox{%
 \epsfxsize=65.024mm
 \epsfbox{zah-2.eps}
 }
  \end{center}
 \vspace*{3pt}
{{\figurename~2}\ \ \small{Конечное деление данных на 3~группы:
   \textit{1}~--- недиагностированные;
   \textit{2}~--- диагностированные;
   \textit{3}~--- отсутствие диагноза}}


%\pagebreak

\vspace*{12pt}

\addtocounter{figure}{1}   


\noindent
 признаков и получена высокая достоверность прогнозирования.

Для некоторого набора признаков ниже приведена система классификационных функций:
\begin{multline*}
f_1 =
5{,}91 X_1+12{,}03 X_3-31{,}42 X_4+7{,}94X_8-{}\\
{}-0{,}02X_{11}-1{,}8X_{12}-6{,}1X_{13}+16{,}77X_{14}+137{,}72X_{15}+{}\\
{}+13{,}9X_{16}+1{,}89X_{17}-2{,}35X_{18}-11{,}34X_{20}-0{,}02X_{22}+{}\\
{}+42{,}23X_{27} +3{,}96X_{30}-0{,}48X_{31}-96{,}71\,;
\end{multline*}

\vspace*{-12pt}

\noindent
\begin{multline*}
f_2 =
5{,}53X_1+24{,}2X_3-46{,}25X_4+5X_8-0{,}01X_{11}+{}\\
{}+17{,}87X_{12}+23{,}5X_{13}-14{,}41X_{14}+93{,}54X_{15}+{}
\\
{}+\;23{,}43X_{16}-2{,}4X_{17}-7{,}93*X_{18}-3{,}63X_{20}-0{,}02X_{22}+{}\\
{}+21{,}74X_{27}+4{,}84X_{30}-0{,}19X_{31}-65{,}22\,.
\end{multline*}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{Литература}
\begin{thebibliography}{9}


\bibitem{book2} %1
\Au{Афифи А., Эйзен С.} Статистический анализ. Подход с
использованием ЭВМ~/ Пер с англ. И.\,С.~Енюкова, И.\,Д.~Новикова.~--- М.: Мир, 1982.
488~с. (\Au{Afifi~A.\,A., Azen~S.\,P.} Statstical analysis. A~computer oriented
approach.~--- 2nd ed.~--- New York\,--\,San Francisco\,--\,London: A~Subsidiary of 
Harcourt Brace Jovanovich Publs., 1979. 442~p.)

\bibitem{book1} %2
\Au{Truett J., Cornfield J., Kannel~W.} A~multivariate analysis of
the risk of coronary heart disease in Framingham~// J.~Chronic Diseases, 1967. 
Vol.~20. P.~511--524.

\bibitem{book4} %3
\Au{Реброва О.\,Ю.} Статистический анализ медицинских данных.
Применение пакета прикладных программ STATISTICA.~--- М.: Медиа Сфера, 2002. 312~с.

\bibitem{book5} %4
\Au{Халафян А.\,А.} Современные статистические методы медицинских исследований.~--- 
М.: Эдиториал УРСС, 2008. 320~с.



\bibitem{book7}
\Au{Захарова Т.\,В., Золоева М.\,В.} Прогнозирование состояния
пациентов~// Обозрение прикладной и промышленной математики, 2007.
Т.~14. Вып.~2. C.~298--299.

\bibitem{book8}
\Au{Драницына М.\,А., Захарова Т.\,В.} Классификация состояний
пациентов с целью прогнозирования результатов лечения~// Обозрение
прикладной и промышленной математики, 2009. Т.~16. Вып.~5. C.~840--841.

\bibitem{book9}
\Au{Драницына М.\,А., Захарова Т.\,В.} Дискриминантный анализ для
классификации и прогнозирования результатов лечения~// Системы и
средства информатики, 2013. Т.~23. №\,2. С.~89--95.


\end{thebibliography} } }

\end{multicols}

\hfill{\small\textit{Поступила в редакцию 10.01.13}}


\vspace*{16pt}

\hrule

\vspace*{2pt}

\hrule

\def\tit{PREDICTION AND CLASSIFICATION METHOD FOR~CENSORED~DATA}

\def\aut{T.\,V.~Zakharova and E.\,M.~Abramova}

\def\titkol{Prediction and classification method for~censored~data}

\def\autkol{T.\,V.~Zakharova and E.\,M.~Abramova}


\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-9pt}

\noindent
Department of Mathematical Statistics, 
Faculty of Computational Mathematics and Cybernetics, 
M.\,V.~Lomonosov Moscow State University, Moscow 119991, Russian Federation\\
 
\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND APPLICATIONS\ \ \ 2013\ \ \ volume~7\ \ \ issue\ 4}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND APPLICATIONS\ \ \ 2013\ \ \ volume~7\ \ \ issue\ 4
\hfill \textbf{\thepage}}}

\vspace*{9pt}

\Abste{The classification method 
for noninsulin-dependent diabetes mellitus patients cohort  is presented
and the technique for identification of diabetes 
mellitus indicators is described. The basic medical data we dealt with 
turned out to be unfit for classification. The main obstacle 
for applying classical discrimination approaches was insufficiency 
and incompleteness of original data. For data processing, the authors suggest 
to select different sets of discriminant characteristics and 
to obtain classification functions for each set. The number of these 
sets depends on data incompleteness degree. The more data are omitted, 
the more different sets are needed.
Each patient finally refers to the group, for which he gets the greater 
number of matches in classification.
This multistep procedure reimburses small sample size and insufficiency 
and incompleteness of original data.}

\KWE{hypothesis; censored data; discriminant variables; classification functions; forecasting}


\DOI{10.14357/19922264130411}

%\Ack
%\noindent
%?????

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
{%\baselineskip=10.8pt
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{9}


\bibitem{1-zah-1} %1
\Aue{Afifi, A.\,A., and S.\,P~Azen}. 1979. 
\textit{Statistical analysis. A~computer oriented approach}.  2nd ed.
New York\,--\,San Francisco\,--\,London: A~Subsidiary of 
Harcourt Brace Jovanovich Publs. 442~p.

\bibitem{4-zah-1} %2
\Aue{Truett, J., J.~Cornfield, and W.~Kannel}. 
1967. A~multivariate analysis of the risk of coronary heart disease in Framingham. 
\textit{J.~Chronic Diseases} 20:511--524.

\bibitem{2-zah-1} %3
\Aue{Rebrova, O.\,Ju.} 2002. 
\textit{Statisticheskiy analiz meditsinskikh dannykh. 
Primenenie paketa prikladnykh programm STATISTICA} 
[\textit{Statistical analysis of medical data. Application software package STATISTICA}]. 
Moscow: Media Sfera. 312~p.

\bibitem{3-zah-1} %4
\Aue{Halafjan, A.\,A.} 2008. 
\textit{Sovremennye statisticheskie metody meditsinskikh issledovaniy} 
[\textit{Advanced statistical methods for medical research}]. Moscow: Editorial URSS.
320~p.



\bibitem{5-zah-1}
\Aue{Zakharova, T.\,V., and M.\,V.~Zoloeva}. 
2007. Prognozirovanie sostoyaniya patsientov [The patients' conditions forecast]. 
\textit{Obozrenie Prikladnoi i Promyshlennoy Matematiki} 
[\textit{Review  of Applied  Industrial Mathematics}] 14:298--299.

\vspace*{2pt}

\bibitem{6-zah-1}
\Aue{Dranitsyna, M.\,A., and T.\,V.~Zakharova}. 2009. 
Klassifi\-ka\-tsiya sostoyaniy patsientov s tsel'yu prognozirovaniya re\-zul'\-ta\-tov lecheniya 
[Classification of patients' conditions to forecast the outcomes of the treatment]. 
\textit{Obozrenie Prikladnoy i Promyshlennoy Matematiki} 
[\textit{Review of Applied  Industrial Mathematics}] 16:840--841.

\vspace*{2pt}

 
\bibitem{7-zah-1}
\Aue{Dranitsyna, M.\,A., and T.\,V.~Zakharova}. 
2013. Diskri\-mi\-nantnyy analiz dlya klassifikatsii i prognozirovaniya rezul'tatov lecheniya 
[Discriminant analysis for classification and forecasting outcomes of the treatment]. 
\textit{Systemy i Sredstva Informatiki~---
Systems and Means of Informatics}
23(2):89--95.
\end{thebibliography}
} }

\end{multicols}

\hfill{\small\textit{Received January 10, 2013}}

\Contr

\noindent
\textbf{Zakharova Tatyana V.} (b.\ 1967)~--- Candidate of Science (PhD) in physics and 
mathematics, scientist, Department of Mathematical Statistics, Faculty of 
Computational Mathematics and Cybernetics, M.\,V.~Lomonosov Moscow State 
University, Moscow 119991, Russian Federation; lsa@cs.msu.ru

\vspace*{3pt}

\noindent
\textbf{Abramova Ekaterina M.} (b.\ 1989)~--- student, Department of Mathematical 
Statistics, Faculty of Computational Mathematics and Cybernetics, 
M.\,V.~Lomonosov Moscow State University, Moscow 119991, Russian Federation; 
houselake@gmail.com

 \label{end\stat}
\renewcommand{\bibname}{\protect\rm Литература}