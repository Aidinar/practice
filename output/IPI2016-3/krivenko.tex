\def\stat{krivenko}

\def\tit{КРИТЕРИИ ЗНАЧИМОСТИ ОТБОРА ПРИЗНАКОВ КЛАССИФИКАЦИИ}

\def\titkol{Критерии значимости отбора признаков классификации}

\def\aut{М.\,П.~Кривенко$^1$}

\def\autkol{М.\,П.~Кривенко}

\titel{\tit}{\aut}{\autkol}{\titkol}

\index{Кривенко М.\,П.}
\index{Krivenko M.\,P.}


%{\renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]
%{Работа выполнена при частичной поддержке РФФИ (проект 16-07-00272 А).}}


\renewcommand{\thefootnote}{\arabic{footnote}}
\footnotetext[1]{Институт проблем информатики Федерального исследовательского центра 
<<Информатика и~управление>> Российской академии наук, 
\mbox{mkrivenko@ipiran.ru}}

\vspace*{-10pt}

\Abst{Рассмотрена задача отбора признаков классификации и~вопросы оценивания качества 
получаемых решений. Среди различных методов отбора признаков внимание обращено на 
последовательные процедуры; мерой качества классификации выбрана вероятность 
правильной классификации. Для оценивания этой характеристики предложено использовать 
метод перепроверки и~бут\-стреп-ме\-тод, а~для исследования ряда выборочных значений~--- 
сравнительный анализ доверительных интервалов и~критерии однородности биномиальных 
пропорций. При построении байесовского классификатора для данных применялась модель 
смеси нормальных распределений; ее параметры оценивались с~помощью  
EM (expectation--maximization) ал\-го\-рит\-ма. В~качестве эксперимента рассмотрена задача обоснованного выбора 
признаков классификации при прогнозировании типа мочевых камней в~урологии. Показано, 
что сокращать совокупность анализируемых показателей можно не только без потери 
качества принимаемых решений, но и~с повышением вероятности правильного прогноза типа 
камня.}
 
\KW{селекция признаков; последовательная селекция вперед и~назад; 
байесовская классификация данных; проверка однородности двоичных 
последовательностей; прогноз типа камня в~урологии}

\DOI{10.14357/19922264160305} 


\vskip 10pt plus 9pt minus 6pt

\thispagestyle{headings}

\begin{multicols}{2}

\label{st\stat}
  


\section{Введение}
     
     Сокращение числа переменных (признаков) может привести 
к~повышению эффективности классификации данных и~к~более глубокому 
пониманию их природы. Соответствующие постановки задач и~применяемые 
методы востребованы на практике в~весьма разнообразных областях 
распознавания образов и~машинного обучения: категоризации текстов, 
дистанционном сканировании, обнаружении\linebreak наркотиков, маркетинге, 
обработке речи, распознавании рукописных символов, медицине и~т.\,д. 
Особый интерес вызывают задачи, когда данные оказываются 
высокоразмерными, а~объем обуча\-ющей выборки относительно мал. Получить 
пред-\linebreak варительное представление о соответствующей проблеме можно из 
разд.~10~[1], примерами обстоятельных обзоров могут служить работы~[2, 
3]. 
     
     Причины, по которым приходится корректировать совокупность 
анализируемых признаков, могут заключаться в~следующем: 
     \begin{itemize}
\item повышение эффективности обучения и~применения классификатора 
путем сокращения вычислительных затрат (уменьшение времени обработки 
и освобождение памяти от хранения ненужных атрибутов);
\item снижение стоимости последующего сбора данных за счет измерения 
только тех переменных, которые имеют отношение к~распознаванию;
\item создание предпосылок для повышения качества классификатора; 
\item упрощение описания классификатора благодаря более ясному 
пониманию природы данных и~структуры модели;
\item предоставление возможности специалистам в~предметной области 
прояснить суть протекающих процессов.
\end{itemize}

\section{Задачи и~методы селекции признаков}

     Сокращение числа признаков может осуществляться либо путем отбора 
(селекции, выбора подмножества исходных переменных), либо путем 
извлечения (формирования, определения линейного или нелинейного 
преобразования со\-во\-куп\-ности исходных переменных для получения меньшего 
набора). Далее речь пойдет только о методах отбора, так как упрощение модели 
данных и~повышение качества классификации ставятся в~данной работе во 
главу угла. 
     
     Постановка задачи построения методов селекции подразумевает 
оптимизацию некоторой целевой функции. В~зависимости от того, как связаны 
задачи предварительной обработки состава анализируемых признаков и~задачи 
классификации дан-\linebreak\vspace*{-12pt}

\pagebreak

\noindent
ных, обычно выделяются две основные категории методов: 
     \begin{enumerate}[(1)]
\item не связанные со свойствами классификатора, их обычно называют 
методами фильтрации;
\item учитывающие характеристики последующей классификации данных, 
к~ним относятся настраивающие классификатор методы (НКл-ме\-то\-ды) 
и~формирующие классификатор методы (ФКл-ме\-тоды). 
\end{enumerate}

     Понятно, что от второй группы методов следует ждать лучшие по 
сравнению с~методами фильтрации результаты. Настраивающие классификатор методы (wrapper methods) 
построены так, что подмножества признаков оцениваются с~учетом 
прогностической точности алгоритма классификации, т.\,е.\ подход зависит от 
классификатора. Вы\-чис\-ли\-тель\-но они более требовательны, чем методы 
фильтрации. Формирующие классификатор ме\-то\-ды (еmbedded methods) отличаются тем, что поиск 
оптимального набора признаков встроен в~структуру классификатора, а~не 
реализуется отдельно от построения классификатора. Подход зависит от 
классификатора, и~его можно рассматривать как поиск решения 
в~объединенном пространстве признаков и~моделей классификатора. 
     
     Обычно многие признаки оказываются неинформативными (не 
способствующими классификации) или избыточными (дублирующими, 
существенно связанными между собой признаками). Классификация может 
стать более продуктивной и~эффективной только при использовании 
релевантных и~неизбыточных признаков~[4]. 
     
     В процессе итерационного отбора признаков есть два ключевых шага~--- 
оценивание и~генерирование подмножества признаков, суть которых состоит 
в~следующем:
     \begin{itemize}
\item оценивание определяет качество некоторого подмножества признаков; 
НКл- и~ФКл-ме\-то\-ды, как правило, используют меры, основанные на 
производительности классификатора; методы фильтрации~--- меры, 
основанные на свойствах данных;
\item генерирование является средством создания некоторого подмножества 
признаков; процедура может основываться на простом ранжировании 
отдельных признаков или заключаться в~коррекции текущего состава 
подмножества путем добавления или удаления элементов.
\end{itemize}

     Для того чтобы выбрать подходящий набор признаков, необходимо 
средство измерения спо\-соб\-ности признака внести свой вклад в~отделимость 
классов либо индивидуально, либо в~контексте других уже выбранных 
признаков, т.\,е.\ необходимы средства измерения значимости и~из\-бы\-точ\-ности. 
Меры, учитывающие правила классификации, подразумевают использование 
выделенного набора признаков при формировании и~применении 
классификатора, т.\,е.\ отличающиеся наборы признаков могут давать 
различные классификаторы. Широко используемым примером подобных мер 
может служить вероятность ошибок классификатора и~оценка ее значения 
с~помощью частоты появления ошибок классификатора, обученного 
с~помощью выбранного набора признаков. 
     
     Существуют три основные категории алгоритмов поиска для выбора 
подмножества признаков: гарантированный, последовательный и~
случайный~\cite{2-kri}.
     
     Гарантированный поиск обеспечивает нахождение оптимального 
(в~смысле заданного критерия) подмножества признаков. Конечно, полный 
(исчерпывающий) поиск является гарантированным, но стратегия поиска 
необязательно должна быть исчерпывающей, чтобы стать гарантированной 
(например, метод ветвей и~границ гарантирует получение решения).
     
     Последовательный поиск: признаки добавляются или удаляются 
последовательно (последовательный вперед или назад отбор). Такие методы не 
являются оптимальными, но они просты в~реализации и~быстро дают результат.
     
     Случайный поиск подразумевает подходы, которые используют 
случайные механизмы при реализации указанных выше способов. Встраивание 
случайности в~методы отбора признаков может быть полезным в~следующих 
случаях: набор возможных подмножеств признаков велик и~не доступен для 
обработки; детерминированные алгоритмы оказываются подвержены 
попаданию в~ловушку локальных экстремумов критерия отбора признаков; 
когда выгоды от получения хорошего решения значительно перевешивают 
возникающие затраты, т.\,е.\ стоит потратить время на привлечение случайного 
механизма, чтобы перепроверить полученные результаты. Варианты случайных 
процедур отбора признаков приведены в~[5].
     
     По ряду причин обычно приходится отказываться от гарантированного 
поиска в~пользу субоптимальных методов (последовательный и~случайный 
поиск): высокие вычислительные сложности получения оптимальных решений, 
не всегда выполняются условия того, чтобы неисчерпывающий поиск 
становился гарантированным (например, условие монотонности для метода 
ветвей и~границ). 
     
     Последовательный поиск включает в~первую очередь последовательный 
отбор вперед (sequential forward selection~--- SFS) и~последовательный отбор 
назад (sequential backward selection~--- SBS), а~также различные обобщения 
этих двух методов.
     
     Метод SFS итерационно добавляет по одному новые признаки к~уже 
сформированному набору, руководствуясь качеством получаемого решения. 
Основным недостатком этого метода является то, что он не включает в~себя 
механизм для удаления ранее добавленных признаков из уже сформированного 
на очередном шаге набора признаков, хотя добавления могут сделать 
ненужными признаки, ранее уже вошедшие в~формируемый набор. Метод SBS 
отличается от SFS тем, что признаки не добавляются, а~удаляются.
     
     В данной работе в~качестве классификатора рассматривается байесовская 
решающая процедура, причем модель данных~--- смесь нормальных 
распределений. В~качестве показателя эффективности классификации 
выступает вероятность правильной классификации~$P_c$. Оценка этого 
показателя есть частота правильной классификации при многократном 
применении классификатора. Из-за высокой сложности постановок реальных 
задач (многомерность данных, применение итерационного EM-ал\-го\-рит\-ма 
для оценивания параметров смеси, ограниченность объема обучающих данных) 
при оценивании показателя приходится прибегать к~методам управления 
обработкой выборки.
     
     Для селекции признаков предлагается применять последовательный 
метод с~настройкой классификатора для каждого апробируемого набора 
признаков. При этом использовался как метод SBS, так и~SFS. Выбор именно 
селекции и~последовательных методов отбора объясняется рядом причин: 
     \begin{itemize}
\item простота реализации, 
\item на начальном, поисковом, этапе исследований порождаются 
информативные наборы признаков, обеспечивающие возможность 
интерпретации полученных решений, в~частности с~позиций качества 
классификатора появляется возможность высказать предположения об 
эффективной размерности пространства признаков, выделить наименее 
и~наиболее информативные признаки, увериться или усомниться 
относительно сложившихся в~предметной об\-ласти моделей данных. 
\end{itemize}

\section{Критерии значимости}

     Последовательные методы отбора включают генерирование варианта 
набора признаков и~оценивание для него вероятности правильной 
классификации. Таким образом, при использовании определенного метода 
управления обработкой выборки получаем бинарную последовательность~--- 
последовательность испытаний с~двумя исходами (<<успех>>, когда 
классификатор не ошибся, <<не\-успех>> в~противном случае). При применении 
бут\-стреп-ме\-то\-да речь идет о~последовательности испытаний Бернулли, 
тогда оценка вероятности\linebreak правиль\-ной классификации есть случайная величина, 
имеющая биномиальное распределение.\linebreak Если же привлекается метод 
перепроверки, то использование биномиального распределения даст некоторое 
приближение для распределения оценки вероятности правильной 
классификации, позволяющее получить первое представление о реальном 
качестве анализируемого набора признаков. Для обоих методов в~ходе их 
реализации возникают последовательности наблюденных значений, которые 
могут стать источником непараметрических оценок для требуемых величин.
     
     Дадим постановки возможных задач анализа, возникающих в~связи 
с~анализом результатов отбора признаков. Имеется~$k$~независимых 
биномиальных популяций $X_1,\ldots ,X_k$, распределения которых
     $$
     X_i\sim \mathrm{Binomial}\left (n_i, \pi_i\right)\,,\enskip i=1,\ldots, k\,,
     $$
где $n_1,\ldots ,n_k$ известны и, возможно, различны, а~вероятности успеха 
$0\hm\leq \pi_1,\ldots, \pi_k\hm\leq 1$ неизвестны. Со значением~$i$ связаны 
следующие действия: выбор определенного набора признаков, по\-стро\-ение 
соответствующего классификатора на основе смеси распределений, оценивание 
по~$n_i$ наблюденным значениям вероятности правильной 
классификации~$\pi_i$. 

     Для определенного значения~$i$ оценка максимального правдоподобия 
вероятности успеха есть $\hat{\pi}_i=X_i/n_i$. При больших значениях~$n_i$ 
и~условиях, что ни~$\pi_i$, ни $1\hm- \pi_i$ не являются малыми величинами, 
$\hat{\pi}_i$ имеет приблизительно нормальное распределение. Более 
практичной в~случае сравнительного анализа результатов отбора признаков 
оказывается интервальная оценка для~$\pi_i$. Используемый для этих целей 
доверительный интервал может быть двухсторонний или односторонний, 
а~также принимать различную форму~[6]. Наиболее распространенным при 
построении доверительного интервала является использование нормальной 
аппроксимации. При этом в~случае одностороннего интервала из-за асимметрии 
истинного распределения ошибка может оказаться существенной, в~[7] дается 
простое и~эффективное решение этой проб\-лемы. 
     
     Пусть классификатор оперирует с~$M$~классами, вероятности 
появления которых равны $p_1,\ldots, p_M$. На практике нелишней 
оказывается проверка того, отличается ли построенная классификация от 
действий <<наугад>>, т.\,е.\ отнесения некоторого объекта к~определенному 
классу случайным образом и~только в~соответствии со значениями $p_1,\ldots, 
p_M$. Дело в~том, что классификация <<наугад>> дает $P_c=\sum_{j=1}^M 
p_j^2$; эта величина не меньше  и~может приближаться к~1 при возрастании 
разброса значений $p_1,\ldots, p_M$. Таким образом, наблюденное кажущееся 
большим значение~$P_c$ может и~не говорить о~достоинствах принятого 
классификатора. Прос\-тым способом контроля значимости результатов, 
получаемых в~ходе селекции признаков, является графический анализ 
зависимости односторонних\linebreak доверительных интервалов от размерности 
признакового пространства с~указанием уровня, от\-ве\-ча\-юще\-го классификации 
<<наугад>>: выход нижней\linebreak границы доверительного интервала за этот уровень 
говорит о~том, что соответствующий вариант набора признаков вообще не 
информативен. 
     
     Более общий подход в~анализе совокупности результатов отбора 
признаков заключается в~по\-стро\-ении и~использовании тестов однородности 
биномиальных пропорций. Нулевая гипотеза об\linebreak однород\-ности проверяется 
против альтернативы весьма общего вида:

\vspace*{4pt}

\noindent
$$
  H_0:\ \pi_1=\cdots =\pi_k=\pi_0
  $$
  
  \vspace*{-4pt}
  
\noindent
  против 
  $$ H_1: \pi_i\not= \pi_j
    $$
  для некоторых  $i\hm\not=j$,
где~$\pi_0$ обычно неизвестно.

     Достаточно много работ посвящено разработке подобных тестов, 
особенно для $k\hm=2$, что соответствует случаю $2\times2$ таблицы 
сопряженности (например, в~[8] рассматриваются~22~различных тес\-та). При 
анализе результатов селекции признаков речь идет о~сравнении двух 
определенных наборов признаков с~возможностью ответить на вопрос, какой из 
них более информативен. Интересно, что в~этом случае существует 
исчерпыва\-ющее решение соответствующей проблемы~--- равномерно наиболее 
мощный несмещенный (РНМН)  критерий, основанный на статистике числа 
успехов в~одной популяции при условии конкретного суммарного числа 
успехов в~обеих популяциях~[9, разд.~4.5]. Но сказать, что этот критерий 
широко известен и~активно используется, нельзя. Причина проста: он 
основывается на гипергеометрическом распределении и~трудоемок 
в~применении. 

Автор данной статьи занимался вопросами точных вычислений 
для гипергеометрического рас\-пределения и~его аппроксимации с~помощью\linebreak 
биномиального, пуассоновского, нормального  
и~бе\-та-рас\-пре\-де\-ле\-ний~[10], что позволило обес\-печить корректное 
использование РНМН-кри\-те\-рия для сравнения двух биномиальных 
со\-во\-куп\-ностей. 
{ %\looseness=1

}
     
     В более общем случае $k\hm>2$ имеется также достаточно много 
критериев, построенных на различных
 принципах и~способах практической 
реализации (см., например,~[11, 12]); в~первую очередь речь идет о следующих 
критериях: 
      точные; 
 стандартные Пирсона (Pearson) и~Вилкса (Wilks); 
 Потхоффа--Витингхилла (Potthoff--Whittinghill); 
 Сю (Xu); 
 Пауля и~Денга (Paul and Deng), 
а~также модификации отдельных из них. Сравнительный анализ 
основных процедур из приведенного перечня был проведен в~[12] 
методом моделирования с~учетом ситуаций, когда присутствуют так 
называемые разреженные данные (sparse data): некоторые~$n_i$ малы 
или некоторые из~$\pi_i$ близки к~0 или~1. Этот анализ позволил 
сформулировать следующие выводы:
\begin{itemize}
\item обнаружены случаи разреженных данных, для которых стандартные 
тесты, тест Пот\-хоф\-фа--Ви\-тинг\-хил\-ла и~его модификация, тест Пауля 
и~Денга выполняются неадекватно;
\item тесты точные и~Сю обладают адекватными характеристиками в~любых 
рассмотренных условиях моделирования, при этом точные методы в~целом 
схожи между собой, но некоторые различия возникли между точными 
тестами и~тес\-том Сю.
\end{itemize}

     Данные выводы основаны на результатах моделирования, поэтому всегда 
остается место для сомнений. Его можно рассеять только при эмпирическом 
сравнительном анализе критериев в~рамках конкретных ограничений.

\section{Эксперименты}

     Совместно со специалистами НИИ урологии и~интервенционной 
радиологии им.~Н.\,А.~Лопаткина~--- филиал ФГБУ <<НМИРЦ>> Минздрава 
России С.\,А.~Головановым и~А.\,В.~Сивковым проводились исследования 
возможности прогнозировать химический состав мочевых камней у пациентов 
с~уролитиазом по метаболическим показателям мочи и~сыворотки крови.

     \begin{table*}[b]\small
     \begin{center}
     \Caption{Классификация типов камней по составу}
     \vspace*{2ex}
     
     \begin{tabular}{|c|c|l|}
     \hline
Названия типа классификации и~камней&Число 
классов&\multicolumn{1}{c|}{\tabcolsep=0pt\begin{tabular}{c}Правила классификации:\\
номер класса, условие\end{tabular}}\\
\hline
\tabcolsep=0pt\begin{tabular}{c}Cмешанная общего вида:\\
оксалатные, уратные, фосфатные, пр.\end{tabular}&4&\tabcolsep=0pt\begin{tabular}{l}1, 
если WH\;+\;WD\;$>$\;50\%\\
2, если UA\;+\;UADH\;+\;Amur\;$>$\;50\%\\
3, если Dh\;+\;BRU\;+\;STRU\;$>$\;50\%\\
4 иначе\end{tabular}\\
\hline
\end{tabular}
\end{center}
\end{table*}
     
     Задача прогнозирования состава камня по набору показателей была 
сформулирована как задача обучаемой классификации типов камней, 
распадающаяся на следующие отдельные элементы.
     \begin{enumerate}[1.]
\item Предполагается, что исследователем задана классификация типов 
камней по составу. Она может включать, в~принципе, произвольное чис\-ло 
классов~$M$ и~должна быть четкой, т.\,е.\ любой камень по составу должен 
соответствовать только одному классу.
\item Для отдельных классов принимается вероятностное описание 
входящих в~него наборов показателей. Например, если~$u$~--- вектор 
значений всех показателей, то считается известным распределение $f_i(u)$ 
для каждого $j$-го класса. Кроме этого, предполагаются заданными 
вероятности~$p_j$ появления классов, $j\hm= 1,\ldots ,M$.\linebreak В~качестве 
классификатора рассматривался байесовский классификатор с~единичной 
функцией потерь.
     \item Для реализации описанной схемы вместо~$p_j$ и~$f_j(u)$ 
подставляются их оценки $p_j^*$ и~$f_j^*(u)$. Для $p_j^*$ это не что иное, как 
преваленс (prevalence)~--- доля субъектов в~популяции, которые имеют камень 
из $i$-го класса. В~качестве $f_j^*(u)$ предлагается применять модель смеси 
нормальных распределений и~EM-ал\-го\-ритм для оценивания параметров этой 
модели.
     \end{enumerate}
     
     Для решения задачи прогнозирования исходные данные о составе 
мочевых камней и~показателях состояния пациентов представлялись как  
таб\-ли\-ца <<объ\-ект--приз\-нак>>, где объекты~--- пациенты, а~признаки 
включали группу признаков, характеризу\-ющих химический состав камня 
пациента, а~также группу метаболических и~антропологических признаков 
пациента.
     
     В группу признаков, характеризующих хими\-ческий состав камня 
пациента, входили такие минеральные компоненты мочевых камней, как 
вевеллит (WH), веделлит (WD), мочевая кислота безвод\-ная (UA), мочевая 
кислота дигидрат (UADH), аммония урат (AMUR), даллит, или карбонатапатит 
(Dh), брушит (BRU), струвит (STRU), цистин (CYS). Здесь и~далее в~подобных 
ситуациях в~скобках приводятся общепринятые обозначения показателей.
     
     В данной работе рассматривалась классификация типов камней по 
составу, описанная в~табл.~1. Задание порога в~50\% отражает привычное 
пред\-став\-ле\-ние о~классификации на основе домини\-ру\-юще\-го значения того или 
иного компонента. 
     

     
     В группе метаболических признаков пациента были представлены 
биохимические показатели сыворотки крови~--- общий кальций (Са\_ser), 
мочевая кислота (UA\_ser), фосфаты (P\_ser); биохимические показатели 
суточной экскреции с~мочой кальция (Ca\_ur), мочевой кислоты (UA\_ur), 
фосфатов (P\_ur).
     
     Учитывая важное влияние концентраций этих веществ в~конечной моче 
на степень перена\-сы\-щенности мочи и, следовательно, на ее литогенный\linebreak 
потенциал, рассчитывали также концентрационные показатели (в~мМол/л), 
такие как концентрация в~моче кальция (CaUrC), мочевой кислоты (\mbox{UaUrC}), 
фосфатов (PhUrC). Помимо этого учитывали такие физико-химические 
показатели мочи, как удельный вес (Spec\_Grav), pH мочи (pH), суточный объем 
мочи (Diuresis) и~антропологические показатели пациента~--- рост (Height) 
и~вес (Weight). Таким образом, в~задаче обучаемой классификации 
использовались~14~показателей: Са\_ser, UA\_ser, P\_ser, Ca\_ur, UA\_ur, P\_ur, 
CaUrC, UaUrC, PhUrC, Spec\_Grav, pH, Diuresis, Height, Weight. Полученный 
классификатор использовался для прогноза типа камня по представляемым 
данным о показателях. Для того чтобы охарактеризовать качество 
классификатора, использовалась вероятность правильной классификации. Чем 
выше значение вероятности правильной классификации, тем выше точность 
прогноза. Анализ полученных результатов позволил сделать вывод, что прогноз 
возможен, но надо быть готовым к~не очень высоким результатам при 
увеличении числа классов (в~част\-ности, от $M\hm=2$ к~4). 
Источником повышения эффективности прогноза может стать уточнение 
набора показателей, на основе которых строится классификация. 
     
     Оценивание вероятности правильной классификации можно проводить 
одним из следующих способов: 
     \begin{itemize}
\item повторно используя обучающую выборку как для построения 
классификатора, так и~для получения~$P_c^*$ (T-оцен\-ка, от слова thrifty);
\item привлекая метод перепроверки (CV-оцен\-ка, от термина  
cross-validation);
\item используя бут\-стреп-ме\-тод (B-оцен\-ка, от термина bootstrap). 
\end{itemize}

 \begin{table*}[b]\small
     \begin{center}
     \Caption{Выбор эффективной размерности признаков}
     \vspace*{2ex}
     
     \begin{tabular}{|c|cccccccc|c|c|c|}
     \hline
№&\multicolumn{8}{c|}{Набор значений $d$}&
\tabcolsep=0pt\begin{tabular}{c}Критерий\\ значимости\end{tabular}&
\tabcolsep=0pt\begin{tabular}{c}Критический\\ уровень\\ значимости\end{tabular}&
\tabcolsep=0pt\begin{tabular}{c}Принятие 
нулевой гипотезы\\ об однородности\\ при 5\%-ном уровне значимости\end{tabular}\\
\hline
1& & 8, &9, &10, &11, &12, &13, &14&Сю&4,8\%&Отвергается\\
2& & 8, &9, &10, &11, &12,& & 14&Сю&61,1\%\hphantom{9}&Принимается\\
3&7, &8, &9, &10, &11, &12, &13, & 14&Сю&0,0\%&Отвергается\\
4& & && & & & 13, & 14&РНМН&1,2\%&Отвергается\\
5&&8,&&&&&13&&РНМН&1,0\%&Отвергается\\
\hline
\end{tabular}
\end{center}
\end{table*}

     В данной работе применялся классический вариант метода перепроверки: 
исключим из исходной совокупности данных $i$-й объект; для оставшегося 
набора данных построим байесовский классификатор и~применим его 
к~исключенному объекту; далее, вспомнив номер класса, к~которому 
в~действительности принадлежит $i$-й объект, сравним его с~тем, который 
дала байесовская процедура, и~получим ответ, совершила она ошибку или нет; 
подобные действия повторим для каждого значения~$i$. В~результате будет 
получена CV-оцен\-ка для~$P_c$. Обычно считается, что она является более 
качественной, чем T-оцен\-ка, обладающая <<завышенным оптимизмом>> 
(подгонка модели байесовского классификатора и~оценка его качества 
происходит по одной и~той же обучающей выборке). 
     
     Описание B-оценки начнем с~модели байесовского классификатора. 
Предположим, что распределение данных, относящихся к~$j$-му классу, есть 
смесь нормальных распределений 
$$
f_j(u)= \sum\limits_{i=1}^k  q_{ji}N\left(\mu_{ji},\Sigma_{ji}\right)\,.
$$
 Тогда плотность распределения данных, 
подвергающихся байесовской классификации, представима в~виде 
$$
g(u)=  \sum\limits_{j=1}^M p_j \sum\limits_{i=1}^k q_{ji} 
N\left(u,\mu_{ji},\Sigma_{ji}\right)\,.
$$
Но 
реально~$g(u)$ не задана, а~имеется лишь обучающая выборка, с~помощью 
которой можно получить оценку 
$$
g^*(u)= \sum\limits_{j=1}^M p_j^* \sum\limits_{i=1}^k 
q^*_{ji} N\left(u,\mu^*_{ji},\Sigma^*_{ji}\right)\,.
$$
 Таким образом, становятся заданными 
все элементы теперь уже эмпирического байесовского классификатора, 
с~помощью которого любое~$x$ можно отнести к~некоторому классу. Качество 
классификатора характеризуется с~помощью вероятности правильной 
классификации~$P_c$, которую посчитать  аналитически затруднительно, 
а~потому она бу-\linebreak
\vspace*{-12pt}

\columnbreak

 \noindent
 \begin{center}  %fig1
 \vspace*{-6pt}
 \mbox{%
 \epsfxsize=77.995mm
 \epsfbox{kri-1.eps}
 }
\end{center} 


%\vspace*{3pt}

\noindent
{{\figurename~1}\ \ \small{Зависимость эффективности селекции от чис\-ла признаков~$d$ в~случае SBS  
и~B-оцен\-ки величины~$P_c$ (для отдельного~$d$ приведено значение оценки~--- 
горизонтальный штрих и~90\%-ный доверительный интевал~--- вертикальный отрезок)}}



 \vspace*{9pt}
 


\noindent
дет оцениваться с~помощью моделирования обуча\-ющей 
выборки из $g^*(u)$~--- так называемой бут\-стреп-вы\-бор\-ки~$x^B$. 
В~результате получаем алгоритм бут\-стреп-оце\-ни\-ва\-ния~$P_c$, 
включающий следующие шаги: оценивание по обучающей выборке па\-ра\-мет\-ров 
смеси~$g^*(u)$; формирование бут\-стреп-вы\-бор\-ки~$x^B$ из~$g^*(u)$; 
классификация с~помощью $g^*(u)$ данных из~$x^B$ и~подсчет числа случаев 
правильной классификации. Такая процедура позволяет для любого набора 
признаков дать оценку вероятности правильной классификации. Теперь для 
различных наборов признаков на основе биномиального
 распределения можно 
строить необходимые доверительные интервалы, проверять гипотезу об 
однородности результатов анализа классификаторов для ряда наборов 
признаков, сравнивать отдельные варианты наборов. Результаты отбора 
признаков с~помощью метода SBS и~B-оцен\-ки для~$P_c$ пред\-став\-ле\-ны на 
рис.~1.


     Результаты исследования наиболее интересных наборов признаков 
отражены в~табл.~2. Для критерия Сю действенность предложенной им 
аппрок-\linebreak\vspace*{-12pt}

\columnbreak

\noindent
симации проверялась с~помощью моделирования и~полностью 
подтвердилась. Анализ табл.~2 поз\-во\-ляет сделать следующие практически 
важные выводы:
     \begin{itemize}
\item значения размерности пространства признаков от~8 до~14 с~точки 
зрения эффективности классификации практически эквивалентны (строки~1 
и~2 табл.~2);
\item снижение размерности до~7 дает значимые потери в~эффективности 
классификации (строка~3 табл.~2);
\item значение размерности~13 заслуживает пристального внимания, так как 
может привести к~повышению эффективности классификации по сравнению 
с обычным использованием всех показателей (строка~4 табл.~2) или по 
сравнению с~применением наиболее <<экономичного>> варианта $d\hm=8$ 
(строка~5 табл.~2).
\end{itemize}

     Практически те же результаты дал и~метод SFS.
     
     Данная схема бутстреп-ана\-ли\-за позволяет ответить на вопрос, на что 
можно рассчитывать с~точки зрения качества классификации при 
использовании байесовского классификатора на основе смеси нормальных 
распределений и~данных, распределенных действительно как смесь 
нормальных распределений. 
     
     Метод перепроверки из-за зависимости от\-дельных экспериментов по 
оценке качества клас\-сификатора не позволяет полностью формально 
сопоставлять их результаты, но по сравнению с~результатами  
бут\-стреп-ана\-ли\-за он дает возможность получить представление об 
адекватности принятой модели данных (рис.~2). 

     Из рис.~2 видно, что метод перепроверки дает существенно более 
осторожные результаты, хотя из\linebreak\vspace*{-12pt}


\vspace*{12pt}

\noindent
 \begin{center}  %fig2
 \vspace*{-6pt}
\mbox{%
 \epsfxsize=77.995mm
 \epsfbox{kri-2.eps}
 }
\end{center} 


%\vspace*{3pt}

\noindent
{{\figurename~2}\ \ \small{Зависимость эффективности селекции от чис\-ла признаков~$d$ при 
классификации <<наугад>>~(\textit{1}) и~с~использованием байесовских классификаторов 
(\textit{2}~--- SBS; \textit{3}~--- SFS; черные значки~---  
B-оцен\-ка для~$P_c$; пустые значки~--- CV-оцен\-ка для~$P_c$)}}



% \vspace*{9pt}
     

     
\noindent
 них опять же следует целесообразность 
применения для прогнозирования состава камня не всей, а~лишь части 
совокупности показателей. 
     
     Снижение эффективности по методу перепроверки по сравнению  
с~бут\-стреп-ме\-то\-дом мож\-но частично объяснять примененным вариантом\linebreak  
CV-оцен\-ки и~ограниченным объемом исходных данных. Для иллюстрации 
этого анализировалась зависимость эффективности классификации от объема 
обучающей выборки. Оказалось, что в~рассматриваемом случае CV-оцен\-ка 
является нижней границей для истинного значения, а~T- и~B-оцен\-ки, близкие 
между собой, служат верхними границами. Их значения с~ростом размера 
исходной выборки сходятся к~истинной величине вероятности правильной 
классификации, но достигают этого значения при значительных размерах 
исходной выборки (более~2000~наблюденных значений).

\vspace*{-6pt}

\section{Заключение}

     Существуют различные подходы к~решению зада\-чи отбора признаков, 
еще более богатым ока\-зы\-ва\-ет\-ся набор соответствующих методов. 
В~прикладных областях к~этому многообразию добавляется фактическая 
неоднозначность получающегося решения. Оно в~принципе может оказаться 
формально единственным, но фактически значимо неотличимым от множества 
других. По этой причине\linebreak возрастает роль критериев значимости получен-\linebreak  ных
решений. Для нужд задачи классификации\linebreak
 данных предлагается использовать 
такую интегральную характеристику эффективности, как вероятность 
правильной классификации. Для ее\linebreak оценивания необходимо прибегать 
к~анализу последовательности испытаний Бернулли, при этом пол\-ностью 
корректные результаты будут получены при использовании  
бут\-стреп-ме\-то\-да обработки исходной выборки. 
     
     Проведенные эксперименты в~задаче прогнозирования химического 
состава мочевых камней создают предпосылки для повышения качества 
получаемых решений (сокращение перечня проводимых анализов может 
привести к~росту точности прогноза), дают толчок специалистам в~предметной 
об\-ласти для прояснения сути протекающих процессов.
{\looseness=-1

}

\vspace*{-6pt}
     
{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
\bibitem{1-kri}
\Au{Webb A.\,R., Copsey K.\,D.} Statistical pattern recognition.~---3rd ed.~--- 
Chichester, U.K.: John Wiley \& Sons, 2011. 616~p.
\bibitem{2-kri}
\Au{Liu H., Yu L.} Toward integrating feature selection algorithms for classification 
and clustering~// IEEE Trans. Knowl. Data Eng., 2005. Vol.~17. P.~491--502.
\bibitem{3-kri}
\Au{Saeys Y., Inza I., Larrannaga~P.} A~review of feature selection techniques in 
bioinformatics~// Bioinformatics, 2007. Vol.~23. P.~2507--2517.
\bibitem{4-kri}
\Au{Yu L., Liu H.} Efficient feature selection via analysis of relevance and 
redundancy~// J.~Machine Learning Res., 2004. Vol.~5. P.~1205--1224.
\bibitem{5-kri}
\Au{Stracuzzi D.\,J.} Randomized feature selection~// Computational methods of 
feature selection.~--- Boca Raton, FL, USA: Chapman and Hall/CRC, 2007.  
P.~41--62.
\bibitem{6-kri}
\Au{Dasgupta A., Zhang T.} Binomial and multinomial parameters, inference on~// Encyclopedia of statistical sciences.~--- New York, NY, USA: John Wiley 
\& Sons, 2006. P.~501--519.
\bibitem{7-kri}
\Au{Hall P.} Improving the normal approximation when constructing one-sided 
confidence intervals for binomial or Poisson parameters~// Biometrika, 1982. 
Vol.~69. P.~647--652.
\bibitem{8-kri}
\Au{Upton G.\,J.\,G.} A~comparison of alternative tests for the $2\times2$ 
comparative trial~// J.~Roy. Stat. Soc. A, 1982. Vol.~145.  
P.~86--105.
\bibitem{9-kri}
\Au{Lehmann E.\,L., Romano J.\,P.} Testing statistical hypotheses.~--- 3rd ed.~--- 
New York, NY, USA: Springer, 2005. 784~p.
\bibitem{10-kri}
\Au{Кривенко М.\,П.} Задачи выборочного контроля при досмотре лиц, багажа 
и~транспорта~// Обозрение прикладной и~промышленной математики, 2011. 
Vol.~18. P.~125--126.
\bibitem{11-kri}
\Au{Potthoff R.\,F.} Homogeneity, Potthoff--Whittighill tests of~// Encyclopedia 
of statistical sciences.~--- New York, NY, USA: John Wiley \& Sons, 2006.  
P.~3217--3220.
\bibitem{12-kri}
\Au{Klein M., Linton P.} On a comparison of tests of homogeneity of binomial 
proportions.~--- Washington: Center for Statistical Research \& Methodology 
Research and Methodology Directorate U.S. Census Bureau, 2013. {\sf 
https://www.census.gov/srd/papers/pdf/rrs2013-03.pdf}.
\end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-6pt}

\hfill{\small\textit{Поступила в~редакцию 14.06.16}}

\vspace*{6pt}

%\newpage

%\vspace*{-24pt}

\hrule

\vspace*{2pt}

\hrule

%\vspace*{8pt}



\def\tit{SIGNIFICANCE TESTS OF~FEATURE SELECTION FOR~CLASSIFICATION}

\def\titkol{Significance tests of feature selection for~classification}

\def\aut{M.\,P.~Krivenko}

\def\autkol{M.\,P.~Krivenko}

\titel{\tit}{\aut}{\autkol}{\titkol}

\vspace*{-9pt}

\noindent
Institute of Informatics Problems, Federal Research Center ``Computer Science and 
Control'' of the Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, 
Russian Federation


\def\leftfootline{\small{\textbf{\thepage}
\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND
APPLICATIONS\ \ \ 2016\ \ \ volume~10\ \ \ issue\ 3}
}%
 \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---
INFORMATICS AND APPLICATIONS\ \ \ 2016\ \ \ volume~10\ \ \ issue\ 3
\hfill \textbf{\thepage}}}

\vspace*{3pt}



\Abste{The paper considers the problem of feature selection for classification and issues related to 
the assessment of the quality of the solutions. Among the different methods of feature selection, 
attention is paid to sequential procedures; the probability of the correct classification is used to 
measure the quality of the classification. To evaluate this indicator, it is proposed to use 
cross-validation and the bootstrap method. At the same time, to investigate the set of sample values of 
probability of the correct classification, it is suggested to use comparative analysis of confidence 
intervals and the test for homogeneity of binomial proportions. While constructing Bayesian 
classifier as the data model mixture of normal distributions is adopted, the model parameters are 
estimated by the expectation--maximization algorithm. As an experiment, the paper considers the problem of  
well-thoughtout choice of classification characteristics when predicting the type of urinary stones 
in urology. It is demonstrated that the set of used features can be reduced not only without losing 
the quality of decisions, but also with increase of probability of correct prediction of the stone 
type.}

\KWE{feature selection; sequential forward and backward selections; Bayes classification; test of 
homogeneity of binomial proportions; prediction of stone types in urology}

\DOI{10.14357/19922264160305} 

\vspace*{-9pt}

%\Ack
%\noindent



%\vspace*{3pt}

  \begin{multicols}{2}

\renewcommand{\bibname}{\protect\rmfamily References}
%\renewcommand{\bibname}{\large\protect\rm References}

{\small\frenchspacing
 {%\baselineskip=10.8pt
 \addcontentsline{toc}{section}{References}
 \begin{thebibliography}{99}
\bibitem{1-kri-1}
\Aue{Webb, A.\,R., and K.\,D.~Copsey}. 2011. \textit{Statistical pattern recognition}. 
3rd ed. Chichester, U.K.: John Wiley \& Sons. 616~p.
\bibitem{2-kri-1}
\Au{Liu, H., and L.~Yu.} 2005. Toward integrating feature selection algorithms for 
classification and clustering. \textit{IEEE Trans. Knowl.  Data Eng.}  
17:491--502.
\bibitem{3-kri-1}
\Aue{Saeys, Y., I.~Inza, and P. Larrannaga.} 2007. A~review of feature selection 
techniques in bioinformatics. \textit{Bioinformatics} 23:2507--2517.
\bibitem{4-kri-1}
\Aue{Yu, L., and H. Liu}. 2004. Efficient feature selection via analysis of relevance 
and redundancy. \textit{J.~Machine Learning Res.} 5:1205--1224.
\bibitem{5-kri-1}
\Aue{Stracuzzi, D.\,J.} 2007. Randomized feature selection. \textit{Computational 
methods of feature selection}. Boca Raton, FL: Chapman and Hall/CRC.  
41--62.
\bibitem{6-kri-1}
\Aue{Dasgupta, A., and T. Zhang}. 2006. Binomial and multinomial parameters, 
inference on. \textit{Encyclopedia of statistical sciences}. New York, NY: John 
Wiley \& Sons. 501--519.
\bibitem{7-kri-1}
\Aue{Hall, P.} 1982. Improving the normal approximation when constructing 
one-sided confidence intervals for binomial or Poisson parameters. \textit{Biometrika} 
69:647--652.
\bibitem{8-kri-1}
\Aue{Upton, G.\,J.\,G.} 1982. A comparison of alternative tests for the $2\times2$ 
comparative trial. \textit{J.~Roy. Stat. Soc. A} 145:86--105.
\bibitem{9-kri-1}
\Aue{Lehmann, E.\,L., and J.\,P.~Romano}. 2005. \textit{Testing statistical 
hypotheses}. 3rd ed. New York, NY: Springer. 784~p.
\bibitem{10-kri-1}
\Aue{Krivenko, M.\,P.} 2011. Zadachi vyborochnogo kontrolya pri dosmotre lits, 
bagazha i~transporta [Tasks of sampling during the inspection of individuals, 
baggage and transport]. \textit{Obozrenie prikladnoy i~promyshlennoy matematiki} 
[Review of applied and industrial mathematics] 18:125--126.
\bibitem{11-kri-1}
\Aue{Potthoff, R.\,F.} 2006. Homogeneity, Potthoff--Whittighill tests of. 
\textit{Encyclopedia of statistical sciences}. New York, NY: John Wiley \& Sons. 
3217--3220.
\bibitem{12-kri-1}
\Aue{Klein, M., and P. Linton.} 2013. On a comparison of tests of homogeneity of 
binomial proportions. Center for Statistical Research \& Methodology Research and 
Methodology Directorate U.S. Census Bureau Washington. Available at: {\sf 
https://www.census.gov/srd/papers/pdf/rrs2013-03.pdf} (accessed April~25, 2016).
   \end{thebibliography}

 }
 }

\end{multicols}

\vspace*{-9pt}

\hfill{\small\textit{Received June 14, 2016}}

\vspace*{-3pt}

\Contr

\noindent
\textbf{Krivenko Mikhail P.} (b.\ 1946)~--- 
Doctor of Science in technology, professor, leading scientist, 
Institute of Informatics Problems, Federal Research Center ``Computer 
Science and Control'' of the Russian Academy of Sciences, 44-2~Vavilov Str., 
Moscow 119333, Russian Federation; \mbox{mkrivenko@ipiran.ru}




  \label{end\stat}
  
  
  \renewcommand{\bibname}{\protect\rm Литература}