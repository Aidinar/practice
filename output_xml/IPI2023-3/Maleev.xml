<?xml version="1.0" encoding="utf-8"?>
<papers>
  <paper>
    <metadata>
      <author value="\index{}"/>
      <author value="\index{}"/>
      <author value="\index{}"/>
      <author value="\index{}"/>
      <annotation value="\Abst{Глубокие сверточные нейронные сети широко применяются для задач детектирования объектов. Однако современные модели глубоких сверточных нейронных сетей требуют больших вы чис ли тель ных ресурсов, что за труд ня ет их развертывание на мобильных и встро ен ных устройствах с ограниченными ресурсами. Бинарные нейронные сети поз во ля ют снизить требования к устройствам. В бинарных нейронных сетях активации и/или веса принимают только двоичные значения $(-1, 1)$. Пред став лен ный в работе метод применяет балансировку и нормализацию це ло чис лен ных значений весов при прямом распространении и двухэтапную аппроксимацию функции знака при обрат ном. Приведены результаты срав не ния точ ности обнаружения на наборе данных PASCAL Face и ско рости работы и размера модели на мобильном устройстве для пред став лен но го в работе метода, модели без применения бинаризации, сети TinyML и методов Bi-Real Net и ABC-Net.}"/>
      <keywords>
        <braces>
          <text value="\KW{бинарные нейронные сети; сверточные нейронные сети; обнаружение объектов; ускорение модели}"/>
        </braces>
      </keywords>
    </metadata>
    <fulltext>
      <literature/>
      <text value="maleev"/>
      <text value="ИССЛЕДОВАНИЕ ЭФФЕКТИВНОСТИ ПРИМЕНЕНИЯ БИНАРНЫХ НЕЙРОННЫХ СЕТЕЙ ПРИ ДЕТЕКТИРОВАНИИ ОБЪЕКТА НА ИЗОБРАЖЕНИИ"/>
      <text value="Исследование эффективности применения бинарных нейронных сетей при детектировании объекта на изображении"/>
      <text value="Д."/>
      <text value="О. Королев$^1$, О."/>
      <text value="Г. Малеев$^2$"/>
      <text value="Д."/>
      <text value="О. Королев, О."/>
      <text value="Г. Малеев"/>
      <command value="\titel">
        <braces>
          <braces>
            <text value="{}"/>
            <command value="\tit">
              <braces/>
              <braces>
                <braces>
                  <text value="{}"/>
                  <command value="\aut">
                    <braces/>
                    <braces>
                      <braces>
                        <text value="{}"/>
                        <command value="\autkol">
                          <braces/>
                          <braces>
                            <braces>
                              <text value="{}"/>
                              <command value="\titkol">
                                <braces/>
                              </command>
                            </braces>
                          </braces>
                        </command>
                      </braces>
                    </braces>
                  </command>
                </braces>
              </braces>
            </command>
          </braces>
        </braces>
      </command>
      <text value="Королев Д."/>
      <text value="О."/>
      <text value="Малеев О."/>
      <text value="Г."/>
      <text value="Korolev D."/>
      <text value="O."/>
      <text value="Maleev O."/>
      <text value="G."/>
      <command value="\renewcommand">
        <braces>
          <braces>
            <text value="{}"/>
            <command value="\thefootnote">
              <braces/>
              <braces>
                <braces>
                  <text value="{}"/>
                  <command value="\arabic">
                    <braces>
                      <braces>
                        <text value="{}"/>
                        <text value="footnote"/>
                      </braces>
                    </braces>
                    <braces/>
                    <braces/>
                  </command>
                </braces>
              </braces>
            </command>
          </braces>
        </braces>
      </command>
      <command value="\footnotetext">
        <braces>
          <text value="\footnotetext[1]{}"/>
        </braces>
      </command>
      <text value="Институт компьютерных наук и технологий Санкт-Петербургского политехнического университета Петра Великого,"/>
      <command value="\mbox">
        <braces>
          <braces>
            <text value="{}"/>
            <affiliation>
              <braces>
                <text value="korolev.do512@gmail.com"/>
              </braces>
            </affiliation>
          </braces>
        </braces>
        <braces/>
        <braces/>
      </command>
      <command value="\footnotetext">
        <braces>
          <text value="\footnotetext[2]{}"/>
        </braces>
      </command>
      <text value="Институт компьютерных наук и технологий Санкт-Петербургского политехнического университета Петра Великого,"/>
      <command value="\mbox">
        <braces>
          <braces>
            <text value="{}"/>
            <text value="maleev"/>
            <command value="\_og">
              <braces>
                <text value="@spbstu.ru"/>
              </braces>
              <braces/>
              <braces/>
            </command>
          </braces>
        </braces>
      </command>
      <braces>
        <text value="{}"/>
        <text value="TOCVAL"/>
      </braces>
      <command value="\vspace*">
        <braces>
          <braces>
            <text value="{}"/>
            <text value="-4pt"/>
          </braces>
        </braces>
        <braces/>
      </command>
      <command value="\vskip">
        <braces>
          <text value="10pt plus 9pt minus 6pt"/>
        </braces>
      </command>
      <command value="\thispagestyle">
        <braces>
          <braces>
            <text value="{}"/>
            <text value="headings"/>
          </braces>
        </braces>
        <braces/>
      </command>
      <command value="\begin">
        <braces>
          <braces>
            <text value="{}"/>
            <text value="2"/>
          </braces>
        </braces>
        <braces/>
      </command>
      <command value="\label">
        <braces>
          <braces>
            <text value="{}"/>
            <text value="st"/>
            <command value="\stat">
              <braces/>
            </command>
          </braces>
        </braces>
      </command>
      <section id="id1">
        <braces>
          <text value="\section{}"/>
        </braces>
        <text value="Введение"/>
        <command value="\vspace*">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="-2pt"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value="Вопросам разработки методов, алгоритмов и программно-аппаратных комплексов обработки и классификации изображений с детектированием объектов посвящено достаточно много научных работ"/>
          </braces>
          <braces/>
          <braces>
            <text value="1--4"/>
          </braces>
          <braces/>
          <braces>
            <text value=". Практические решения данной задачи находят широкое применение в системах управления и безопасности, видеоаналитике, системах контроля производства, сельском хозяйстве и т."/>
          </braces>
        </command>
        <text value="д. Распространенным подходом к классификации изображений и обнаружению объектов стало применение сверточных нейронных сетей"/>
        <text value="5"/>
        <text value=". Благодаря глубокой структуре с множеством уровней и миллионами параметров, глубокие сверточные нейронные сети демонстрируют высокую точность в широком классе задач. Например, сеть VGG-16, содержащая около 140 млн 32-битных параметров с плавающей запятой, достигает точности 92,7"/>
        <text value="в задаче классификации изображений на наборе данных ImageNet"/>
        <text value="6"/>
        <text value=". Вместе с тем такая сеть требует более 500 МБ дискового пространства и для выполнения классификации требует около"/>
        <formula id="id2" value="$1{,}6\cdot &#10;10^{10}$"/>
        <text value="арифметических операций с плавающей запятой. Понятно, что использование такой архитектуры приводит к необходимости применения достаточно высокопроизводительного оборудования, включающего, как правило, графические ускорители для проведения матричных вычислений"/>
        <text value="6"/>
        <text value=". Предлагаемая в статье реализация алгоритма детектирования объектов с применением бинарных нейронных сетей требует значительно меньшего объема вычислений и памяти, что позволяет проводить детектирование объектов в реальном масштабе времени на встроенных устройствах."/>
        <figure id="id3" value="Token(TokenType.COMMAND&amp;quot;, &amp;quot;\begin{figure*}&#10;  \vspace*{1pt}&#10;\begin{center}&#10;   \mbox{%&#10;\epsfxsize=162.253mm &#10;\epsfbox{mal-1.eps}&#10;}&#10;&#10;\vspace*{6pt}&#10;&#10;  {\small Форма функций Identity~(\textit{а}) и~Hardtanh~(\textit{б})}&#10;  \end}&#10;  \end{figure*}&amp;quot;, line=93, col=18)">
          <command value="\vspace*">
            <braces>
              <braces>
                <text value="{}"/>
                <text value="-9pt"/>
              </braces>
            </braces>
            <braces/>
          </command>
        </figure>
      </section>
      <section id="id4">
        <braces>
          <text value="\section{}"/>
        </braces>
        <text value="Бинарные нейронные сети"/>
        <text value="В бинарных нейронных сетях значения выходов нейронов и/или весов принимают только двоичные значения"/>
        <formula id="id5" value="$(-1, 1)$"/>
        <text value=". При этом 32-битные операции умножения и накопления могут быть заменены поразрядными логическими операциями XNOR и операциями подсчета накопления bitcount, заключающимися в подсчете количества единиц"/>
        <text value="6"/>
        <text value=". Такой подход позволяет получить значительное увеличение быстродействия и уменьшение размера модели. Для прямого распространения в качестве функции активации может быть применена функция"/>
        <command value="\mbox">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="знака"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value=":"/>
          </braces>
        </command>
        <command value="\noindent">
          <braces>
            <text value="\noindent"/>
          </braces>
        </command>
        <command value="\begin"/>
        <command value="\mathrm">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="sgn"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <text value="(x)="/>
        <command value="\begin">
          <braces>
            <text value="1, &amp;amp;"/>
          </braces>
        </command>
        <command value="\mbox">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="если"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <text value="x"/>
        <command value="\geq">
          <braces>
            <text value="0"/>
          </braces>
        </command>
        <text value=";"/>
        <text value="0, &amp;amp;"/>
        <command value="\mbox">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="если"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <text value="x&amp;lt;0"/>
        <text value="."/>
        <command value="\end">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="cases"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <command value="\end">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="equation*"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value="Функция знака проста в реализации и неплохо работает на практике, однако ее невозможно использовать при обучении в алгоритме обратного распространения ошибки из-за ее недифференцируемости при"/>
          </braces>
        </command>
        <formula id="id6" value="$x\hm= 0$"/>
        <text value=". Для решения этой проблемы при обучении применяют функции Identity и Hardtanh"/>
        <text value="6"/>
        <text value=". Функция Identity, в отличие от Hardtanh, передает информацию о градиенте без учета эффекта бинаризации. Функция Hardtanh учитывает бинаризацию, однако из-за наличия интервала отсечения отбрасывает информацию за его пределами. Обе эти функции теряют информацию о градиенте и на практике могут приводить к уменьшению точности:"/>
        <command value="\begin">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="2"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <command value="\mbox">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="Identity"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value=":&amp;amp;"/>
          </braces>
        </command>
        <text value="&amp;amp;y&amp;amp;=x"/>
        <text value=";"/>
        <text value="6pt"/>
        <command value="\mbox">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="Hardtanh"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value=":&amp;amp;"/>
          </braces>
        </command>
        <text value="&amp;amp;y&amp;amp;="/>
        <command value="\mathrm">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="Hardtanh"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <text value="(x)."/>
        <command value="\end">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="alignat*"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value="На рисунке представлена форма функций Identity и Hardtanh"/>
          </braces>
        </command>
        <command value="\cite">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="5-mal"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <command value="\specialsymbol">
          <braces>
            <text value="~---"/>
          </braces>
        </command>
        <text value="задача нетривиальная. Далее рассмотрим основные этапы предлагаемого авторами метода построения бинарной"/>
        <command value="\mbox">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="сети"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value="."/>
          </braces>
        </command>
      </section>
      <section id="id7">
        <braces>
          <text value="\section{}"/>
        </braces>
        <text value="Алгоритм бинаризации"/>
        <text value="В основе использованного в работе метода лежит способ IR-Net (Information Retention Network)"/>
        <text value="5"/>
        <text value=". Для дополнительной минимизации ошибки бинаризации применяется целочисленный битовый сдвиг со значением$s$над двоичными весами. Это позволяет расширить возможности представления двоичных весов без необходимости выполнять операции с целочисленными значениями в процессе обучения. При этом бинаризация весов и активаций сети имеет следующий вид:"/>
        <command value="\noindent">
          <braces>
            <text value="\noindent"/>
          </braces>
        </command>
        <command value="\begin">
          <braces>
            <text value="Q_w("/>
          </braces>
        </command>
        <command value="\hat">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="w"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value="_"/>
          </braces>
          <braces>
            <braces>
              <text value="{}"/>
              <command value="\mathrm">
                <braces>
                  <braces>
                    <text value="{}"/>
                    <text value="std"/>
                  </braces>
                </braces>
                <braces/>
                <braces/>
                <braces>
                  <text value=")&amp;amp;=B_w"/>
                </braces>
              </command>
            </braces>
          </braces>
        </command>
        <command value="\mbox">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="&amp;lt;&amp;lt;&amp;gt;&amp;gt;"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <text value="s ="/>
        <command value="\mathrm">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="sign"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <text value="("/>
        <command value="\hat">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="w"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value="_"/>
          </braces>
          <braces>
            <braces>
              <text value="{}"/>
              <command value="\mathrm">
                <braces>
                  <braces>
                    <text value="{}"/>
                    <text value="std"/>
                  </braces>
                </braces>
                <braces/>
                <braces/>
                <braces>
                  <text value=")"/>
                </braces>
              </command>
            </braces>
          </braces>
        </command>
        <command value="\mbox">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="&amp;lt;&amp;lt;&amp;gt;&amp;gt;"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <text value="s"/>
        <text value=";"/>
        <text value="Q_a(a)&amp;amp;=B_a ="/>
        <command value="\mathrm">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="sign"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <text value="(a)"/>
        <text value="."/>
        <command value="\end">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="align*"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value="Значение битового сдвига$s$определяется как$$s="/>
          </braces>
        </command>
        <command value="\mathrm">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="round"/>
            </braces>
          </braces>
          <braces/>
        </command>
        <command value="\left">
          <braces>
            <text value="("/>
          </braces>
        </command>
        <command value="\log">
          <braces>
            <text value="_2"/>
          </braces>
        </command>
        <command value="\left">
          <braces>
            <text value="("/>
          </braces>
        </command>
        <command value="\fr">
          <braces>
            <braces>
              <text value="{}"/>
            </braces>
          </braces>
        </command>
        <command value="\hat">
          <braces>
            <braces>
              <text value="{}"/>
              <text value="w"/>
            </braces>
          </braces>
          <braces/>
          <braces>
            <text value="_"/>
          </braces>
          <braces>
            <braces>
              <text value="{}"/>
              <command value="\mathrm">
                <braces>
                  <braces>
                    <text value="{}"/>
                    <text value="std"/>
                  </braces>
                </braces>
                <braces/>
                <braces/>
              </command>
            </braces>
          </braces>
        </command>
        <text value="_1"/>
        <braces>
          <text value="{}"/>
          <text value="n"/>
        </braces>
        <command value="\right">
          <braces>
            <text value=")"/>
          </braces>
        </command>
        <command value="\right">
          <braces>
            <text value=")"/>
          </braces>
        </command>
        <text value=",$$где$n$"/>
        <command value="\specialsymbol">
          <braces>
            <text value="~---"/>
          </braces>
        </command>
        <text value="размерность вектора весов;"/>
        <formula id="id8" value="$\|\hat{w}_{\mathrm{std}}\}_1$~--- \mbox{L1-нор}\-ма &#10;век\-то\-ра весов (сумма абсолютных значений век\-то\-ра).&#10;  &#10;Основная операция сети для прямого рас\-про\-стра\-не\-ния может быть &#10;пред\-став\-ле\-на~как&#10;  $$&#10;  z=\left( B_w \odot B_a\right)\;\mbox{&amp;lt;&amp;lt;&amp;gt;&amp;gt;}\;s\,.&#10;  $$&#10;  &#10;\subsection{Бинаризация весов и~активаций при~прямом &#10;распространении}&#10; &#10;  Для уменьшения влияния ошибок бинаризации в~рас\-смат\-ри\-ва\-емом методе &#10;предлагается уравновешивать веса, вычитая сред\-нее значение из весов пол\-ной &#10;точ\-ности:&#10;  $$&#10;  \hat{w}=w-\bar{w}\,.&#10;  $$&#10;  &#10;  Кроме того, для увеличения ста\-биль\-ности процесса обуче\-ния и~уменьшения &#10;влияния эф\-фек\-та снижения точ\-ности, связанного с~чрезмерным рос\-том &#10;величины весов и,~следовательно, рос\-том величины градиента, дополнительно &#10;предлагается проводить нормализацию урав\-но\-ве\-шен\-ных ве\-сов:&#10;  $$&#10;  \hat{w}_{\mathrm{std}} =\fr{\hat{w}}{\sigma(\hat{w})}\,,&#10;  $$&#10;где $\sigma(\cdot)$~--- стандартное от\-кло\-не\-ние. &#10;&#10;  &#10;&#10;%\pagebreak&#10;  &#10;  Эти операции делают веса полной точ\-ности рав\-но\-мер\-но распределенными, &#10;что повышает ста\-биль\-ность обуче\-ния бинарных нейронных сетей и,~как &#10;следствие, точ\-ность.&#10;  &#10;  Для прямого распространения в~качестве функции активации используется &#10;функ\-ция знака. При этом двоичные значения могут быть получены  &#10;сле\-ду\-ющим об\-ра\-зом:&#10;  \begin{align*}&#10;  Q_w\left(\hat{w}_{\mathrm{std}}\right) &amp;amp;= B_w =\mathrm{sign}\left( &#10;\hat{w}_{\mathrm{std}}\right)\,;\\&#10;  Q_a(a) &amp;amp;= B_a =\mathrm{sign}\left(a\right)\,.&#10;  \end{align*}&#10;&#10;\subsection{Двухэтапная аппроксимация при~обратном &#10;распространении}&#10;&#10;  Бинарная функция активации может приводить к~потере точ\-ности, за\-труд\-няя &#10;передачу градиента при обрат\-ном распространении. Для эффективного &#10;обуче\-ния сети долж\-ны быть применены методы, обес\-пе\-чи\-ва\-ющие большую &#10;спо\-соб\-ность к~об\-нов\-ле\-нию в~начале процесса обуче\-ния и~небольшую ошиб\-ку &#10;градиента в~\mbox{конце}.&#10;  &#10;  Для обратного распространения предлагается применять двухэтапный способ &#10;аппроксимации функ\-ции знака~\cite{5-mal}: &#10;  \begin{enumerate}[(1)]&#10;\item на первом этапе для аппроксимации функции знака применяется &#10;функ\-ция Identity. При этом на пер\-вом этапе не проводится отсечения &#10;градиентов (значение отсечения очень велико). При переходе ко второму &#10;этапу форма ап\-прок\-си\-ма\-ции изменяется от функ\-ции Identity к~форме &#10;Hardtanh, а~значение отсечения по\-сте\-пен\-но снижается до еди\-ницы; &#10;\item на втором этапе значение интервала отсечения становится рав\-ным &#10;единице. Форма аппроксимации по\-сте\-пен\-но принимает вид функ\-ции знака, &#10;обес\-пе\-чи\-ва\-ющей со\-гла\-со\-ван\-ность прямого и~об\-рат\-но\-го рас\-про\-стра\-не\-ния. &#10;  \end{enumerate}&#10;  &#10;  Функция аппроксимации $g(x)$ для обратного распространения опре\-де\-ля\-ет\-ся~как&#10;  $$&#10;  g(x)=k\,\mathrm{tanh}\,tx\,,&#10;  $$&#10;где $g(x)$~--- аппроксимация функции знака; $t$ и~$k$~--- управ\-ля\-ющие &#10;переменные, из\-ме\-ня\-ющие свои значения в~процессе обуче\-ния. Эти переменные &#10;могут быть опре\-де\-ле\-ны~как&#10;&#10;\noindent&#10;\begin{align*}&#10;t &amp;amp;= T_{\min} \cdot 10^{(i/N)\mathrm{log}\left (T_{\max}/T_{\min}\right)}\,;\\&#10;k&amp;amp;= \max\left( \fr{1}{t}, 1\right),&#10;\end{align*}&#10;где $i$~--- текущая эпоха; $N$~--- чис\-ло эпох; $T_{\min}$ и~$T_{\max}$~---  &#10;па\-ра\-мет\-ры, рав\-ные $10^{-1}$ и~$10^1$.&#10;&#10;\vspace*{-6pt}&#10;&#10;\section{Результаты}&#10;&#10;  Для экспериментальной нейронной сети в~работе выбрана широко известная &#10;архитектура SSD (single shot detector)~\cite{9-mal} с~до\-бав\-ле\-ни\-ем слоя пакетной &#10;нормализации~\cite{10-mal}. Модель бинарной сети, реализованная на основе &#10;пред\-став\-лен\-но\-го метода, была обуче\-на для детектирования объектов &#10;с~определением координат огра\-ни\-чи\-ва\-ющей рамки~\cite{12-mal}. &#10;В~качестве обуча\-ющей выборки использовался набор данных WIDER &#10;FACE~\cite{11-mal}, содержащий 12\,881~изоб\-ра\-же\-ние. &#10;  &#10;  Тестирование производительности бинарной нейронной сети проводилось на &#10;мобильном устройстве с~процессором MediaTek Helio P22 MT6762  &#10;(4\;$\times$\;Cortex-A53 2000~МГц, 4\;$\times$\;Cortex-A53 1500~МГц). &#10;Тестирование точ\-ности производилось на наборе данных PASCAL &#10;Face~\cite{13-mal}, содержащем 851~изобра\-же\-ние и~1341~лицо, ограниченные &#10;прямоугольными рам\-ками.&#10;  &#10;   Для развертывания предварительно обученной модели использовался &#10;фрейм\-ворк daBNN~\cite{14-mal}, под\-дер\-жи\-ва\-ющий мобильные &#10;устройства с~операционной сис\-те\-мой Android.&#10;  &#10;  Результаты экспериментов в~сравнении с~ранее известными методами Bi-Real &#10;Net~\cite{7-mal} и~ABC-Net~\cite{8-mal} и~применении автоматического &#10;преобразования модели с~использованием фрейм\-вор\-ка \mbox{TensorFlow} Lite &#10;приведены в~таб\-лице.&#10;&#10;&#10;&#10;%\begin{table*}[b]\small&#10;  \begin{center}&#10;  \tabcolsep=2.5pt&#10;  {\small \begin{tabular}{|l|c|c|c|}&#10;  \multicolumn{4}{c}{Результаты работы моделей}\\&#10;  \multicolumn{4}{c}{\ }\\[-6pt]&#10;  \hline&#10;\multicolumn{1}{|c|}{Модель}&amp;amp;\tabcolsep=0pt\begin{tabular}{c}Точность,\\ \%\end{tabular}&amp;amp;\tabcolsep=0pt\begin{tabular}{c}Время\\ работы, мс\end{tabular}&amp;amp;&#10;\tabcolsep=0pt\begin{tabular}{c}Размер,\\ МБ\end{tabular}\\&#10;\hline&#10;Полной точности&amp;amp;98,61&amp;amp;1811\hphantom{9}&amp;amp;89,69\\&#10;Предложенный метод&amp;amp;98,04&amp;amp;223&amp;amp;11,91\\&#10;Bi-Real Net&amp;amp;97,98&amp;amp;254&amp;amp;12,56\\&#10;ABC-Net&amp;amp;97,02&amp;amp;240&amp;amp;11,64\\&#10;TensorFlow Lite&amp;amp;98,56&amp;amp;645&amp;amp;23,78\\&#10;\hline&#10;\end{tabular}&#10;}&#10;\end{center}&#10;%\end{table*}&#10;  &#10;  &#10;\vspace*{-6pt}&#10;&#10;\section{Заключение}&#10;  &#10;  Предлагаемый в~данной \mbox{статье} метод по\-стро\-ения бинарной нейронной сети &#10;поз\-во\-ля\-ет уменьшить время обработки изоб\-ра\-же\-ния в~8,1~раза, а~объем &#10;памяти, за\-ни\-ма\-емый моделью, в~7,5~раза. При этом происходит &#10;незначительное падение точ\-ности обнаружения на тес\-то\-вом наборе данных &#10;\mbox{PASCAL} Face (0,57\%).&#10;  &#10;  Реализованный метод превосходит ранее известные методы Bi-Real &#10;Net~\cite{7-mal} и~ABC-Net~\cite{8-mal} по точ\-ности и~имеет лучшее  &#10;быст\-ро\-дей\-ст\-вие. &#10;  &#10;  Также предлагаемый авторами метод продемонстрировал в~2,8~раза лучшее &#10;быст\-ро\-дей\-ст\-вие и~более чем в~2~раза меньшие требования по памяти, чем &#10;рас\-про\-стра\-нен\-ный в~на\-сто\-ящее время инструмент TensorFlow  &#10;Lite~\cite{15-mal}, под\-дер\-жи\-ва\-ющий выполнение квантования весов &#10;до~8~бит точ\-ности.&#10;  &#10;  Реализованный метод показал высокую точ\-ность обнаружения, практически &#10;не усту\-па\-ющую пол\-но\-раз\-мер\-ным сверточным сетям, и~может эффективно &#10;применяться для по\-стро\-ения моделей нейронных сетей, ре\-ша\-ющих задачи &#10;обнаружения объектов, на мобильных и~встро\-ен\-ных устройствах &#10;с~ограниченными ре\-сур\-сами.&#10;  &#10;{\small\frenchspacing&#10; {\baselineskip=10.7pt&#10; %\addcontentsline{toc}{section}{References}&#10; \begin{thebibliography}{99}&#10;\bibitem{1-mal}&#10;\Au{Pathak A.\,R., Pandey~M., Rautaray~S.\,S.} Application of deep learning for object &#10;detection~// Procedia Comput. Sci., 2018. Vol.~132. P.~1706--1717. doi: &#10;10.1016/j.procs. 2018.05.144.&#10;&#10;\bibitem{3-mal} %2&#10;\Au{Jiao L., Zhang F., Liu~F., Yang~S., Li~L., Feng~Z., Qu~R.} A~survey of deep learning-based &#10;object detection~// IEEE Access, 2019. Vol.~7. P.~128837--128868. doi: &#10;10.1109/ \mbox{ACCESS}.2019.2939201.&#10;\bibitem{4-mal} %3&#10;\Au{Lu S., Wang~B., Wang~H., Chen~L., Linjian~M., Zhang~X.} A~real-time object detection &#10;algorithm for video~// Comput. Electr. Eng., 2019. Vol.~77. P.~398--408. doi: &#10;10.1016/ j.compeleceng.2019.05.009.&#10;\bibitem{2-mal} %4&#10;\Au{Wu X., Sahoo~D., Hoi~S.\,C.} Recent advances in deep learning for object detection~// &#10;Neurocomputing, 2020. Vol.~396. P.~39--64. doi: 10.1016/j.neucom.2020.01.085.&#10;\bibitem{5-mal} %5&#10; \Au{Qin H., Gong~R., Liu~X., Shen~M., Wei~Z., Yu~F., Song~J.} Forward and backward &#10;information retention for accurate binary neural networks~// Conference on Computer &#10;Vision and Pattern Recognition Proceedings.~--- Seattle, WA, USA: IEEE, 2020. P.~2247--2256. doi: &#10;10.1109/ CVPR42600.2020.00232.&#10;\bibitem{6-mal}&#10;\Au{Qin H., Gong~R., Liu~X., Bai~X., Song~J., Sebe~N.} Binary neural networks: A~survey~// &#10;Pattern Recogn., 2020. Vol.~105. Art.~107281. 14~p. doi: 10.1016/j.patcog. 2020.107281.&#10;&#10;\bibitem{9-mal} %7&#10;\Au{Liu W., Anguelov~D., Erhan~D., Szegedy~C., Reed~S.\,E., Fu~C., Berg~A.\,C.}  SSD: Single &#10;shot MultiBox detector~// Computer vision~/ Eds. B.~Leibe, J.~Matas, &#10;N.~Sebe, M.~Welling.~--- Lecture notes in computer science ser.~--- Cham: Springer, 2016. &#10;Vol.~9905. P.~21--37. doi: 10.1007/ 978-3-319-46448-0\_2.&#10;\bibitem{10-mal} %8&#10;\Au{Cai Z., He~X., Sun~J., Vasconcelos~N.} Deep learning with low precision by half-wave &#10;Gaussian quantization~// Conference on Computer Vision and Pattern Recognition Proceedings.~--- IEEE, &#10;2017. P.~5406--5414. doi: 10.1109/ CVPR.2017.574.&#10;\bibitem{12-mal} %9&#10;\Au{Ren S., He~K., Girshick~R.\,B., Sun~J.} Faster \mbox{R-CNN}: Towards real-time object detection &#10;with region proposal networks~// IEEE T. Pattern Anal., 2015. Vol.~39. &#10;P.~1137--1149. doi: 10.1109/\mbox{TPAMI}.2016.2577031.&#10;\bibitem{11-mal} %10&#10;\Au{Yang S., Luo~P., Loy~C.\,C., Tang~X.} WIDER FACE: A~face detection benchmark~//  &#10;Conference on Computer Vision and Pattern Recognition Proceedings.~--- IEEE, 2016. P.~5525--5533. doi: &#10;10.1109/CVPR.2016.596.&#10;&#10;\bibitem{13-mal} %11&#10;\Au{Yan J., Zhang~X., Lei~Z., Li~S.} Face detection by structural models~// Image Vision &#10;Comput., 2014. Vol.~32. P.~790--799. doi: 10.1016/j.imavis.2013.12.004.&#10;\bibitem{14-mal} %12&#10;\Au{Zhang J., Pan~Y., Yao~T., Zhao~H., Mei~T.} daBNN: A~super fast inference &#10;framework for binary neural networks on ARM devices~// 27th ACM Conference (International)  &#10;on Multimedia Proceedings.~--- New York, NY, USA: ACM, 2019. P.~2272--2275. doi: &#10;10.1145/3343031.3350534.&#10;&#10;\bibitem{7-mal} %13&#10;\Au{Liu Z., Wu~B., Luo~W., Yang~X., Liu~W., Cheng~K.} Bi-Real Net: Enhancing the performance &#10;of 1-bit CNNs with improved representational capability and advanced training algorithm~// &#10;Computer vision~/ Eds. V.~Ferrari, M.~Hebert, &#10;C.~Sminchisescu, Y.~Weiss.~--- Lecture notes in computer science &#10;ser.~--- Cham: Springer, 2018. Vol.~11219. P.~747--763. doi:  &#10;10.1007/978-3-030-01267-0\_44.&#10;\bibitem{8-mal} %14&#10;\Au{Lin X., Zhao~C., Pan~W.} Towards accurate binary convolutional neural network~// 31st  &#10;Conference (International) on Neural Information Processing Systems Proceedings.~--- Red Hook, &#10;NY, USA: Curran Associates Inc., 2017. P.~345--353.&#10;\bibitem{15-mal}&#10;TensorFlow. TensorFlow Lite guide. {\sf https://www.\linebreak tensorflow.org/lite}.&#10;\end{thebibliography}&#10;&#10; }&#10; }&#10;&#10;\end{multicols}&#10;&#10;\vspace*{-7pt}&#10;&#10;\hfill{\small\textit{Поступила в~редакцию 22.07.22}}&#10;&#10;\vspace*{6pt}&#10;&#10;%\pagebreak&#10;&#10;%\newpage&#10;&#10;%\vspace*{-28pt}&#10;&#10;\hrule&#10;&#10;\vspace*{2pt}&#10;&#10;\hrule&#10;&#10;\vspace*{-2pt}&#10;&#10;&#10;&#10;\def\tit{EFFICIENCY OF~BINARY NEURAL NETWORKS FOR~OBJECT~DETECTION~ON~AN~IMAGE}&#10;&#10;&#10;\def\titkol{Efficiency of~binary neural networks for~object &#10;detection on~an~image}&#10;&#10;&#10;\def\aut{D.\,O.~Korolev and~O.\,G.~Maleev}&#10;&#10;\def\autkol{D.\,O.~Korolev and~O.\,G.~Maleev}&#10;&#10;\titel{\tit}{\aut}{\autkol}{\titkol}&#10;&#10;\vspace*{-12pt}&#10;&#10;&#10;\noindent&#10;  Peter the Great St.\ Petersburg Polytechnic University, 29~Polytechnicheskaya &#10;Str., St.\ Petersburg 195251, Russian Federation&#10;&#10;&#10;&#10;\def\leftfootline{\small{\textbf{\thepage}&#10;\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND&#10;APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 3}&#10;}%&#10; \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---&#10;INFORMATICS AND APPLICATIONS\ \ \ 2023\ \ \ volume~17\ \ \ issue\ 3&#10;\hfill \textbf{\thepage}}}&#10;&#10;\vspace*{3pt}&#10;&#10;  &#10;    &#10;  \Abste{Deep convolutional neural networks are widely used for object detection. However, modern deep convolutional neural network models are &#10;  computationally expensive hindering their deployment in resource-constrained mobile and embedded devices. Binary neural networks help to alleviate the resource &#10;requirements of devices. Activations and weights in binary neural networks are limited by binary values $"/>
        <text value="(-1, 1)"/>
        <formula id="id9" value="$. &#10;The proposed method implements balancing and standardization of floating-point weights in forward propagation and &#10;two-stage\linebreak\vspace*{-12pt}}&#10;&#10;\Abstend{sign function approximation in back propagation. The paper presents the results of detection accuracy on &#10;the PASCAL Face dataset as well as the results of speed and model size on the mobile device&#10; for the proposed method, the model without binarization, the TinyML network, and Bi-Real Net and ABC-Net methods.}&#10;  &#10;  \KWE{binary neural networks; convolutional neural networks; objects &#10;detection; model acceleration}&#10;  &#10;\DOI{10.14357/19922264230312}{TOCVAL}&#10;&#10;%\vspace*{-20pt}&#10;&#10;%\Ack&#10;%\noindent&#10;&#10;  &#10;&#10;%\vspace*{6pt}&#10;&#10;  \begin{multicols}{2}&#10;&#10;\renewcommand{\bibname}{\protect\rmfamily References}&#10;%\renewcommand{\bibname}{\large\protect\rm References}&#10;&#10;{\small\frenchspacing&#10; {%\baselineskip=10.8pt&#10; \addcontentsline{toc}{section}{References}&#10; \begin{thebibliography}{99} &#10;\bibitem{1-mal-1}&#10;\Aue{Pathak, A.\,R., M.~Pandey, and S.\,S.~Rautaray.} 2018. Application of deep learning for &#10;object detection. \textit{Procedia Comput. Sci.} 132:1706--1717. doi: 10.1016/j.procs. 2018.05.144.&#10;\bibitem{3-mal-1} %2&#10;\Aue{Jiao, L., F.~Zhang, F.~Liu, S.~Yang, L.~Li, Z.~Feng, and R.~Qu.} 2019. A~survey of deep &#10;learning-based object detection. \textit{IEEE Access} 7:128837--128868. doi: &#10;10.1109/ \mbox{ACCESS}.2019.2939201.&#10;\bibitem{4-mal-1} %3&#10;\Aue{Lu, S., B.~Wang, H.~Wang, L.~Chen, M.~Linjian, and X.~Zhang.} 2019. A~real-time object &#10;detection algorithm for video. \textit{Comput. Electr. Eng.} 77:398--408. doi: &#10;10.1016/ j.compeleceng.2019.05.009.&#10;\bibitem{2-mal-1} %4&#10;\Aue{Wu, X., D.~Sahoo, and S.\,C.~Hoi.} 2020. Recent advances in deep learning for object &#10;detection. \textit{Neurocomputing} 396:39--64. doi: 10.1016/j.neucom.2020.01.085.&#10;&#10;\bibitem{5-mal-1}&#10;\Aue{Qin, H., R.~Gong, X.~Liu, M.~Shen, Z.~Wei, F.~Yu, and J.~Song.} 2020. Forward and &#10;backward information retention for accurate binary neural networks. \textit{Conference on &#10;Computer Vision and Pattern Recognition Proceedings}. Seattle, WA: IEEE. 2247--2256. doi: &#10;10.1109/ CVPR42600.2020.00232.&#10;\bibitem{6-mal-1}&#10;\Aue{Qin, H., R.~Gong, X.~Liu, X.~Bai, J.~Song, and N.~Sebe.} 2020. Binary neural networks: &#10;A~survey. \textit{Pattern Recogn.} 105:107281. 14~p. doi: 10.1016/j.patcog.2020.107281.&#10;&#10;\bibitem{9-mal-1} %7&#10;\Aue{Liu, W., D.~Anguelov, D.~Erhan, C.~Szegedy, S.\,E.~Reed, C.~Fu, and A.\,C.~Berg.} 2016. &#10;SSD: Single shot MultiBox detector. \textit{Computer vision}. Eds. &#10;B.~Leibe, J.~Matas, N.~Sebe, and M.~Welling. Lecture notes in computer science ser. Cham: &#10;Springer. 9905:21--37. doi: 10.1007/978-3-319-46448-0\_2.&#10;\bibitem{10-mal-1} %8&#10;\Aue{Cai, Z., X.~He, J.~Sun, and N.~Vasconcelos.} 2017. Deep learning with low precision by &#10;half-wave Gaussian quantization. \textit{Conference on Computer Vision and Pattern &#10;Recognition Proceedings}. IEEE. 5406--5414.  doi: 10.1109/ CVPR.2017.574.&#10;&#10;\bibitem{12-mal-1} %9&#10;\Aue{Ren, S., K.~He, R.\,B.~Girshick, and J.~Sun.} 2017. Faster R-CNN: Towards real-time object &#10;detection with region proposal networks. \textit{IEEE T. Pattern Anal.} 39(6):1137--1149. doi: &#10;10.1109/\mbox{TPAMI}.2016.2577031.&#10;\bibitem{11-mal-1} %10&#10;\Aue{Yang, S., P.~Luo, C.\,C.~Loy, and X.~Tang.} 2016. WIDER FACE: A~face detection &#10;benchmark. \textit{Conference on Computer Vision and Pattern Recognition Proceedings}. IEEE.&#10; 5525--5533. doi: 10.1109/CVPR.2016.596.&#10;&#10;\bibitem{13-mal-1} %11&#10;\Aue{Yan, J., X.~Zhang, Z.~Lei, and S.~Li.} 2014. Face detection by structural models. &#10;\textit{Image Vision Comput.} 32(10):790--799. doi: 10.1016/j.imavis.2013.12.004.&#10;\bibitem{14-mal-1} %12&#10;\Aue{Zhang, J., Y.~Pan, T.~Yao, H.~Zhao, and T.~Mei.} 2019. daBNN: A~super fast inference &#10;framework for binary neural networks on ARM devices. \textit{27th ACM Conference (International) on &#10;Multimedia Proceedings}. New York, NY: ACM. 2272--2275. doi: 10.1145/3343031.3350534.&#10;&#10;\bibitem{7-mal-1} %13&#10;\Aue{Liu, Z., B.~Wu, W.~Luo, X.~Yang, W.~Liu, and K.~Cheng.} 2018. Bi-Real Net: Enhancing &#10;the performance of 1-bit CNNs with improved representational capability and advanced training &#10;algorithm. \textit{Computer vision}. Eds. V.~Ferrari, M.~Hebert, &#10;C.~Sminchisescu, and Y.~Weiss. Lecture notes in computer science ser. Cham: Springer. &#10;11219:747--763. doi: 10.1007/978-3-030-01267-0\_44.&#10;\bibitem{8-mal-1} %14&#10;\Aue{Lin, X., C.~Zhao, and W.~Pan.} 2017. Towards accurate binary convolutional neural &#10;network. \textit{31st Conference (International) on Neural Information Processing Systems Proceedings}. Red &#10;Hook, NY: Curran Associates Inc. 345--353.&#10;&#10; \bibitem{15-mal-1}&#10;  TensorFlow. TensorFlow Lite guide. Available at: {\sf   https:// www.tensorflow.org/lite} (accessed &#10;July~13, 2023).&#10;  \end{thebibliography}&#10;&#10; }&#10; }&#10;&#10;\end{multicols}&#10;&#10;\vspace*{-6pt}&#10;&#10;\hfill{\small\textit{Received July 22, 2022}} &#10;&#10;\vspace*{-12pt}&#10;  &#10;  \Contr&#10;  &#10;  \noindent&#10;  \textbf{Korolev Denis O.} (b.\ 1999)~--- student, Institute of Computer Science &#10;and Technology, Peter the Great St.\ Petersburg Polytechnic University,  &#10;29~Polytechnicheskaya Str., St.\ Petersburg 195251, Russian Federation; &#10;\mbox{korolev.do512@gmail.com}&#10;  &#10;  \vspace*{3pt}&#10;  &#10;  \noindent&#10;  \textbf{Maleev Oleg G.} (b.\ 1971)~--- Candidate of Science (PhD) in technology, &#10;associate professor, Institute of Computer Science and Technology, Peter the Great &#10;St.\ Petersburg Polytechnic University, 29~Polytechnicheskaya Str., St.\ Petersburg &#10;195251, Russian Federation; \mbox{maleev\_og@spbstu.ru}&#10;&#10;&#10;\label{end\stat}&#10;&#10;\renewcommand{\bibname}{\protect\rm Литература} "/>
      </section>
    </fulltext>
  </paper>
</papers>