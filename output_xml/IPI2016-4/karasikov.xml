<?xml version="1.0" encoding="utf-8"?>
<papers>
  <paper>
    <metadata>
      <author value="\index{}"/>
      <author value="\index{}"/>
      <author value="\index{}"/>
      <author value="\index{}"/>
      <annotation value="\Abst{Работа посвящена задаче многоклассовой признаковой классификации временных рядов. Признаковая классификация временных рядов заключается в сопоставлении каждому временному ряду его краткого признакового описания и позволяет решать задачу классификации в пространстве признаков. Исследуются методы построения пространства признаков временн${{ы}"/>
    </metadata>
    <fulltext>
      <literature/>
      <command value="\let"/>
      <command value="\varvec"/>
      <command value="\vec"/>
      <command value="\renewcommand">
        <braces>
          <braces>
            <text value="{}"/>
            <command value="\vec">
              <braces/>
              <braces/>
              <braces>
                <text value="1"/>
              </braces>
              <braces/>
              <braces>
                <braces>
                  <text value="{}"/>
                  <command value="\boldsymbol">
                    <braces>
                      <braces>
                        <text value="{}"/>
                        <text value="#1"/>
                      </braces>
                    </braces>
                    <braces/>
                    <braces/>
                  </command>
                </braces>
              </braces>
            </command>
          </braces>
        </braces>
      </command>
      <text value="karasikov"/>
      <text value="КЛАССИФИКАЦИЯ ВРЕМЕННЫХ РЯДОВ В ПРОСТРАНСТВЕ ПАРАМЕТРОВ ПОРОЖДАЮЩИХ МОДЕЛЕЙ$^*$"/>
      <text value="Классификация временных рядов в пространстве параметров порождающих моделей"/>
      <text value="М."/>
      <text value="Е. Карасиков$^1$, В."/>
      <text value="В. Стрижов$^2$"/>
      <text value="М."/>
      <text value="Е. Карасиков, В."/>
      <text value="В. Стрижов"/>
      <command value="\titel">
        <braces>
          <braces>
            <text value="{}"/>
            <command value="\tit">
              <braces/>
              <braces>
                <braces>
                  <text value="{}"/>
                  <command value="\aut">
                    <braces/>
                    <braces>
                      <braces>
                        <text value="{}"/>
                        <command value="\autkol">
                          <braces/>
                          <braces>
                            <braces>
                              <text value="{}"/>
                              <command value="\titkol">
                                <braces/>
                              </command>
                            </braces>
                          </braces>
                        </command>
                      </braces>
                    </braces>
                  </command>
                </braces>
              </braces>
            </command>
          </braces>
        </braces>
      </command>
      <text value="Карасиков М."/>
      <text value="Е."/>
      <text value="Стрижов В."/>
      <text value="В."/>
      <text value="Karasikov M."/>
      <text value="E."/>
      <text value="Strijov V."/>
      <text value="V."/>
      <braces>
        <text value="{}"/>
        <command value="\renewcommand">
          <braces>
            <braces>
              <text value="{}"/>
              <command value="\thefootnote">
                <braces/>
                <braces>
                  <braces>
                    <text value="{}"/>
                    <command value="\fnsymbol">
                      <braces>
                        <braces>
                          <text value="{}"/>
                          <text value="footnote"/>
                        </braces>
                      </braces>
                      <braces/>
                      <braces/>
                    </command>
                  </braces>
                </braces>
              </command>
            </braces>
          </braces>
        </command>
      </braces>
      <command value="\footnotetext">
        <braces>
          <text value="\footnotetext[1]{}"/>
        </braces>
      </command>
      <text value="Работа выполнена при финансовой поддержке РФФИ (проект 16-37-00485)."/>
      <command value="\renewcommand">
        <braces>
          <braces>
            <text value="{}"/>
            <command value="\thefootnote">
              <braces/>
              <braces>
                <braces>
                  <text value="{}"/>
                  <command value="\arabic">
                    <braces>
                      <braces>
                        <text value="{}"/>
                        <text value="footnote"/>
                      </braces>
                    </braces>
                    <braces/>
                    <braces/>
                  </command>
                </braces>
              </braces>
            </command>
          </braces>
        </braces>
      </command>
      <command value="\footnotetext">
        <braces>
          <text value="\footnotetext[1]{}"/>
        </braces>
      </command>
      <text value="Московский физико-технический институт, Сколковский институт науки и технологий,"/>
      <command value="\mbox">
        <braces>
          <braces>
            <text value="{}"/>
            <affiliation>
              <braces>
                <text value="karasikov@phystech.edu"/>
              </braces>
            </affiliation>
          </braces>
        </braces>
        <braces/>
        <braces/>
      </command>
      <command value="\footnotetext">
        <braces>
          <text value="\footnotetext[2]{}"/>
        </braces>
      </command>
      <text value="Вычислительный центр им."/>
      <text value="А."/>
      <text value="А. Дородницына Федерального исследовательского центра &amp;lt;&amp;lt;Информатика и управление&amp;gt;&amp;gt; Российской академии наук,"/>
      <command value="\mbox">
        <braces>
          <braces>
            <text value="{}"/>
            <affiliation>
              <braces>
                <text value="strijov@ccas.ru"/>
              </braces>
            </affiliation>
          </braces>
        </braces>
        <braces/>
        <braces/>
      </command>
      <formula id="id1" value="$х рядов,&#10;    при этом временной ряд рассматривается как последовательность сегментов, &#10;    аппроксимируемых некоторой параметрической моделью, параметры которой используются &#10;    в~качестве их признаковых описаний.&#10;    Построенное признаковое описание сегмента временного ряда наследует от &#10;    модели аппроксимации такое полезное свойство, как инвариантность относительно &#10;    сдвига.&#10;    Для решения задачи классификации в~качестве признаковых описаний временн$"/>
      <command value="\acute">
        <braces>
          <braces>
            <text value="{}"/>
            <command value="\mbox">
              <braces>
                <braces>
                  <text value="{}"/>
                  <text value="ы"/>
                </braces>
              </braces>
              <braces/>
              <braces/>
            </command>
            <formula id="id2" value="$х рядов &#10;    предлагается использовать распределения параметров аппроксимирующих сегменты &#10;    моделей, что обобщает базовые методы, использующие непосредственно сами параметры &#10;    аппроксимирующих моделей.&#10;    Проведен ряд вычислительных экспериментов на реальных данных, показавших &#10;    высокое качество решения задачи многоклассовой классификации.&#10;    Эксперименты показали превосходство предлагаемого метода над базовым &#10;    и~многими распространенными методами классификации временных рядов на всех &#10;    рассмотренных наборах данных.}&#10;&#10;\KW{временные ряды; многоклассовая классификация; сегментация временных рядов; &#10;гиперпараметры аппроксимирующей модели; модель авторегрессии; дискретное &#10;преобразование Фурье}&#10;&#10;\DOI{10.14357/19922264160413} &#10;&#10;&#10;\vskip 10pt plus 9pt minus 6pt&#10;&#10;\thispagestyle{headings}&#10;&#10;\begin{multicols}{2}&#10;&#10;\label{st\stat}&#10;&#10;\section{Введение}&#10;%\label{sec:introduction}&#10;&#10;Временн$\acute{\mbox{ы}}$м рядом~$x$ будем называть конечную упорядоченную &#10;последовательность чисел&#10;$$&#10;x = \left[x^{(1)}, \dots, x^{(t)}\right]\,.&#10;$$&#10;Временн$\acute{\mbox{ы}}$е ряды являются объектом исследования &#10;в~таких задачах анализа данных, как прогнозирование,&#10;  обнаружение аномалий, сегментация~\cite{geurts2005segment},&#10;  клас\-те\-ри\-за\-ция и~классификация~\cite{geurts2005segment}.&#10;Обзор по задачам и~методам анализа временн$\acute{\mbox{ы}}$х рядов дается &#10;в~\cite{Esling:2012:TDM:2379776.2379788}.&#10;Последние годы связаны с~ростом интереса к~данной области, проявляющемся &#10;в~непрекращающемся предложении новых методов анализа временных рядов~--- метрик, &#10;алгоритмов сегментации, кластеризации и~др.&#10;&#10;В данной работе рассматривается задача классификации временн$\acute{\mbox{ы}}$х рядов, &#10;возникающая во многих приложениях&#10;  (медицинская диагностика по электрокардиограммам~\cite{basil2014automatic} &#10;  и~электроэнцефалограммам~\cite{alomari2013automated},&#10;  классификация типов физической активности по данным &#10;  акселерометра~\cite{Kwapisz:2011:ARU:1964897.1964918},&#10;  верификация динамических подписей~\cite{gruber2006signature}~и~т.\,д.).&#10;&#10;Формально задача классификации в~общем виде ставится следующим образом.&#10;Пусть~$X$~--- множество описаний объектов произвольной природы,&#10;$Y$~--- конечное множество меток классов.&#10;Предполагается существование целевой функции~--- отоб\-ра\-же\-ния~$y:\;X&#10;\hm\toY$,&#10;значения которого известны только на~объектах обучающей выборки&#10;$$&#10;    \mathfrak{D} = \left\{(x_1,y_1),\dots,(x_m,y_m)\right\} \subset X\times Y\,.&#10;$$&#10;Требуется построить классификатор~$a:\;X\toY$~--- отображение,&#10;приближающее целевую функцию~$y$ на~множестве~$X$.&#10;При $|Y|\hm&amp;gt;2$ задачу классификации будем называть многоклассовой.&#10;Задачей классификации временн$\acute{\mbox{ы}}$х рядов будем называть задачу классификации, &#10;в~которой объектами классификации являются временн$\acute{\mbox{ы}}$е ряды.&#10;&#10;Задание метрики, или функции расстояния~\cite{Ding:2008:QMT:1454159.1454226}, &#10;на парах временн$\acute{\mbox{ы}}$х рядов позволяет применять метрические методы классификации.&#10;При удачном выборе метрики классификация может производиться простейшими метрическими &#10;алгоритмами классификации, например методом ближайшего соседа~\cite{jeong2011weighted}.&#10;Данный подход к~решению задачи классификации временн$\acute{\mbox{ы}}$х рядов чрезвычайно распространен &#10;в~силу того, что позволяет свести исходную задачу классификации временн$\acute{\mbox{ы}}$х рядов &#10;к~задаче выбора метрики.&#10;&#10;Второй подход к~решению задачи классификации состоит в~построении для &#10;каждого временн$\acute{\mbox{о}}$го ряда его информативного признакового &#10;описания~$\mathbf{f}:\;X\hm\to\mathbb{R}^n$, позволяющего строить точные &#10;классификаторы с~хорошей обобщающей способностью.&#10;Построение информативного пространства признаков исходных объектов&#10; множества~$X$,\linebreak&#10;  позволяющего добиться заданной точности классификации и~значительно &#10; упрощающего по\-сле\-ду\-ющий анализ, является важнейшим этапом решения задачи классификации.&#10;Признаки могут задавать\-ся экспертом.&#10;Так, в~работе~\cite{Nanopoulos01feature-basedclassification} предлагается использовать &#10;в~качестве признаков статистические функции (среднее, отклонения от среднего, &#10;коэффициенты эксцесса и~др.).&#10;Стоит заметить, что при таком подходе к~построению пространства признаков &#10;час\-то удается добиться необходимого качества классификации путем выбора &#10;соответствующих конкретной задаче признаков (см., например,~\cite{wiens2012patient}), &#10;а~сам выбор признаков становится важной технической задачей.&#10;Другой метод построения пространства признаков заключается в~задании &#10;параметрической регрессионной или аппроксимирующей модели временн$\acute{\mbox{о}}$го ряда.&#10;Тогда в~качестве признаков временн$\acute{\mbox{ы}}$х рядов будут выступать параметры &#10;настроенной модели.&#10;В~работе~\cite{morchen2003time} в~качестве признаков предлагается &#10;использовать коэффициенты дискретного преобразования Фурье (DFT) &#10;и~дискретного вейв\-лет-пре\-обра\-зо\-ва\-ния (DWT), &#10;а~в~\cite{kini2013large, kuznetsov2015description}~--- модели авторегрессии.&#10;%В~\cite{kalliovirta2015gaussian} исследуются свойства смеси моделей авторегрессии.&#10;Таким образом, при данном методе построения признаковых описаний &#10;возникает задача выбора аппроксимирующей модели временн$\acute{\mbox{о}}$го ряда.&#10;%Об исчерпывающих исследованиях этой задачи авторам неизвестно.&#10;&#10;В работе исследуются методы классификации временн$\acute{\mbox{ы}}$х рядов, использующие &#10;в~качестве их признаковых описаний параметры аппроксимирующих моделей.&#10;Приводится сравнение моделей аппроксимации.&#10;Из временн$\acute{\mbox{о}}$го ряда могут извлекаться сегменты~--- его &#10;подпоследовательности, для которых признаковые описания строятся так же, как и~для &#10;исходных временн$\acute{\mbox{ы}}$х рядов.&#10;Использование подпоследовательностей позволяет обобщить алгоритмы классификации.&#10; Так, в~работе~\cite{geurts2005segment} предлагается алгоритм классификации &#10; временн$\acute{\mbox{ы}}$х\linebreak&#10;  рядов методом голосования их случайных сегментов &#10; (непрерывных подпоследовательностей со\linebreak случайным начальным элементом).&#10;В~данной\linebreak&#10; работе предлагается алгоритм классификации вре\-мен\-н$\acute{\mbox{ы}}$х рядов в~пространстве &#10;параметров распределений признаков их сегментов, который сравнивается с~родственным &#10;ему алгоритмом голосования сегментов~\cite{geurts2005segment}.&#10;В~разд.~7 приводятся результаты экспериментов на реальных данных, показывающие &#10;высокое качество и~общность предлагаемого алгоритма в~сочетании с~методом &#10;признаковых описаний временн$\acute{\mbox{ы}}$х рядов параметрами аппроксимирующих их моделей.&#10;&#10;&#10;\section{Постановка задачи}&#10;%\label{sec:problem_statement}&#10;&#10;Поставим задачу многоклассовой классификации временн$\acute{\mbox{ы}}$х рядов в~общем виде.&#10;Пусть $(X,\rho)$~--- метрическое пространство временн$\acute{\mbox{ы}}$х рядов, &#10;$Y$~--- множество меток классов, $\mathfrak{D}\subset X\times Y$~--- &#10;конечная обучающая выборка.&#10;&#10;Пусть~$S$~--- процедура сегментации:&#10;  \begin{equation}&#10;  \label{eq:segmentation}&#10;  S(x)\subset 2^{\mathbf{S}(x)}\,,&#10;  \end{equation}&#10;  где $\mathbf{S}(x)$~--- множество всех сегментов временн$\acute{\mbox{о}}$го ряда~$x\hm\in X$;&#10;  $\mathbf{f}(S(x))\hm\in\mathbb{R}^n$~--- процедура по\-стро\-ения &#10;  признакового описания набора сегментов;&#10;  $b$~--- алгоритм многоклассовой классификации:&#10;  \begin{equation}&#10;  \label{eq:classification}&#10;  b:\;\mathbb{R}^n\toY\,.&#10;  \end{equation}&#10;&#10;Рассмотрим семейство~$A=\left\{a:\;X\hm\toY\right\}$ алгоритмов классификации вида&#10;\begin{equation}&#10;\label{eq:classifiers}&#10;a=b\circ\mathbf{f}\circS\,.&#10;\end{equation}&#10;&#10;Пусть задана функция потерь&#10;$&#10;\mathscr{L}:\;X\times Y\times Y\hm\to\mathbb{R}&#10;$&#10;и функционал качества&#10;\begin{equation}&#10;\label{eq:empirical_risk}&#10;Q(a,\mathfrak{D})=&#10;\fr{1}{|\mathfrak{D}|}&#10;\sum\limits_{(x,y)\in\mathfrak{D}}\mathscr{L}\left(x, a(x),y\right)\,.&#10;\end{equation}&#10;&#10;В качестве методов обучения~$\mu(\mathfrak{D})\in A$ будем использовать следующие:&#10;$$&#10;\mu_{\mathbf{f},S}(\mathfrak{D})=\hat{b}\circ\mathbf{f}\circS\,,&#10;$$&#10;где~$\hat{b}$~--- минимизатор эмпирического риска:&#10;$$&#10;\hat{b}=\argmin_{b}Q(b\circ\mathbf{f}\circS,\mathfrak{D})\,.&#10;$$&#10;&#10;Оптимальный метод обучения определяется по скользящему контролю:&#10;$$&#10;\mu^* = \argmin_{\mathbf{f},\,S}\widehat{\mathrm{CV}}(\mu_{\mathbf{f},S},\mathfrak{D})\,,&#10;$$&#10;где $\widehat{\mathrm{CV}}(\mu,\mathfrak{D})$~--- внешний критерий качества метода &#10;обучения~$\mu$;&#10;при этом исходная обучающая выборка~$\mathfrak{D}$ случайно разбивается~$r$~раз &#10;на обучающую и~контрольную~($\mathfrak{D}\hm=\mathfrak{L}_1\sqcup\mathfrak{T}_1=&#10;\dots=\mathfrak{L}_r\sqcup\mathfrak{T}_r$),&#10;\begin{equation}&#10;\label{eq:cross_validation}&#10;\widehat{\mathrm{CV}}(\mu,\mathfrak{D})=&#10;\fr{1}{r}\sum\limits_{v=1}^{r}Q(\mu(\mathfrak{L}_v),\mathfrak{T}_v)\,,&#10;\end{equation}&#10;где&#10;\begin{equation}&#10;\label{eq:total_quality}&#10;Q(a,\mathfrak{T})=\fr{1}{|\mathfrak{T}|}&#10;\sum\limits_{(x,y)\in\mathfrak{T}}\vec1\{a(x)=y\}\,.&#10;\end{equation}&#10;Средняя точность (precision) классификации объектов класса~$c\hm\in Y$ оценивается функционалом скользящего контроля~\eqref{eq:cross_validation} с~модифицированным функционалом качества~$Q$:&#10;\begin{equation}&#10;\label{eq:class_quality}&#10;Q_c(a,\mathfrak{T})=&#10;\fr{\left|\left\{(x,y)\in\mathfrak{T}\,|\,a(x)=y=&#10;c\right\}\right|}{\left|\left\{(x,y)\in\mathfrak{T}\,|\,y=c\right\}\right|}\,.&#10;\end{equation}&#10;&#10;\section{Сегментация временных рядов}&#10;%\label{sec:segmenting}&#10;&#10;\noindent&#10;\textbf{Определение 1.}\&#10;Сегментом временн$\acute{\mbox{о}}$го ряда~$x\hm=[x^{(1)},\dots,x^{(t)}]$ будем &#10;называть любую его непрерывную подпоследовательность~$s\hm=[x^{(i)}]_{i=t_0}^{t_1}$, &#10;$1\hm\leqslant t_0\hm\leqslant t_1\hm\leqslant t.$&#10;&#10;\smallskip&#10;&#10;\noindent&#10;\textbf{Определение 2.}\&#10;Под сегментацией будем понимать отображение временн$\acute{\mbox{ы}}$х рядов &#10;во множество их сегментов~\eqref{eq:segmentation}.&#10;&#10;&#10;\smallskip&#10;&#10;\subsection*{Примеры}&#10;&#10;\begin{enumerate}[1.]&#10;\item&#10;  Тривиальная сегментация&#10;  \begin{equation}&#10;  \label{eq:equal_fragmenting}&#10;  S(x)=\{x\},\ \forall x\in X\,.&#10;  \end{equation}&#10;&#10;\item&#10;  Случайное выделение сегментов некоторой длины~$\ell$~\cite{geurts2005segment}.&#10;&#10;\item&#10;  Важным является случай квазипериодичности временн$\acute{\mbox{о}}$го &#10;  ряда, когда сам ряд состоит из похожих в~определенном смысле сегментов, &#10;  называемых периодами:&#10;  \begin{multline*}&#10;%  \label{eq:periodic}&#10;  x=\left[\underbrace{x^{(1)},\dots,x^{(t_1)}}_{s^{(1)}},\underbrace{x^{(t_1+1)},&#10;\dots,x^{(t_2)}}_{s^{(2)}},\dots\right.\\&#10;\left.\dots,\underbrace{x^{(t_{p-1}+1)},\dots,x^{(t)}}_{s^{(p)}}&#10;  \right]\,.&#10;  \end{multline*}&#10;  Тогда в~качестве процедуры сегментации можно взять разбиение на периоды:&#10;  \begin{equation*}&#10;  %\label{eq:period_segmentation}&#10;  S(x)= \left\{s^{(1)},\dots,s^{(p)}\right\}\,.&#10;  \end{equation*}&#10;\end{enumerate}&#10;&#10;&#10;\section{Аппроксимирующая модель сегмента временного ряда}&#10;%\label{sec:regression_model}&#10;&#10;Поскольку сегмент временн$\acute{\mbox{о}}$го ряда сам является временн$\acute{\mbox{ы}}$м &#10;рядом, в~этом разделе слово сегмент будем опускать.&#10;&#10;\smallskip&#10;&#10;\noindent&#10;\textbf{Определение 3.}\&#10;Параметрической аппроксими\-ру\-ющей моделью временн$\acute{\mbox{о}}$го ряда~$x$ будем называть отображение&#10;\begin{equation}&#10;\label{eq:regression}&#10;g:\;\mathbb{R}^n\times X\toX\,.&#10;\end{equation}&#10;&#10;\smallskip&#10;&#10;В слово &amp;lt;&amp;lt;аппроксимирующая&amp;gt;&amp;gt; вкладывается тот смысл, что модель должна приближать &#10;временн$\acute{\mbox{о}}$й ряд в~пространстве $(X,\rho)$, т.\,е.\ &#10;для некоторого $\mathbf{w}\hm\in \mathbb{R}^n$&#10;$$&#10;g(\mathbf{w},x)=\hat{x}\,,&#10;$$&#10;где&#10;$$&#10;\rho(\hat{x},x)&amp;lt;\varepsilon\,.&#10;$$&#10;При этом естественно взять в~качестве признакового описания временн$\acute{\mbox{о}}$го ряда~$x$&#10; вектор оптимальных параметров его модели.&#10;&#10;\smallskip&#10;%\label{def:feature_description}&#10;&#10;\noindent&#10;\textbf{Определение 4.}\&#10;Признаковым описанием вре\-мен\-н$\acute{\mbox{о}}$го ряда~$x$, порожденным &#10;параметрической моделью~$g(\mathbf{w},x)$, назовем вектор оптимальных &#10;па\-ра\-мет\-ров этой модели:&#10;\begin{equation}&#10;\label{eq:feature_solution}&#10;\mathbf{w}_g(x)=&#10;\argmin_{\mathbf{w}\in \mathbb{R}^n} \rho\left(g(\mathbf{w},x),x\right)\,.&#10;\end{equation}&#10;&#10;&#10;В качестве аппроксимирующих моделей предлагается использовать следующие.&#10;\begin{enumerate}[1.]&#10;\item \textbf{Модель линейной регрессии}.&#10;Пусть задан $r$-ком\-по\-нент\-ный временной &#10;ряд (например, время и~три пространственные координаты):&#10;$$&#10;x = [\vec{x}^{(1)}, \dots, \vec{x}^{(t)}]\,,&#10;$$&#10;где&#10;$$&#10;\vec{x}^{(k)}=[x_1^{(k)},\dots,x_r^{(k)}]^{\mathrm{T}},\enskip k=1,\dots,t\,.&#10;$$&#10;Рассмотрим модель линейной регрессии одной из компонент &#10;временн$\acute{\mbox{о}}$го ряда на остальные компоненты как аппроксимирующую модель:&#10;$$&#10;g(\mathbf{w},x)=\left[\hat{\vec{x}}^{(1)},\dots,\hat{\vec{x}}^{(t)}\right]\,,&#10;$$&#10; где &#10; $$&#10;\hat{\vec{x}}^{(k)}=\left[x_1^{(k)},\dots,x_{r-1}^{(k)},\hat{x}_r^{(k)}\right]^{\mathrm{T}},\enskip &#10;k\hm=1,\dots,t\,,&#10;$$&#10;$$&#10;\underbrace{&#10;\begin{bmatrix}&#10;\hat{x}_r^{(1)} \\&#10;\vdots  \\&#10;\hat{x}_r^{(t)}&#10;\end{bmatrix}&#10;}_{\hat{\mathbf{x}}_r}&#10;=&#10;\underbrace{&#10;\begin{bmatrix}&#10;x_1^{(1)} &amp;amp; \cdots &amp;amp; x_{r-1}^{(1)} \\&#10;\vdots    &amp;amp; \ddots &amp;amp; \vdots       \\&#10;x_1^{(t)} &amp;amp; \cdots &amp;amp; x_{r-1}^{(t)}&#10;\end{bmatrix}&#10;}_{\mathbf{X}}&#10;\underbrace{&#10;\begin{bmatrix}&#10;w_1 \\&#10;\vdots  \\&#10;w_{r-1}&#10;\end{bmatrix}&#10;}_{\mathbf{w}}.&#10;$$&#10;Тогда, выбрав в~качестве~$\rho$ евклидово расстояние, по &#10;определению~4 получим признаковое описание объекта~$x$:&#10;&#10;\noindent&#10;\begin{multline}&#10;\label{eq:linear_regression}&#10;\hspace*{-1mm}\mathbf{w}_g(x)=&#10;\argmin\limits_{\mathbf{w}\in \mathbb{R}^n} \|\mathbf{x}_r-\hat{\mathbf{x}}_r\|^2_2={}\\&#10;\hspace*{-1mm}{}=&#10;\argmin\limits_{\mathbf{w}\in \mathbb{R}^n} \|\mathbf{x}_r-\mathbf{X}\mathbf{w}\|^2_2=&#10;\left(\mathbf{X}^{\mathsf{T}}\mathbf{X}\right)^{-1}\mathbf{X}^{\mathsf{T}}\mathbf{x}_r\,.&#10;\end{multline}&#10;&#10;\item \textbf{Модель авторегрессии {\boldmath{$\mathbf{AR}(p)$}}}.&#10;&#10;Задан временной ряд&#10;$$&#10;x = [x^{(1)},\dots,x^{(t)}],\ x^{(k)}\in\mathbb{R}\,,\enskip k=1,\dots,t\,.&#10;$$&#10;Выберем в~качестве модели аппроксимации авторегрессионную модель порядка~$p$:&#10;\begin{equation*}&#10;g(\mathbf{w},x)=\left[\hat{x}^{(1)},\dots,\hat{x}^{(t)}\right]\,,&#10;\label{eq:autoregressive_model}&#10;\end{equation*}&#10;где&#10;\begin{equation*}&#10;\hat{x}^{(k)}=&#10;\begin{cases}&#10;x^{(k)}\,, &amp;amp; k=1,\dots,p\,;\\&#10;w_0 + \sum\limits_{i=1}^{p} w_i x^{(k-i)}\,, &amp;amp; k=p+1,\dots,t\,.&#10;\end{cases}&#10;\end{equation*}&#10;Далее признаковое описание определяется аналогично случаю линейной &#10;регрессии~\eqref{eq:linear_regression}.&#10;&#10;\item \textbf{Дискретное преобразование Фурье}.&#10;Задан временной ряд&#10;$$&#10;x = \left[x^{(0)},\dots,x^{(t-1)}\right],\ x^{(k)}\in\mathbb{C},\ k=0,\dots,t-1.&#10;$$&#10;Взяв в~качестве аппроксимирующей модели обратное преобразование Фурье&#10;$$&#10;g(\mathbf{w},x)=\left[\hat{x}^{(0)},\dots,\hat{x}^{(t-1)}\right]\,,&#10;$$&#10;где&#10;\begin{multline}&#10;\label{eq:fourier_approximation}&#10;\hat{x}^{(k)}=\fr{1}{t}\sum\limits_{j=0}^{t-1} &#10;\left(w_{2j}+iw_{2j+1}\right) e^{({2\pii}/t)kj}\,,\\ k=0,\dots,t-1\,,&#10;\end{multline}&#10;получим, что признаковым описанием вре\-мен\-н$\acute{\mbox{о}}$го ряда~$x$ является прямое преобразование:&#10;\begin{equation}&#10;\label{eq:fourier}&#10;\mathbf{w}_g(x)=\left[w_0,\dots,w_{2t-1}\right]\,,&#10;\end{equation}&#10;где &#10;\begin{multline*}&#10;w_{2k}+iw_{2k+1}=\sum\limits_{j=0}^{t-1} x^{(j)} &#10;e^{-({2\pii}/{t})kj}\,,\\ k=0,\dots,t-1\,.&#10;\end{multline*}&#10;Переписывая~\eqref{eq:fourier_approximation} в~матричном виде, &#10;заметим, что, как и~в предыдущих случаях, параметры модели~$\mathbf{w}$ &#10;эквивалентно находятся при помощи линейной регрессии временн$\acute{\mbox{о}}$го &#10;ряда на столбцы матрицы Фурье.&#10;Выбор лишь некоторых комплексных амплитуд соответствует регрессии временн$\acute{\mbox{о}}$го &#10;ряда на соответствующие столбцы матрицы Фурье.&#10;Случай дискретного вейв\-лет-пре\-об\-ра\-зо\-ва\-ния аналогичен.&#10;\end{enumerate}&#10;&#10;Заметим, что в~первых двух случаях используются билинейные аппроксимирующие &#10;моде-\linebreak\vspace*{-12pt}&#10;&#10;\columnbreak&#10;&#10;\noindent&#10;ли~$g(\mathbf{w},x)$, а~в~третьем~--- линейная.&#10;Приведенные примеры демонстрируют большую общность построения пространства &#10;признаков при помощи моделей типа~\eqref{eq:regression} и~решения оптимизационной\linebreak &#10;задачи~\eqref{eq:feature_solution}.&#10;Вообще говоря, при $|X|\hm\geqslant 2$ любая процедура построения признаковых &#10;описаний~$\mathbf{f}:\;X\hm\to\mathbb{R}^n$ задается эквивалентно решением &#10;оптимизационной задачи~\eqref{eq:feature_solution} при выборе соответствующей &#10;пары~$(g,\rho)$.&#10;&#10;\section{Распределения признаков сегментов}&#10;%\label{sec:distribution}&#10;&#10;Объединим идеи, изложенные в~предыдущих разделах.&#10;Согласно аппроксимирующей модели~\eqref{eq:regression}\linebreak получим для &#10;каж\-до\-го сегмента~$s^{(k)}\hm\in S(x)\hm=\left\{s^{(1)},\ldots,s^{(p)}\right\}$ &#10;временн$\acute{\mbox{о}}$го ряда~$x$ его признаковое &#10;описание~$\mathbf{w}^{(k)}:=\mathbf{w}_g(s^{(k)})$, решив оптимизационную &#10;задачу~\eqref{eq:feature_solution}.&#10;Тогда всему набору \mbox{сегментов}~$S(x)$ будет соответствовать выборка:&#10;\begin{equation}&#10;\label{eq:segments_features}&#10;\vec{F}=\left(\mathbf{w}^{(1)},\dots,\mathbf{w}^{(p)}\right)\,.&#10;\end{equation}&#10;Примем гипотезу простоты выборки~\eqref{eq:segments_features}.&#10;&#10;\smallskip&#10;&#10;\noindent&#10;\textbf{Гипотеза~1.}\&#10;\textit{Выборка~$"/>
            <command value="\vec">
              <braces>
                <braces>
                  <text value="{}"/>
                  <text value="F"/>
                </braces>
              </braces>
              <braces/>
            </command>
            <command value="\hm">
              <braces>
                <text value="="/>
              </braces>
            </command>
            <command value="\left">
              <braces>
                <text value="("/>
              </braces>
            </command>
            <command value="\vec">
              <braces>
                <braces>
                  <text value="{}"/>
                  <text value="f"/>
                </braces>
              </braces>
              <braces/>
              <braces>
                <text value="^"/>
              </braces>
              <braces>
                <braces>
                  <text value="{}"/>
                  <text value="(1)"/>
                </braces>
              </braces>
              <braces/>
              <braces>
                <text value=","/>
              </braces>
            </command>
            <command value="\dots">
              <braces>
                <text value=","/>
              </braces>
            </command>
            <command value="\vec">
              <braces>
                <braces>
                  <text value="{}"/>
                  <text value="f"/>
                </braces>
              </braces>
              <braces/>
              <braces>
                <text value="^"/>
              </braces>
              <braces>
                <braces>
                  <text value="{}"/>
                  <text value="(p)"/>
                </braces>
              </braces>
              <braces/>
            </command>
            <command value="\right">
              <braces>
                <text value=")"/>
              </braces>
            </command>
            <formula id="id3" value="$~--- &#10;прос\-тая, т.\,е.\ случайная, независимая и~однородная, где}&#10; $\mathbf{w}^{(k)}\sim\mathsf{P}_0$.&#10;&#10;&#10;\smallskip&#10;&#10;Пусть имеется параметрическое семейство &#10;распределений~$\left\{\mathsf{P}_{\vec\theta}\right\}_{\vec\theta\in &#10;\Theta}$.&#10;Будем рассматривать вероятностную модель, в~которой объект~$x$ &#10;зависит от случайного параметра~$\vec\theta$.&#10;\smallskip&#10;&#10;\noindent&#10;\textbf{Гипотеза~2.}\&#10;$p(x|\vec\theta,y)=p(x|\vec\theta)$.&#10;&#10;\smallskip&#10;Тогда&#10;\begin{multline*}&#10;p(x,y)=&#10;p(\vec{F},y)={}\\&#10;{}=&#10;\int\limits_{\Theta}p(\vec{F},\vec\theta,y)\,d\vec\theta=&#10;\int\limits_{\Theta}p(\vec{F}|\vec\theta)p(\vec\theta,y)\,d\vec\theta\,.&#10;\end{multline*}&#10;При этом распределение~$p(\vec\theta,y)$ предлагается оценивать на этапе &#10;обучения, где признаковыми описаниями объектов~$x_i$ задачи классификации являются &#10;оценки параметров~$\vec\theta_i$:&#10;$$&#10;\hat{\vec\theta}_i=T(x_i)=T(\vec{F}_i)\,.&#10;$$&#10;Получив оценку~$\hat{p}(\vec\theta,y)$, находим оценку плот\-ности~$\hat{p}(x,y)$:&#10;$$&#10;\hat{p}(x,y)=&#10;\int\limits_{\Theta}p(\vec{F}|\vec\theta)\hat{p}(\vec\theta,y)\,d\vec\theta\,,&#10;$$&#10;по которой строится байесовский классификатор.&#10;&#10;\pagebreak&#10;&#10;В алгоритмической постановке задачи классификации получим~$\hat{p}(y|\vec\theta)&#10;\hm=\delta(a(\vec\theta),y)$ и&#10;$$&#10;\hat{p}(\vec\theta,y)=\delta(a(\vec\theta),y)p(\vec\theta)\,.&#10;$$&#10;Тогда&#10;\begin{multline*}&#10;\hat{p}(x,y)=&#10;\int\limits_{\Theta}\!p\left(\vec{F}|\vec\theta\right)\hat{p}&#10;(\vec\theta,y)d\vec\theta={}\\&#10;{}=&#10;\int\limits_{\Theta}\!p\left(\vec{F}|\vec\theta\right)\delta\left(a\left(\vec\theta\right),y\right)&#10;p\left(\vec\theta\right)\,d\vec\theta={}\\&#10;{}=\int\limits_{a^{-1}(y)}\!p\left(\vec{F}|\vec\theta\right)p\left(\vec\theta\right)\,d\vec\theta=&#10;\int\limits_{a^{-1}(y)}\!p\left(\vec\theta|\vec{F}\right)p\left(\vec{F}\right)\,d\vec\theta\,.&#10;\end{multline*}&#10;Приближая распределение~$p(\vec\theta|\vec{F})$ вырожденным &#10;$\delta(\vec\theta-T(\vec{F}))$, получим&#10;\begin{multline*}&#10;\hat{p}(y|x)=&#10;\!\int\limits_{a^{-1}(y)}\!\!\! \!p\left(\vec\theta|\vec{F}\right)\,d\vec\theta=&#10;\!\int\limits_{a^{-1}(y)}\!\!\!\!\delta\left(\vec\theta-T\left(\vec{F}\right)\right)\,&#10;d\vec\theta={}\\&#10;{}=&#10;\delta\left(a(T(\vec{F})),y\right).&#10;\end{multline*}&#10;Таким образом, задача классификации временн$\acute{\mbox{ы}}$х рядов свелась к~задаче &#10;классификации оценок параметров распределений &#10;семейства~$\left\{\mathsf{P}_{\vec\theta}\right\}_{\vec\theta\in \Theta}$.&#10;&#10;В качестве оценок параметров~$\vec\theta$ предлагается брать оценки максимального &#10;правдоподобия:&#10;\begin{multline*}&#10;\hat{\vec\theta}=&#10;T(x)=&#10;\argmax_{\vec\theta\in\Theta}\mathcal{L}\left(\vec\theta\,|\,x\right)=&#10;\argmax_{\vec\theta\in\Theta}p(\vec{F}|\vec\theta)={}\\&#10;{}=&#10;\argmax_{\vec\theta\in\Theta}\prod_{k}p(\mathbf{w}^{(k)}|\vec\theta).&#10;\end{multline*}&#10;&#10;Заметим, что в~частном случае тривиальной сегментации~\eqref{eq:equal_fragmenting} и~семейства вырожденных распределений оценка~$\hat{\vec\theta}$ является исходным признаковым описанием.&#10;Таким образом, предложенный подход к~построению признакового описания временн$\acute{\mbox{о}}$го ряда&#10;\begin{equation*}&#10;%\label{eq:parameter_estimation}&#10;\mathbf{f}:\;x\mapsto\hat{\vec\theta}&#10;\end{equation*}&#10;является достаточно общим и~при этом хорошо интерпретируется.&#10;&#10;&#10;\section{Алгоритм классификации}&#10;%\label{sec:classification}&#10;&#10;Для завершения построения классификатора временн$\acute{\mbox{ы}}$х &#10;рядов~\eqref{eq:classifiers} построим многоклассовый &#10;классификатор~$b$~\eqref{eq:classification} по обучающей &#10;выборке~$\left\{(\mathbf{f}(x),y)\,|\,(x,y)\hm\in\mathfrak{D}\right\}$.&#10;&#10;Сведем задачу многоклассовой классификации к~задачам бинарной классификации &#10;при помощи стратегий One-vs-All и~One-vs-One.&#10;&#10;В~данной работе для решения задач бинарной классификации, где~$Y=\{-1,+1\}$, &#10;берутся различные модификации SVM (support vector machine).&#10;&#10;\vspace*{-6pt}&#10;&#10;&#10;\section{Вычислительный эксперимент}&#10;%\label{sec:computational_experiment}&#10;&#10;\vspace*{-2pt}&#10;&#10;Вычислительный эксперимент проводился на данных для задачи классификации &#10;типов физической активности человека.&#10;&#10;\vspace*{-6pt}&#10;&#10;\subsection{Датасет WISDM}&#10;&#10;\vspace*{-2pt}&#10;&#10;Датасет (набор данных) WISDM~\cite{Kwapisz:2011:ARU:1964897.1964918} содержит &#10;показания акселерометра для~6~видов человеческой активности.&#10;Необработанные данные, пред\-став\-ля\-ющие собой последовательность размеченных &#10;показаний акселерометра (по тройке чисел на каждый отсчет времени с~интервалом &#10;в~50~мс), были разбиты на временн$\acute{\mbox{ы}}$е ряды длиной &#10;по~200~отсчетов~(10~с).&#10;Распределение полученных временн$\acute{\mbox{ы}}$х рядов по классам приведено &#10;в~табл.~1.&#10;&#10;\vspace*{12pt}&#10;&#10;\noindent&#10; %tabl1&#10;%\vspace*{3pt}&#10;{{\tablename~1}\ \ \small{Распределение временн$\acute{\mbox{ы}}$х рядов по классам. Набор данных&#10;  WISDM}}&#10;&#10;{\small&#10;\begin{center}&#10;   \tabcolsep=14pt&#10;  \begin{tabular}{|l|c|}&#10;    \hline&#10;    \multicolumn{1}{|c|}{Классы} &amp;amp; Число объектов\\&#10;    \hline&#10;    1.\ Jogging (бежит) &amp;amp;  1624\hphantom{9}\\&#10;    2.\ Walking (идет) &amp;amp;  2087\hphantom{9}\\&#10;    3.\ Upstairs (поднимается)&amp;amp; 549\\&#10;    4.\ Downstairs (спускается)&amp;amp; 438\\&#10;    5.\ Sitting (сидит) &amp;amp; 276\\&#10;    6.\ Standing (стоит)&amp;amp; 231\\&#10;     \hline&#10;  \end{tabular}&#10;  \end{center}}&#10;  &#10;  \addtocounter{table}{1}&#10;%\end{table*}&#10;&#10;\subsubsection{Ручное выделение признаков}&#10;&#10;\paragraph*{Выбор признаков.}&#10;%\label{par:manual_feature_selection}&#10;Каждая компонента вре\-мен\-н$\acute{\mbox{о}}$\-го ряда описывалась ее средним, &#10;стандартным отклонением, средним модулем отклонения от среднего, гистограммой &#10;с~10~областями равной \mbox{ширины}.&#10;Полученные признаки для каждой компоненты объединялись, и~к~ним добавлялся признак &#10;средней величины ускорения.&#10;Таким образом, каждый временной ряд описывался~40~признаками.&#10;&#10;&#10;\vspace*{-12pt}&#10;&#10;\paragraph*{Классификатор.}&#10;Задача многоклассовой классификации сводилась к~задаче бинарной &#10;классификации при помощи подхода One-vs-One.&#10;В качестве бинарного классификатора использовался SVM с~RBF (radial basis function)&#10;яд\-ром &#10;и~па\-ра\-мет\-ра\-ми $C\hm=8{,}5$ и~$\gamma\hm=0{,}12$.&#10;&#10;\vspace*{-12pt}&#10;&#10;\paragraph*{Результаты.}&#10;На диаграмме рис.~1 демонстрируется качество классификации при усреднении по &#10;$r\hm=50$  случайным разбиениям исходной выборки на тес\-то\-вую и~контрольную &#10;в~пропорции~7 к~3.&#10;&#10;&#10;&#10;&#10;&#10;Как видно из~табл.~2, классы~2, 3 и~4 недостаточно хорошо отделяются друг от друга.&#10;&#10;\pagebreak&#10;&#10;\end{multicols}&#10;\begin{figure*} %fig1-2&#10; \vspace*{1pt}&#10; \begin{minipage}[t]{80mm}&#10; \begin{center}  &#10; \mbox{%&#10;\epsfxsize=78.057mm&#10;\epsfbox{kar-1.eps}&#10;}&#10;\end{center}&#10;\vspace*{-11pt}&#10;\Caption{Набор данных WISDM.&#10;Средняя точность~0,9726~--- вычисляется по формуле~\eqref{eq:total_quality}.&#10;Средние точности классификации для каждого класса вычисляются по формуле~\eqref{eq:class_quality}}&#10;%\end{figure}&#10;%\begin{figure}&#10;\end{minipage}&#10;\hfill&#10; \vspace*{1pt}&#10;  \begin{minipage}[t]{80mm}&#10; \begin{center}  &#10; \mbox{%&#10;\epsfxsize=78.057mm&#10;\epsfbox{kar-2.eps}&#10;}&#10;\end{center}&#10;\vspace*{-11pt}&#10;\Caption{Точность классификации для параметров модели авторегрессии в~качестве признаковых описаний}&#10;\end{minipage}&#10;\end{figure*}&#10;&#10;\begin{table*}\small %tabl2&#10;\begin{minipage}[t]{80mm}&#10;\begin{center}&#10;\Caption{Усредненная матрица неточностей. Ручное выделение признаков. &#10;Набор данных WISDM\newline&#10;}&#10;\vspace*{2ex}&#10;&#10;\tabcolsep=6.4pt&#10;\begin{tabular}{|c|c|c|c|c|c|c|}&#10;\hline&#10;Класс &amp;amp; \multicolumn{6}{c|}{Предсказанный класс} \\ &#10;  \cline{2-7}&#10;объекта &amp;amp; $1$ &amp;amp; $2$ &amp;amp; $3$ &amp;amp; $4$ &amp;amp; $5$ &amp;amp; $6$\\ &#10;\hline&#10; 1 &amp;amp; \textbf{1,00} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 2 &amp;amp; 0,00 &amp;amp; \textbf{0,99} &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 3 &amp;amp; 0,03 &amp;amp; 0,04 &amp;amp; \textbf{0,89} &amp;amp; $0,04$ &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 4 &amp;amp; 0,02 &amp;amp; 0,05 &amp;amp; 0,05 &amp;amp; \textbf{0,88} &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 5 &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0,98} &amp;amp; 0,00\\ &#10; 6 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{1,00}\\ &#10; \hline&#10;\end{tabular}&#10;\end{center}&#10;%\end{table*}&#10;\end{minipage}&#10;\hfill&#10;%\begin{table}\small %tabl3&#10;\begin{minipage}[t]{80mm}&#10;\begin{center}&#10;\Caption{Усредненная матрица неточностей. Признаки, порожденные моделью &#10;авторегрессии. Набор данных ~WISDM}&#10;\vspace*{2ex}&#10;&#10;&#10;\tabcolsep=6.5pt&#10;\begin{tabular}{|c|c|c|c|c|c|c|}&#10;\hline&#10;Класс &amp;amp; \multicolumn{6}{c|}{Предсказанный класс} \\ &#10;  \cline{2-7}&#10;объекта &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6\\ &#10;  \hline&#10; 1 &amp;amp; \textbf{1,00} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 2 &amp;amp; 0,00 &amp;amp; \textbf{0,99} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 3 &amp;amp; 0,01 &amp;amp; 0,02 &amp;amp; \textbf{0,95} &amp;amp; 0,02 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 4 &amp;amp; 0,00 &amp;amp; 0,02 &amp;amp; 0,04 &amp;amp; \textbf{0,94} &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 5 &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0,97} &amp;amp; 0,01\\ &#10; 6 &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,01 &amp;amp; \textbf{0,97}\\ &#10;\hline&#10;\end{tabular}&#10;\end{center}&#10;\end{minipage}&#10;\end{table*}&#10;&#10;\begin{multicols}{2}&#10;&#10;&#10;\subsubsection{Модель авторегрессии} %~(\ref{eq:autoregressive_model})}&#10;&#10;\paragraph*{Признаковое описание.}&#10;%\label{par:ar_feature_selection}&#10;Во втором эксперименте в~качестве признаковых описаний временн$\acute{\mbox{ы}}$х &#10;рядов использовались все статистические функции, что брались в~первом эксперименте, &#10;за исключением гистограммы, вместо которой использовалось~7~коэффициентов &#10;модели авторегрессии AR($6$)~(см.~\eqref{eq:autoregressive_model}).&#10;Таким образом, каждый временной ряд описывался~31~числом.&#10;Также проводилась предварительная нормализация признаков.&#10;&#10;\vspace*{-6pt}&#10;&#10;\paragraph*{Классификатор.}&#10;Задача многоклассовой классификации сводилась к~задаче &#10;бинарной классификации при помощи подхода One-vs-All.&#10;В~качестве бинарного классификатора использовалась SVM с~RBF-яд\=ром &#10;и~параметрами $C\hm=8$ и~$\gamma\hm=0{,}8$.&#10;&#10;\vspace*{-6pt}&#10;&#10;\paragraph*{Результаты.}&#10;На диаграмме рис.~2 и~в~табл.~3 показано качество классификации при усреднении по&#10;$r\hm=50$ случайным разбиениям исходной выборки на тестовую и~контрольную &#10;в~отношении~7 к~3.&#10;&#10;&#10;&#10;&#10;Несмотря на неравномерное распределение объектов по классам, &#10;использование признакового описания, порожденного моделью авторегрессии, &#10;позволяет значительно повысить качество классификации.&#10;Точность построенного классификатора минимальна для~4-го класса~--- Downstairs~--- &#10;и~со\-став\-ля\-ет~94,3\%.&#10;&#10;\subsection{Датасет USC-HAD}&#10;%\label{seq:usc_had_dataset}&#10;&#10;\begin{figure*}[b] %fig3&#10;\vspace*{6pt}&#10;\begin{center}&#10;\mbox{%&#10;\epsfxsize=128.626mm&#10;\epsfbox{kar-3.eps}&#10;}&#10;\end{center}&#10;\vspace*{-9pt}&#10;\Caption{Точность классификации для параметров модели авторегрессии &#10;в~качестве признаковых описаний}&#10;\label{fig:USCHAD_AR_FOURIER}&#10;\end{figure*}&#10;&#10;&#10;Датасет USC-HAD~\cite{mi12:ubicomp-sagaware} содержит показания акселерометра &#10;для~12~типов физической активности человека:&#10;\begin{enumerate}[1)]&#10;  \item walk forward (идет вперед);&#10;  \item walk left (идет влево);&#10;  \item walk right (идет вправо);&#10;  \item go upstairs (подъем по лестнице);&#10;  \item go downstairs (спуск по лестнице);&#10;  \item run forward (бежит вперед);&#10;  \item jump up and down (делает прыжок);&#10;  \item sit and fidget (сидит);&#10;  \item stand (стоит);&#10;  &#10;  \pagebreak&#10;  &#10;  &#10;  \item sleep (спит);&#10;  \item elevator up (поднимается в~лифте);&#10;  \item elevator down (спускается в~лифте).&#10;\end{enumerate}&#10;&#10;Выборка содержит примерно по~70~шестикомпонентных временн$\acute{\mbox{ы}}$х &#10;рядов для каждого класса, а средняя длина временн$\acute{\mbox{о}}$го ряда~--- 3300. &#10;Частота записи измерений сенсора~100~Гц.&#10;&#10;\vspace*{-6pt}&#10;&#10;&#10;\subsubsection{Модель авторегрессии %~(\ref{eq:autoregressive_model}) &#10;и~Фурье} %~(\ref{eq:fourier})}&#10;&#10;\vspace*{-2pt}&#10;&#10;\paragraph*{Признаковое описание.}&#10;%\label{par:ar_fourier_feature_selection_USCHAD}&#10;Исходные временн$\acute{\mbox{ы}}$е ряды приводились к~частоте~10~Гц &#10;при помощи осреднения.&#10;&#10;В качестве признаковых описаний преобразованных временн$\acute{\mbox{ы}}$х рядов брались &#10;статистические функции, описанные в~п.~7.1.1, &#10;за исключением гистограммы.&#10;Также для каждой компоненты отдельно и~для модуля результирующего &#10;ускорения и~поворота добавлялось по~11~параметров авторегрессионной &#10;модели~$\text{AR}(10)$~(см.~\eqref{eq:autoregressive_model}).&#10;Затем проводилась нормализация признаков и~добавлялись коэффициенты &#10;Фурье~\eqref{eq:fourier} с~индексами~3--12.&#10;Таким образом, каждый~6-ком\-по\-нент\-ный временной ряд описывался~128~признаками.&#10;&#10;\vspace*{-12pt}&#10;&#10;\paragraph*{Классификатор.}&#10;Задача многоклассовой классификации сводилась к~задаче бинарной &#10;классификации при помощи подхода One-vs-One.&#10;В~качестве бинарного классификатора использовалась SVM с~RBF-яд\-ром и~параметрами &#10;$C\hm=10$ и~$\gamma\hm=0{,}13$.&#10;&#10;%\vspace*{-12pt}&#10;&#10;\paragraph*{Результаты.}&#10;На диаграмме рис.~3 показано качество классификации &#10;при усреднении по $r\hm=500$ случайным разбиениям исходной выборки на тес\-то\-вую &#10;и~контрольную в~отношении~7 к~3.&#10;&#10;&#10;&#10;&#10;&#10;&#10;Из~табл.~4 видно, что использование коэффициентов Фурье значительно повысило &#10;качество классификации.&#10;Хуже всего класс~8 (sit and fidget) отделяется от класса~9 (stand).&#10;Точность классификации для него составляет~92,2\%.&#10;&#10;\vspace*{-6pt}&#10;&#10;&#10;\subsubsection{Классификация голосованием и~классификация в~пространстве &#10;распределений параметров}&#10;&#10;\vspace*{-2pt}&#10;&#10;Рассмотрим алгоритм классификации в~сочетании с~процедурой сегментации временн$\acute{\mbox{ы}}$х &#10;рядов.&#10;В качестве процедуры сегментации~$S(x)$ (см.~\eqref{eq:segmentation}) &#10;будем использовать выделение сегментов фиксированной длины.&#10;Решим задачу классификации для первых~10~классов (за исключением &amp;lt;&amp;lt;elevator up&amp;gt;&amp;gt; &#10;и~&amp;lt;&amp;lt;elevator down&amp;gt;&amp;gt;, которые плохо отделяются друг от друга при малой длине сегментов) &#10;двумя алгоритмами.&#10;&#10;В алгоритме голосования классификатор~$b:\;\mathbb{R}^n\hm\toY$ обучается на &#10;новой обучающей выборке для сегментов исходных временн$\acute{\mbox{ы}}$х рядов&#10;&#10;\noindent&#10;$$&#10;\mathfrak{D}_S=\left\{(\mathbf{w}_g(s),y):\;(x,y)\in\mathfrak{D},\,s\in S(x)\right\}.&#10;$$&#10;Далее производится голосование&#10;$\hat{y}\hm=\argmax_{y}\sum\limits_{s\in S(x)}1\left[b(\mathbf{w}_g(s))=y\right].$&#10;&#10;Алгоритм классификации в~пространстве гиперпараметров &#10;(распределений параметров аппрокси-\linebreak\vspace*{-12pt}&#10;&#10;\pagebreak&#10;&#10;\end{multicols}&#10;&#10;\begin{table*}\small %tabl4&#10;\begin{center}&#10;\parbox{396pt}{\Caption{Усредненная матрица неточностей. Признаки, порожденные моделью авторегрессии. &#10;Набор данных USC-HAD}&#10;\label{tbl:USCHAD_AR_FOURIER_confusion}&#10;}&#10;&#10;\vspace*{2ex}&#10;&#10;\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}&#10;  \hline&#10;Класс &amp;amp; \multicolumn{12}{c|}{Предсказанный класс} \\ &#10;\cline{2-13}&#10;объекта &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 &amp;amp; 10 &amp;amp; 11 &amp;amp; 12\\ &#10;\hline&#10; 1&amp;amp; \textbf{0{,}99} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 2&amp;amp; 0,01 &amp;amp; \textbf{0{,}97} &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 3&amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{1{,}00} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 4&amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0{,}99} &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 5&amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,01 &amp;amp; \textbf{0{,}97} &amp;amp; 0,02 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 6&amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{1{,}00} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 7&amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0{,}99} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 8&amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0{,}92} &amp;amp; 0,08 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 9&amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,01 &amp;amp; \textbf{0{,}99} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 10\hphantom{9} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{1{,}00} &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 11\hphantom{9} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00&amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; &#10; \textbf{1{,}00} &amp;amp; 0,00\\ &#10; 12\hphantom{9} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp;0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,02 &amp;amp; 0,00 &amp;amp; 0,01 &amp;amp; \textbf{0{,}97}\\ &#10; \hline&#10;\end{tabular}&#10;\end{center}&#10;\end{table*}&#10;\begin{figure*} %fig4&#10;\vspace*{1pt}&#10;\begin{center}&#10;\mbox{%&#10;\epsfxsize=87.865mm&#10;\epsfbox{kar-4.eps}&#10;}&#10;\end{center}&#10;\vspace*{-9pt}&#10;\Caption{Зависимость средней точности классификации от длины сегментов:&#10;\textit{1}~--- голосование;&#10;\textit{2}~--- гиперпараметры.&#10;Набор данных USC-HAD, первые $10$~классов.&#10;Точность классификации вычисляется по формуле~\eqref{eq:total_quality}}&#10;\label{fig:USCHAD_AR_VOTING_VS_DISTR}&#10;\end{figure*}&#10;&#10;\begin{multicols}{2}&#10;&#10;\noindent&#10;мирующих моделей был описан &#10;в~разд.~5).&#10;В~эксперименте использовалось семейство нормальных распреде\-лений с~диагональной &#10;ковариационной мат\-рицей.&#10;&#10;Задача многоклассовой классификации решалась при помощи подхода One-vs-One &#10;бинарными классификаторами SVM с~RBF-яд\-ром и~параметрами $C\hm=100$&#10;и~$\gamma\hm=0{,}017$.&#10;&#10;На графике рис.~4 приведены результаты для средней &#10;точности решения задачи многоклассовой классификации обоими алгоритмами.&#10;&#10;Из графика можно видеть, что оба алгоритма позволяют повысить качество &#10;классификации, причем алгоритм классификации в~пространстве гиперпараметров &#10;при длине сегмента~50 достигает качества~98,2\% и~показывает результат выше, &#10;чем алгоритм голосования.&#10;&#10;Объединим результаты из последних двух экспериментов.&#10;Будем обучать два классификатора.&#10;Первый классификатор~$a_1$~--- One-vs-One SVM с~RBF-яд\-ром и~параметрами&#10;$C\hm=10$ и~$\gamma\hm=0{,}13$~--- будет разделять классы~11, 12 и~первые &#10;десять классов для исходных временн$\acute{\mbox{ы}}$х рядов.&#10;Второй классификатор~$a_2$~--- One-vs-One SVM с~RBF-яд\-ром &#10;и~параметрами $C\hm=100$ и~$\gamma\hm=0{,}017$~--- &#10;классификатор в~пространстве гиперпараметров, описанный в~предыду\-щем эксперименте.&#10;&#10;Итоговый классификатор выглядит следующим образом:&#10;\begin{equation}&#10;\label{eq:final_classifier}&#10;a(x)=\begin{cases}&#10;a_1(x), &amp;amp;\ a_1(x)\in\{11, 12\}\,;\\&#10;a_2(x)\ &amp;amp;\ \mbox{иначе}\,.&#10;\end{cases}&#10;\end{equation}&#10;&#10;&#10;\paragraph*{Результаты.}&#10;На диаграмме рис.~5 и~в~табл.~5 демонстрируется качество &#10;классификации построенного классификатора~\eqref{eq:final_classifier} &#10;при усреднении по $r\hm=500$ случайным разбиениям исходной выборки на тес\-то\-вую &#10;и~контрольную в~отношении~7 к~3.&#10;&#10;\pagebreak&#10;&#10;\end{multicols}&#10;&#10;\begin{figure*} %fig5&#10;\vspace*{1pt}&#10;\begin{center}&#10;\mbox{%&#10;\epsfxsize=128.626mm&#10;\epsfbox{kar-5.eps}&#10;}&#10;\end{center}&#10;\vspace*{-9pt}&#10;\Caption{Точность классификации для гиперпараметров в~качестве признаковых описаний.&#10;Набор данных USC-HAD}&#10;\label{fig:hyperparams}&#10;\end{figure*}&#10;&#10;&#10;\begin{table*}\small %tabl5&#10;\begin{center}&#10;\parbox{380pt}{\Caption{Усредненная матрица неточностей. Признаки~--- гиперпараметры. Набор данных&#10;USC-HAD}&#10;&#10;}&#10;\label{tbl:hyperparams_confusion}&#10;\vspace*{2ex}&#10;&#10;\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}&#10;  \hline&#10;Класс &amp;amp; \multicolumn{12}{c|}{Предсказанный класс} \\ &#10;\cline{2-13}&#10;объекта &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8&amp;amp; 9 &amp;amp; 10 &amp;amp; 11 &amp;amp; 12\\ &#10;\hline&#10; 1 &amp;amp; \textbf{1{,}00} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 2 &amp;amp; 0,01 &amp;amp; \textbf{0,98} &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 3 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0{,}99} &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 4 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0{,}99} &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 5 &amp;amp; 0,01 &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0{,}97} &amp;amp; 0,01 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 6 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{1{,}00} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 7 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0{,}99} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 8 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0{,}93} &amp;amp; 0,06 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\&#10; 9 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,03 &amp;amp; \textbf{0{,}97} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00\\&#10; 10\hphantom{9} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{1{,}00} &amp;amp; 0,00 &amp;amp; 0,00\\ &#10; 11\hphantom{9} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; \textbf{0{,}99} &amp;amp; 0,00\\&#10; 12\hphantom{9} &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,00 &amp;amp; 0,02 &amp;amp; 0,00 &amp;amp; 0,01 &amp;amp; &#10; \textbf{0{,}97}\\&#10; \hline&#10;\end{tabular}&#10;\end{center}&#10;\end{table*}&#10;&#10;\begin{multicols}{2}&#10;&#10;\section{Заключение}&#10;&#10;В работе показано, что метод признакового описания временн$\acute{\mbox{о}}$го &#10;ряда оптимальными параметрами аппроксимирующих его моделей дает высокое &#10;качество решения задачи классификации.&#10;Предложенный метод вычислительно эффективен и~не требователен к~памяти &#10;вычислительного устройства.&#10;&#10;В~работе также предложен алгоритм классификации временн$\acute{\mbox{ы}}$х рядов в~пространстве &#10;распределений параметров моделей, порождающих их\linebreak сегменты. &#10;Он обобщает предыдущий метод классификации временн$\acute{\mbox{ы}}$х рядов и~позволяет &#10;производить более тонкую настройку алгоритма клас\-си\-фи\-кации.&#10;{ %\looseness=1&#10;&#10;}&#10;&#10;{\small\frenchspacing&#10; {%\baselineskip=10.8pt&#10; \addcontentsline{toc}{section}{References}&#10; \begin{thebibliography}{99}&#10;\bibitem{geurts2005segment}&#10;\Au{Geurts~P., Wehenkel~L.}&#10; Segment and combine approach for non-parametric time-series classification~//&#10;{Knowledge discovery in databases: PKDD 2005}.~--- Berlin--Heidelberg: Springer, 2005. &#10;P.~478--485.&#10;&#10;\bibitem{Esling:2012:TDM:2379776.2379788}&#10;\Au{Esling~P., Agon~C.}&#10;Time-series data mining~//&#10;\newblock {ACM Comput. Surv.}, 2012. Vol.~45. No.\,1. Article~12. P.~1--34.&#10;&#10;\bibitem{basil2014automatic}&#10;\Au{Basil~T., Lakshminarayan~C.}&#10;Automatic classification of heartbeats~//&#10;{22nd European Signal Processing Conference Proceedings}, 2014. P.~1542--1546.&#10;&#10;\bibitem{alomari2013automated}&#10;\Au{Alomari~M.\,H., Samaha~A., AlKamha~K.}&#10; Automated classification of l/r hand movement eeg signals using advanced &#10; feature extraction and machine learning~//&#10;{Int. J.~Adv. Comput. Sci. Appl.}, 2013. Vol.~4. No.\,6. P.~207--212.&#10;&#10;\bibitem{Kwapisz:2011:ARU:1964897.1964918}&#10;\Au{Kwapisz~J.\,R., Weiss~G.\,M., Moore~S.\,A.}&#10;Activity recognition using cell phone accelerometers~//&#10;{ACM SigKDD Explorations Newsletter}, 2011. Vol.~12. No.\,2. P.~74--82.&#10;&#10;\bibitem{gruber2006signature}&#10;\Au{Gruber~C., Coduro~M., Sick~B.}&#10; Signature verification with dynamic rbf networks and time series motifs~//&#10;{10th  Workshop (International) on Frontiers in Handwriting Recognition}.&#10; La Baule, 2006. &#10;P.~455--460.&#10;&#10;\bibitem{Ding:2008:QMT:1454159.1454226}&#10;\Au{Ding~H., Trajcevski~G., Scheuermann~P., Wang~X., Keogh~E.}&#10;Querying and mining of time series data: Experimental comparison of representations and distance measures~//&#10;{Proc. VLDB Endow}, 2008. Vol.~1. No.\,2. P.~1542--1552.&#10; doi:10.14778/1454159.1454226.&#10;&#10;\bibitem{jeong2011weighted}&#10;\Au{Jeong~Y.\,S., Jeong~M.\,K., Omitaomu~O.\,A.}&#10;Weighted dynamic time warping for time series classification~//&#10;{Pattern Recogn.}, 2011. Vol.~44. No.\,9. P.~2231--2240.&#10;doi:10.1016/j.patcog.2010.09.022.&#10;&#10;\bibitem{Nanopoulos01feature-basedclassification}&#10;\Au{Nanopoulos~A., Alcock~R., Manolopoulos~Y.}&#10;Feature-based classification of time-series data~//&#10;{Int. J.~Comput. Res.}, 2001. Vol.~10. P.~49--61.&#10;&#10;\bibitem{wiens2012patient}&#10;\Au{Wiens~J., Horvitz~E., Guttag~J.\,V.}&#10;Patient risk stratification for hospital-associated c. diff as a time-series classification task~//&#10;{Adv. Neur. Inform. Proc. Syst.}, 2012. Vol.~25. P.~467--475.&#10;&#10;\bibitem{morchen2003time}&#10;\Au{M$"/>
            <command value="\ddot">
              <braces>
                <braces>
                  <text value="{}"/>
                  <command value="\mbox">
                    <braces>
                      <braces>
                        <text value="{}"/>
                        <text value="o"/>
                      </braces>
                    </braces>
                    <braces/>
                    <braces/>
                  </command>
                  <formula id="id4" value="$rchen~F.}&#10; Time series feature extraction for data mining using dwt and dft,&#10; 2003. Unpubl.&#10;&#10;\bibitem{kini2013large}&#10;\Au{Kini~B.\,V., Sekhar~C.\,C.}&#10; Large margin mixture of ar models for time series classification~//&#10;{Appl. Soft Comp.}, 2013. Vol.~13. No.\,1. P.~361--371.&#10;&#10;\bibitem{kuznetsov2015description}&#10;\Au{Кузнецов М.\,П., Ивкин Н.\,П.}&#10; Алгоритм классификации временных рядов акселерометра по комбинированному признаковому описанию~//&#10; {Машинное обучение и~анализ данных}, 2015. Т.~1. №\,11. С.~1471--1483.&#10;&#10;\bibitem{mi12:ubicomp-sagaware}&#10;\Au{Zhang~M., Sawchuk~A.\,A.}&#10; USC-HAD: A~daily activity dataset for ubiquitous activity recognition &#10; using wearable sensors~//&#10; {ACM Conference (International) on Ubiquitous Computing Workshop on Situation, &#10; Activity and Goal Awareness}.~--- Pittsburgh, PA, USA, 2012.&#10; \end{thebibliography}&#10;&#10; }&#10; }&#10;&#10;\end{multicols}&#10;&#10;%\vspace*{-6pt}&#10;&#10;\hfill{\small\textit{Поступила в~редакцию 10.05.16}}&#10;&#10;\vspace*{14pt}&#10;&#10;%\newpage&#10;&#10;%\vspace*{-24pt}&#10;&#10;\hrule&#10;&#10;\vspace*{2pt}&#10;&#10;\hrule&#10;&#10;\vspace*{8pt}&#10;&#10;&#10;\def\tit{FEATURE-BASED TIME-SERIES CLASSIFICATION}&#10;&#10;\def\titkol{Feature-based time-series classification}&#10;&#10;\def\aut{M.\,E.~Karasikov$^{1,2}$ and V.\,V.~Strijov$^3$}&#10;&#10;\def\autkol{M.\,E.~Karasikov and V.\,V.~Strijov}&#10;&#10;\titel{\tit}{\aut}{\autkol}{\titkol}&#10;&#10;\vspace*{-9pt}&#10;&#10;&#10;    &#10;\noindent&#10;   $^1$Moscow Institute of Physics and Technology,&#10;    9~Institutskiy Per., &#10;Dolgoprudny, Moscow Region 141700, Russian\linebreak&#10;$\hphantom{^1}$Federation&#10;    &#10;\noindent&#10;$^2$Skolkovo Institute of Science and Technology, Skolkovo Innovation Center,&#10;Building~3, Moscow 143016, Russian\linebreak&#10;$\hphantom{^1}$Federation&#10;&#10;\noindent&#10;$^3$A.\,A.~Dorodnicyn Computing Center, &#10;Federal Research Center ``Computer Science and Control&amp;apos;&amp;apos; &#10;of the Russian\linebreak&#10;$\hphantom{^1}$Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, &#10;Russian Federation&#10;&#10;&#10;&#10;\def\leftfootline{\small{\textbf{\thepage}&#10;\hfill INFORMATIKA I EE PRIMENENIYA~--- INFORMATICS AND&#10;APPLICATIONS\ \ \ 2016\ \ \ volume~10\ \ \ issue\ 4}&#10;}%&#10; \def\rightfootline{\small{INFORMATIKA I EE PRIMENENIYA~---&#10;INFORMATICS AND APPLICATIONS\ \ \ 2016\ \ \ volume~10\ \ \ issue\ 4&#10;\hfill \textbf{\thepage}}}&#10;&#10;\vspace*{3pt}&#10;&#10;&#10;     &#10;\Abste{The paper is devoted to the multiclass time series classification problem.&#10;The feature-based approach that uses meaningful and concise representations for feature space construction is applied.&#10;    A~time series is considered as a sequence of segments &#10;    approximated by parametric models, and their parameters are used as time series &#10;    features.&#10;        This feature construction method inherits from the&#10;        approximation model such unique properties as shift invariance.&#10;    The authors propose an approach to solve the time series classification problem &#10;    using distributions of parameters of the approximation model.&#10;    The proposed approach is applied to the human activity classification problem.&#10;    The computational experiments on real data demonstrate superiority of&#10;    the proposed algorithm over baseline solutions.}&#10;&#10;\KWE{time series; multiclass classification; time series segmentation; hyperparameters of approximation model; autoregressive model; discrete Fourier transform}&#10;&#10;\DOI{10.14357/19922264160413} &#10;&#10;&#10;%\vspace*{-9pt}&#10;&#10;\Ack&#10;\noindent&#10;The work was supported by the Russian Foundation for Basic Research &#10;(project 16-37-00485).&#10;&#10;\pagebreak&#10;&#10;%\vspace*{3pt}&#10;&#10;  \begin{multicols}{2}&#10;&#10;\renewcommand{\bibname}{\protect\rmfamily References}&#10;%\renewcommand{\bibname}{\large\protect\rm References}&#10;&#10;{\small\frenchspacing&#10; {%\baselineskip=10.8pt&#10; \addcontentsline{toc}{section}{References}&#10; \begin{thebibliography}{99}&#10;&#10;\bibitem{geurts2005segment-1}&#10;\Aue{Geurts,~P., and L.~Wehenkel}.&#10;2005.&#10; Segment and combine approach for non-parametric time-series classification.&#10;\textit{Knowledge Discovery in Databases: PKDD 2005}. &#10;Berlin--Heidelberg: Springer. 478--485.&#10;&#10;\bibitem{Esling:2012:TDM:2379776.23797880-1}&#10;\Aue{Esling,~P., and C.~Agon}.&#10;2012.&#10;Time-series data mining.&#10;\textit{ACM Comput. Surv}. 45(1):12:1--12:34.&#10;&#10;\bibitem{basil2014automatic-1}&#10;\Aue{Basil,~T., and C.~Lakshminarayan}.&#10;2014.&#10;Automatic classification of heartbeats.&#10;\textit{22nd European Signal Processing Conference Proceedings}. 1542--1546.&#10;&#10;\bibitem{alomari2013automated-1}&#10;\Aue{Alomari,~M.\,H., A.~Samaha, and K.~AlKamha}.&#10;2013.&#10;Automated classification of l/r hand movement eeg signals using advanced feature extraction and machine learning.&#10;\textit{Int. J.~Adv. Comput. Sci. Appl.} 4(6):207--212.&#10;&#10;\bibitem{Kwapisz:2011:ARU:1964897.1964918-1}&#10;\Aue{Kwapisz,~J.\,R., G.\,M.~Weiss, and S.\,A.~Moore}.&#10;2011.&#10;Activity recognition using cell phone accelerometers.&#10;\textit{ACM SigKDD Explorations Newsletter} 12(2):74--82.&#10;&#10;\bibitem{gruber2006signature-1}&#10;\Aue{Gruber,~C., M.~Coduro, and B.~Sick}.&#10;2006.&#10; Signature verification with dynamic rbf networks and time series motifs.&#10;\textit{10th  Workshop (International) on Frontiers in Handwriting Recognition}.&#10; La Baule. 455-460.&#10;&#10;\bibitem{Ding:2008:QMT:1454159.1454226-1}&#10;\Aue{Ding,~H., G.~Trajcevski, P.~Scheuermann, X.~Wang, and E.~Keogh}.&#10;2008.&#10; Querying and mining of time series data: Experimental comparison of &#10; representations and distance measures.&#10;\textit{Proc. VLDB Endow} 1(2):1542--1552.&#10; doi: 10.14778/1454159.1454226.&#10;&#10;\bibitem{jeong2011weighted-1}&#10;\Aue{Jeong,~Y.\,S., M.\,K.~Jeong, and O.\,A.~Omitaomu}.&#10;2011.&#10; Weighted dynamic time warping for time series classification.&#10;\textit{Pattern Recogn.}. 44(9):2231--2240.&#10;doi: 10.1016/j.patcog.2010.09.022.&#10;&#10;\bibitem{Nanopoulos01feature-basedclassification-1}&#10;\Aue{Nanopoulos,~A., R.~Alcock, and Y.~Manolopoulos}.&#10;2001.&#10;Feature-based classification of time-series data.&#10;\textit{Int. J.~Comput. Res.} 10:49--61.&#10;&#10;\bibitem{wiens2012patient-1}&#10;\Aue{Wiens,~J., E.~Horvitz, and J.\,V.~Guttag.}&#10;2012.&#10;Patient risk stratification for hospital-associated c. diff as a time-series classification task.&#10;\textit{Adv. Neur. Inform. Proc. Syst.} 25:467--475.&#10;&#10;\bibitem{morchen2003time-1}&#10;\Aue{M$"/>
                  <command value="\ddot">
                    <braces>
                      <braces>
                        <text value="{}"/>
                        <command value="\mbox">
                          <braces>
                            <braces>
                              <text value="{}"/>
                              <text value="o"/>
                            </braces>
                          </braces>
                          <braces/>
                          <braces/>
                        </command>
                        <formula id="id5" value="$rchen,~F.}&#10;2003.&#10;Time series feature extraction for data mining using dwt and dft.&#10;Unpubl.&#10;&#10;\bibitem{kini2013large-1}&#10;\Aue{Kini,~B.\,V., and C.\,C.~Sekhar}.&#10;2013.&#10; Large margin mixture of ar models for time series classification.&#10;\textit{Appl. Soft Comp.} 13(1):361--371.&#10;&#10;\bibitem{kuznetsov2015description-1}&#10;\Au{Kuznetsov,~M.\,P., and N.\,P.~Ivkin.}&#10;2015.&#10;Algoritm klassifikatsii vremennykh ryadov akselerometra po kombinirovannomu &#10;priznakovomu opisaniyu [Time series classification algorithm using combined feature description].&#10;\textit{Mashinnoe obuchenie i~analiz dannykh} [Machine Learning and Data Analysis]&#10; 1(11):1471--1483.&#10;&#10;\bibitem{mi12:ubicomp-sagaware-1}&#10;\Aue{Zhang,~M., and A.\,A.~Sawchuk.}&#10;2012.&#10;USC-HAD: A~daily activity dataset for ubiquitous activity recognition&#10;  using wearable sensors.&#10;\textit{ACM Conference (International)&#10;on Ubiquitous Computing Workshop on Situation, Activity and Goal Awareness}. &#10;Pittsburgh, PA.&#10;\end{thebibliography}&#10;&#10; }&#10; }&#10;&#10;\end{multicols}&#10;&#10;\vspace*{-3pt}&#10;&#10;\hfill{\small\textit{Received May 10, 2016}}&#10;&#10;&#10;\Contr&#10;&#10;\noindent&#10;\textbf{Karasikov Mikhail E.} (b.\ 1992)~--- &#10;student, Moscow Institute of Physics and Technology, 9~Institutskiy Per., &#10;Dolgoprudny, Moscow Region 141700, Russian Federation;  &#10;student, Skolkovo Institute of Science and Technology, Skolkovo Innovation Center,&#10;Building~3, Moscow 143016, Russian Federation; \mbox{karasikov@phystech.edu}&#10;&#10;\vspace*{3pt}&#10;&#10;\noindent&#10;\textbf{Strijov Vadim V.} (b.\ 1967)~--- &#10;Doctor of Science in physics and mathematics, leading scientist, &#10;A.\,A.~Dorodnicyn Computing Center, Federal Research Center ``Computer Science and Control&amp;apos;&amp;apos; &#10;of the Russian Academy of Sciences, 44-2~Vavilov Str., Moscow 119333, &#10;Russian Federation; \mbox{strijov@ccas.ru}&#10;\label{end\stat}&#10;&#10;&#10;\renewcommand{\bibname}{\protect\rm Литература} "/>
                      </braces>
                    </braces>
                  </command>
                </braces>
              </braces>
            </command>
          </braces>
        </braces>
      </command>
    </fulltext>
  </paper>
</papers>