{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Лексический анализатор1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(TokenType.COMMAND, '\\\\documentclass', line=2, col=1)\n",
      "Token(TokenType.LBRACE, '{', line=2, col=15)\n",
      "Token(TokenType.TEXT, 'article', line=2, col=16)\n",
      "Token(TokenType.RBRACE, '}', line=2, col=23)\n",
      "Token(TokenType.COMMAND, '\\\\begin', line=3, col=1)\n",
      "Token(TokenType.SECTION, '\\\\section', line=4, col=1)\n",
      "Token(TokenType.LBRACE, '{', line=4, col=9)\n",
      "Token(TokenType.TEXT, 'Introduction', line=4, col=10)\n",
      "Token(TokenType.RBRACE, '}', line=4, col=22)\n",
      "Token(TokenType.TEXT, 'This is a test document with ', line=5, col=1)\n",
      "Token(TokenType.COMMENT, ' комментарий', line=5, col=30)\n",
      "Token(TokenType.TEXT, 'some ', line=6, col=1)\n",
      "Token(TokenType.COMMAND, '\\\\textit', line=6, col=6)\n",
      "Token(TokenType.LBRACE, '{', line=6, col=13)\n",
      "Token(TokenType.TEXT, 'formatted', line=6, col=14)\n",
      "Token(TokenType.RBRACE, '}', line=6, col=23)\n",
      "Token(TokenType.TEXT, 'text and a ', line=6, col=25)\n",
      "Token(TokenType.COMMAND, '\\\\textbf', line=6, col=36)\n",
      "Token(TokenType.LBRACE, '{', line=6, col=43)\n",
      "Token(TokenType.TEXT, 'command', line=6, col=44)\n",
      "Token(TokenType.RBRACE, '}', line=6, col=51)\n",
      "Token(TokenType.TEXT, '.\\n\\n', line=8, col=-2)\n",
      "Token(TokenType.BEGIN_FIGURE, '\\\\begin{figure}', line=8, col=1)\n",
      "Token(TokenType.COMMAND, '\\\\caption', line=9, col=5)\n",
      "Token(TokenType.LBRACE, '{', line=9, col=13)\n",
      "Token(TokenType.TEXT, 'A figure', line=9, col=14)\n",
      "Token(TokenType.RBRACE, '}', line=9, col=22)\n",
      "Token(TokenType.END_FIGURE, '\\\\end{figure}', line=10, col=1)\n",
      "Token(TokenType.BEGIN_BIBLIO, '\\\\begin{thebibliography}', line=12, col=1)\n",
      "Token(TokenType.LBRACE, '{', line=12, col=24)\n",
      "Token(TokenType.TEXT, '9', line=12, col=25)\n",
      "Token(TokenType.RBRACE, '}', line=12, col=26)\n",
      "Token(TokenType.BIBITEM, '\\\\bibitem', line=13, col=1)\n",
      "Token(TokenType.LBRACE, '{', line=13, col=9)\n",
      "Token(TokenType.TEXT, 'key1', line=13, col=10)\n",
      "Token(TokenType.RBRACE, '}', line=13, col=14)\n",
      "Token(TokenType.TEXT, 'Author, Title\\n', line=14, col=-13)\n",
      "Token(TokenType.END_BIBLIO, '\\\\end{thebibliography}', line=14, col=1)\n",
      "Token(TokenType.COMMAND, '\\\\end', line=15, col=1)\n",
      "Token(TokenType.EOF, '', line=16, col=1)\n"
     ]
    }
   ],
   "source": [
    "#Лексический анализатор2 \n",
    "import re\n",
    "from enum import Enum, auto\n",
    "\n",
    "class TokenType(Enum):\n",
    "    COMMAND = auto()          # \\command\n",
    "    SECTION = auto()          # \\section\n",
    "    BEGIN = auto()            # \\begin\n",
    "    END = auto()              # \\end\n",
    "    BEGIN_FIGURE = auto()     # \\begin{figure}\n",
    "    END_FIGURE = auto()       # \\end{figure}\n",
    "    BEGIN_BIBLIO = auto()     # \\begin{thebibliography}\n",
    "    END_BIBLIO = auto()       # \\end{thebibliography}\n",
    "    BIBITEM = auto()          # \\bibitem\n",
    "    LBRACE = auto()           # {\n",
    "    RBRACE = auto()           # }\n",
    "    LBRACKET = auto()         # [\n",
    "    RBRACKET = auto()         # ]\n",
    "    TEXT = auto()             # обычный текст\n",
    "    COMMENT = auto()          # % комментарий\n",
    "    ESCAPED = auto()          # \\%\n",
    "    KEY = auto()              # ключ в bibitem\n",
    "    EOF = auto()              # конец файла\n",
    "\n",
    "class Token:\n",
    "    def __init__(self, type: TokenType, value: str = '', line: int = 0, col: int = 0):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.line = line\n",
    "        self.col = col\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Token({self.type}, {repr(self.value)}, line={self.line}, col={self.col})'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "class Lexer:\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "        self.pos = 0\n",
    "        self.line = 1\n",
    "        self.col = 1\n",
    "        self.current_char = self.text[0] if self.text else None\n",
    "    \n",
    "    def error(self, message):\n",
    "        raise Exception(f'Lexer error at line {self.line}, col {self.col}: {message}')\n",
    "    \n",
    "    def advance(self):\n",
    "        if self.current_char == '\\n':\n",
    "            self.line += 1\n",
    "            self.col = 1\n",
    "        else:\n",
    "            self.col += 1\n",
    "        \n",
    "        self.pos += 1\n",
    "        if self.pos >= len(self.text):\n",
    "            self.current_char = None\n",
    "        else:\n",
    "            self.current_char = self.text[self.pos]\n",
    "    \n",
    "    def skip_whitespace(self):\n",
    "        while self.current_char is not None and self.current_char.isspace():\n",
    "            self.advance()\n",
    "    \n",
    "    def get_text(self):\n",
    "        result = []\n",
    "        while (self.current_char is not None and \n",
    "               self.current_char not in ['\\\\', '{', '}', '[', ']', '%']):\n",
    "            result.append(self.current_char)\n",
    "            self.advance()\n",
    "        return ''.join(result)\n",
    "    \n",
    "    def get_comment(self):\n",
    "        result = []\n",
    "        while self.current_char is not None and self.current_char != '\\n':\n",
    "            result.append(self.current_char)\n",
    "            self.advance()\n",
    "        return ''.join(result)\n",
    "    \n",
    "    def get_command_name(self):\n",
    "        result = []\n",
    "        # Команда может состоять из букв или одного спецсимвола\n",
    "        if self.current_char and (self.current_char.isalpha() or self.current_char in ['@', '*', '_']):\n",
    "            result.append(self.current_char)\n",
    "            self.advance()\n",
    "            while self.current_char and self.current_char.isalpha():\n",
    "                result.append(self.current_char)\n",
    "                self.advance()\n",
    "        return ''.join(result)\n",
    "    \n",
    "    def get_key(self):\n",
    "        result = []\n",
    "        while self.current_char and (self.current_char.isalnum() or self.current_char in ['-', '_', ':']):\n",
    "            result.append(self.current_char)\n",
    "            self.advance()\n",
    "        return ''.join(result)\n",
    "    \n",
    "    def get_next_token(self):\n",
    "        while self.current_char is not None:\n",
    "            if self.current_char.isspace():\n",
    "                self.skip_whitespace()\n",
    "                continue\n",
    "            \n",
    "            # Комментарии\n",
    "            if self.current_char == '%':\n",
    "                start_line = self.line\n",
    "                start_col = self.col\n",
    "                self.advance()\n",
    "                comment = self.get_comment()\n",
    "                return Token(TokenType.COMMENT, comment, start_line, start_col)\n",
    "            \n",
    "            # Экранированные символы\n",
    "            if self.current_char == '\\\\':\n",
    "                # Проверяем, не является ли это командой\n",
    "                start_pos = self.pos\n",
    "                start_line = self.line\n",
    "                start_col = self.col\n",
    "                self.advance()\n",
    "                \n",
    "                if self.current_char is None:\n",
    "                    return Token(TokenType.ESCAPED, '\\\\', start_line, start_col)\n",
    "                \n",
    "                # Команды \\begin, \\end, \\section, \\bibitem\n",
    "                if self.current_char.isalpha():\n",
    "                    command = self.get_command_name()\n",
    "                    full_cmd = '\\\\' + command\n",
    "                    \n",
    "                    if full_cmd == '\\\\begin':\n",
    "                        # Проверяем следующий аргумент\n",
    "                        self.skip_whitespace()\n",
    "                        if self.current_char == '{':\n",
    "                            self.advance()\n",
    "                            env = self.get_text()\n",
    "                            if self.current_char == '}':\n",
    "                                self.advance()\n",
    "                                if env == 'figure':\n",
    "                                    return Token(TokenType.BEGIN_FIGURE, full_cmd + '{figure}', start_line, start_col)\n",
    "                                elif env == 'thebibliography':\n",
    "                                    return Token(TokenType.BEGIN_BIBLIO, full_cmd + '{thebibliography}', start_line, start_col)\n",
    "                    \n",
    "                    elif full_cmd == '\\\\end':\n",
    "                        # Аналогично для \\end\n",
    "                        self.skip_whitespace()\n",
    "                        if self.current_char == '{':\n",
    "                            self.advance()\n",
    "                            env = self.get_text()\n",
    "                            if self.current_char == '}':\n",
    "                                self.advance()\n",
    "                                if env == 'figure':\n",
    "                                    return Token(TokenType.END_FIGURE, full_cmd + '{figure}', start_line, start_col)\n",
    "                                elif env == 'thebibliography':\n",
    "                                    return Token(TokenType.END_BIBLIO, full_cmd + '{thebibliography}', start_line, start_col)\n",
    "                    \n",
    "                    elif full_cmd == '\\\\section':\n",
    "                        return Token(TokenType.SECTION, full_cmd, start_line, start_col)\n",
    "                    \n",
    "                    elif full_cmd == '\\\\bibitem':\n",
    "                        return Token(TokenType.BIBITEM, full_cmd, start_line, start_col)\n",
    "                    \n",
    "                    # Обычная команда\n",
    "                    return Token(TokenType.COMMAND, full_cmd, start_line, start_col)\n",
    "                \n",
    "                else:\n",
    "                    # Экранированный символ\n",
    "                    char = self.current_char\n",
    "                    self.advance()\n",
    "                    return Token(TokenType.ESCAPED, '\\\\' + char, start_line, start_col)\n",
    "            \n",
    "            # Скобки и аргументы\n",
    "            if self.current_char == '{':\n",
    "                self.advance()\n",
    "                return Token(TokenType.LBRACE, '{', self.line, self.col-1)\n",
    "            \n",
    "            if self.current_char == '}':\n",
    "                self.advance()\n",
    "                return Token(TokenType.RBRACE, '}', self.line, self.col-1)\n",
    "            \n",
    "            if self.current_char == '[':\n",
    "                self.advance()\n",
    "                return Token(TokenType.LBRACKET, '[', self.line, self.col-1)\n",
    "            \n",
    "            if self.current_char == ']':\n",
    "                self.advance()\n",
    "                return Token(TokenType.RBRACKET, ']', self.line, self.col-1)\n",
    "            \n",
    "            # Обычный текст\n",
    "            text = self.get_text()\n",
    "            if text:\n",
    "                return Token(TokenType.TEXT, text, self.line, self.col-len(text))\n",
    "            \n",
    "            self.error(f\"Unexpected character: {self.current_char}\")\n",
    "        \n",
    "        return Token(TokenType.EOF, '', self.line, self.col)\n",
    "\n",
    "# Пример использования\n",
    "def tokenize_latex(text):\n",
    "    lexer = Lexer(text)\n",
    "    tokens = []\n",
    "    while True:\n",
    "        token = lexer.get_next_token()\n",
    "        tokens.append(token)\n",
    "        if token.type == TokenType.EOF:\n",
    "            break\n",
    "    return tokens\n",
    "\n",
    "# Тестовый пример\n",
    "if __name__ == \"__main__\":\n",
    "    test_text = r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\begin{document}\n",
    "\\section{Introduction}\n",
    "This is a test document with % комментарий\n",
    "some \\textit{formatted} text and a \\textbf{command}.\n",
    "\n",
    "\\begin{figure}\n",
    "    \\caption{A figure}\n",
    "\\end{figure}\n",
    "\n",
    "\\begin{thebibliography}{9}\n",
    "\\bibitem{key1} Author, Title\n",
    "\\end{thebibliography}\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "    \n",
    "    tokens = tokenize_latex(test_text)\n",
    "    for token in tokens:\n",
    "        print(token)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6a51a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
